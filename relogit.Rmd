## Rare Events Logit


$$
\pi_i = \frac{1}{1 + \exp(-X \beta)}
$$

Prior correction: p. 144
$$
\beta_0 - \ln \left(\frac{1 - \tau}{\tau} \frac{\bar{y}}{1 - \bar{y}} \right)
$$

Weighting:

- ones are weighted by $\tau / \bar{y}$
- zeros are weighted by $(1 - \tau) / \bar{1 - \bar{y}}$

The log likelihood would then be
$$
\ln L_w(\beta | y) = w_1 \sum_{Y_i = 1} \ln (\pi_i) + w_0 \sum_{Y_i = 0} \ln (1 - \pi_i)
$$

Bias correcting:

Firth's / Jeffrey's Likelihood:

The penalized log probability is
$$
\ln L(\beta | Y)^* = \ln L(\beta | Y) + 0.5 \ln |I(\beta)|
$$
where $I(\beta)$ is the information matrix,
$$
I(\beta) = X'WX
$$
and
$$
W = \diag(\pi (1 - \pi))
$$

In Stan this could be implemented by 
```
transformed paramters {

}
model {
  target += 0.5 * log_det()
}

```

- Andrew Gelman. Nov 5, 2014. "The Firth bias correction, penalization, and weakly informative priors: A case for log-F priors in logistic and related regressions‚Äù [LINK](http://andrewgelman.com/2014/11/05/firth-bias-correction-penalization-weakly-informative-priors-case-log-f-priors-logistic-related-regressions/)
- http://lib.ugent.be/fulltxt/RUG01/002/163/708/RUG01-002163708_2014_0001_AC.pdf

## Sampling on the Dependent Variable



## 
