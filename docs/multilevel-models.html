<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Updating: A Set of Bayesian Notes</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Updating: A Set of Bayesian Notes">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Updating: A Set of Bayesian Notes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jrnold.github.io/bayesian_notes" />
  
  
  <meta name="github-repo" content="jrnold/bayesian_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Updating: A Set of Bayesian Notes" />
  <meta name="twitter:site" content="@jrnld" />
  
  

<meta name="author" content="Jeffrey B. Arnold">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="hierarchical-models.html">
<link rel="next" href="notes.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>

\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\median}{median}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\logistic}{Logistic}
\DeclareMathOperator{\logit}{Logit}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

% This follows BDA
\newcommand{\dunif}{\mathrm{U}}
\newcommand{\dnorm}{\mathrm{N}}
\newcommand{\dlnorm}{\mathrm{lognormal}}
\newcommand{\dmvnorm}{\mathrm{N}}
\newcommand{\dgamma}{\mathrm{Gamma}}
\newcommand{\dinvgamma}{\mathrm{Inv-Gamma}}
\newcommand{\dchisq}[1]{\chi^2_{#1}}
\newcommand{\dinvchisq}[1]{\mathrm{Inv-}\chi^2_{#1}}
\newcommand{\dexp}{\mathrm{Expon}}
\newcommand{\dlaplace}{\mathrm{Laplace}}
\newcommand{\dweibull}{\mathrm{Weibull}}
\newcommand{\dwishart}[1]{\mathrm{Wishart}_{#1}}
\newcommand{\dinvwishart}[1]{\mathrm{Inv-Wishart}_{#1}}
\newcommand{\dlkj}{\mathrm{LkjCorr}}
\newcommand{\dt}[1]{t_{#1}}
\newcommand{\dbeta}{\mathrm{Beta}}
\newcommand{\ddirichlet}{\mathrm{Dirichlet}}
\newcommand{\dlogistic}{\mathrm{Logistic}}
\newcommand{\dllogistic}{\mathrm{Log-logistic}}
\newcommand{\dpois}{\mathrm{Poisson}}
\newcommand{\dbin}{\mathrm{Bin}}
\newcommand{\dmultinom}{\mathrm{Multinom}}
\newcommand{\dnbinom}{\mathrm{Neg-bin}}
\newcommand{\dnbinomalt}{\mathrm{Neg-bin2}}
\newcommand{\dbetabinom}{\mathrm{Beta-bin}}
\newcommand{\dcauchy}{\mathrm{Cauchy}}
\newcommand{\dhalfcauchy}{\mathrm{Cauchy}^{+}}
\newcommand{\dlkjcorr}{\mathrm{LKJ}^{+}}



\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]

  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Bayesian Notes</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Theory</b></span></li>
<li class="chapter" data-level="1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>1</b> Bayesian Inference</a></li>
<li class="part"><span><b>II Computation</b></span></li>
<li class="chapter" data-level="2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>2</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>2.1</b> Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-sampling"><i class="fa fa-check"></i><b>2.2</b> Markov Chain Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#references"><i class="fa fa-check"></i><b>2.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>3</b> MCMC Diagnostics</a><ul>
<li class="chapter" data-level="3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#reparameterize-models"><i class="fa fa-check"></i><b>3.1</b> Reparameterize Models</a></li>
<li class="chapter" data-level="3.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#convergence-diagnostics"><i class="fa fa-check"></i><b>3.2</b> Convergence Diagnostics</a><ul>
<li class="chapter" data-level="3.2.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#potential-scale-reduction-hatr"><i class="fa fa-check"></i><b>3.2.1</b> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</a></li>
<li class="chapter" data-level="3.2.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#references-1"><i class="fa fa-check"></i><b>3.2.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation-effective-sample-size-and-mcse"><i class="fa fa-check"></i><b>3.3</b> Autocorrelation, Effective Sample Size, and MCSE</a><ul>
<li class="chapter" data-level="3.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#effective-sample-size"><i class="fa fa-check"></i><b>3.3.1</b> Effective Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#thinning"><i class="fa fa-check"></i><b>3.4</b> Thinning</a><ul>
<li class="chapter" data-level="3.4.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#traceplots"><i class="fa fa-check"></i><b>3.4.1</b> Traceplots</a></li>
<li class="chapter" data-level="3.4.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#monte-carlo-standard-error-mcse"><i class="fa fa-check"></i><b>3.4.2</b> Monte Carlo Standard Error (MCSE)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#hmc-nut-specific-diagnostics"><i class="fa fa-check"></i><b>3.5</b> HMC-NUT Specific Diagnostics</a><ul>
<li class="chapter" data-level="3.5.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#divergent-transitions"><i class="fa fa-check"></i><b>3.5.1</b> Divergent transitions</a></li>
<li class="chapter" data-level="3.5.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#maximum-treedepth"><i class="fa fa-check"></i><b>3.5.2</b> Maximum Treedepth</a></li>
<li class="chapter" data-level="3.5.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#bayesian-fraction-of-missing-information"><i class="fa fa-check"></i><b>3.5.3</b> Bayesian Fraction of Missing Information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="posterior-inference.html"><a href="posterior-inference.html"><i class="fa fa-check"></i><b>4</b> Posterior Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#prerequisites"><i class="fa fa-check"></i><b>4.1</b> Prerequisites</a></li>
<li class="chapter" data-level="4.2" data-path="posterior-inference.html"><a href="posterior-inference.html#introduction"><i class="fa fa-check"></i><b>4.2</b> Introduction</a></li>
<li class="chapter" data-level="4.3" data-path="posterior-inference.html"><a href="posterior-inference.html#functions-of-the-posterior-distribution"><i class="fa fa-check"></i><b>4.3</b> Functions of the Posterior Distribution</a></li>
<li class="chapter" data-level="4.4" data-path="posterior-inference.html"><a href="posterior-inference.html#marginal-effects"><i class="fa fa-check"></i><b>4.4</b> Marginal Effects</a><ul>
<li class="chapter" data-level="4.4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#example-marginal-effect-plot-for-x"><i class="fa fa-check"></i><b>4.4.1</b> Example: Marginal Effect Plot for X</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>5</b> Model Checking</a><ul>
<li class="chapter" data-level="5.1" data-path="model-checking.html"><a href="model-checking.html#why-check-models"><i class="fa fa-check"></i><b>5.1</b> Why check models?</a></li>
<li class="chapter" data-level="5.2" data-path="model-checking.html"><a href="model-checking.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2</b> Posterior Predictive Checks</a><ul>
<li class="chapter" data-level="5.2.1" data-path="model-checking.html"><a href="model-checking.html#bayesian-p-values"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian p-values</a></li>
<li class="chapter" data-level="5.2.2" data-path="model-checking.html"><a href="model-checking.html#test-quantities"><i class="fa fa-check"></i><b>5.2.2</b> Test quantities</a></li>
<li class="chapter" data-level="5.2.3" data-path="model-checking.html"><a href="model-checking.html#p-values-vs.u-values"><i class="fa fa-check"></i><b>5.2.3</b> p-values vs. u-values</a></li>
<li class="chapter" data-level="5.2.4" data-path="model-checking.html"><a href="model-checking.html#marginal-predictive-checks"><i class="fa fa-check"></i><b>5.2.4</b> Marginal predictive checks</a></li>
<li class="chapter" data-level="5.2.5" data-path="model-checking.html"><a href="model-checking.html#outliers"><i class="fa fa-check"></i><b>5.2.5</b> Outliers</a></li>
<li class="chapter" data-level="5.2.6" data-path="model-checking.html"><a href="model-checking.html#grapical-posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2.6</b> Grapical Posterior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="model-checking.html"><a href="model-checking.html#sources"><i class="fa fa-check"></i><b>5.3</b> Sources</a></li>
</ul></li>
<li class="part"><span><b>III Models</b></span></li>
<li class="chapter" data-level="6" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Introduction to Stan and Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#prerequites"><i class="fa fa-check"></i><b>6.1</b> Prerequites</a></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#the-statistical-model"><i class="fa fa-check"></i><b>6.2</b> The Statistical Model</a><ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling"><i class="fa fa-check"></i><b>6.2.1</b> Sampling</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#convergence-diagnostics-and-model-fit"><i class="fa fa-check"></i><b>6.2.2</b> Convergence Diagnostics and Model Fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html"><i class="fa fa-check"></i><b>7</b> Heteroskedasticity and Robust Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#prerequisites-1"><i class="fa fa-check"></i><b>7.1</b> Prerequisites</a></li>
<li class="chapter" data-level="7.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#linear-regression-with-student-t-distributed-errors"><i class="fa fa-check"></i><b>7.2</b> Linear Regression with Student t distributed errors</a><ul>
<li class="chapter" data-level="7.2.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#double-exponential-laplace-errors"><i class="fa fa-check"></i><b>7.2.1</b> Double Exponential (Laplace) Errors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity"><i class="fa fa-check"></i><b>7.3</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="7.3.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#covariates"><i class="fa fa-check"></i><b>7.3.1</b> Covariates</a></li>
<li class="chapter" data-level="7.3.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#student-t-error"><i class="fa fa-check"></i><b>7.3.2</b> Student-t Error</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#references-2"><i class="fa fa-check"></i><b>7.4</b> References</a><ul>
<li class="chapter" data-level="7.4.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#robust-regression"><i class="fa fa-check"></i><b>7.4.1</b> Robust regression</a></li>
<li class="chapter" data-level="7.4.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity-1"><i class="fa fa-check"></i><b>7.4.2</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="7.4.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#qunatile-regression"><i class="fa fa-check"></i><b>7.4.3</b> Qunatile regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>8</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="8.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#generalized-linear-models-1"><i class="fa fa-check"></i><b>8.1</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="8.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#count-models"><i class="fa fa-check"></i><b>8.2</b> Count Models</a><ul>
<li class="chapter" data-level="8.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson"><i class="fa fa-check"></i><b>8.2.1</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example"><i class="fa fa-check"></i><b>8.3</b> Example</a></li>
<li class="chapter" data-level="8.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#negative-binomial"><i class="fa fa-check"></i><b>8.4</b> Negative Binomial</a><ul>
<li class="chapter" data-level="8.4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-3"><i class="fa fa-check"></i><b>8.4.1</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial-categorical-models"><i class="fa fa-check"></i><b>8.5</b> Multinomial / Categorical Models</a></li>
<li class="chapter" data-level="8.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#gamma-regression"><i class="fa fa-check"></i><b>8.6</b> Gamma Regression</a></li>
<li class="chapter" data-level="8.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#beta-regression"><i class="fa fa-check"></i><b>8.7</b> Beta Regression</a></li>
<li class="chapter" data-level="8.8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#ordered-logistic"><i class="fa fa-check"></i><b>8.8</b> Ordered Logistic</a></li>
<li class="chapter" data-level="8.9" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-4"><i class="fa fa-check"></i><b>8.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="binomial-models.html"><a href="binomial-models.html"><i class="fa fa-check"></i><b>9</b> Binomial Models</a><ul>
<li class="chapter" data-level="9.0.1" data-path="binomial-models.html"><a href="binomial-models.html#link-functions-link-function"><i class="fa fa-check"></i><b>9.0.1</b> Link Functions {link-function}</a></li>
<li class="chapter" data-level="9.0.2" data-path="binomial-models.html"><a href="binomial-models.html#stan"><i class="fa fa-check"></i><b>9.0.2</b> Stan</a></li>
<li class="chapter" data-level="9.0.3" data-path="binomial-models.html"><a href="binomial-models.html#example-vote-turnout"><i class="fa fa-check"></i><b>9.0.3</b> Example: Vote Turnout</a></li>
<li class="chapter" data-level="9.0.4" data-path="binomial-models.html"><a href="binomial-models.html#separation"><i class="fa fa-check"></i><b>9.0.4</b> Separation</a></li>
<li class="chapter" data-level="9.1" data-path="binomial-models.html"><a href="binomial-models.html#rare-events-logit"><i class="fa fa-check"></i><b>9.1</b> Rare Events Logit</a></li>
<li class="chapter" data-level="9.2" data-path="binomial-models.html"><a href="binomial-models.html#case-control"><i class="fa fa-check"></i><b>9.2</b> Case Control</a><ul>
<li class="chapter" data-level="9.2.1" data-path="binomial-models.html"><a href="binomial-models.html#references-6"><i class="fa fa-check"></i><b>9.2.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html"><i class="fa fa-check"></i><b>10</b> Unbounded Count Models</a><ul>
<li class="chapter" data-level="10.1" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#poisson-1"><i class="fa fa-check"></i><b>10.1</b> Poisson</a></li>
<li class="chapter" data-level="10.2" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#negative-binomial-1"><i class="fa fa-check"></i><b>10.2</b> Negative Binomial</a><ul>
<li class="chapter" data-level="10.2.1" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#stan-1"><i class="fa fa-check"></i><b>10.2.1</b> Stan</a></li>
<li class="chapter" data-level="10.2.2" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#example-number-of-number-o"><i class="fa fa-check"></i><b>10.2.2</b> Example: Number of Number o</a></li>
<li class="chapter" data-level="10.2.3" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#references-7"><i class="fa fa-check"></i><b>10.2.3</b> References</a></li>
<li class="chapter" data-level="10.2.4" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#link-functions"><i class="fa fa-check"></i><b>10.2.4</b> Link functions</a></li>
<li class="chapter" data-level="10.2.5" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#stan-2"><i class="fa fa-check"></i><b>10.2.5</b> Stan</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#example-bilateral-sanctions"><i class="fa fa-check"></i><b>10.3</b> Example: Bilateral Sanctions</a></li>
<li class="chapter" data-level="10.4" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#negative-binomial-2"><i class="fa fa-check"></i><b>10.4</b> Negative Binomial</a><ul>
<li class="chapter" data-level="10.4.1" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#example-economic-sanctions-ii-ex-econ-sanctions-2"><i class="fa fa-check"></i><b>10.4.1</b> Example: Economic Sanctions II {ex-econ-sanctions-2}</a></li>
<li class="chapter" data-level="10.4.2" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#references-8"><i class="fa fa-check"></i><b>10.4.2</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="categorical-variables.html"><a href="categorical-variables.html"><i class="fa fa-check"></i><b>11</b> Categorical Variables</a><ul>
<li class="chapter" data-level="11.1" data-path="categorical-variables.html"><a href="categorical-variables.html#example-mexico-vote-choice"><i class="fa fa-check"></i><b>11.1</b> Example: Mexico Vote Choice</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ordered-categorical-outcomes.html"><a href="ordered-categorical-outcomes.html"><i class="fa fa-check"></i><b>12</b> Ordered Categorical Outcomes</a></li>
<li class="chapter" data-level="13" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html"><i class="fa fa-check"></i><b>13</b> Shrinkage and Regularization</a><ul>
<li class="chapter" data-level="13.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#normal-linear-regression-model"><i class="fa fa-check"></i><b>13.1</b> Normal Linear Regression Model</a></li>
<li class="chapter" data-level="13.2" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#penalized-regression"><i class="fa fa-check"></i><b>13.2</b> Penalized Regression</a><ul>
<li class="chapter" data-level="13.2.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#ridge-regression"><i class="fa fa-check"></i><b>13.2.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="13.2.2" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#lasso"><i class="fa fa-check"></i><b>13.2.2</b> Lasso</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#bayesian-shrinkage-priors"><i class="fa fa-check"></i><b>13.3</b> Bayesian Shrinkage Priors</a></li>
<li class="chapter" data-level="13.4" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#differences-between-bayesian-shrinkage-and-penalized-likelihood"><i class="fa fa-check"></i><b>13.4</b> Differences between Bayesian Shrinkage and Penalized Likelihood</a></li>
<li class="chapter" data-level="13.5" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#hierarchical-shrinkage-priors"><i class="fa fa-check"></i><b>13.5</b> Hierarchical Shrinkage Priors</a></li>
<li class="chapter" data-level="13.6" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#example-1"><i class="fa fa-check"></i><b>13.6</b> Example</a><ul>
<li class="chapter" data-level="13.6.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#double-exponential-laplace-prior"><i class="fa fa-check"></i><b>13.6.1</b> Double Exponential (Laplace) Prior</a></li>
<li class="chapter" data-level="13.6.2" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#hierarchical-prior-hs"><i class="fa fa-check"></i><b>13.6.2</b> Hierarchical Prior (HS)</a></li>
<li class="chapter" data-level="13.6.3" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#comparison"><i class="fa fa-check"></i><b>13.6.3</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#shrinkage-parameters"><i class="fa fa-check"></i><b>13.7</b> Shrinkage Parameters</a></li>
<li class="chapter" data-level="13.8" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#choice-of-hyperparameter-on-tau"><i class="fa fa-check"></i><b>13.8</b> Choice of Hyperparameter on <span class="math inline">\(\tau\)</span></a></li>
<li class="chapter" data-level="13.9" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#r-implementations"><i class="fa fa-check"></i><b>13.9</b> R Implementations</a></li>
<li class="chapter" data-level="13.10" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#bayesian-model-averaging"><i class="fa fa-check"></i><b>13.10</b> Bayesian Model Averaging</a><ul>
<li class="chapter" data-level="13.10.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#zellners-g-prior"><i class="fa fa-check"></i><b>13.10.1</b> Zellner’s g-prior</a></li>
</ul></li>
<li class="chapter" data-level="13.11" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#slab-and-spike-priors"><i class="fa fa-check"></i><b>13.11</b> Slab and Spike Priors</a></li>
<li class="chapter" data-level="13.12" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#technical-notes"><i class="fa fa-check"></i><b>13.12</b> Technical Notes</a></li>
<li class="chapter" data-level="13.13" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#multiple-comparisons-and-thresholding-rules"><i class="fa fa-check"></i><b>13.13</b> Multiple Comparisons and Thresholding rules</a></li>
<li class="chapter" data-level="13.14" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#examples-of-applications-of-sensitivity-analysis"><i class="fa fa-check"></i><b>13.14</b> Examples of Applications of Sensitivity Analysis</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>14</b> Hierarchical Models</a><ul>
<li class="chapter" data-level="14.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-baseball-hits"><i class="fa fa-check"></i><b>14.1</b> Example: Baseball Hits</a><ul>
<li class="chapter" data-level="14.1.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#other-examples"><i class="fa fa-check"></i><b>14.1.1</b> Other Examples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>15</b> Multilevel Models</a><ul>
<li class="chapter" data-level="15.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-radon"><i class="fa fa-check"></i><b>15.1</b> Example: Radon</a><ul>
<li class="chapter" data-level="15.1.1" data-path="multilevel-models.html"><a href="multilevel-models.html#data"><i class="fa fa-check"></i><b>15.1.1</b> Data</a></li>
<li class="chapter" data-level="15.1.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercepts-models"><i class="fa fa-check"></i><b>15.1.2</b> Varying Intercepts Models</a></li>
<li class="chapter" data-level="15.1.3" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercept-model"><i class="fa fa-check"></i><b>15.1.3</b> Varying Intercept Model</a></li>
<li class="chapter" data-level="15.1.4" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-slope-model"><i class="fa fa-check"></i><b>15.1.4</b> Varying Slope Model</a></li>
<li class="chapter" data-level="15.1.5" data-path="multilevel-models.html"><a href="multilevel-models.html#group-level-predictors"><i class="fa fa-check"></i><b>15.1.5</b> Group Level Predictors</a></li>
<li class="chapter" data-level="15.1.6" data-path="multilevel-models.html"><a href="multilevel-models.html#lme4"><i class="fa fa-check"></i><b>15.1.6</b> lme4</a></li>
<li class="chapter" data-level="15.1.7" data-path="multilevel-models.html"><a href="multilevel-models.html#rstanarm"><i class="fa fa-check"></i><b>15.1.7</b> rstanarm</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="multilevel-models.html"><a href="multilevel-models.html#pooling-of-hierarchical-parameters"><i class="fa fa-check"></i><b>15.2</b> Pooling of Hierarchical Parameters</a></li>
<li class="chapter" data-level="15.3" data-path="multilevel-models.html"><a href="multilevel-models.html#extensions"><i class="fa fa-check"></i><b>15.3</b> Extensions</a></li>
<li class="chapter" data-level="15.4" data-path="multilevel-models.html"><a href="multilevel-models.html#references-9"><i class="fa fa-check"></i><b>15.4</b> References</a></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span><ul>
<li class="chapter" data-level="15.5" data-path="multilevel-models.html"><a href="multilevel-models.html#parameters"><i class="fa fa-check"></i><b>15.5</b> Parameters</a></li>
<li class="chapter" data-level="15.6" data-path="multilevel-models.html"><a href="multilevel-models.html#miscellaneous-mathematical-background"><i class="fa fa-check"></i><b>15.6</b> Miscellaneous Mathematical Background</a><ul>
<li class="chapter" data-level="15.6.1" data-path="multilevel-models.html"><a href="multilevel-models.html#location-scale-families"><i class="fa fa-check"></i><b>15.6.1</b> Location-Scale Families</a></li>
<li class="chapter" data-level="15.6.2" data-path="multilevel-models.html"><a href="multilevel-models.html#scale-mixtures-of-normal-distributions"><i class="fa fa-check"></i><b>15.6.2</b> Scale Mixtures of Normal Distributions</a></li>
<li class="chapter" data-level="15.6.3" data-path="multilevel-models.html"><a href="multilevel-models.html#covariance-correlation-matrix-decomposition"><i class="fa fa-check"></i><b>15.6.3</b> Covariance-Correlation Matrix Decomposition</a></li>
<li class="chapter" data-level="15.6.4" data-path="multilevel-models.html"><a href="multilevel-models.html#qr-factorization"><i class="fa fa-check"></i><b>15.6.4</b> QR Factorization</a></li>
<li class="chapter" data-level="15.6.5" data-path="multilevel-models.html"><a href="multilevel-models.html#cholesky-decomposition"><i class="fa fa-check"></i><b>15.6.5</b> Cholesky Decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="notes.html"><a href="notes.html"><i class="fa fa-check"></i><b>16</b> Notes</a><ul>
<li class="chapter" data-level="16.1" data-path="notes.html"><a href="notes.html#syllabi"><i class="fa fa-check"></i><b>16.1</b> Syllabi</a></li>
<li class="chapter" data-level="16.2" data-path="notes.html"><a href="notes.html#textbooks"><i class="fa fa-check"></i><b>16.2</b> Textbooks</a></li>
<li class="chapter" data-level="16.3" data-path="notes.html"><a href="notes.html#topics"><i class="fa fa-check"></i><b>16.3</b> Topics</a><ul>
<li class="chapter" data-level="16.3.1" data-path="notes.html"><a href="notes.html#overviews"><i class="fa fa-check"></i><b>16.3.1</b> Overviews</a></li>
<li class="chapter" data-level="16.3.2" data-path="notes.html"><a href="notes.html#bayesian-philosophy"><i class="fa fa-check"></i><b>16.3.2</b> Bayesian Philosophy</a></li>
<li class="chapter" data-level="16.3.3" data-path="notes.html"><a href="notes.html#bayesian-frequentist-debates"><i class="fa fa-check"></i><b>16.3.3</b> Bayesian Frequentist Debates</a></li>
<li class="chapter" data-level="16.3.4" data-path="notes.html"><a href="notes.html#categorical"><i class="fa fa-check"></i><b>16.3.4</b> Categorical</a></li>
<li class="chapter" data-level="16.3.5" data-path="notes.html"><a href="notes.html#identifiability"><i class="fa fa-check"></i><b>16.3.5</b> Identifiability</a></li>
<li class="chapter" data-level="16.3.6" data-path="notes.html"><a href="notes.html#time-series"><i class="fa fa-check"></i><b>16.3.6</b> Time Series</a></li>
<li class="chapter" data-level="16.3.7" data-path="notes.html"><a href="notes.html#topic-models"><i class="fa fa-check"></i><b>16.3.7</b> Topic Models</a></li>
<li class="chapter" data-level="16.3.8" data-path="notes.html"><a href="notes.html#nonparametric-bayesian-methods"><i class="fa fa-check"></i><b>16.3.8</b> Nonparametric Bayesian Methods</a></li>
<li class="chapter" data-level="16.3.9" data-path="notes.html"><a href="notes.html#prior-elicitation"><i class="fa fa-check"></i><b>16.3.9</b> Prior Elicitation</a></li>
<li class="chapter" data-level="16.3.10" data-path="notes.html"><a href="notes.html#variable-selection"><i class="fa fa-check"></i><b>16.3.10</b> Variable Selection</a></li>
<li class="chapter" data-level="16.3.11" data-path="notes.html"><a href="notes.html#shrinkage"><i class="fa fa-check"></i><b>16.3.11</b> Shrinkage</a></li>
<li class="chapter" data-level="16.3.12" data-path="notes.html"><a href="notes.html#applied-bayes-rule"><i class="fa fa-check"></i><b>16.3.12</b> Applied Bayes Rule</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="notes.html"><a href="notes.html#computation-methods"><i class="fa fa-check"></i><b>16.4</b> Computation Methods</a><ul>
<li class="chapter" data-level="16.4.1" data-path="notes.html"><a href="notes.html#software"><i class="fa fa-check"></i><b>16.4.1</b> Software</a></li>
<li class="chapter" data-level="16.4.2" data-path="notes.html"><a href="notes.html#stan-3"><i class="fa fa-check"></i><b>16.4.2</b> Stan</a></li>
<li class="chapter" data-level="16.4.3" data-path="notes.html"><a href="notes.html#diagrams"><i class="fa fa-check"></i><b>16.4.3</b> Diagrams</a></li>
<li class="chapter" data-level="16.4.4" data-path="notes.html"><a href="notes.html#political-science-bayesian-works"><i class="fa fa-check"></i><b>16.4.4</b> Political Science Bayesian Works</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="notes.html"><a href="notes.html#model-checking-1"><i class="fa fa-check"></i><b>16.5</b> Model Checking</a></li>
<li class="chapter" data-level="16.6" data-path="notes.html"><a href="notes.html#general-applications-and-models"><i class="fa fa-check"></i><b>16.6</b> General Applications and Models</a><ul>
<li class="chapter" data-level="16.6.1" data-path="notes.html"><a href="notes.html#mixed-methods-and-qualitative-research"><i class="fa fa-check"></i><b>16.6.1</b> Mixed Methods and Qualitative Research</a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="notes.html"><a href="notes.html#hierarchical-modeling"><i class="fa fa-check"></i><b>16.7</b> Hierarchical Modeling</a></li>
<li class="chapter" data-level="16.8" data-path="notes.html"><a href="notes.html#shrinkageregularization"><i class="fa fa-check"></i><b>16.8</b> Shrinkage/Regularization</a><ul>
<li class="chapter" data-level="16.8.1" data-path="notes.html"><a href="notes.html#examples"><i class="fa fa-check"></i><b>16.8.1</b> Examples</a></li>
<li class="chapter" data-level="16.8.2" data-path="notes.html"><a href="notes.html#latent-variable-models"><i class="fa fa-check"></i><b>16.8.2</b> Latent Variable Models</a></li>
</ul></li>
<li class="chapter" data-level="16.9" data-path="notes.html"><a href="notes.html#bayes-theorem-examples"><i class="fa fa-check"></i><b>16.9</b> Bayes Theorem Examples</a><ul>
<li class="chapter" data-level="16.9.1" data-path="notes.html"><a href="notes.html#miscallaneous"><i class="fa fa-check"></i><b>16.9.1</b> Miscallaneous</a></li>
<li class="chapter" data-level="16.9.2" data-path="notes.html"><a href="notes.html#german-tank-problem"><i class="fa fa-check"></i><b>16.9.2</b> German Tank Problem</a></li>
</ul></li>
<li class="chapter" data-level="16.10" data-path="notes.html"><a href="notes.html#good-turing-estimator"><i class="fa fa-check"></i><b>16.10</b> Good-Turing Estimator</a></li>
<li class="chapter" data-level="16.11" data-path="notes.html"><a href="notes.html#reproducibility"><i class="fa fa-check"></i><b>16.11</b> Reproducibility</a><ul>
<li class="chapter" data-level="16.11.1" data-path="notes.html"><a href="notes.html#uncategorized"><i class="fa fa-check"></i><b>16.11.1</b> Uncategorized</a></li>
</ul></li>
<li class="chapter" data-level="16.12" data-path="notes.html"><a href="notes.html#empirical-bayes"><i class="fa fa-check"></i><b>16.12</b> Empirical Bayes</a></li>
<li class="chapter" data-level="16.13" data-path="notes.html"><a href="notes.html#things-to-cover"><i class="fa fa-check"></i><b>16.13</b> Things to cover</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-10.html"><a href="references-10.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Updating: A Set of Bayesian Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multilevel-models" class="section level1">
<h1><span class="header-section-number">15</span> Multilevel Models</h1>
<p>Multilevel models are commonly used hierarchical model. They extend (generalized) linear models to include coefficients that vary by discrete groups.</p>
<p>Suppose that there are <span class="math inline">\(i = 1, dots, n\)</span> observations, and each observation is in one of <span class="math inline">\(j = 1, \dots, J\)</span> groups. Let <span class="math inline">\(j[i]\)</span> be the group for <span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha_{j[i]} + \beta_{j[i]} x_i, \sigma^2) \\
\begin{pmatrix}
\alpha_j \\
\beta_j
\end{pmatrix} 
&amp; \sim
\dnorm
\left(
\begin{pmatrix}
\mu_\alpha \\
\mu_\beta
end{pmatrix},
\Omega
\right)
\end{aligned} .
\]</span></p>
<p><em>Pooled model</em>: All coefficients are common between groups. This is equivalent to a linear model. <span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha + \beta x_i, \sigma^2) \\
\begin{pmatrix}
\alpha \\
\betap
\end{pmatrix} 
&amp;\sim
\dnorm
\left(
\begin{pmatrix}
\mu_\alpha \\
\mu_\beta
end{pmatrix},
\Omega
\right)
\end{aligned}
\]</span></p>
<p><em>Pooled model</em>: All coefficients are common between groups. This is equivalent to a linear model. <span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha + \beta x_i, \sigma^2) \\
\end{aligned}
\]</span> <em>Varying-intercept</em>: The slope coefficients (<span class="math inline">\(\beta\)</span>) are common between groups, but the intercepts (<span class="math inline">\(\alpha_j\)</span>) vary by group. <span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha_{j[i]} + \beta x_i, \sigma^2) \\
\end{aligned}
\]</span> <em>Varying-slope model</em>: The groups share a common intercept, <span class="math inline">\(\alpha\)</span>, but the slope coefficient (<span class="math inline">\(\beta\)</span>), varies between groups. This is less common since it is hard to think of cases when it is appropriate. <span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha + \beta_{j[i]} x_i, \sigma^2) \\
\end{aligned}
\]</span> These models go by different names in different literatures: <em>hierarchical (generalized) linear models</em>, <em>nested data models</em>, <em>mixed models</em>, <em>random coefficients</em>, <em>random-effects</em>, <em>random parameter models</em>, <em>split-plot designs</em>.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
<p>The model can be extended to other cases:</p>
<ul>
<li>generalized linear models</li>
<li>multiple parameters</li>
</ul>
<p>One of the difficulties in these models is the prior to the covariance matrix, <span class="math inline">\(\Omega\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="multilevel_files/figure-html/unnamed-chunk-2-1.png" alt="Visual representation of hierarchical models" width="70%" />
<p class="caption">
Figure 15.1: Visual representation of hierarchical models
</p>
</div>
<div id="example-radon" class="section level2">
<h2><span class="header-section-number">15.1</span> Example: Radon</h2>
<p>This example models the presence of radon in houess in Minnesota which appears in <span class="citation">Gelman and Hill (2007)</span> and <span class="citation">Gelman et al. (2013)</span>. This is partly derived from a <a href="http://mc-stan.org/documentation/case-studies/radon.html">Stan Case Study</a>, which uses <code>PyStan</code> instead of <strong>rstan</strong>.</p>
<div id="data" class="section level3">
<h3><span class="header-section-number">15.1.1</span> Data</h3>
<p>The <a href="https://www.rdocumentation.org/packages/rstanarm/topics/radon">rstanarm</a> data is included in the <strong><a href="https://cran.r-project.org/package=rstanarm">rstanarm</a></strong> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;radon&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;rstanarm&quot;</span>)
radon
<span class="co">#&gt;     floor         county log_radon log_uranium</span>
<span class="co">#&gt; 1       1         AITKIN    0.8329     -0.6890</span>
<span class="co">#&gt; 2       0         AITKIN    0.8329     -0.6890</span>
<span class="co">#&gt; 3       0         AITKIN    1.0986     -0.6890</span>
<span class="co">#&gt; 4       0         AITKIN    0.0953     -0.6890</span>
<span class="co">#&gt; 5       0          ANOKA    1.1632     -0.8473</span>
<span class="co">#&gt; 6       0          ANOKA    0.9555     -0.8473</span>
<span class="co">#&gt; 7       0          ANOKA    0.4700     -0.8473</span>
<span class="co">#&gt; 8       0          ANOKA    0.0953     -0.8473</span>
<span class="co">#&gt; 9       0          ANOKA   -0.2231     -0.8473</span>
<span class="co">#&gt; 10      0          ANOKA    0.2624     -0.8473</span>
<span class="co">#&gt; 11      0          ANOKA    0.2624     -0.8473</span>
<span class="co">#&gt; 12      0          ANOKA    0.3365     -0.8473</span>
<span class="co">#&gt; 13      0          ANOKA    0.4055     -0.8473</span>
<span class="co">#&gt; 14      0          ANOKA   -0.6931     -0.8473</span>
<span class="co">#&gt; 15      0          ANOKA    0.1823     -0.8473</span>
<span class="co">#&gt; 16      0          ANOKA    1.5261     -0.8473</span>
<span class="co">#&gt; 17      0          ANOKA    0.3365     -0.8473</span>
<span class="co">#&gt; 18      0          ANOKA    0.7885     -0.8473</span>
<span class="co">#&gt; 19      0          ANOKA    1.7918     -0.8473</span>
<span class="co">#&gt; 20      0          ANOKA    1.2238     -0.8473</span>
<span class="co">#&gt; 21      0          ANOKA    0.6419     -0.8473</span>
<span class="co">#&gt; 22      0          ANOKA    1.7047     -0.8473</span>
<span class="co">#&gt; 23      0          ANOKA    1.8563     -0.8473</span>
<span class="co">#&gt; 24      0          ANOKA    0.6931     -0.8473</span>
<span class="co">#&gt; 25      0          ANOKA    1.9021     -0.8473</span>
<span class="co">#&gt; 26      0          ANOKA    1.1632     -0.8473</span>
<span class="co">#&gt; 27      0          ANOKA    1.9315     -0.8473</span>
<span class="co">#&gt; 28      0          ANOKA    1.9601     -0.8473</span>
<span class="co">#&gt; 29      0          ANOKA    2.0541     -0.8473</span>
<span class="co">#&gt; 30      0          ANOKA    1.6677     -0.8473</span>
<span class="co">#&gt; 31      0          ANOKA    1.5261     -0.8473</span>
<span class="co">#&gt; 32      0          ANOKA    1.5041     -0.8473</span>
<span class="co">#&gt; 33      0          ANOKA    1.0647     -0.8473</span>
<span class="co">#&gt; 34      0          ANOKA    2.1041     -0.8473</span>
<span class="co">#&gt; 35      0          ANOKA    0.5306     -0.8473</span>
<span class="co">#&gt; 36      0          ANOKA    1.4586     -0.8473</span>
<span class="co">#&gt; 37      0          ANOKA    1.7047     -0.8473</span>
<span class="co">#&gt; 38      0          ANOKA    1.4110     -0.8473</span>
<span class="co">#&gt; 39      0          ANOKA    0.8755     -0.8473</span>
<span class="co">#&gt; 40      0          ANOKA    1.0986     -0.8473</span>
<span class="co">#&gt; 41      0          ANOKA    0.4055     -0.8473</span>
<span class="co">#&gt; 42      0          ANOKA    1.2238     -0.8473</span>
<span class="co">#&gt; 43      0          ANOKA    1.0986     -0.8473</span>
<span class="co">#&gt; 44      1          ANOKA    0.6419     -0.8473</span>
<span class="co">#&gt; 45      1          ANOKA   -1.2040     -0.8473</span>
<span class="co">#&gt; 46      0          ANOKA    0.9163     -0.8473</span>
<span class="co">#&gt; 47      1          ANOKA    0.1823     -0.8473</span>
<span class="co">#&gt; 48      0          ANOKA    0.8329     -0.8473</span>
<span class="co">#&gt; 49      0          ANOKA   -0.3567     -0.8473</span>
<span class="co">#&gt; 50      0          ANOKA    0.5878     -0.8473</span>
<span class="co">#&gt; 51      0          ANOKA    1.0986     -0.8473</span>
<span class="co">#&gt; 52      0          ANOKA    0.8329     -0.8473</span>
<span class="co">#&gt; 53      0          ANOKA    0.5878     -0.8473</span>
<span class="co">#&gt; 54      0          ANOKA    0.4055     -0.8473</span>
<span class="co">#&gt; 55      0          ANOKA    0.6931     -0.8473</span>
<span class="co">#&gt; 56      0          ANOKA    0.6419     -0.8473</span>
<span class="co">#&gt; 57      1         BECKER    0.2624     -0.1135</span>
<span class="co">#&gt; 58      0         BECKER    1.4816     -0.1135</span>
<span class="co">#&gt; 59      1         BECKER    1.5261     -0.1135</span>
<span class="co">#&gt; 60      0       BELTRAMI    1.8563     -0.5934</span>
<span class="co">#&gt; 61      0       BELTRAMI    1.5476     -0.5934</span>
<span class="co">#&gt; 62      0       BELTRAMI    1.7579     -0.5934</span>
<span class="co">#&gt; 63      1       BELTRAMI    0.8329     -0.5934</span>
<span class="co">#&gt; 64      1       BELTRAMI   -0.6931     -0.5934</span>
<span class="co">#&gt; 65      1       BELTRAMI    1.5476     -0.5934</span>
<span class="co">#&gt; 66      1       BELTRAMI    1.5041     -0.5934</span>
<span class="co">#&gt; 67      0         BENTON    1.9021     -0.1429</span>
<span class="co">#&gt; 68      0         BENTON    1.0296     -0.1429</span>
<span class="co">#&gt; 69      1         BENTON    1.0986     -0.1429</span>
<span class="co">#&gt; 70      0         BENTON    1.0986     -0.1429</span>
<span class="co">#&gt; 71      0       BIGSTONE    1.9879      0.3871</span>
<span class="co">#&gt; 72      0       BIGSTONE    1.6292      0.3871</span>
<span class="co">#&gt; 73      0       BIGSTONE    0.9933      0.3871</span>
<span class="co">#&gt; 74      0      BLUEEARTH    1.6292      0.2716</span>
<span class="co">#&gt; 75      0      BLUEEARTH    2.5726      0.2716</span>
<span class="co">#&gt; 76      0      BLUEEARTH    1.9879      0.2716</span>
<span class="co">#&gt; 77      0      BLUEEARTH    1.9315      0.2716</span>
<span class="co">#&gt; 78      0      BLUEEARTH    2.5572      0.2716</span>
<span class="co">#&gt; 79      1      BLUEEARTH    1.7750      0.2716</span>
<span class="co">#&gt; 80      0      BLUEEARTH    2.2618      0.2716</span>
<span class="co">#&gt; 81      0      BLUEEARTH    1.8083      0.2716</span>
<span class="co">#&gt; 82      0      BLUEEARTH    1.3610      0.2716</span>
<span class="co">#&gt; 83      1      BLUEEARTH    2.6672      0.2716</span>
<span class="co">#&gt; 84      0      BLUEEARTH    0.6419      0.2716</span>
<span class="co">#&gt; 85      0      BLUEEARTH    1.9459      0.2716</span>
<span class="co">#&gt; 86      0      BLUEEARTH    1.5686      0.2716</span>
<span class="co">#&gt; 87      0      BLUEEARTH    2.2618      0.2716</span>
<span class="co">#&gt; 88      1          BROWN    0.9555      0.2776</span>
<span class="co">#&gt; 89      0          BROWN    1.9169      0.2776</span>
<span class="co">#&gt; 90      1          BROWN    1.4110      0.2776</span>
<span class="co">#&gt; 91      0          BROWN    2.3224      0.2776</span>
<span class="co">#&gt; 92      0        CARLTON    0.8329     -0.3323</span>
<span class="co">#&gt; 93      0        CARLTON    0.6419     -0.3323</span>
<span class="co">#&gt; 94      0        CARLTON    1.2528     -0.3323</span>
<span class="co">#&gt; 95      1        CARLTON    1.7405     -0.3323</span>
<span class="co">#&gt; 96      0        CARLTON    1.4816     -0.3323</span>
<span class="co">#&gt; 97      0        CARLTON    1.3863     -0.3323</span>
<span class="co">#&gt; 98      0        CARLTON    0.3365     -0.3323</span>
<span class="co">#&gt; 99      0        CARLTON    1.4586     -0.3323</span>
<span class="co">#&gt; 100     0        CARLTON   -0.1054     -0.3323</span>
<span class="co">#&gt; 101     0        CARLTON    0.7419     -0.3323</span>
<span class="co">#&gt; 102     0         CARVER    0.5306      0.0959</span>
<span class="co">#&gt; 104     0         CARVER    2.5649      0.0959</span>
<span class="co">#&gt; 106     1         CARVER    2.6946      0.0959</span>
<span class="co">#&gt; 108     1         CARVER    1.5686      0.0959</span>
<span class="co">#&gt; 110     0         CARVER    2.2721      0.0959</span>
<span class="co">#&gt; 112     1         CARVER   -2.3026      0.0959</span>
<span class="co">#&gt; 114     0           CASS    1.3350     -0.6082</span>
<span class="co">#&gt; 115     0           CASS    2.0149     -0.6082</span>
<span class="co">#&gt; 116     0           CASS    0.6931     -0.6082</span>
<span class="co">#&gt; 117     0           CASS    1.6864     -0.6082</span>
<span class="co">#&gt; 118     0           CASS    1.4110     -0.6082</span>
<span class="co">#&gt; 119     0       CHIPPEWA    2.0541      0.2737</span>
<span class="co">#&gt; 120     0       CHIPPEWA    0.4055      0.2737</span>
<span class="co">#&gt; 121     0       CHIPPEWA    2.3125      0.2737</span>
<span class="co">#&gt; 122     0       CHIPPEWA    2.2513      0.2737</span>
<span class="co">#&gt; 123     0        CHISAGO   -0.1054     -0.7353</span>
<span class="co">#&gt; 124     0        CHISAGO    1.5041     -0.7353</span>
<span class="co">#&gt; 125     0        CHISAGO    1.6292     -0.7353</span>
<span class="co">#&gt; 126     0        CHISAGO    0.7885     -0.7353</span>
<span class="co">#&gt; 127     0        CHISAGO    0.5878     -0.7353</span>
<span class="co">#&gt; 128     0        CHISAGO    2.1041     -0.7353</span>
<span class="co">#&gt; 129     1           CLAY    0.0000      0.3438</span>
<span class="co">#&gt; 130     0           CLAY    2.5649      0.3438</span>
<span class="co">#&gt; 131     0           CLAY    0.9933      0.3438</span>
<span class="co">#&gt; 132     1           CLAY    1.2809      0.3438</span>
<span class="co">#&gt; 133     0           CLAY    3.2847      0.3438</span>
<span class="co">#&gt; 134     0           CLAY    0.4700      0.3438</span>
<span class="co">#&gt; 135     0           CLAY    2.5726      0.3438</span>
<span class="co">#&gt; 136     0           CLAY    2.1861      0.3438</span>
<span class="co">#&gt; 137     0           CLAY    2.9755      0.3438</span>
<span class="co">#&gt; 138     1           CLAY    0.9555      0.3438</span>
<span class="co">#&gt; 139     0           CLAY    2.2083      0.3438</span>
<span class="co">#&gt; 140     0           CLAY    2.5802      0.3438</span>
<span class="co">#&gt; 141     0           CLAY    1.3083      0.3438</span>
<span class="co">#&gt; 142     1           CLAY    1.9459      0.3438</span>
<span class="co">#&gt; 143     1     CLEARWATER    1.5892     -0.0599</span>
<span class="co">#&gt; 144     0     CLEARWATER    1.2528     -0.0599</span>
<span class="co">#&gt; 145     1     CLEARWATER    0.0000     -0.0599</span>
<span class="co">#&gt; 146     0     CLEARWATER    1.2528     -0.0599</span>
<span class="co">#&gt; 147     0           COOK    1.0296     -0.5050</span>
<span class="co">#&gt; 148     0           COOK    0.4055     -0.5050</span>
<span class="co">#&gt; 149     0     COTTONWOOD    1.9315      0.3396</span>
<span class="co">#&gt; 150     1     COTTONWOOD    2.4159      0.3396</span>
<span class="co">#&gt; 151     1     COTTONWOOD   -2.3026      0.3396</span>
<span class="co">#&gt; 152     1     COTTONWOOD    0.9555      0.3396</span>
<span class="co">#&gt; 153     0       CROWWING    0.6419     -0.6334</span>
<span class="co">#&gt; 154     0       CROWWING    0.5306     -0.6334</span>
<span class="co">#&gt; 155     1       CROWWING    0.0953     -0.6334</span>
<span class="co">#&gt; 156     0       CROWWING    0.0000     -0.6334</span>
<span class="co">#&gt; 157     0       CROWWING    1.0986     -0.6334</span>
<span class="co">#&gt; 158     0       CROWWING    1.5041     -0.6334</span>
<span class="co">#&gt; 159     0       CROWWING    0.4700     -0.6334</span>
<span class="co">#&gt; 160     0       CROWWING    1.4351     -0.6334</span>
<span class="co">#&gt; 161     1       CROWWING    0.9555     -0.6334</span>
<span class="co">#&gt; 162     1       CROWWING    1.9169     -0.6334</span>
<span class="co">#&gt; 163     0       CROWWING    1.4816     -0.6334</span>
<span class="co">#&gt; 164     0       CROWWING    1.7228     -0.6334</span>
<span class="co">#&gt; 165     0         DAKOTA    1.3083     -0.0241</span>
<span class="co">#&gt; 166     0         DAKOTA    1.0647     -0.0241</span>
<span class="co">#&gt; 167     0         DAKOTA    2.6878     -0.0241</span>
<span class="co">#&gt; 168     0         DAKOTA    1.9169     -0.0241</span>
<span class="co">#&gt; 169     0         DAKOTA    2.0919     -0.0241</span>
<span class="co">#&gt; 170     0         DAKOTA    0.9933     -0.0241</span>
<span class="co">#&gt; 171     1         DAKOTA    1.0647     -0.0241</span>
<span class="co">#&gt; 172     0         DAKOTA    1.5041     -0.0241</span>
<span class="co">#&gt; 173     1         DAKOTA    0.5878     -0.0241</span>
<span class="co">#&gt; 174     0         DAKOTA    0.7419     -0.0241</span>
<span class="co">#&gt; 175     0         DAKOTA    0.7419     -0.0241</span>
<span class="co">#&gt; 176     0         DAKOTA    0.4700     -0.0241</span>
<span class="co">#&gt; 177     0         DAKOTA    2.2721     -0.0241</span>
<span class="co">#&gt; 178     0         DAKOTA    2.1041     -0.0241</span>
<span class="co">#&gt; 179     0         DAKOTA    1.2809     -0.0241</span>
<span class="co">#&gt; 180     1         DAKOTA   -0.1054     -0.0241</span>
<span class="co">#&gt; 181     0         DAKOTA    1.6487     -0.0241</span>
<span class="co">#&gt; 182     0         DAKOTA    1.1939     -0.0241</span>
<span class="co">#&gt; 183     0         DAKOTA    2.3888     -0.0241</span>
<span class="co">#&gt; 184     0         DAKOTA    2.1163     -0.0241</span>
<span class="co">#&gt; 185     0         DAKOTA    1.8563     -0.0241</span>
<span class="co">#&gt; 186     0         DAKOTA    1.5892     -0.0241</span>
<span class="co">#&gt; 187     0         DAKOTA    1.8083     -0.0241</span>
<span class="co">#&gt; 188     0         DAKOTA    0.1823     -0.0241</span>
<span class="co">#&gt; 189     0         DAKOTA    2.1748     -0.0241</span>
<span class="co">#&gt; 190     0         DAKOTA    2.1861     -0.0241</span>
<span class="co">#&gt; 191     0         DAKOTA    1.9315     -0.0241</span>
<span class="co">#&gt; 192     0         DAKOTA    0.8755     -0.0241</span>
<span class="co">#&gt; 193     0         DAKOTA    0.5306     -0.0241</span>
<span class="co">#&gt; 194     0         DAKOTA    1.0647     -0.0241</span>
<span class="co">#&gt; 195     0         DAKOTA    1.8871     -0.0241</span>
<span class="co">#&gt; 196     0         DAKOTA    0.5878     -0.0241</span>
<span class="co">#&gt; 197     0         DAKOTA    1.5476     -0.0241</span>
<span class="co">#&gt; 198     0         DAKOTA    1.2238     -0.0241</span>
<span class="co">#&gt; 199     0         DAKOTA    1.5041     -0.0241</span>
<span class="co">#&gt; 200     0         DAKOTA    3.0587     -0.0241</span>
<span class="co">#&gt; 201     0         DAKOTA    2.2192     -0.0241</span>
<span class="co">#&gt; 202     0         DAKOTA    0.0000     -0.0241</span>
<span class="co">#&gt; 203     0         DAKOTA    1.6094     -0.0241</span>
<span class="co">#&gt; 204     0         DAKOTA    1.6292     -0.0241</span>
<span class="co">#&gt; 205     0         DAKOTA    0.1823     -0.0241</span>
<span class="co">#&gt; 206     0         DAKOTA    2.0412     -0.0241</span>
<span class="co">#&gt; 207     0         DAKOTA    1.7047     -0.0241</span>
<span class="co">#&gt; 208     0         DAKOTA    1.3083     -0.0241</span>
<span class="co">#&gt; 209     0         DAKOTA    1.6094     -0.0241</span>
<span class="co">#&gt; 210     0         DAKOTA    1.5686     -0.0241</span>
<span class="co">#&gt; 211     0         DAKOTA    0.4055     -0.0241</span>
<span class="co">#&gt; 212     0         DAKOTA    1.2528     -0.0241</span>
<span class="co">#&gt; 213     0         DAKOTA    1.4586     -0.0241</span>
<span class="co">#&gt; 214     0         DAKOTA    0.9555     -0.0241</span>
<span class="co">#&gt; 215     0         DAKOTA    0.4055     -0.0241</span>
<span class="co">#&gt; 216     0         DAKOTA    0.4055     -0.0241</span>
<span class="co">#&gt; 217     0         DAKOTA    0.6931     -0.0241</span>
<span class="co">#&gt; 218     0         DAKOTA    1.5892     -0.0241</span>
<span class="co">#&gt; 219     1         DAKOTA    0.4055     -0.0241</span>
<span class="co">#&gt; 220     0         DAKOTA    1.3610     -0.0241</span>
<span class="co">#&gt; 221     0         DAKOTA    2.1861     -0.0241</span>
<span class="co">#&gt; 222     0         DAKOTA    1.4816     -0.0241</span>
<span class="co">#&gt; 223     0         DAKOTA    1.5041     -0.0241</span>
<span class="co">#&gt; 224     0         DAKOTA    1.5261     -0.0241</span>
<span class="co">#&gt; 225     0         DAKOTA    0.8329     -0.0241</span>
<span class="co">#&gt; 226     0         DAKOTA   -0.5108     -0.0241</span>
<span class="co">#&gt; 227     0         DAKOTA    1.7750     -0.0241</span>
<span class="co">#&gt; 228     0          DODGE    1.7047      0.2639</span>
<span class="co">#&gt; 229     0          DODGE    1.9879      0.2639</span>
<span class="co">#&gt; 230     0          DODGE    1.7579      0.2639</span>
<span class="co">#&gt; 231     0        DOUGLAS    2.0149      0.1557</span>
<span class="co">#&gt; 232     0        DOUGLAS    1.5892      0.1557</span>
<span class="co">#&gt; 233     0        DOUGLAS    1.9315      0.1557</span>
<span class="co">#&gt; 234     0        DOUGLAS    1.8718      0.1557</span>
<span class="co">#&gt; 235     1        DOUGLAS    1.3350      0.1557</span>
<span class="co">#&gt; 236     0        DOUGLAS    1.7228      0.1557</span>
<span class="co">#&gt; 237     0        DOUGLAS    2.0669      0.1557</span>
<span class="co">#&gt; 238     0        DOUGLAS    1.5041      0.1557</span>
<span class="co">#&gt; 239     0        DOUGLAS    1.0296      0.1557</span>
<span class="co">#&gt; 240     0      FARIBAULT    1.2528      0.2950</span>
<span class="co">#&gt; 241     0      FARIBAULT    1.4586      0.2950</span>
<span class="co">#&gt; 242     0      FARIBAULT    0.8755      0.2950</span>
<span class="co">#&gt; 243     1      FARIBAULT    0.3365      0.2950</span>
<span class="co">#&gt; 244     0      FARIBAULT    1.6677      0.2950</span>
<span class="co">#&gt; 245     0      FARIBAULT   -1.6094      0.2950</span>
<span class="co">#&gt; 246     1       FILLMORE    0.9555      0.4149</span>
<span class="co">#&gt; 247     0       FILLMORE    1.1939      0.4149</span>
<span class="co">#&gt; 248     0       FREEBORN    1.1939      0.2242</span>
<span class="co">#&gt; 249     0       FREEBORN    2.2721      0.2242</span>
<span class="co">#&gt; 250     0       FREEBORN    1.4586      0.2242</span>
<span class="co">#&gt; 251     0       FREEBORN    2.2083      0.2242</span>
<span class="co">#&gt; 252     0       FREEBORN    1.8563      0.2242</span>
<span class="co">#&gt; 253     0       FREEBORN    3.4874      0.2242</span>
<span class="co">#&gt; 254     0       FREEBORN    2.5878      0.2242</span>
<span class="co">#&gt; 255     1       FREEBORN    0.8329      0.2242</span>
<span class="co">#&gt; 256     1       FREEBORN    1.7405      0.2242</span>
<span class="co">#&gt; 257     0        GOODHUE    2.6672      0.1966</span>
<span class="co">#&gt; 258     1        GOODHUE    1.9459      0.1966</span>
<span class="co">#&gt; 259     0        GOODHUE    2.0412      0.1966</span>
<span class="co">#&gt; 260     1        GOODHUE    2.2925      0.1966</span>
<span class="co">#&gt; 261     0        GOODHUE    0.9933      0.1966</span>
<span class="co">#&gt; 262     0        GOODHUE    3.7751      0.1966</span>
<span class="co">#&gt; 263     0        GOODHUE    1.6094      0.1966</span>
<span class="co">#&gt; 264     0        GOODHUE    1.6094      0.1966</span>
<span class="co">#&gt; 265     0        GOODHUE    1.2809      0.1966</span>
<span class="co">#&gt; 266     0        GOODHUE    1.5892      0.1966</span>
<span class="co">#&gt; 267     0        GOODHUE    1.7405      0.1966</span>
<span class="co">#&gt; 268     0        GOODHUE    1.2809      0.1966</span>
<span class="co">#&gt; 269     0        GOODHUE    1.3863      0.1966</span>
<span class="co">#&gt; 270     0        GOODHUE    1.9169      0.1966</span>
<span class="co">#&gt; 271     0       HENNEPIN    2.0794     -0.0965</span>
<span class="co">#&gt; 272     0       HENNEPIN    1.2238     -0.0965</span>
<span class="co">#&gt; 273     1       HENNEPIN    0.7885     -0.0965</span>
<span class="co">#&gt; 274     0       HENNEPIN    0.5306     -0.0965</span>
<span class="co">#&gt; 275     0       HENNEPIN    1.4110     -0.0965</span>
<span class="co">#&gt; 276     0       HENNEPIN    0.6419     -0.0965</span>
<span class="co">#&gt; 277     0       HENNEPIN    0.9555     -0.0965</span>
<span class="co">#&gt; 278     0       HENNEPIN    2.4248     -0.0965</span>
<span class="co">#&gt; 279     0       HENNEPIN    0.9933     -0.0965</span>
<span class="co">#&gt; 280     0       HENNEPIN    1.3863     -0.0965</span>
<span class="co">#&gt; 281     0       HENNEPIN    2.0149     -0.0965</span>
<span class="co">#&gt; 282     0       HENNEPIN    0.3365     -0.0965</span>
<span class="co">#&gt; 283     0       HENNEPIN    0.0000     -0.0965</span>
<span class="co">#&gt; 284     0       HENNEPIN   -0.6931     -0.0965</span>
<span class="co">#&gt; 285     1       HENNEPIN    0.9555     -0.0965</span>
<span class="co">#&gt; 286     0       HENNEPIN    1.8083     -0.0965</span>
<span class="co">#&gt; 287     0       HENNEPIN    0.7419     -0.0965</span>
<span class="co">#&gt; 288     0       HENNEPIN    1.7047     -0.0965</span>
<span class="co">#&gt; 289     0       HENNEPIN    1.1314     -0.0965</span>
<span class="co">#&gt; 290     0       HENNEPIN    1.0986     -0.0965</span>
<span class="co">#&gt; 291     0       HENNEPIN    1.7228     -0.0965</span>
<span class="co">#&gt; 292     0       HENNEPIN    1.4351     -0.0965</span>
<span class="co">#&gt; 293     0       HENNEPIN    1.3863     -0.0965</span>
<span class="co">#&gt; 294     0       HENNEPIN    2.7081     -0.0965</span>
<span class="co">#&gt; 295     0       HENNEPIN    1.9879     -0.0965</span>
<span class="co">#&gt; 296     0       HENNEPIN    0.8755     -0.0965</span>
<span class="co">#&gt; 297     1       HENNEPIN    1.0647     -0.0965</span>
<span class="co">#&gt; 298     0       HENNEPIN    1.5041     -0.0965</span>
<span class="co">#&gt; 299     0       HENNEPIN    0.4700     -0.0965</span>
<span class="co">#&gt; 300     0       HENNEPIN    2.1633     -0.0965</span>
<span class="co">#&gt; 301     0       HENNEPIN    1.7405     -0.0965</span>
<span class="co">#&gt; 302     0       HENNEPIN    2.1633     -0.0965</span>
<span class="co">#&gt; 303     0       HENNEPIN    1.3610     -0.0965</span>
<span class="co">#&gt; 304     0       HENNEPIN    0.6419     -0.0965</span>
<span class="co">#&gt; 305     0       HENNEPIN    0.6931     -0.0965</span>
<span class="co">#&gt; 306     0       HENNEPIN    1.7228     -0.0965</span>
<span class="co">#&gt; 307     0       HENNEPIN    0.9555     -0.0965</span>
<span class="co">#&gt; 308     1       HENNEPIN   -0.1054     -0.0965</span>
<span class="co">#&gt; 309     0       HENNEPIN    0.7885     -0.0965</span>
<span class="co">#&gt; 310     0       HENNEPIN    1.0647     -0.0965</span>
<span class="co">#&gt; 311     0       HENNEPIN    1.3863     -0.0965</span>
<span class="co">#&gt; 312     0       HENNEPIN    1.4816     -0.0965</span>
<span class="co">#&gt; 313     0       HENNEPIN    1.5686     -0.0965</span>
<span class="co">#&gt; 314     0       HENNEPIN    1.0647     -0.0965</span>
<span class="co">#&gt; 315     0       HENNEPIN    1.4351     -0.0965</span>
<span class="co">#&gt; 316     0       HENNEPIN    0.5306     -0.0965</span>
<span class="co">#&gt; 317     0       HENNEPIN    1.4816     -0.0965</span>
<span class="co">#&gt; 318     1       HENNEPIN   -0.2231     -0.0965</span>
<span class="co">#&gt; 319     0       HENNEPIN    1.7228     -0.0965</span>
<span class="co">#&gt; 320     1       HENNEPIN    1.2238     -0.0965</span>
<span class="co">#&gt; 321     0       HENNEPIN    1.7228     -0.0965</span>
<span class="co">#&gt; 322     0       HENNEPIN    0.9555     -0.0965</span>
<span class="co">#&gt; 323     0       HENNEPIN    1.0296     -0.0965</span>
<span class="co">#&gt; 324     0       HENNEPIN    2.1401     -0.0965</span>
<span class="co">#&gt; 325     0       HENNEPIN    1.2238     -0.0965</span>
<span class="co">#&gt; 326     0       HENNEPIN    1.1939     -0.0965</span>
<span class="co">#&gt; 327     0       HENNEPIN    2.1633     -0.0965</span>
<span class="co">#&gt; 328     0       HENNEPIN    0.5878     -0.0965</span>
<span class="co">#&gt; 329     0       HENNEPIN    1.7579     -0.0965</span>
<span class="co">#&gt; 330     0       HENNEPIN    2.5726     -0.0965</span>
<span class="co">#&gt; 331     0       HENNEPIN    1.0296     -0.0965</span>
<span class="co">#&gt; 332     0       HENNEPIN    1.5686     -0.0965</span>
<span class="co">#&gt; 333     0       HENNEPIN    1.7405     -0.0965</span>
<span class="co">#&gt; 334     0       HENNEPIN    2.6319     -0.0965</span>
<span class="co">#&gt; 335     1       HENNEPIN    2.0412     -0.0965</span>
<span class="co">#&gt; 336     0       HENNEPIN    1.7579     -0.0965</span>
<span class="co">#&gt; 337     0       HENNEPIN    1.5476     -0.0965</span>
<span class="co">#&gt; 338     0       HENNEPIN    2.0412     -0.0965</span>
<span class="co">#&gt; 339     0       HENNEPIN    0.9933     -0.0965</span>
<span class="co">#&gt; 340     0       HENNEPIN    1.5261     -0.0965</span>
<span class="co">#&gt; 341     0       HENNEPIN    1.7918     -0.0965</span>
<span class="co">#&gt; 342     0       HENNEPIN    0.8329     -0.0965</span>
<span class="co">#&gt; 343     0       HENNEPIN    0.9163     -0.0965</span>
<span class="co">#&gt; 344     0       HENNEPIN    1.4110     -0.0965</span>
<span class="co">#&gt; 345     0       HENNEPIN    1.5476     -0.0965</span>
<span class="co">#&gt; 346     0       HENNEPIN    1.5476     -0.0965</span>
<span class="co">#&gt; 347     0       HENNEPIN    2.3979     -0.0965</span>
<span class="co">#&gt; 348     0       HENNEPIN    2.0412     -0.0965</span>
<span class="co">#&gt; 349     0       HENNEPIN    1.1314     -0.0965</span>
<span class="co">#&gt; 350     0       HENNEPIN    0.4700     -0.0965</span>
<span class="co">#&gt; 351     1       HENNEPIN    0.5306     -0.0965</span>
<span class="co">#&gt; 352     0       HENNEPIN    2.8094     -0.0965</span>
<span class="co">#&gt; 353     0       HENNEPIN    1.1632     -0.0965</span>
<span class="co">#&gt; 354     0       HENNEPIN    1.6487     -0.0965</span>
<span class="co">#&gt; 355     0       HENNEPIN    1.6094     -0.0965</span>
<span class="co">#&gt; 356     0       HENNEPIN    1.8083     -0.0965</span>
<span class="co">#&gt; 357     1       HENNEPIN    0.0000     -0.0965</span>
<span class="co">#&gt; 358     0       HENNEPIN    0.6419     -0.0965</span>
<span class="co">#&gt; 359     0       HENNEPIN    1.3863     -0.0965</span>
<span class="co">#&gt; 360     0       HENNEPIN    1.7405     -0.0965</span>
<span class="co">#&gt; 361     1       HENNEPIN   -0.6931     -0.0965</span>
<span class="co">#&gt; 362     0       HENNEPIN    0.9933     -0.0965</span>
<span class="co">#&gt; 363     0       HENNEPIN    1.3083     -0.0965</span>
<span class="co">#&gt; 364     0       HENNEPIN    1.8405     -0.0965</span>
<span class="co">#&gt; 365     0       HENNEPIN    3.1655     -0.0965</span>
<span class="co">#&gt; 366     0       HENNEPIN    1.3863     -0.0965</span>
<span class="co">#&gt; 367     0       HENNEPIN    1.0986     -0.0965</span>
<span class="co">#&gt; 368     0       HENNEPIN    1.1314     -0.0965</span>
<span class="co">#&gt; 369     0       HENNEPIN    1.5686     -0.0965</span>
<span class="co">#&gt; 370     0       HENNEPIN    1.1314     -0.0965</span>
<span class="co">#&gt; 371     0       HENNEPIN    1.4586     -0.0965</span>
<span class="co">#&gt; 372     0       HENNEPIN    1.3610     -0.0965</span>
<span class="co">#&gt; 373     0       HENNEPIN    1.1314     -0.0965</span>
<span class="co">#&gt; 374     0       HENNEPIN    1.4816     -0.0965</span>
<span class="co">#&gt; 375     1       HENNEPIN    1.0986     -0.0965</span>
<span class="co">#&gt; 376     0        HOUSTON    1.2528      0.5035</span>
<span class="co">#&gt; 377     0        HOUSTON    2.1518      0.5035</span>
<span class="co">#&gt; 378     0        HOUSTON    2.2083      0.5035</span>
<span class="co">#&gt; 379     1        HOUSTON    1.5892      0.5035</span>
<span class="co">#&gt; 380     0        HOUSTON    1.3083      0.5035</span>
<span class="co">#&gt; 381     1        HOUSTON    0.8329      0.5035</span>
<span class="co">#&gt; 382     1        HUBBARD    1.0647     -0.4006</span>
<span class="co">#&gt; 383     1        HUBBARD   -0.1054     -0.4006</span>
<span class="co">#&gt; 384     0        HUBBARD    0.4700     -0.4006</span>
<span class="co">#&gt; 385     0        HUBBARD    1.5476     -0.4006</span>
<span class="co">#&gt; 386     1        HUBBARD    1.3350     -0.4006</span>
<span class="co">#&gt; 387     0         ISANTI    1.3083     -0.7519</span>
<span class="co">#&gt; 388     0         ISANTI    1.1314     -0.7519</span>
<span class="co">#&gt; 389     0         ISANTI    0.8329     -0.7519</span>
<span class="co">#&gt; 390     0         ITASCA    0.6931     -0.6633</span>
<span class="co">#&gt; 391     0         ITASCA    0.9933     -0.6633</span>
<span class="co">#&gt; 392     0         ITASCA    0.6419     -0.6633</span>
<span class="co">#&gt; 393     0         ITASCA    0.9163     -0.6633</span>
<span class="co">#&gt; 394     0         ITASCA    1.4816     -0.6633</span>
<span class="co">#&gt; 395     0         ITASCA    0.9933     -0.6633</span>
<span class="co">#&gt; 396     0         ITASCA    0.1823     -0.6633</span>
<span class="co">#&gt; 397     0         ITASCA    1.2238     -0.6633</span>
<span class="co">#&gt; 398     0         ITASCA    0.9555     -0.6633</span>
<span class="co">#&gt; 399     0         ITASCA    2.2513     -0.6633</span>
<span class="co">#&gt; 400     0         ITASCA    0.3365     -0.6633</span>
<span class="co">#&gt; 401     0        JACKSON    2.1401      0.3090</span>
<span class="co">#&gt; 402     0        JACKSON    1.6292      0.3090</span>
<span class="co">#&gt; 403     0        JACKSON    1.0986      0.3090</span>
<span class="co">#&gt; 404     0        JACKSON    2.5802      0.3090</span>
<span class="co">#&gt; 405     0        JACKSON    2.7344      0.3090</span>
<span class="co">#&gt; 406     0        KANABEC    0.6419     -0.0534</span>
<span class="co">#&gt; 407     0        KANABEC    1.3610     -0.0534</span>
<span class="co">#&gt; 408     0        KANABEC    2.0794     -0.0534</span>
<span class="co">#&gt; 409     0        KANABEC    0.9933     -0.0534</span>
<span class="co">#&gt; 410     0      KANDIYOHI    2.4336      0.1097</span>
<span class="co">#&gt; 411     0      KANDIYOHI    1.4351      0.1097</span>
<span class="co">#&gt; 412     0      KANDIYOHI    2.5177      0.1097</span>
<span class="co">#&gt; 413     0      KANDIYOHI    1.9169      0.1097</span>
<span class="co">#&gt; 414     0        KITTSON    1.9459     -0.0078</span>
<span class="co">#&gt; 415     1        KITTSON    1.5261     -0.0078</span>
<span class="co">#&gt; 416     1        KITTSON    0.0000     -0.0078</span>
<span class="co">#&gt; 417     0    KOOCHICHING    0.5878     -0.8818</span>
<span class="co">#&gt; 418     0    KOOCHICHING    0.4055     -0.8818</span>
<span class="co">#&gt; 419     1    KOOCHICHING    0.7419     -0.8818</span>
<span class="co">#&gt; 420     1    KOOCHICHING    0.0953     -0.8818</span>
<span class="co">#&gt; 421     0    KOOCHICHING    0.0953     -0.8818</span>
<span class="co">#&gt; 422     1    KOOCHICHING    1.0647     -0.8818</span>
<span class="co">#&gt; 423     1    KOOCHICHING    0.3365     -0.8818</span>
<span class="co">#&gt; 424     1    LACQUIPARLE    2.4336      0.3110</span>
<span class="co">#&gt; 426     0    LACQUIPARLE    2.7788      0.3110</span>
<span class="co">#&gt; 428     1           LAKE    0.3365     -0.6916</span>
<span class="co">#&gt; 429     0           LAKE    0.3365     -0.6916</span>
<span class="co">#&gt; 430     0           LAKE    0.5306     -0.6916</span>
<span class="co">#&gt; 431     0           LAKE    0.0000     -0.6916</span>
<span class="co">#&gt; 432     0           LAKE    1.0647     -0.6916</span>
<span class="co">#&gt; 433     0           LAKE   -0.5108     -0.6916</span>
<span class="co">#&gt; 434     0           LAKE    0.4700     -0.6916</span>
<span class="co">#&gt; 435     0           LAKE    1.9741     -0.6916</span>
<span class="co">#&gt; 436     0           LAKE   -0.5108     -0.6916</span>
<span class="co">#&gt; 437     0 LAKEOFTHEWOODS    2.3224     -0.6817</span>
<span class="co">#&gt; 438     1 LAKEOFTHEWOODS    1.4816     -0.6817</span>
<span class="co">#&gt; 439     0 LAKEOFTHEWOODS    1.2238     -0.6817</span>
<span class="co">#&gt; 440     1 LAKEOFTHEWOODS    1.0986     -0.6817</span>
<span class="co">#&gt; 441     0        LESUEUR    2.5337      0.1944</span>
<span class="co">#&gt; 442     1        LESUEUR    1.4586      0.1944</span>
<span class="co">#&gt; 443     0        LESUEUR    1.5261      0.1944</span>
<span class="co">#&gt; 444     0        LESUEUR    1.3863      0.1944</span>
<span class="co">#&gt; 445     0        LESUEUR    1.2238      0.1944</span>
<span class="co">#&gt; 446     0        LINCOLN    2.8679      0.4449</span>
<span class="co">#&gt; 447     0        LINCOLN    2.3702      0.4449</span>
<span class="co">#&gt; 448     0        LINCOLN    2.0794      0.4449</span>
<span class="co">#&gt; 449     1        LINCOLN    1.2809      0.4449</span>
<span class="co">#&gt; 450     0           LYON    1.8871      0.3947</span>
<span class="co">#&gt; 451     1           LYON    1.9459      0.3947</span>
<span class="co">#&gt; 452     0           LYON    1.6487      0.3947</span>
<span class="co">#&gt; 453     0           LYON    2.4932      0.3947</span>
<span class="co">#&gt; 454     0           LYON    1.6487      0.3947</span>
<span class="co">#&gt; 455     0           LYON    2.1972      0.3947</span>
<span class="co">#&gt; 456     0           LYON    1.7750      0.3947</span>
<span class="co">#&gt; 457     0           LYON    1.5476      0.3947</span>
<span class="co">#&gt; 458     0         MCLEOD    2.3418      0.1404</span>
<span class="co">#&gt; 459     0         MCLEOD    1.3863      0.1404</span>
<span class="co">#&gt; 460     0         MCLEOD    0.6419      0.1404</span>
<span class="co">#&gt; 461     0         MCLEOD    2.3026      0.1404</span>
<span class="co">#&gt; 462     0         MCLEOD    0.8755      0.1404</span>
<span class="co">#&gt; 463     0         MCLEOD    1.5041      0.1404</span>
<span class="co">#&gt; 464     0         MCLEOD    1.0647      0.1404</span>
<span class="co">#&gt; 465     1         MCLEOD    0.1823      0.1404</span>
<span class="co">#&gt; 466     0         MCLEOD    0.2624      0.1404</span>
<span class="co">#&gt; 467     1         MCLEOD    0.5306      0.1404</span>
<span class="co">#&gt; 468     1         MCLEOD    3.2387      0.1404</span>
<span class="co">#&gt; 469     1         MCLEOD   -2.3026      0.1404</span>
<span class="co">#&gt; 470     0         MCLEOD    2.3702      0.1404</span>
<span class="co">#&gt; 471     0       MAHNOMEN    1.3863      0.1496</span>
<span class="co">#&gt; 472     1       MARSHALL    0.4700      0.0138</span>
<span class="co">#&gt; 473     0       MARSHALL    3.1739      0.0138</span>
<span class="co">#&gt; 474     1       MARSHALL    0.0000      0.0138</span>
<span class="co">#&gt; 475     1       MARSHALL    0.4055      0.0138</span>
<span class="co">#&gt; 476     1       MARSHALL    0.1823      0.0138</span>
<span class="co">#&gt; 477     0       MARSHALL    1.0647      0.0138</span>
<span class="co">#&gt; 478     0       MARSHALL    3.8774      0.0138</span>
<span class="co">#&gt; 479     1       MARSHALL    0.0000      0.0138</span>
<span class="co">#&gt; 480     0       MARSHALL    2.1282      0.0138</span>
<span class="co">#&gt; 481     0         MARTIN    1.4351      0.1659</span>
<span class="co">#&gt; 482     1         MARTIN   -0.5108      0.1659</span>
<span class="co">#&gt; 483     0         MARTIN    1.9169      0.1659</span>
<span class="co">#&gt; 484     0         MARTIN    2.0281      0.1659</span>
<span class="co">#&gt; 485     0         MARTIN    2.2300      0.1659</span>
<span class="co">#&gt; 486     0         MARTIN   -0.5108      0.1659</span>
<span class="co">#&gt; 487     0         MARTIN    0.4700      0.1659</span>
<span class="co">#&gt; 488     0         MEEKER    0.8755      0.0240</span>
<span class="co">#&gt; 489     0         MEEKER    1.3863      0.0240</span>
<span class="co">#&gt; 490     0         MEEKER    1.9879      0.0240</span>
<span class="co">#&gt; 491     0         MEEKER    0.7885      0.0240</span>
<span class="co">#&gt; 492     0         MEEKER    1.1939      0.0240</span>
<span class="co">#&gt; 493     1      MILLELACS   -0.5108     -0.2101</span>
<span class="co">#&gt; 494     0      MILLELACS    1.7579     -0.2101</span>
<span class="co">#&gt; 495     0       MORRISON    0.4055     -0.0932</span>
<span class="co">#&gt; 496     0       MORRISON    0.7885     -0.0932</span>
<span class="co">#&gt; 497     0       MORRISON    1.5041     -0.0932</span>
<span class="co">#&gt; 498     0       MORRISON    0.9163     -0.0932</span>
<span class="co">#&gt; 499     0       MORRISON    1.6094     -0.0932</span>
<span class="co">#&gt; 500     1       MORRISON    1.1314     -0.0932</span>
<span class="co">#&gt; 501     0       MORRISON    1.1314     -0.0932</span>
<span class="co">#&gt; 502     0       MORRISON    1.0647     -0.0932</span>
<span class="co">#&gt; 503     0       MORRISON    1.3863     -0.0932</span>
<span class="co">#&gt; 504     0          MOWER    2.3979      0.2609</span>
<span class="co">#&gt; 505     0          MOWER    1.8718      0.2609</span>
<span class="co">#&gt; 506     0          MOWER    0.7419      0.2609</span>
<span class="co">#&gt; 507     0          MOWER    1.1314      0.2609</span>
<span class="co">#&gt; 508     0          MOWER    1.5261      0.2609</span>
<span class="co">#&gt; 509     0          MOWER    0.7885      0.2609</span>
<span class="co">#&gt; 510     0          MOWER    2.0919      0.2609</span>
<span class="co">#&gt; 511     1          MOWER    0.3365      0.2609</span>
<span class="co">#&gt; 512     0          MOWER    2.2300      0.2609</span>
<span class="co">#&gt; 513     1          MOWER    0.1823      0.2609</span>
<span class="co">#&gt; 514     0          MOWER    2.3702      0.2609</span>
<span class="co">#&gt; 515     0          MOWER    3.1822      0.2609</span>
<span class="co">#&gt; 516     0          MOWER    2.2192      0.2609</span>
<span class="co">#&gt; 517     0         MURRAY    2.5014      0.3988</span>
<span class="co">#&gt; 518     0       NICOLLET    2.1041      0.2480</span>
<span class="co">#&gt; 519     0       NICOLLET    2.3888      0.2480</span>
<span class="co">#&gt; 520     0       NICOLLET    1.4586      0.2480</span>
<span class="co">#&gt; 521     0       NICOLLET    2.7600      0.2480</span>
<span class="co">#&gt; 522     0         NOBLES    1.7047      0.4055</span>
<span class="co">#&gt; 523     0         NOBLES    1.8405      0.4055</span>
<span class="co">#&gt; 524     0         NOBLES    2.2824      0.4055</span>
<span class="co">#&gt; 525     0         NORMAN    2.1041      0.2652</span>
<span class="co">#&gt; 526     0         NORMAN    0.5306      0.2652</span>
<span class="co">#&gt; 527     1         NORMAN    0.5306      0.2652</span>
<span class="co">#&gt; 528     0        OLMSTED    1.8718      0.2432</span>
<span class="co">#&gt; 529     0        OLMSTED    1.5041      0.2432</span>
<span class="co">#&gt; 530     0        OLMSTED    2.4248      0.2432</span>
<span class="co">#&gt; 531     0        OLMSTED    2.3125      0.2432</span>
<span class="co">#&gt; 532     0        OLMSTED    1.5261      0.2432</span>
<span class="co">#&gt; 533     0        OLMSTED    2.0919      0.2432</span>
<span class="co">#&gt; 534     0        OLMSTED    0.8755      0.2432</span>
<span class="co">#&gt; 535     0        OLMSTED    1.1939      0.2432</span>
<span class="co">#&gt; 536     0        OLMSTED    1.6292      0.2432</span>
<span class="co">#&gt; 537     0        OLMSTED    1.4351      0.2432</span>
<span class="co">#&gt; 538     0        OLMSTED    0.1823      0.2432</span>
<span class="co">#&gt; 539     0        OLMSTED    0.7419      0.2432</span>
<span class="co">#&gt; 540     1        OLMSTED    0.1823      0.2432</span>
<span class="co">#&gt; 541     0        OLMSTED    1.0986      0.2432</span>
<span class="co">#&gt; 542     0        OLMSTED    0.7885      0.2432</span>
<span class="co">#&gt; 543     0        OLMSTED    2.0669      0.2432</span>
<span class="co">#&gt; 544     0        OLMSTED    1.3610      0.2432</span>
<span class="co">#&gt; 545     0        OLMSTED    0.9555      0.2432</span>
<span class="co">#&gt; 546     0        OLMSTED    1.0986      0.2432</span>
<span class="co">#&gt; 547     1        OLMSTED    0.5878      0.2432</span>
<span class="co">#&gt; 548     0        OLMSTED    0.9555      0.2432</span>
<span class="co">#&gt; 549     0        OLMSTED    2.2513      0.2432</span>
<span class="co">#&gt; 550     1        OLMSTED   -0.3567      0.2432</span>
<span class="co">#&gt; 551     0      OTTERTAIL    1.0296     -0.2047</span>
<span class="co">#&gt; 552     1      OTTERTAIL    0.1823     -0.2047</span>
<span class="co">#&gt; 553     1      OTTERTAIL    0.7885     -0.2047</span>
<span class="co">#&gt; 554     0      OTTERTAIL    2.4932     -0.2047</span>
<span class="co">#&gt; 555     1      OTTERTAIL    2.5416     -0.2047</span>
<span class="co">#&gt; 556     0      OTTERTAIL    1.1939     -0.2047</span>
<span class="co">#&gt; 557     0      OTTERTAIL    1.4586     -0.2047</span>
<span class="co">#&gt; 558     0      OTTERTAIL    1.3610     -0.2047</span>
<span class="co">#&gt; 559     1     PENNINGTON    1.3350     -0.0740</span>
<span class="co">#&gt; 560     0     PENNINGTON    1.7750     -0.0740</span>
<span class="co">#&gt; 561     1     PENNINGTON   -0.9163     -0.0740</span>
<span class="co">#&gt; 562     0           PINE    1.4351     -0.1633</span>
<span class="co">#&gt; 563     0           PINE    1.0647     -0.1633</span>
<span class="co">#&gt; 564     0           PINE    0.6931     -0.1633</span>
<span class="co">#&gt; 565     1           PINE    0.2624     -0.1633</span>
<span class="co">#&gt; 566     0           PINE    0.2624     -0.1633</span>
<span class="co">#&gt; 567     0           PINE    0.4700     -0.1633</span>
<span class="co">#&gt; 568     0      PIPESTONE    2.2513      0.4786</span>
<span class="co">#&gt; 569     0      PIPESTONE    0.5878      0.4786</span>
<span class="co">#&gt; 570     0      PIPESTONE    2.5014      0.4786</span>
<span class="co">#&gt; 571     1      PIPESTONE    1.4816      0.4786</span>
<span class="co">#&gt; 572     0           POLK    1.9459      0.2661</span>
<span class="co">#&gt; 573     1           POLK    0.4055      0.2661</span>
<span class="co">#&gt; 574     1           POLK    0.9555      0.2661</span>
<span class="co">#&gt; 575     0           POLK    2.2721      0.2661</span>
<span class="co">#&gt; 576     0           POPE    1.3610      0.2811</span>
<span class="co">#&gt; 577     0           POPE    1.2528      0.2811</span>
<span class="co">#&gt; 578     0         RAMSEY    1.9315     -0.4181</span>
<span class="co">#&gt; 579     0         RAMSEY    1.3083     -0.4181</span>
<span class="co">#&gt; 580     0         RAMSEY    0.8329     -0.4181</span>
<span class="co">#&gt; 581     0         RAMSEY    0.9933     -0.4181</span>
<span class="co">#&gt; 582     0         RAMSEY    0.7885     -0.4181</span>
<span class="co">#&gt; 583     0         RAMSEY    1.9601     -0.4181</span>
<span class="co">#&gt; 584     0         RAMSEY    0.2624     -0.4181</span>
<span class="co">#&gt; 585     0         RAMSEY    1.3610     -0.4181</span>
<span class="co">#&gt; 586     0         RAMSEY    1.2809     -0.4181</span>
<span class="co">#&gt; 587     0         RAMSEY    1.4586     -0.4181</span>
<span class="co">#&gt; 588     1         RAMSEY    0.5306     -0.4181</span>
<span class="co">#&gt; 589     1         RAMSEY    1.0647     -0.4181</span>
<span class="co">#&gt; 590     0         RAMSEY    2.1633     -0.4181</span>
<span class="co">#&gt; 591     0         RAMSEY    1.8405     -0.4181</span>
<span class="co">#&gt; 592     0         RAMSEY    1.6677     -0.4181</span>
<span class="co">#&gt; 593     0         RAMSEY    1.0296     -0.4181</span>
<span class="co">#&gt; 594     0         RAMSEY    0.2624     -0.4181</span>
<span class="co">#&gt; 595     0         RAMSEY    1.2809     -0.4181</span>
<span class="co">#&gt; 596     0         RAMSEY    1.7228     -0.4181</span>
<span class="co">#&gt; 597     1         RAMSEY    2.3224     -0.4181</span>
<span class="co">#&gt; 598     0         RAMSEY    1.7228     -0.4181</span>
<span class="co">#&gt; 599     0         RAMSEY    0.2624     -0.4181</span>
<span class="co">#&gt; 600     0         RAMSEY    1.6094     -0.4181</span>
<span class="co">#&gt; 601     0         RAMSEY    1.4110     -0.4181</span>
<span class="co">#&gt; 602     0         RAMSEY    1.2809     -0.4181</span>
<span class="co">#&gt; 603     0         RAMSEY    0.9555     -0.4181</span>
<span class="co">#&gt; 604     0         RAMSEY    0.2624     -0.4181</span>
<span class="co">#&gt; 605     0         RAMSEY    1.0296     -0.4181</span>
<span class="co">#&gt; 606     0         RAMSEY    0.5878     -0.4181</span>
<span class="co">#&gt; 607     0         RAMSEY    1.1632     -0.4181</span>
<span class="co">#&gt; 608     0         RAMSEY   -0.2231     -0.4181</span>
<span class="co">#&gt; 609     0         RAMSEY    0.0953     -0.4181</span>
<span class="co">#&gt; 610     0        REDWOOD    0.6931      0.3663</span>
<span class="co">#&gt; 611     0        REDWOOD    1.3610      0.3663</span>
<span class="co">#&gt; 612     0        REDWOOD    2.1972      0.3663</span>
<span class="co">#&gt; 613     0        REDWOOD    2.0149      0.3663</span>
<span class="co">#&gt; 614     1        REDWOOD    3.0350      0.3663</span>
<span class="co">#&gt; 615     0       RENVILLE    1.8083      0.3806</span>
<span class="co">#&gt; 616     0       RENVILLE    0.7885      0.3806</span>
<span class="co">#&gt; 617     1       RENVILLE    1.7750      0.3806</span>
<span class="co">#&gt; 618     0           RICE    2.2824      0.1931</span>
<span class="co">#&gt; 619     0           RICE    1.8718      0.1931</span>
<span class="co">#&gt; 620     0           RICE    1.5476      0.1931</span>
<span class="co">#&gt; 621     0           RICE    1.7405      0.1931</span>
<span class="co">#&gt; 622     0           RICE    2.9497      0.1931</span>
<span class="co">#&gt; 623     1           RICE    0.9163      0.1931</span>
<span class="co">#&gt; 624     0           RICE    1.1314      0.1931</span>
<span class="co">#&gt; 625     0           RICE    1.6487      0.1931</span>
<span class="co">#&gt; 626     0           RICE    2.0541      0.1931</span>
<span class="co">#&gt; 627     0           RICE    2.1041      0.1931</span>
<span class="co">#&gt; 628     0           RICE    1.5686      0.1931</span>
<span class="co">#&gt; 629     0           ROCK    2.1401      0.5280</span>
<span class="co">#&gt; 630     0           ROCK    0.5306      0.5280</span>
<span class="co">#&gt; 631     1         ROSEAU    1.8083     -0.2120</span>
<span class="co">#&gt; 632     1         ROSEAU    0.1823     -0.2120</span>
<span class="co">#&gt; 633     0         ROSEAU    2.4423     -0.2120</span>
<span class="co">#&gt; 634     1         ROSEAU    1.4816     -0.2120</span>
<span class="co">#&gt; 635     1         ROSEAU    1.3083     -0.2120</span>
<span class="co">#&gt; 636     0         ROSEAU    2.3418     -0.2120</span>
<span class="co">#&gt; 637     1         ROSEAU    1.2528     -0.2120</span>
<span class="co">#&gt; 638     0         ROSEAU    1.1632     -0.2120</span>
<span class="co">#&gt; 639     0         ROSEAU    1.3083     -0.2120</span>
<span class="co">#&gt; 640     0         ROSEAU    1.0296     -0.2120</span>
<span class="co">#&gt; 641     0         ROSEAU    1.4110     -0.2120</span>
<span class="co">#&gt; 642     1         ROSEAU    0.2624     -0.2120</span>
<span class="co">#&gt; 643     1         ROSEAU    0.5878     -0.2120</span>
<span class="co">#&gt; 644     1         ROSEAU    1.4586     -0.2120</span>
<span class="co">#&gt; 645     0        STLOUIS   -0.1054     -0.4747</span>
<span class="co">#&gt; 646     1        STLOUIS   -0.5108     -0.4747</span>
<span class="co">#&gt; 647     0        STLOUIS    0.9163     -0.4747</span>
<span class="co">#&gt; 648     0        STLOUIS    0.8755     -0.4747</span>
<span class="co">#&gt; 649     0        STLOUIS    1.5476     -0.4747</span>
<span class="co">#&gt; 650     0        STLOUIS    2.4069     -0.4747</span>
<span class="co">#&gt; 651     0        STLOUIS    2.7081     -0.4747</span>
<span class="co">#&gt; 652     0        STLOUIS    2.1633     -0.4747</span>
<span class="co">#&gt; 653     0        STLOUIS    1.5261     -0.4747</span>
<span class="co">#&gt; 654     0        STLOUIS    0.4700     -0.4747</span>
<span class="co">#&gt; 655     0        STLOUIS    1.3863     -0.4747</span>
<span class="co">#&gt; 656     0        STLOUIS    0.6419     -0.4747</span>
<span class="co">#&gt; 657     0        STLOUIS    0.5306     -0.4747</span>
<span class="co">#&gt; 658     0        STLOUIS   -0.5108     -0.4747</span>
<span class="co">#&gt; 659     1        STLOUIS   -0.6931     -0.4747</span>
<span class="co">#&gt; 660     1        STLOUIS   -0.5108     -0.4747</span>
<span class="co">#&gt; 661     0        STLOUIS    2.1748     -0.4747</span>
<span class="co">#&gt; 662     1        STLOUIS    0.5306     -0.4747</span>
<span class="co">#&gt; 663     0        STLOUIS    0.4055     -0.4747</span>
<span class="co">#&gt; 664     0        STLOUIS    2.1748     -0.4747</span>
<span class="co">#&gt; 665     0        STLOUIS    2.4159     -0.4747</span>
<span class="co">#&gt; 666     0        STLOUIS    0.4700     -0.4747</span>
<span class="co">#&gt; 667     0        STLOUIS    0.1823     -0.4747</span>
<span class="co">#&gt; 668     1        STLOUIS    0.0000     -0.4747</span>
<span class="co">#&gt; 669     0        STLOUIS   -0.2231     -0.4747</span>
<span class="co">#&gt; 670     0        STLOUIS    1.4586     -0.4747</span>
<span class="co">#&gt; 671     0        STLOUIS    1.2528     -0.4747</span>
<span class="co">#&gt; 672     1        STLOUIS    0.7885     -0.4747</span>
<span class="co">#&gt; 673     0        STLOUIS    1.0986     -0.4747</span>
<span class="co">#&gt; 674     0        STLOUIS    0.6419     -0.4747</span>
<span class="co">#&gt; 675     0        STLOUIS    0.6419     -0.4747</span>
<span class="co">#&gt; 676     0        STLOUIS    0.9163     -0.4747</span>
<span class="co">#&gt; 677     0        STLOUIS    0.5878     -0.4747</span>
<span class="co">#&gt; 678     1        STLOUIS   -0.1054     -0.4747</span>
<span class="co">#&gt; 679     0        STLOUIS    2.4681     -0.4747</span>
<span class="co">#&gt; 680     0        STLOUIS    0.6419     -0.4747</span>
<span class="co">#&gt; 681     0        STLOUIS    1.0647     -0.4747</span>
<span class="co">#&gt; 682     1        STLOUIS    1.2809     -0.4747</span>
<span class="co">#&gt; 683     0        STLOUIS    1.3083     -0.4747</span>
<span class="co">#&gt; 684     0        STLOUIS    1.2809     -0.4747</span>
<span class="co">#&gt; 685     0        STLOUIS    1.1314     -0.4747</span>
<span class="co">#&gt; 686     1        STLOUIS    1.1939     -0.4747</span>
<span class="co">#&gt; 687     0        STLOUIS    1.1632     -0.4747</span>
<span class="co">#&gt; 688     0        STLOUIS    1.2238     -0.4747</span>
<span class="co">#&gt; 689     1        STLOUIS    0.5878     -0.4747</span>
<span class="co">#&gt; 690     0        STLOUIS    1.7405     -0.4747</span>
<span class="co">#&gt; 691     0        STLOUIS    1.2528     -0.4747</span>
<span class="co">#&gt; 692     0        STLOUIS    0.4700     -0.4747</span>
<span class="co">#&gt; 693     0        STLOUIS    3.4751     -0.4747</span>
<span class="co">#&gt; 694     0        STLOUIS    0.1823     -0.4747</span>
<span class="co">#&gt; 695     0        STLOUIS    0.7885     -0.4747</span>
<span class="co">#&gt; 696     0        STLOUIS   -0.1054     -0.4747</span>
<span class="co">#&gt; 697     0        STLOUIS    0.4700     -0.4747</span>
<span class="co">#&gt; 698     0        STLOUIS    0.3365     -0.4747</span>
<span class="co">#&gt; 699     0        STLOUIS    1.1632     -0.4747</span>
<span class="co">#&gt; 700     0        STLOUIS    1.9879     -0.4747</span>
<span class="co">#&gt; 701     0        STLOUIS    0.4055     -0.4747</span>
<span class="co">#&gt; 702     0        STLOUIS    0.3365     -0.4747</span>
<span class="co">#&gt; 703     0        STLOUIS    0.4700     -0.4747</span>
<span class="co">#&gt; 704     0        STLOUIS    1.6292     -0.4747</span>
<span class="co">#&gt; 705     0        STLOUIS    0.8755     -0.4747</span>
<span class="co">#&gt; 706     0        STLOUIS    0.9163     -0.4747</span>
<span class="co">#&gt; 707     0        STLOUIS    0.2624     -0.4747</span>
<span class="co">#&gt; 708     0        STLOUIS    1.7047     -0.4747</span>
<span class="co">#&gt; 709     0        STLOUIS    0.1823     -0.4747</span>
<span class="co">#&gt; 710     0        STLOUIS    0.4055     -0.4747</span>
<span class="co">#&gt; 711     1        STLOUIS    1.9879     -0.4747</span>
<span class="co">#&gt; 712     0        STLOUIS    0.1823     -0.4747</span>
<span class="co">#&gt; 713     0        STLOUIS    1.2238     -0.4747</span>
<span class="co">#&gt; 714     0        STLOUIS    1.1939     -0.4747</span>
<span class="co">#&gt; 715     0        STLOUIS    0.4700     -0.4747</span>
<span class="co">#&gt; 716     0        STLOUIS    1.3083     -0.4747</span>
<span class="co">#&gt; 717     0        STLOUIS   -0.1054     -0.4747</span>
<span class="co">#&gt; 718     0        STLOUIS    0.5306     -0.4747</span>
<span class="co">#&gt; 719     0        STLOUIS    0.4055     -0.4747</span>
<span class="co">#&gt; 720     0        STLOUIS    1.0296     -0.4747</span>
<span class="co">#&gt; 721     0        STLOUIS    1.2238     -0.4747</span>
<span class="co">#&gt; 722     0        STLOUIS    0.0000     -0.4747</span>
<span class="co">#&gt; 723     0        STLOUIS   -0.3567     -0.4747</span>
<span class="co">#&gt; 724     0        STLOUIS    0.7419     -0.4747</span>
<span class="co">#&gt; 725     0        STLOUIS    0.6931     -0.4747</span>
<span class="co">#&gt; 726     0        STLOUIS    0.0000     -0.4747</span>
<span class="co">#&gt; 727     0        STLOUIS    1.7047     -0.4747</span>
<span class="co">#&gt; 728     0        STLOUIS    0.4700     -0.4747</span>
<span class="co">#&gt; 729     0        STLOUIS    1.1632     -0.4747</span>
<span class="co">#&gt; 730     0        STLOUIS    0.6419     -0.4747</span>
<span class="co">#&gt; 731     1        STLOUIS    0.0000     -0.4747</span>
<span class="co">#&gt; 732     0        STLOUIS    1.2238     -0.4747</span>
<span class="co">#&gt; 733     0        STLOUIS    0.5878     -0.4747</span>
<span class="co">#&gt; 734     0        STLOUIS    1.1632     -0.4747</span>
<span class="co">#&gt; 735     1        STLOUIS   -0.2231     -0.4747</span>
<span class="co">#&gt; 736     0        STLOUIS    1.4816     -0.4747</span>
<span class="co">#&gt; 737     0        STLOUIS    0.4055     -0.4747</span>
<span class="co">#&gt; 738     0        STLOUIS    0.6419     -0.4747</span>
<span class="co">#&gt; 739     0        STLOUIS    0.4700     -0.4747</span>
<span class="co">#&gt; 740     1        STLOUIS    0.8329     -0.4747</span>
<span class="co">#&gt; 741     0        STLOUIS    0.9163     -0.4747</span>
<span class="co">#&gt; 742     0        STLOUIS    1.0296     -0.4747</span>
<span class="co">#&gt; 743     0        STLOUIS    0.5878     -0.4747</span>
<span class="co">#&gt; 744     1        STLOUIS    0.1823     -0.4747</span>
<span class="co">#&gt; 745     1        STLOUIS    0.6419     -0.4747</span>
<span class="co">#&gt; 746     0        STLOUIS   -1.2040     -0.4747</span>
<span class="co">#&gt; 747     0        STLOUIS    0.8329     -0.4747</span>
<span class="co">#&gt; 748     0        STLOUIS    1.5476     -0.4747</span>
<span class="co">#&gt; 749     0        STLOUIS    0.7885     -0.4747</span>
<span class="co">#&gt; 750     0        STLOUIS    0.7419     -0.4747</span>
<span class="co">#&gt; 751     0        STLOUIS   -0.2231     -0.4747</span>
<span class="co">#&gt; 752     0        STLOUIS    1.8718     -0.4747</span>
<span class="co">#&gt; 753     0        STLOUIS    1.1314     -0.4747</span>
<span class="co">#&gt; 754     0        STLOUIS    0.7419     -0.4747</span>
<span class="co">#&gt; 755     0        STLOUIS    0.0000     -0.4747</span>
<span class="co">#&gt; 756     0        STLOUIS    1.2238     -0.4747</span>
<span class="co">#&gt; 757     0        STLOUIS    0.6419     -0.4747</span>
<span class="co">#&gt; 758     0        STLOUIS    0.6419     -0.4747</span>
<span class="co">#&gt; 759     0        STLOUIS    0.8329     -0.4747</span>
<span class="co">#&gt; 760     0        STLOUIS    1.4816     -0.4747</span>
<span class="co">#&gt; 761     1          SCOTT    2.9653      0.0631</span>
<span class="co">#&gt; 762     1          SCOTT    2.2192      0.0631</span>
<span class="co">#&gt; 763     0          SCOTT    0.7419      0.0631</span>
<span class="co">#&gt; 764     0          SCOTT    2.4423      0.0631</span>
<span class="co">#&gt; 765     0          SCOTT    2.3321      0.0631</span>
<span class="co">#&gt; 766     1          SCOTT    0.7885      0.0631</span>
<span class="co">#&gt; 767     0          SCOTT    0.2624      0.0631</span>
<span class="co">#&gt; 768     0          SCOTT    1.1939      0.0631</span>
<span class="co">#&gt; 769     1          SCOTT    0.7419      0.0631</span>
<span class="co">#&gt; 770     0          SCOTT    1.4816      0.0631</span>
<span class="co">#&gt; 771     0          SCOTT    0.8329      0.0631</span>
<span class="co">#&gt; 772     0          SCOTT    1.7047      0.0631</span>
<span class="co">#&gt; 773     0          SCOTT    3.2308      0.0631</span>
<span class="co">#&gt; 774     0      SHERBURNE    1.6487     -0.6834</span>
<span class="co">#&gt; 775     0      SHERBURNE    0.8755     -0.6834</span>
<span class="co">#&gt; 776     0      SHERBURNE    1.1939     -0.6834</span>
<span class="co">#&gt; 777     0      SHERBURNE    0.9555     -0.6834</span>
<span class="co">#&gt; 778     0      SHERBURNE    1.0647     -0.6834</span>
<span class="co">#&gt; 779     0      SHERBURNE    1.1632     -0.6834</span>
<span class="co">#&gt; 780     0      SHERBURNE    0.5306     -0.6834</span>
<span class="co">#&gt; 781     0      SHERBURNE    1.5686     -0.6834</span>
<span class="co">#&gt; 782     0         SIBLEY    1.4110      0.2372</span>
<span class="co">#&gt; 783     0         SIBLEY    1.6292      0.2372</span>
<span class="co">#&gt; 784     0         SIBLEY    0.4700      0.2372</span>
<span class="co">#&gt; 785     0         SIBLEY    1.5892      0.2372</span>
<span class="co">#&gt; 786     0        STEARNS    2.0281      0.1164</span>
<span class="co">#&gt; 787     0        STEARNS    1.8718      0.1164</span>
<span class="co">#&gt; 788     0        STEARNS    2.1282      0.1164</span>
<span class="co">#&gt; 789     0        STEARNS    0.7885      0.1164</span>
<span class="co">#&gt; 790     0        STEARNS    1.2238      0.1164</span>
<span class="co">#&gt; 791     0        STEARNS    0.3365      0.1164</span>
<span class="co">#&gt; 792     0        STEARNS    1.6292      0.1164</span>
<span class="co">#&gt; 793     1        STEARNS    0.0953      0.1164</span>
<span class="co">#&gt; 794     0        STEARNS    1.9601      0.1164</span>
<span class="co">#&gt; 795     0        STEARNS    1.7579      0.1164</span>
<span class="co">#&gt; 796     0        STEARNS    2.3224      0.1164</span>
<span class="co">#&gt; 797     0        STEARNS    1.9021      0.1164</span>
<span class="co">#&gt; 798     1        STEARNS    0.9933      0.1164</span>
<span class="co">#&gt; 799     0        STEARNS    1.2238      0.1164</span>
<span class="co">#&gt; 800     1        STEARNS    0.4700      0.1164</span>
<span class="co">#&gt; 801     0        STEARNS    1.6292      0.1164</span>
<span class="co">#&gt; 802     0        STEARNS    2.0149      0.1164</span>
<span class="co">#&gt; 803     0        STEARNS    2.6810      0.1164</span>
<span class="co">#&gt; 804     0        STEARNS    0.6419      0.1164</span>
<span class="co">#&gt; 805     0        STEARNS    2.0149      0.1164</span>
<span class="co">#&gt; 806     0        STEARNS    0.9933      0.1164</span>
<span class="co">#&gt; 807     0        STEARNS    1.3350      0.1164</span>
<span class="co">#&gt; 808     0        STEARNS    0.6931      0.1164</span>
<span class="co">#&gt; 809     1        STEARNS    0.8329      0.1164</span>
<span class="co">#&gt; 810     0        STEARNS    1.6292      0.1164</span>
<span class="co">#&gt; 811     0         STEELE    2.0015      0.2698</span>
<span class="co">#&gt; 812     0         STEELE    1.3350      0.2698</span>
<span class="co">#&gt; 813     0         STEELE    1.0986      0.2698</span>
<span class="co">#&gt; 814     0         STEELE    1.5041      0.2698</span>
<span class="co">#&gt; 815     0         STEELE    2.1401      0.2698</span>
<span class="co">#&gt; 816     0         STEELE    1.6487      0.2698</span>
<span class="co">#&gt; 817     0         STEELE    1.3083      0.2698</span>
<span class="co">#&gt; 818     0         STEELE    0.4700      0.2698</span>
<span class="co">#&gt; 819     0         STEELE    2.1633      0.2698</span>
<span class="co">#&gt; 820     0         STEELE    2.3702      0.2698</span>
<span class="co">#&gt; 821     0        STEVENS    2.0919      0.4708</span>
<span class="co">#&gt; 822     0        STEVENS    1.5261      0.4708</span>
<span class="co">#&gt; 823     0          SWIFT    1.1314      0.3160</span>
<span class="co">#&gt; 824     0          SWIFT    0.9163      0.3160</span>
<span class="co">#&gt; 825     0          SWIFT    0.4700      0.3160</span>
<span class="co">#&gt; 826     0          SWIFT    1.5892      0.3160</span>
<span class="co">#&gt; 827     0           TODD    1.9315     -0.0468</span>
<span class="co">#&gt; 828     0           TODD    0.7885     -0.0468</span>
<span class="co">#&gt; 829     1           TODD    1.8083     -0.0468</span>
<span class="co">#&gt; 830     1       TRAVERSE    1.0986      0.4976</span>
<span class="co">#&gt; 831     0       TRAVERSE    1.9169      0.4976</span>
<span class="co">#&gt; 832     0       TRAVERSE    2.9653      0.4976</span>
<span class="co">#&gt; 833     0       TRAVERSE    1.4110      0.4976</span>
<span class="co">#&gt; 834     0        WABASHA    1.7918      0.1501</span>
<span class="co">#&gt; 835     0        WABASHA    2.2083      0.1501</span>
<span class="co">#&gt; 836     0        WABASHA    2.1401      0.1501</span>
<span class="co">#&gt; 837     1        WABASHA    0.1823      0.1501</span>
<span class="co">#&gt; 838     0        WABASHA    1.1632      0.1501</span>
<span class="co">#&gt; 839     0        WABASHA    2.4510      0.1501</span>
<span class="co">#&gt; 840     0        WABASHA    2.2721      0.1501</span>
<span class="co">#&gt; 841     0         WADENA    1.0986     -0.6720</span>
<span class="co">#&gt; 842     1         WADENA   -0.2231     -0.6720</span>
<span class="co">#&gt; 843     1         WADENA    1.1939     -0.6720</span>
<span class="co">#&gt; 844     0         WADENA    1.5686     -0.6720</span>
<span class="co">#&gt; 845     0         WADENA    1.5892     -0.6720</span>
<span class="co">#&gt; 846     0         WASECA   -0.6931      0.2124</span>
<span class="co">#&gt; 847     0         WASECA    2.2407      0.2124</span>
<span class="co">#&gt; 848     0         WASECA    0.5878      0.2124</span>
<span class="co">#&gt; 849     1         WASECA    0.0000      0.2124</span>
<span class="co">#&gt; 850     0     WASHINGTON    2.3321     -0.1475</span>
<span class="co">#&gt; 851     0     WASHINGTON    2.0541     -0.1475</span>
<span class="co">#&gt; 852     0     WASHINGTON    0.8329     -0.1475</span>
<span class="co">#&gt; 853     0     WASHINGTON    1.8871     -0.1475</span>
<span class="co">#&gt; 854     0     WASHINGTON    2.5096     -0.1475</span>
<span class="co">#&gt; 855     0     WASHINGTON    1.5476     -0.1475</span>
<span class="co">#&gt; 856     0     WASHINGTON    1.8405     -0.1475</span>
<span class="co">#&gt; 857     0     WASHINGTON    1.8871     -0.1475</span>
<span class="co">#&gt; 858     0     WASHINGTON    1.0647     -0.1475</span>
<span class="co">#&gt; 859     0     WASHINGTON    0.6931     -0.1475</span>
<span class="co">#&gt; 860     1     WASHINGTON    0.2624     -0.1475</span>
<span class="co">#&gt; 861     0     WASHINGTON    0.9163     -0.1475</span>
<span class="co">#&gt; 862     0     WASHINGTON    0.0953     -0.1475</span>
<span class="co">#&gt; 863     1     WASHINGTON    0.2624     -0.1475</span>
<span class="co">#&gt; 864     0     WASHINGTON    0.5306     -0.1475</span>
<span class="co">#&gt; 865     0     WASHINGTON   -0.1054     -0.1475</span>
<span class="co">#&gt; 866     0     WASHINGTON    0.5878     -0.1475</span>
<span class="co">#&gt; 867     0     WASHINGTON    1.5686     -0.1475</span>
<span class="co">#&gt; 868     1     WASHINGTON    0.5878     -0.1475</span>
<span class="co">#&gt; 869     0     WASHINGTON    1.2238     -0.1475</span>
<span class="co">#&gt; 870     1     WASHINGTON   -0.1054     -0.1475</span>
<span class="co">#&gt; 871     0     WASHINGTON    2.2925     -0.1475</span>
<span class="co">#&gt; 872     0     WASHINGTON    1.6864     -0.1475</span>
<span class="co">#&gt; 873     0     WASHINGTON    2.1518     -0.1475</span>
<span class="co">#&gt; 874     0     WASHINGTON    0.6931     -0.1475</span>
<span class="co">#&gt; 875     0     WASHINGTON    1.9021     -0.1475</span>
<span class="co">#&gt; 876     0     WASHINGTON    1.3610     -0.1475</span>
<span class="co">#&gt; 877     0     WASHINGTON    1.7918     -0.1475</span>
<span class="co">#&gt; 878     0     WASHINGTON    1.6094     -0.1475</span>
<span class="co">#&gt; 879     1     WASHINGTON    0.9555     -0.1475</span>
<span class="co">#&gt; 880     0     WASHINGTON    2.3795     -0.1475</span>
<span class="co">#&gt; 881     0     WASHINGTON    0.9163     -0.1475</span>
<span class="co">#&gt; 882     0     WASHINGTON    0.7885     -0.1475</span>
<span class="co">#&gt; 883     0     WASHINGTON    1.5686     -0.1475</span>
<span class="co">#&gt; 884     0     WASHINGTON    1.3350     -0.1475</span>
<span class="co">#&gt; 885     0     WASHINGTON    2.6027     -0.1475</span>
<span class="co">#&gt; 886     0     WASHINGTON    1.0986     -0.1475</span>
<span class="co">#&gt; 887     0     WASHINGTON    1.4816     -0.1475</span>
<span class="co">#&gt; 888     0     WASHINGTON    1.3610     -0.1475</span>
<span class="co">#&gt; 889     0     WASHINGTON    0.6419     -0.1475</span>
<span class="co">#&gt; 890     0     WASHINGTON    0.4700     -0.1475</span>
<span class="co">#&gt; 891     0     WASHINGTON    0.6419     -0.1475</span>
<span class="co">#&gt; 892     0     WASHINGTON    0.3365     -0.1475</span>
<span class="co">#&gt; 893     0     WASHINGTON    1.9021     -0.1475</span>
<span class="co">#&gt; 894     0     WASHINGTON    3.0204     -0.1475</span>
<span class="co">#&gt; 895     0     WASHINGTON    1.8083     -0.1475</span>
<span class="co">#&gt; 896     0       WATONWAN    2.6319      0.1832</span>
<span class="co">#&gt; 897     1       WATONWAN    2.3321      0.1832</span>
<span class="co">#&gt; 898     1       WATONWAN    1.7579      0.1832</span>
<span class="co">#&gt; 899     0         WILKIN    2.2407      0.2360</span>
<span class="co">#&gt; 900     0         WINONA    1.2528      0.4632</span>
<span class="co">#&gt; 901     0         WINONA    1.4351      0.4632</span>
<span class="co">#&gt; 902     0         WINONA    2.4596      0.4632</span>
<span class="co">#&gt; 903     0         WINONA    1.9879      0.4632</span>
<span class="co">#&gt; 904     0         WINONA    1.5686      0.4632</span>
<span class="co">#&gt; 905     1         WINONA    0.6419      0.4632</span>
<span class="co">#&gt; 906     1         WINONA   -0.2231      0.4632</span>
<span class="co">#&gt; 907     0         WINONA    1.5686      0.4632</span>
<span class="co">#&gt; 908     0         WINONA    2.3321      0.4632</span>
<span class="co">#&gt; 909     0         WINONA    2.4336      0.4632</span>
<span class="co">#&gt; 910     0         WINONA    2.0412      0.4632</span>
<span class="co">#&gt; 911     0         WINONA    2.4765      0.4632</span>
<span class="co">#&gt; 912     1         WINONA   -0.5108      0.4632</span>
<span class="co">#&gt; 913     0         WRIGHT    1.9169     -0.0900</span>
<span class="co">#&gt; 914     0         WRIGHT    1.6864     -0.0900</span>
<span class="co">#&gt; 915     0         WRIGHT    1.1632     -0.0900</span>
<span class="co">#&gt; 916     0         WRIGHT    0.7885     -0.0900</span>
<span class="co">#&gt; 917     0         WRIGHT    2.0015     -0.0900</span>
<span class="co">#&gt; 918     0         WRIGHT    1.6487     -0.0900</span>
<span class="co">#&gt; 919     0         WRIGHT    0.8329     -0.0900</span>
<span class="co">#&gt; 920     1         WRIGHT    0.8755     -0.0900</span>
<span class="co">#&gt; 921     0         WRIGHT    2.7726     -0.0900</span>
<span class="co">#&gt; 922     0         WRIGHT    2.2618     -0.0900</span>
<span class="co">#&gt; 923     0         WRIGHT    1.8718     -0.0900</span>
<span class="co">#&gt; 924     0         WRIGHT    1.5261     -0.0900</span>
<span class="co">#&gt; 925     0         WRIGHT    1.6292     -0.0900</span>
<span class="co">#&gt; 926     0 YELLOWMEDICINE    1.3350      0.3553</span>
<span class="co">#&gt; 927     0 YELLOWMEDICINE    1.0986      0.3553</span></code></pre></div>
<p>The data consist of 919 observations of radon levels of houses from 85 counties.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">radon_county &lt;-<span class="st"> </span>radon <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(county) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">log_radon_mean =</span> <span class="kw">mean</span>(log_radon),
            <span class="dt">log_radon_sd =</span> <span class="kw">sd</span>(log_radon), 
            <span class="dt">log_uranium =</span> <span class="kw">mean</span>(log_uranium),
            <span class="dt">n =</span> <span class="kw">length</span>(county))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> radon,
             <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> log_radon, <span class="dt">x =</span> <span class="kw">fct_reorder</span>(county, log_radon, mean))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> radon_county,
             <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(county, log_radon_mean), <span class="dt">y =</span> log_radon_mean),
             <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;log(radon)&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;&quot;</span>)</code></pre></div>
<p><img src="multilevel_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Relationship between mean and sample size</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(radon_county, <span class="kw">aes</span>(<span class="dt">y =</span> log_radon_mean, <span class="dt">x =</span> <span class="kw">log2</span>(n))) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="multilevel_files/figure-html/unnamed-chunk-6-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="varying-intercepts-models" class="section level3">
<h3><span class="header-section-number">15.1.2</span> Varying Intercepts Models</h3>
<p>Consider the general model with an intercept for each county representing the baseline average of the county: <span class="math display">\[
\begin{aligned}
y_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta x_i
\end{aligned}
\]</span> where <span class="math inline">\(j[i]\)</span> means that observation <span class="math inline">\(i\)</span> is in county <span class="math inline">\(j \in (1, \dots, 85)\)</span>.</p>
<p>In this particular example, <span class="math inline">\(y = \mathtt{log_radon}\)</span> and <span class="math inline">\(x = \mathtt{basement}\)</span>. <span class="math display">\[
\begin{aligned}
\mathtt{log\_radon}_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta~\mathtt{basement}_i
\end{aligned}
\]</span></p>
<p>We can put a prior distribution on <span class="math inline">\(\alpha_{j[i]}\)</span>, <span class="math display">\[
\begin{aligned}[t]
\alpha_{j} &amp;\sim N(\gamma, \tau) &amp; \text{for $i \in (1, \dots, 85)$}
\end{aligned}
\]</span> This parameterization nests common cases,</p>
<p><em>Complete pooling:</em> When <span class="math inline">\(\tau \to 0\)</span>, the intercepts are the same, <span class="math display">\[
\begin{aligned}[t]
\alpha_j &amp;= \gamma  &amp; \text{for all $j$.}
\end{aligned}
\]</span></p>
<p><em>No pooling:</em> When <span class="math inline">\(\tau \to \infty\)</span>, prior distribution on the intercepts is equivalent to an improper normal distribution, and there is no shrinkage, <span class="math display">\[
p(\alpha_j) \propto 1,
\]</span> for all <span class="math inline">\(j\)</span>.</p>
<p><em>Partial pooling:</em> When <span class="math inline">\(\tau\)</span> is a parameter, the amount of shrinkage can be estimated from the data. A common prior is <span class="math inline">\(\tau \sim N(0, 2.5)\)</span>, <span class="math display">\[
\tau \sim N^{+}(0, 2.5) .
\]</span></p>
<p>The partial pooling model</p>
</div>
<div id="varying-intercept-model" class="section level3">
<h3><span class="header-section-number">15.1.3</span> Varying Intercept Model</h3>
</div>
<div id="varying-slope-model" class="section level3">
<h3><span class="header-section-number">15.1.4</span> Varying Slope Model</h3>
<p><span class="math display">\[
\begin{aligned}
\mathtt{log\_radon}_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta_{j[i]}~\mathtt{basement}_i
\end{aligned}
\]</span></p>
</div>
<div id="group-level-predictors" class="section level3">
<h3><span class="header-section-number">15.1.5</span> Group Level Predictors</h3>
<p>The <code>radon</code> dataset also contains the county-level measurements of <code>uranium</code>.</p>
<p>One way to include county level measurements is to model the county-level intercepts. The values of each county intercept is a function of the county-level uranium. <span class="math display">\[
\begin{aligned}
\mathtt{log\_radon}_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta_{j[i]}~\mathtt{basement}_i
\alpha_{j} \sim  N(\gamma_0 + \gamma_1~\mathtt{log\_uranium}_j, \tau)
\end{aligned}
\]</span></p>
<p>Alternatively, we can model model the county-level intercepts. The values of each county intercept is a function of the county-level uranium. <span class="math display">\[
\begin{aligned}
\mathtt{log\_radon}_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta_{j[i]}~\mathtt{basement}_i \\
\alpha_{j} &amp;\sim  N(\gamma_0 + \gamma_1~\mathtt{log\_uranium}_j, \tau)
\end{aligned}
\]</span></p>
</div>
<div id="lme4" class="section level3">
<h3><span class="header-section-number">15.1.6</span> lme4</h3>
<p>In R, the most widely used package to estimate mixed-effects models is <strong>lme4</strong>. This esimates models using maximum likelihood or restricted maximum likelihood methods (REML). This will be faster than using full-Bayesian methods but also underestimate the uncertainty, as well as being a worse approximation of the posterior. Additionally, in frequentist inference, the meaning of the random effects is different; they are nuisance parameters and not given standard errors.</p>
<p>See <span class="citation">Bates (2010)</span> and <span class="citation">Bates et al. (2014)</span> for introductions to mixed-effects models with <strong>lme4</strong>. These are also good introductions to classical approaches to mixed effects models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;lme4&quot;</span>)
<span class="co">#&gt; Loading required package: Matrix</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;Matrix&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:tidyr&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     expand</span></code></pre></div>
<p>Complete pooling</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_pooled &lt;-<span class="st"> </span><span class="kw">lm</span>(log_radon <span class="op">~</span><span class="st"> </span>county <span class="op">+</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</code></pre></div>
<p>County-varying intercepts with no-pooling</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_intercept_nopool &lt;-<span class="st"> </span><span class="kw">lm</span>(log_radon <span class="op">~</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</code></pre></div>
<p>County-varying intercepts with partial-pooling</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_intercept_partial &lt;-<span class="st"> </span><span class="kw">lmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</code></pre></div>
<p>Varying slopes with no pooling:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_nopool &lt;-<span class="st"> </span><span class="kw">lm</span>(log_radon <span class="op">~</span><span class="st"> </span>county <span class="op">*</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</code></pre></div>
<p>Varying slopes with partial pooling:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">lmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>floor <span class="op">|</span><span class="st"> </span>county), <span class="dt">data =</span> radon)</code></pre></div>
<p>Including a county-level variable (<code>log_uranium</code>) in various models:</p>
<p>With no-pooling,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">lm</span>(log_radon <span class="op">~</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span>log_uranium, <span class="dt">data =</span> radon)</code></pre></div>
<p>With varying-intercepts</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">lmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span>log_uranium, <span class="dt">data =</span> radon)</code></pre></div>
<p>With varying-intercepts and slopes,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">lmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>floor <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st">  </span>log_uranium, <span class="dt">data =</span> radon)</code></pre></div>
</div>
<div id="rstanarm" class="section level3">
<h3><span class="header-section-number">15.1.7</span> rstanarm</h3>
<p>Some multilevel models can also be estimated using the <strong>rstanarm</strong> functions <code>stan_glmer</code> and <code>stan_lmer</code>. These functions have syntax similar to <strong>lme4</strong> functions, but estimate the mixed models using Bayesian methods with Stan.</p>
<p>Complete pooling</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_pooled &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(log_radon <span class="op">~</span><span class="st"> </span>county <span class="op">+</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</code></pre></div>
<p>County-varying intercepts with no-pooling</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_intercept_nopool &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(log_radon <span class="op">~</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</code></pre></div>
<p>County-varying intercepts with partial-pooling</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_intercept_partial &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</code></pre></div>
<p>Varying slopes with no pooling. <em>There is an error estimating this</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_nopool &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(log_radon <span class="op">~</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>county <span class="op">+</span><span class="st"> </span>county<span class="op">:</span>floor, <span class="dt">data =</span> radon,
                             <span class="dt">prior =</span> <span class="kw">normal</span>(<span class="dt">scale =</span> <span class="dv">1</span>))</code></pre></div>
<p>Varying slopes with partial pooling:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>floor <span class="op">|</span><span class="st"> </span>county), <span class="dt">data =</span> radon)</code></pre></div>
<p>Including a county-level variable (<code>log_uranium</code>) in various models:</p>
<p>With no-pooling,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(log_radon <span class="op">~</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span>log_uranium, <span class="dt">data =</span> radon)</code></pre></div>
<p>With varying-intercepts</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span>log_uranium, <span class="dt">data =</span> radon)</code></pre></div>
<p>With varying-intercepts and slopes,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>floor <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st">  </span>log_uranium, <span class="dt">data =</span> radon)</code></pre></div>
</div>
</div>
<div id="pooling-of-hierarchical-parameters" class="section level2">
<h2><span class="header-section-number">15.2</span> Pooling of Hierarchical Parameters</h2>
<p>This is easiest understood in the case of a model of group means, <span class="math display">\[
\begin{aligned}[t]
y &amp;\sim \dnorm(\mu_{j[i]}, \sigma^2) \\
\mu_{j} &amp;\sim \dnorm(\gamma, \tau^2) .
\end{aligned}
\]</span> Each group has size <span class="math inline">\(n_j\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="left">Sample size, <span class="math inline">\(n_j\)</span></th>
<th align="left">Estimate of <span class="math inline">\(\hat{\mu}_j\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(n_j = 0\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j = \gamma\)</span> (complete pooling)</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(n_j &lt; \frac{\sigma^2}{\tau^2}\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j\)</span> closer to <span class="math inline">\(\gamma\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(n_j = \frac{\sigma^2}{\tau^2}\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j = \frac{1}{2} \bar{y}_j + \frac{1}{2} \gamma\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(n_j &gt; \frac{\sigma^2}{\tau^2}\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j\)</span> closer to <span class="math inline">\(\bar{y}_j\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(n_j = \infty\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j = \bar{y}_j\)</span> (no pooling)</td>
</tr>
</tbody>
</table>
<p>If the hyperparameters were known, the posterior of <span class="math inline">\(\mu_j\)</span> is <span class="math display">\[
\mu_j | y, \gamma, \sigma, \tau \sim \dnorm(\hat{\mu}_j, V_j)
\]</span> where <span class="math display">\[
\begin{aligned}[t]
\hat{\mu}_j &amp;= \frac{\frac{n_j}{\sigma^2} \bar{y}_j + \frac{1}{\tau^2} \gamma}{\frac{n_j}{\sigma^2} + \frac{1}{\tau^2}} \\
V_j &amp;= \frac{1}{\frac{n_j}{\sigma^2} + \frac{1}{\tau^2}}
\end{aligned}
\]</span></p>
<p>Some crude estimates given <span class="math inline">\(\mu_j\)</span>.</p>
<p>The <em>data variance</em>, <span class="math inline">\(\sigma^2\)</span>, is the residual variance, <span class="math display">\[
\E(\sigma^2 | y, \mu)  = \frac{1}{n} \sum_{i = 1}^n (y - \mu_{j[i]})^2 .
\]</span> The global mean is approximately the average of the group-level means, <span class="math display">\[
\begin{aligned}[t]
\E(\gamma | y, \mu) &amp;= \frac{1}{J} \sum_{i = 1}^n \mu_j \\
\Var(\gamma | y, \mu) &amp;= \frac{1}{J} \tau^2
\end{aligned}
\]</span> The group level variance is <span class="math inline">\(\tau^2\)</span> is, <span class="math display">\[
\E(\tau^ | y, \mu) = \frac{1}{J} \sum_{j = 1}^J (\mu_j - \gamma)^2
\]</span></p>
</div>
<div id="extensions" class="section level2">
<h2><span class="header-section-number">15.3</span> Extensions</h2>
<ul>
<li>Including group-level covariates</li>
<li>Prior distributions</li>
<li><p>Prediction</p>
<ul>
<li>new obs in existing groups</li>
<li>new group</li>
<li>new obs in new group</li>
</ul></li>
<li>Modeling correlation between intercept and slopes</li>
<li><p>Non-nested models</p></li>
</ul>
</div>
<div id="references-9" class="section level2">
<h2><span class="header-section-number">15.4</span> References</h2>
<p>Texts:</p>
<ul>
<li><span class="citation">Gelman and Hill (2007 Ch. 11-17)</span>.</li>
<li><span class="citation">Gelman et al. (2013 Ch 5)</span> “Hierarchical Models”</li>
<li><span class="citation">Gelman et al. (2013 Ch 15)</span> “Hierarchical Linear Models”</li>
</ul>
<p>Other</p>
<ul>
<li>Stan models for <a href="https://github.com/stan-dev/example-models/wiki/ARM-Models">ARM</a></li>
<li><a href="http://mc-stan.org/documentation/case-studies/radon.html" class="uri">http://mc-stan.org/documentation/case-studies/radon.html</a></li>
<li><a href="https://biologyforfun.wordpress.com/2016/12/08/crossed-and-nested-hierarchical-models-with-stan-and-r/" class="uri">https://biologyforfun.wordpress.com/2016/12/08/crossed-and-nested-hierarchical-models-with-stan-and-r/</a></li>
</ul>

</div>
</div>



<span class="kw">library</span>(<span class="st">&quot;stringr&quot;</span>)</code></pre></div>
<div id="parameters" class="section level2">
<h2><span class="header-section-number">15.5</span> Parameters</h2>
<table>
<thead>
<tr class="header">
<th align="left">Category</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">modeled data</td>
<td align="left">Data, assigned distribution</td>
</tr>
<tr class="even">
<td align="left">unmodeled data</td>
<td align="left">Data not given a distribution</td>
</tr>
<tr class="odd">
<td align="left">modeled parameters</td>
<td align="left">Parameters with an informative prior distribution</td>
</tr>
<tr class="even">
<td align="left">unmodeled parameters</td>
<td align="left">Parameters with non-informative prior distribution</td>
</tr>
<tr class="odd">
<td align="left">derived quantities</td>
<td align="left">Variables defined deterministicically</td>
</tr>
</tbody>
</table>
<p>See <span class="citation">Gelman and Hill (2007, 366)</span></p>
</div>
<div id="miscellaneous-mathematical-background" class="section level2">
<h2><span class="header-section-number">15.6</span> Miscellaneous Mathematical Background</h2>
<div id="location-scale-families" class="section level3">
<h3><span class="header-section-number">15.6.1</span> Location-Scale Families</h3>
<p>In a <a href="https://en.wikipedia.org/wiki/Location%E2%80%93scale_family">location-scale family</a> of distributions, if the random variable <span class="math inline">\(X\)</span> is distributed with mean 0 and standard deviation 1, then the random variable <span class="math inline">\(Y\)</span>, <span class="math display">\[
Y = \mu + \sigma X ,
\]</span> has mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p><strong>Normal distribution:</strong> Suppose <span class="math inline">\(X \sim \dnorm(0, 1)\)</span>, then <span class="math display">\[
Y = \mu + \sigma X,
\]</span> is equivalent to <span class="math inline">\(Y \sim \dnorm(\mu, \sigma)\)</span> (normal with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>).</p>
<p>** Student-t distribution** (including Cauchy): <span class="math display">\[
\begin{aligned}[t]
X &amp;\sim \dt{\nu}(0, 1) \\
Y &amp;= \mu + \sigma X 
\end{aligned}
\]</span> implies <span class="math display">\[
Y \sim \dt{\nu}(\mu, \sigma),
\]</span> i.e. <span class="math inline">\(Y\)</span> is distributed Student-<span class="math inline">\(t\)</span> with location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\sigma\)</span>.</p>
<p>In Stan, it can be useful parameterize distributions in terms of a mean 0, scale 1 parameters, and separate parameters for the locations and scales. E.g. with normal distributions,</p>
<pre><code>parameters {
  real mu;
  real&lt;lower = 0.0&gt; sigma;
  vector[n] eps;
}
transformed parameters {
  vector[n] y;
  y = mu + sigma * eps;
}
model {
  eps ~ normal(0.0, 1.0);
}</code></pre>
</div>
<div id="scale-mixtures-of-normal-distributions" class="section level3">
<h3><span class="header-section-number">15.6.2</span> Scale Mixtures of Normal Distributions</h3>
<p>Some commonly used distributions can be represented as scale mixtures of normal distributions. For formal details of scale mixtures of normal distributions see <span class="citation">West (1987)</span>. Distributions that are scale-mixtures of normal distributions can be written as, <span class="math display">\[
Y \sim \dnorm(\mu, \sigma_i^2) \\
\sigma_i \sim \pi(\sigma_i)
\]</span> As its name suggests, the individual variances (scales) themselves, have a distribution.</p>
<p>Some examples:</p>
<ul>
<li>Student-t</li>
<li>Double Exponential</li>
<li>Horseshoe or Hierarchical Shrinkage (HS)</li>
<li>Horseshoe Plus or Hierarchical Shrinkage Plus (HS+)</li>
</ul>
<p>Even when analytic forms of the distribution are available, representing them as scale mixtures of normal distributions may be convenient in modeling. In particular, it may allow for drawing samples from the distribution easily. And in HMC, it may induce a more tractable posterior density.</p>
</div>
<div id="covariance-correlation-matrix-decomposition" class="section level3">
<h3><span class="header-section-number">15.6.3</span> Covariance-Correlation Matrix Decomposition</h3>
<p>The suggested method for modeling covariance matrices in Stan is the separation strategy which decomposes a covariance matrix <span class="math inline">\(\Sigma\)</span> can be decomposed into a standard deviation vector <span class="math inline">\(\sigma\)</span>, and a correlation matrix <span class="math inline">\(R\)</span> <span class="citation">(Barnard, McCulloch, and Meng 2000)</span>, <span class="math display">\[
\Sigma = \diag(\sigma) R \diag(\sigma) .
\]</span> This is useful for setting priors on covariance because separate priors can be set for the scales of the variables via <span class="math inline">\(\sigma\)</span>, and the correlation between them, via <span class="math inline">\(R\)</span>.</p>
<p>The <a href="https://github.com/stan-dev/rstanarm/wiki/Prior-distributions">rstanarm</a> <code>decov</code> prior goes further and decomposes the covariance matrix into a correlation matrix, <span class="math inline">\(\mat{R}\)</span>, a diagonal variance matrix <span class="math inline">\(\mat{\Omega}\)</span> with trace <span class="math inline">\(n \sigma^2\)</span>, a scalar global variance <span class="math inline">\(\sigma^2\)</span>, and a simplex <span class="math inline">\(\vec{\pi}\)</span> (proportion of total variance for each variable): <span class="math display">\[
\begin{aligned}[t]
\mat{\Sigma} &amp;= \mat{\Omega} \mat{R}  \\
\diag(\mat{\Omega}) &amp;= n \vec{\pi} \sigma^2
\end{aligned}
\]</span> Separate and interpretable priors can be put on <span class="math inline">\(\mat{R}\)</span>, <span class="math inline">\(\vec{\pi}\)</span>, and <span class="math inline">\(\sigma^2\)</span>.</p>
<p>The LKJ (Lewandowski, ) distribution is a distribution over correlation coefficients, <span class="math display">\[
R \sim \dlkjcorr(\eta) ,
\]</span> where <span class="math display">\[
\dlkjcorr(\Sigma | \eta) \propto \det(\Sigma)^{(\eta - 1)} .
\]</span></p>
<p>This distribution has the following properties:</p>
<ul>
<li><span class="math inline">\(\eta = 1\)</span>: uniform correlations</li>
<li><span class="math inline">\(\eta \to \infty\)</span>: approaches the identity matrix</li>
<li><span class="math inline">\(0 &lt; \eta &lt; 1\)</span>: there is a trough at the identity matrix with higher probabilities placed on non-zero correlations.</li>
<li>For all positive <span class="math inline">\(\eta\)</span> (<span class="math inline">\(\eta &gt; 0\)</span>), <span class="math inline">\(\E(R) = \mat{I}\)</span>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lkjcorr_df &lt;-<span class="st"> </span><span class="cf">function</span>(eta, <span class="dt">n =</span> <span class="dv">2</span>) {
  out &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">rlkjcorr</span>(n, eta))
  out<span class="op">$</span>.row &lt;-<span class="st"> </span><span class="kw">seq_len</span>(<span class="kw">nrow</span>(out))
  out &lt;-<span class="st"> </span><span class="kw">gather</span>(out, .col, value, <span class="op">-</span>.row)
  out<span class="op">$</span>.col &lt;-<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">str_replace</span>(out<span class="op">$</span>.col, <span class="st">&quot;^V&quot;</span>, <span class="st">&quot;&quot;</span>))
  out<span class="op">$</span>eta &lt;-<span class="st"> </span>eta
  out  
}

lkjsims &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map_df</span>(<span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">50</span>, <span class="dv">1000</span>), lkjcorr_df, <span class="dt">n =</span> <span class="dv">50</span>)</code></pre></div>
<p>This simulates a single matrix from the LKJ distribution with different values of <span class="math inline">\(\eta\)</span>. As <span class="math inline">\(\eta \to \infty\)</span>, the off-diagonal correlations tend towards 0, and the correlation matrix to the identity matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(lkjsims,
       <span class="kw">aes</span>(<span class="dt">x =</span> .row, <span class="dt">y =</span> .col, <span class="dt">fill =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>eta, <span class="dt">ncol =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_distiller</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">type =</span> <span class="st">&quot;div&quot;</span>, <span class="dt">palette =</span> <span class="st">&quot;RdYlBu&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_raster</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(), <span class="dt">axis.text =</span> <span class="kw">element_blank</span>()) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;&quot;</span>)</code></pre></div>
<p><img src="appendix_files/figure-html/unnamed-chunk-4-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The density of the off-diagonal correlations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lkjsims <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(.row <span class="op">&lt;</span><span class="st"> </span>.col) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value, <span class="dt">colour =</span> <span class="kw">factor</span>(eta))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>()</code></pre></div>
<p><img src="appendix_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>For other discussions of the LKJ correlation distribution, see these:</p>
<ul>
<li><a href="https://stats.stackexchange.com/questions/2746/how-to-efficiently-generate-random-positive-semidefinite-correlation-matrices/125017#125017" class="uri">https://stats.stackexchange.com/questions/2746/how-to-efficiently-generate-random-positive-semidefinite-correlation-matrices/125017#125017</a></li>
<li><a href="http://www.zinkov.com/posts/2015-06-09-where-priors-come-from/" class="uri">http://www.zinkov.com/posts/2015-06-09-where-priors-come-from/</a></li>
<li><a href="http://www.psychstatistics.com/2014/12/27/d-lkj-priors/" class="uri">http://www.psychstatistics.com/2014/12/27/d-lkj-priors/</a></li>
</ul>
</div>
<div id="qr-factorization" class="section level3">
<h3><span class="header-section-number">15.6.4</span> QR Factorization</h3>
<p>For a full-rank <span class="math inline">\(N \times K\)</span> matrix, the QR factorization is <span class="math display">\[
\mat{X} = \mat{Q} \mat{R} 
\]</span> where <span class="math inline">\(\mat{Q}\)</span> is an orthonormal matrix such that <span class="math inline">\(\mat{Q}\T \mat{Q}\)</span> and <span class="math inline">\(\mat{R}\)</span> is an upper triangular matrix.</p>
<p>Stan function <span class="citation">Team (2016)</span> suggest writing it is <span class="math display">\[
\begin{aligned}[t]
\mat{Q}^* = \mat{Q} \times \sqrt{N - 1} \\
\mat{R}^* = \frac{1}{\sqrt{N - 1}} \mat{R}
\end{aligned}
\]</span></p>
<p>This is used for solving linear model.</p>
<p>Suppose <span class="math inline">\(\vec{\beta}\)</span> is a <span class="math inline">\(K \times 1\)</span> vector, then <span class="math display">\[
\vec{eta} = \mat{x} \vec{\beta} = \mat{Q} \mat{R} \vec{\beta} = \mat{Q}^* \mat{R}^* \vec{\beta} .
\]</span> Suppose <span class="math inline">\(\mat{theta} = \mat{R}^* \vec{\beta}\)</span>, then <span class="math inline">\(\vec{eta} = \mat{Q}^* \mat{\theta}\)</span> and <span class="math inline">\(\vec{beta} = {\mat{R}^*}^{-1} \mat{\theta}\)</span>.</p>
<p><a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/lm.html">rstanarm</a> provides a prior for a normal linear model which uses the QR decomposition to parameterize a prior in terms of <span class="math inline">\(R^2\)</span>.</p>
<p>Stan functions:</p>
<ul>
<li><code>qr_Q(matrix A)</code></li>
<li><code>qr_R(matrix A)</code></li>
</ul>
<p>See <span class="citation">Team (2016 Sec 8.2)</span></p>
</div>
<div id="cholesky-decomposition" class="section level3">
<h3><span class="header-section-number">15.6.5</span> Cholesky Decomposition</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Cholesky_decomposition">Cholesky decomposition</a> of a positive definite matrix <span class="math inline">\(A\)</span> is, <span class="math display">\[
\mat{A} = \mat{L} \mat{L}\T ,
\]</span> where <span class="math inline">\(\mat{L}\)</span> is a lower-triangular matrix.</p>
<ul>
<li>It is similar to a square root for a matrix.</li>
<li><p>It often more numerically stable or efficient to work with the Cholesky decomposition, than with a covariance matrix. When working with the covariance matrix, numerical precision can result in a non positive definite matrix. However, working with <span class="math inline">\(\mat{L}\)</span> will ensure that <span class="math inline">\(\mat{A} = \mat{L} \mat{L}\T\)</span> will be positive definite.</p></li>
<li><p>In Stan</p>
<ul>
<li>Types types <code>cholesky_factor_cov</code>, and <code>cholesky_factor_corr</code> represent the Cholesky factor of covariance and correlation matrices, respectively.</li>
<li>Cholesky decomposition function is <code>cholesky_decompose(matrix A)</code></li>
</ul></li>
<li><p>Multiple functions in Stan are parameterized with Cholesky decompositions instead of or in addition to covariance matrices. Use them if possible; they are more numerically stable.</p>
<ul>
<li><code>lkj_corr_chol_lpdf</code></li>
<li><code>multi_normal_cholesky_lpdf</code></li>
</ul></li>
</ul>
<p>The Cholesky factor is used for sampling from a multivariate normal distribution using i.i.d. standard normal distributions. Suppose <span class="math inline">\(X_1, \dots, X_N\)</span> are <span class="math inline">\(N\)</span> i.i.d. standard normal distributions, <span class="math inline">\(\mat{\Omega}\)</span> is an <span class="math inline">\(N \times N\)</span> lower-triangular matrix such that <span class="math inline">\(\mat{\Omega} \mat{Omega}\T = \mat{\Sigma}\)</span>, and <span class="math inline">\(\mu\)</span> is an <span class="math inline">\(N \times 1\)</span> vector, then <span class="math display">\[
\vec{\mu} + \mat{\Omega} X \sim \dnorm(\vec{\mu}, \mat{\Sigma})
\]</span></p>
<p>See <span class="citation">Team (2016, 40, 147, 241, 246)</span></p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="7">
<li id="fn7"><p><a href="https://en.wikipedia.org/wiki/Multilevel_model" class="uri">https://en.wikipedia.org/wiki/Multilevel_model</a><a href="multilevel-models.html#fnref7">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hierarchical-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="notes.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/bayesian_notes/edit/master/multilevel.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
