<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Updating: A Set of Bayesian Notes</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Updating: A Set of Bayesian Notes">
  <meta name="generator" content="bookdown 0.3.6 and GitBook 2.6.7">

  <meta property="og:title" content="Updating: A Set of Bayesian Notes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jrnold.github.io/bayesian_notes" />
  
  
  <meta name="github-repo" content="jrnold/bayesian_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Updating: A Set of Bayesian Notes" />
  <meta name="twitter:site" content="@jrnld" />
  
  

<meta name="author" content="Jeffrey B. Arnold">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="generalized-linear-models.html">
<link rel="next" href="references-6.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Bayesian Notes</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Theory</b></span></li>
<li class="chapter" data-level="1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>1</b> Bayesian Inference</a></li>
<li class="part"><span><b>II Computation</b></span></li>
<li class="chapter" data-level="2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>2</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>2.1</b> Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-sampling"><i class="fa fa-check"></i><b>2.2</b> Markov Chain Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#references"><i class="fa fa-check"></i><b>2.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>3</b> MCMC Diagnostics</a><ul>
<li class="chapter" data-level="3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#reparameterize-models"><i class="fa fa-check"></i><b>3.1</b> Reparameterize Models</a></li>
<li class="chapter" data-level="3.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#convergence-diagnostics"><i class="fa fa-check"></i><b>3.2</b> Convergence Diagnostics</a><ul>
<li class="chapter" data-level="3.2.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#potential-scale-reduction-hatr"><i class="fa fa-check"></i><b>3.2.1</b> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</a></li>
<li class="chapter" data-level="3.2.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#references-1"><i class="fa fa-check"></i><b>3.2.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation-effective-sample-size-and-mcse"><i class="fa fa-check"></i><b>3.3</b> Autocorrelation, Effective Sample Size, and MCSE</a><ul>
<li class="chapter" data-level="3.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#effective-sample-size"><i class="fa fa-check"></i><b>3.3.1</b> Effective Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#thinning"><i class="fa fa-check"></i><b>3.4</b> Thinning</a><ul>
<li class="chapter" data-level="3.4.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#traceplots"><i class="fa fa-check"></i><b>3.4.1</b> Traceplots</a></li>
<li class="chapter" data-level="3.4.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#monte-carlo-standard-error-mcse"><i class="fa fa-check"></i><b>3.4.2</b> Monte Carlo Standard Error (MCSE)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#hmc-nut-specific-diagnostics"><i class="fa fa-check"></i><b>3.5</b> HMC-NUT Specific Diagnostics</a><ul>
<li class="chapter" data-level="3.5.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#divergent-transitions"><i class="fa fa-check"></i><b>3.5.1</b> Divergent transitions</a></li>
<li class="chapter" data-level="3.5.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#maximum-treedepth"><i class="fa fa-check"></i><b>3.5.2</b> Maximum Treedepth</a></li>
<li class="chapter" data-level="3.5.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#bayesian-fraction-of-missing-information"><i class="fa fa-check"></i><b>3.5.3</b> Bayesian Fraction of Missing Information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="posterior-inference.html"><a href="posterior-inference.html"><i class="fa fa-check"></i><b>4</b> Posterior Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#prerequisites"><i class="fa fa-check"></i><b>4.1</b> Prerequisites</a></li>
<li class="chapter" data-level="4.2" data-path="posterior-inference.html"><a href="posterior-inference.html#introduction"><i class="fa fa-check"></i><b>4.2</b> Introduction</a></li>
<li class="chapter" data-level="4.3" data-path="posterior-inference.html"><a href="posterior-inference.html#functions-of-the-posterior-distribution"><i class="fa fa-check"></i><b>4.3</b> Functions of the Posterior Distribution</a></li>
<li class="chapter" data-level="4.4" data-path="posterior-inference.html"><a href="posterior-inference.html#marginal-effects"><i class="fa fa-check"></i><b>4.4</b> Marginal Effects</a><ul>
<li class="chapter" data-level="4.4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#example-marginal-effect-plot-for-x"><i class="fa fa-check"></i><b>4.4.1</b> Example: Marginal Effect Plot for X</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>5</b> Model Checking</a><ul>
<li class="chapter" data-level="5.1" data-path="model-checking.html"><a href="model-checking.html#why-check-models"><i class="fa fa-check"></i><b>5.1</b> Why check models?</a></li>
<li class="chapter" data-level="5.2" data-path="model-checking.html"><a href="model-checking.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2</b> Posterior Predictive Checks</a><ul>
<li class="chapter" data-level="5.2.1" data-path="model-checking.html"><a href="model-checking.html#bayesian-p-values"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian p-values</a></li>
<li class="chapter" data-level="5.2.2" data-path="model-checking.html"><a href="model-checking.html#test-quantities"><i class="fa fa-check"></i><b>5.2.2</b> Test quantities</a></li>
<li class="chapter" data-level="5.2.3" data-path="model-checking.html"><a href="model-checking.html#p-values-vs.u-values"><i class="fa fa-check"></i><b>5.2.3</b> p-values vs. u-values</a></li>
<li class="chapter" data-level="5.2.4" data-path="model-checking.html"><a href="model-checking.html#marginal-predictive-checks"><i class="fa fa-check"></i><b>5.2.4</b> Marginal predictive checks</a></li>
<li class="chapter" data-level="5.2.5" data-path="model-checking.html"><a href="model-checking.html#outliers"><i class="fa fa-check"></i><b>5.2.5</b> Outliers</a></li>
<li class="chapter" data-level="5.2.6" data-path="model-checking.html"><a href="model-checking.html#grapical-posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2.6</b> Grapical Posterior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="model-checking.html"><a href="model-checking.html#sources"><i class="fa fa-check"></i><b>5.3</b> Sources</a></li>
</ul></li>
<li class="part"><span><b>III Models</b></span></li>
<li class="chapter" data-level="6" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Introduction to Stan and Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#prerequites"><i class="fa fa-check"></i><b>6.1</b> Prerequites</a></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#the-statistical-model"><i class="fa fa-check"></i><b>6.2</b> The Statistical Model</a><ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling"><i class="fa fa-check"></i><b>6.2.1</b> Sampling</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#convergence-diagnostics-and-model-fit"><i class="fa fa-check"></i><b>6.2.2</b> Convergence Diagnostics and Model Fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html"><i class="fa fa-check"></i><b>7</b> Heteroskedasticity and Robust Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#prerequisites-1"><i class="fa fa-check"></i><b>7.1</b> Prerequisites</a></li>
<li class="chapter" data-level="7.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#linear-regression-with-student-t-distributed-errors"><i class="fa fa-check"></i><b>7.2</b> Linear Regression with Student t distributed errors</a><ul>
<li class="chapter" data-level="7.2.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#double-exponential-laplace-errors"><i class="fa fa-check"></i><b>7.2.1</b> Double Exponential (Laplace) Errors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity"><i class="fa fa-check"></i><b>7.3</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="7.3.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#covariates"><i class="fa fa-check"></i><b>7.3.1</b> Covariates</a></li>
<li class="chapter" data-level="7.3.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#student-t-error"><i class="fa fa-check"></i><b>7.3.2</b> Student-t Error</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#references-2"><i class="fa fa-check"></i><b>7.4</b> References</a><ul>
<li class="chapter" data-level="7.4.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#robust-regression"><i class="fa fa-check"></i><b>7.4.1</b> Robust regression</a></li>
<li class="chapter" data-level="7.4.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity-1"><i class="fa fa-check"></i><b>7.4.2</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="7.4.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#qunatile-regression"><i class="fa fa-check"></i><b>7.4.3</b> Qunatile regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>8</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="8.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#generalized-linear-models-1"><i class="fa fa-check"></i><b>8.1</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="8.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#binomial"><i class="fa fa-check"></i><b>8.2</b> Binomial</a><ul>
<li class="chapter" data-level="8.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example-vote-turnout"><i class="fa fa-check"></i><b>8.2.1</b> Example: Vote Turnout</a></li>
<li class="chapter" data-level="8.2.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#extensions"><i class="fa fa-check"></i><b>8.2.2</b> Extensions</a></li>
<li class="chapter" data-level="8.2.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#perfect-separation"><i class="fa fa-check"></i><b>8.2.3</b> Perfect Separation</a></li>
<li class="chapter" data-level="8.2.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-3"><i class="fa fa-check"></i><b>8.2.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#count-models"><i class="fa fa-check"></i><b>8.3</b> Count Models</a><ul>
<li class="chapter" data-level="8.3.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson"><i class="fa fa-check"></i><b>8.3.1</b> Poisson</a></li>
<li class="chapter" data-level="8.3.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-4"><i class="fa fa-check"></i><b>8.3.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#negative-binomial"><i class="fa fa-check"></i><b>8.4</b> Negative Binomial</a><ul>
<li class="chapter" data-level="8.4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial-categorical-models"><i class="fa fa-check"></i><b>8.4.1</b> Multinomial / Categorical Models</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#gamma-regression"><i class="fa fa-check"></i><b>8.5</b> Gamma Regression</a></li>
<li class="chapter" data-level="8.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#beta-regression"><i class="fa fa-check"></i><b>8.6</b> Beta Regression</a></li>
<li class="chapter" data-level="8.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#ordered-logistic"><i class="fa fa-check"></i><b>8.7</b> Ordered Logistic</a></li>
<li class="chapter" data-level="8.8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-5"><i class="fa fa-check"></i><b>8.8</b> References</a></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span></li>
<li class="chapter" data-level="9" data-path="notes.html"><a href="notes.html"><i class="fa fa-check"></i><b>9</b> Notes</a><ul>
<li class="chapter" data-level="9.1" data-path="notes.html"><a href="notes.html#syllabi"><i class="fa fa-check"></i><b>9.1</b> Syllabi</a></li>
<li class="chapter" data-level="9.2" data-path="notes.html"><a href="notes.html#textbooks"><i class="fa fa-check"></i><b>9.2</b> Textbooks</a></li>
<li class="chapter" data-level="9.3" data-path="notes.html"><a href="notes.html#topics"><i class="fa fa-check"></i><b>9.3</b> Topics</a><ul>
<li class="chapter" data-level="9.3.1" data-path="notes.html"><a href="notes.html#overviews"><i class="fa fa-check"></i><b>9.3.1</b> Overviews</a></li>
<li class="chapter" data-level="9.3.2" data-path="notes.html"><a href="notes.html#bayesian-philosophy"><i class="fa fa-check"></i><b>9.3.2</b> Bayesian Philosophy</a></li>
<li class="chapter" data-level="9.3.3" data-path="notes.html"><a href="notes.html#bayesian-frequentist-debates"><i class="fa fa-check"></i><b>9.3.3</b> Bayesian Frequentist Debates</a></li>
<li class="chapter" data-level="9.3.4" data-path="notes.html"><a href="notes.html#categorical"><i class="fa fa-check"></i><b>9.3.4</b> Categorical</a></li>
<li class="chapter" data-level="9.3.5" data-path="notes.html"><a href="notes.html#identifiability"><i class="fa fa-check"></i><b>9.3.5</b> Identifiability</a></li>
<li class="chapter" data-level="9.3.6" data-path="notes.html"><a href="notes.html#time-series"><i class="fa fa-check"></i><b>9.3.6</b> Time Series</a></li>
<li class="chapter" data-level="9.3.7" data-path="notes.html"><a href="notes.html#topic-models"><i class="fa fa-check"></i><b>9.3.7</b> Topic Models</a></li>
<li class="chapter" data-level="9.3.8" data-path="notes.html"><a href="notes.html#nonparametric-bayesian-methods"><i class="fa fa-check"></i><b>9.3.8</b> Nonparametric Bayesian Methods</a></li>
<li class="chapter" data-level="9.3.9" data-path="notes.html"><a href="notes.html#prior-elicitation"><i class="fa fa-check"></i><b>9.3.9</b> Prior Elicitation</a></li>
<li class="chapter" data-level="9.3.10" data-path="notes.html"><a href="notes.html#variable-selection"><i class="fa fa-check"></i><b>9.3.10</b> Variable Selection</a></li>
<li class="chapter" data-level="9.3.11" data-path="notes.html"><a href="notes.html#shrinkage"><i class="fa fa-check"></i><b>9.3.11</b> Shrinkage</a></li>
<li class="chapter" data-level="9.3.12" data-path="notes.html"><a href="notes.html#applied-bayes-rule"><i class="fa fa-check"></i><b>9.3.12</b> Applied Bayes Rule</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="notes.html"><a href="notes.html#computation-methods"><i class="fa fa-check"></i><b>9.4</b> Computation Methods</a><ul>
<li class="chapter" data-level="9.4.1" data-path="notes.html"><a href="notes.html#software"><i class="fa fa-check"></i><b>9.4.1</b> Software</a></li>
<li class="chapter" data-level="9.4.2" data-path="notes.html"><a href="notes.html#stan"><i class="fa fa-check"></i><b>9.4.2</b> Stan</a></li>
<li class="chapter" data-level="9.4.3" data-path="notes.html"><a href="notes.html#diagrams"><i class="fa fa-check"></i><b>9.4.3</b> Diagrams</a></li>
<li class="chapter" data-level="9.4.4" data-path="notes.html"><a href="notes.html#political-science-bayesian-works"><i class="fa fa-check"></i><b>9.4.4</b> Political Science Bayesian Works</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="notes.html"><a href="notes.html#model-checking-1"><i class="fa fa-check"></i><b>9.5</b> Model Checking</a></li>
<li class="chapter" data-level="9.6" data-path="notes.html"><a href="notes.html#general-applications-and-models"><i class="fa fa-check"></i><b>9.6</b> General Applications and Models</a><ul>
<li class="chapter" data-level="9.6.1" data-path="notes.html"><a href="notes.html#mixed-methods-and-qualitative-research"><i class="fa fa-check"></i><b>9.6.1</b> Mixed Methods and Qualitative Research</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="notes.html"><a href="notes.html#hierarchical-modeling"><i class="fa fa-check"></i><b>9.7</b> Hierarchical Modeling</a></li>
<li class="chapter" data-level="9.8" data-path="notes.html"><a href="notes.html#shrinkageregularization"><i class="fa fa-check"></i><b>9.8</b> Shrinkage/Regularization</a><ul>
<li class="chapter" data-level="9.8.1" data-path="notes.html"><a href="notes.html#examples"><i class="fa fa-check"></i><b>9.8.1</b> Examples</a></li>
<li class="chapter" data-level="9.8.2" data-path="notes.html"><a href="notes.html#latent-variable-models"><i class="fa fa-check"></i><b>9.8.2</b> Latent Variable Models</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="notes.html"><a href="notes.html#bayes-theorem-examples"><i class="fa fa-check"></i><b>9.9</b> Bayes Theorem Examples</a><ul>
<li class="chapter" data-level="9.9.1" data-path="notes.html"><a href="notes.html#miscallaneous"><i class="fa fa-check"></i><b>9.9.1</b> Miscallaneous</a></li>
<li class="chapter" data-level="9.9.2" data-path="notes.html"><a href="notes.html#german-tank-problem"><i class="fa fa-check"></i><b>9.9.2</b> German Tank Problem</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="notes.html"><a href="notes.html#good-turing-estimator"><i class="fa fa-check"></i><b>9.10</b> Good-Turing Estimator</a></li>
<li class="chapter" data-level="9.11" data-path="notes.html"><a href="notes.html#reproducibility"><i class="fa fa-check"></i><b>9.11</b> Reproducibility</a><ul>
<li class="chapter" data-level="9.11.1" data-path="notes.html"><a href="notes.html#uncategorized"><i class="fa fa-check"></i><b>9.11.1</b> Uncategorized</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="notes.html"><a href="notes.html#empirical-bayes"><i class="fa fa-check"></i><b>9.12</b> Empirical Bayes</a></li>
<li class="chapter" data-level="9.13" data-path="notes.html"><a href="notes.html#things-to-cover"><i class="fa fa-check"></i><b>9.13</b> Things to cover</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-6.html"><a href="references-6.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Updating: A Set of Bayesian Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\median}{median}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

% This follows BDA
\newcommand{\dunif}{\mathrm{U}}
\newcommand{\dnorm}{\mathrm{N}}
\newcommand{\dlnorm}{\mathrm{lognormal}}
\newcommand{\dmvnorm}{\mathrm{N}}
\newcommand{\dgamma}{\mathrm{Gamma}}
\newcommand{\dinvgamma}{\mathrm{Inv-Gamma}}
\newcommand{\dchisq}[1]{\chi^2_{#1}}
\newcommand{\dinvchisq}[1]{\mathrm{Inv-}\chi^2_{#1}}
\newcommand{\dexp}{\mathrm{Expon}}
\newcommand{\dlaplace}{\mathrm{Laplace}}
\newcommand{\dweibull}{\mathrm{Weibull}}
\newcommand{\dwishart}[1]{\mathrm{Wishart}_{#1}}
\newcommand{\dinvwishart}[1]{\mathrm{Inv-Wishart}_{#1}}
\newcommand{\dlkj}{\mathrm{LkjCorr}}
\newcommand{\dt}[1]{t_{#1}}
\newcommand{\dbeta}{\mathrm{Beta}}
\newcommand{\ddirichlet}{\mathrm{Dirichlet}}
\newcommand{\dlogistic}{\mathrm{Logistic}}
\newcommand{\dllogistic}{\mathrm{Log-logistic}}
\newcommand{\dpois}{\mathrm{Poisson}}
\newcommand{\dbinom}{\mathrm{Bin}}
\newcommand{\dbinom}{\mathrm{Bin-alt}}
\newcommand{\dmultinom}{\mathrm{Multinom}}
\newcommand{\dnbinom}{\mathrm{Neg-bin}}
\newcommand{\dnbinomalt}{\mathrm{Neg-bin-alt}}
\newcommand{\dbetabinom}{\mathrm{Beta-bin}}
\newcommand{\dcauchy}{\mathrm{Cauchy}}
\newcommand{\dhalfcauchy}{\mathrm{Cauchy}^{+}}

\DeclareMathOperator{\logistic}{Logistic}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]
<div id="notes" class="section level1">
<h1><span class="header-section-number">9</span> Notes</h1>
<div id="syllabi" class="section level2">
<h2><span class="header-section-number">9.1</span> Syllabi</h2>
<ul>
<li><p>Ryan Bakker and Johannes Karreth, “Introduction to Applied Bayesian Modeling” ICPSR. Summer 2016.</p>
<ul>
<li><a href="http://www.jkarreth.net/files/bayes2016.pdf">Syllabus</a></li>
<li><a href="https://github.com/jkarreth/Bayes">code</a></li>
</ul></li>
<li><p>Justin Esarey. “Advanced Topics in Political Methodology: Bayesian Statistics” Winter 2015.</p>
<ul>
<li><a href="http://jee3.web.rice.edu/POLS506-syllabus-2015.pdf">Syllabus</a></li>
<li><a href="http://jee3.web.rice.edu/teaching.htm">Lectures</a></li>
</ul></li>
<li><p>Kruschke.</p>
<ul>
<li><a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis site</a></li>
</ul></li>
<li><p>Nick Beauchamp. “Bayesian Methods.” NYU</p>
<ul>
<li><a href="http://www.democraticwriting.com/work/Beauchamp_bayesian_syllabus.pdf">syllabus</a></li>
</ul></li>
<li><p>Alex Tanhk. “Bayesian Methods for the Social Sciences” U of Wisconsin. Spring 2017.</p>
<ul>
<li><a href="https://polisci.wisc.edu/sites/polisci.wisc.edu/files/documents/syllabi/PS%20919%20.pdf">syllabus</a></li>
</ul></li>
<li><p>MTH225 Statistics for Science Spring 2016</p>
<ul>
<li><a href="https://github.com/equinn1/MTH225_Spring2016">github website</a></li>
</ul></li>
<li><p>Ben Goodrich, “Bayesian Statistics for Social Sciences” Columbia University. Spring 2016.</p></li>
<li><p>Bakker. “ntroduction to Applied Bayesian Analysis” University of Georgia.</p>
<ul>
<li><a href="http://spia.uga.edu/faculty_pages/rbakker/bayes/bayes2016_maymester.pdf">syllabus</a></li>
<li><a href="http://spia.uga.edu/faculty_pages/rbakker/bayes/POLS%20Bayes.htm">site</a></li>
</ul></li>
<li>Myimoto. “Advances in Quantitative Psychology: Bayesian Statistics, Modeling &amp; Reasoning” U of Washington. Winter 2017. <a href="http://faculty.washington.edu/jmiyamot/p548/p548-set.htm">site</a></li>
<li><p>Kruschke. “Bayesian Data Analysis” Indiana University. Spring 2016.</p>
<ul>
<li><a href="https://github.com/aloctavodia/Doing_bayesian_data_analysis">PyMC code</a></li>
</ul></li>
<li>Blackwell and Spirling. 2002. “Topics in Political Methodology” Harvard. Fall 2014. <a href="http://www.mattblackwell.org/files/teaching/gov2002-syllabus.pdf">Syllabus</a>. It has a couple of classes on Bayesian methods.</li>
<li>Neil Frazer. Bayesian Data Analysis. Hawaii. Spring 2017. <a href="http://www.soest.hawaii.edu/GG/resources/syllabi-S17/gg695-s17-syl.pdf">syllabus</a></li>
<li>Lopes. 2016. Bayesian Statistical Learning: Readings in Statistics and Econometrics. <a href="http://hedibert.org/current-teaching/" class="uri">http://hedibert.org/current-teaching/</a></li>
<li>Lopes. 2012 <a href="http://hedibert.org/simulation-based-approaches-to-modern-bayesian-econometrics/">Simulation-based approaches to modern Bayesian econometrics</a>. Short course.</li>
<li><p>Lopes. 2015. Bayesian Econometrics. <a href="http://hedibert.org/current-teaching/" class="uri">http://hedibert.org/current-teaching/</a></p></li>
</ul>
</div>
<div id="textbooks" class="section level2">
<h2><span class="header-section-number">9.2</span> Textbooks</h2>
<ul>
<li>Gelman, Andrew, and Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge University Press.</li>
<li>Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. Bayesian Data Analysis. 3rd ed. CRC Press.</li>
<li>Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. “Understanding Predictive Information Criteria for Bayesian Models.” Statistics and Computing 24 (6). Springer: 997–1016.</li>
<li>Gill, Jeff. 2008. Bayesian Methods : A Social and Behavioral Sciences Approach. Second. Boca Raton: Chapman &amp; Hall/CRC.</li>
<li>Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences. Chichester, UK: Wiley.</li>
<li>Kruschke, John. 2010. Doing Bayesian Data Analysis: A Tutorial Introduction with R. Academic Press.</li>
<li>Lynch, Scott M. 2007. Introduction to Applied Bayesian Statistics and Estimation for Social Scientists. New York: Springer.</li>
<li><p>McElreath, Richard. 2016. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. Vol. 122. CRC Press.</p>
<ul>
<li>github page for Statistical Rethinking <a href="https://github.com/rmcelreath/rethinking" class="uri">https://github.com/rmcelreath/rethinking</a></li>
<li><a href="http://xcelab.net/rm/statistical-rethinking/" class="uri">http://xcelab.net/rm/statistical-rethinking/</a></li>
</ul></li>
<li>Lunn, David, Chris Jackson, Nicky Best, Andrew Thomas, and David Spiegelhalter. 2012. The BUGS Book: A Practical Introduction to Bayesian Analysis. Boca Raton, FL: Chapman; Hall/CRC.</li>
<li>Suess, Eric A. and Bruce E. Trumbo. 2010. Introduction to Probability Simulation and Gibbs Sampling with R. New York: Springer.</li>
<li>Suess, Eric A. and Bruce E. Trumbo. 2010. Introduction to Probability Simulation and Gibbs Sampling with R. New York: Springer.</li>
<li>Peter Hoff. 2009. A First Course in Bayesian Statistical Methods</li>
<li>Jaynes. 2003. Probability Theory: The Logic of Science.</li>
<li>Congdon. 2014. Applied Bayesian Modeling.</li>
<li>Wakefield. 2013. Bayesian and Frequentist Regression Methods</li>
<li>Casella and Roberts. 2004. Monte Carlo Statistical Methods</li>
<li><p>Marin and Roberts. 2014. <em>Bayesian Essentials with R.</em> <a href="http://www.springer.com/us/book/9781461486862" class="uri">http://www.springer.com/us/book/9781461486862</a></p></li>
</ul>
</div>
<div id="topics" class="section level2">
<h2><span class="header-section-number">9.3</span> Topics</h2>
<div id="overviews" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Overviews</h3>
<ul>
<li>Michael Clarke <a href="https://m-clark.github.io/docs/IntroBayes.html">Bayesian Basics</a></li>
<li>Jackman. 2004. Bayesian Analysis for Political Research. <em>Annual Review of Political Science</em> DOI: 10.1146/annurev.polisci.7.012003.104706</li>
<li>Kruschke, J.K. &amp; Liddell, T.M. Psychon Bull Rev (2017). <a href="doi:10.3758/s13423-016-1221-4" class="uri">doi:10.3758/s13423-016-1221-4</a> - Cumming, G. (2014). The new statistics why and how. Psychological Science, 25(1), 7–29.</li>
</ul>
</div>
<div id="bayesian-philosophy" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Bayesian Philosophy</h3>
<ul>
<li>Efron. 2010. The Future of Indirect Evidence. <em>Stat Sci</em> <a href="doi:10.1214/09-STS308" class="uri">doi:10.1214/09-STS308</a></li>
<li>Berger. 2006. The case for objective Bayesian analysis. <em>Bayesian Anal</em> <a href="doi:10.1214/06-BA115" class="uri">doi:10.1214/06-BA115</a></li>
<li><p>Brad Efron “Why Isn’t Everyone a Bayesian?” The American Statistician, Vol. 40, No. 1 (Feb., 1986) [include following discussion of Efron’s article]</p>
<ul>
<li>Chernoff. <a href="http://dx.doi.org/10.1080/00031305.1986.10475343" class="uri">http://dx.doi.org/10.1080/00031305.1986.10475343</a></li>
<li>Lindley. <a href="http://dx.doi.org/10.1080/00031305.1986.10475344" class="uri">http://dx.doi.org/10.1080/00031305.1986.10475344</a></li>
<li>Morris. <a href="http://dx.doi.org/10.1080/00031305.1986.10475345" class="uri">http://dx.doi.org/10.1080/00031305.1986.10475345</a></li>
<li>Press. <a href="http://dx.doi.org/10.1080/00031305.1986.10475346" class="uri">http://dx.doi.org/10.1080/00031305.1986.10475346</a></li>
<li>Smith. <a href="http://dx.doi.org/10.1080/00031305.1986.10475347" class="uri">http://dx.doi.org/10.1080/00031305.1986.10475347</a></li>
<li>Efron. Reply. <a href="http://dx.doi.org/10.1080/00031305.1986.10475348" class="uri">http://dx.doi.org/10.1080/00031305.1986.10475348</a></li>
</ul></li>
<li>Philosophy and the practice of Bayesian statistics in the social sciences1. tp://www.stat.columbia.edu/~gelman/research/published/philosophy_chapter.pdf</li>
<li>Aris Spanos “Revisiting data mining: ‘hunting’ with or without a license”</li>
<li>Rubin (1984) Rubin, Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician. Ann. Statist. 12 (1984), no. 4, 1151–1172. <a href="doi:10.1214/aos/1176346785" class="uri">doi:10.1214/aos/1176346785</a>. <a href="http://projecteuclid.org/euclid.aos/1176346785" class="uri">http://projecteuclid.org/euclid.aos/1176346785</a>.</li>
<li>Andrew Gelman Induction and Deduction in Bayesian Data Analysis</li>
<li>Berger, James O. Could Fisher, Jeffreys and Neyman Have Agreed on Testing?. Statist. Sci. 18 (2003), no. 1, 1–32. <a href="doi:10.1214/ss/1056397485" class="uri">doi:10.1214/ss/1056397485</a>. <a href="http://projecteuclid.org/euclid.ss/1056397485" class="uri">http://projecteuclid.org/euclid.ss/1056397485</a>.</li>
<li>Gross2014a: Gross, J. H. (2015), Testing What Matters (If You Must Test at All): A Context-Driven Approach to Substantive and Statistical Significance. American Journal of Political Science, 59: 775–788. <a href="doi:10.1111/ajps.12149" class="uri">doi:10.1111/ajps.12149</a></li>
<li><p>Ng. and Jordan. On Discriminative vs. Generative classifiers: A Comparison of logistic regression and Naive Bayes: <a href="http://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf" class="uri">http://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf</a></p></li>
</ul>
</div>
<div id="bayesian-frequentist-debates" class="section level3">
<h3><span class="header-section-number">9.3.3</span> Bayesian Frequentist Debates</h3>
<ul>
<li>Casella and Berger. 1987. Reconciling Bayesian and Frequentist Evidence in the One-Sided Testing Problem. <em>JASA</em>. <a href="doi:10.1080/01621459.1987.10478396" class="uri">doi:10.1080/01621459.1987.10478396</a></li>
<li><a href="http://www.stat.ufl.edu/archived/casella/Talks/BayesRefresher.pdf">Bayesians and Frequentists : Models, Assumptions, and Inference</a> slides</li>
<li>Kasss Statitsical Inference: The Big Picture <a href="https://arxiv.org/pdf/1106.2895v2.pdf" class="uri">https://arxiv.org/pdf/1106.2895v2.pdf</a></li>
<li>Noah Smith <a href="http://noahpinionblog.blogspot.com/2013/01/bayesian-vs-frequentist-is-there-any.html">Bayesian vs. Frequentist: Is there any “there” there?</a></li>
<li>Kass Kinds of Bayesians <a href="http://www.stat.cmu.edu/~kass/papers/kinds.pdf" class="uri">http://www.stat.cmu.edu/~kass/papers/kinds.pdf</a></li>
<li>Anthony O’Hagan. Science, Subjectivity and Software (Comments on the articles by Berger and Goldstein)</li>
<li>Good, I.J. (1971) 46656 varieties of Bayesians. Letter in American Statistician, 25: 62– 63. Reprinted in Good Thinking, University of Minnesota Press, 1982, pp. 20–21.</li>
</ul>
</div>
<div id="categorical" class="section level3">
<h3><span class="header-section-number">9.3.4</span> Categorical</h3>
<ul>
<li><p>Agresti. Bayesian Inference for Categorical Data Analysis. <a href="http://www.stat.ufl.edu/~aa/cda2/bayes.pdf" class="uri">http://www.stat.ufl.edu/~aa/cda2/bayes.pdf</a></p></li>
<li><p><strong>Perfect Separation</strong></p>
<ul>
<li>Gelman. 2008. “A weakly informative default prior distribution for logistic and other regression models” <em>Ann Applied Stat</em> <a href="doi:10.1214/08-AOAS191" class="uri">doi:10.1214/08-AOAS191</a></li>
<li>Rainey. 2016. “Dealing with Separation in Logistic Regression Models” <em>Political Analysis</em>a</li>
</ul></li>
<li><p><strong>Rare Events</strong></p>
<ul>
<li>King and Zheng. 2001. “Explaining Rare Events in International Relations” <em>Int Org</em> <a href="https://doi.org/10.1162/00208180152507597" class="uri">https://doi.org/10.1162/00208180152507597</a></li>
<li>King, Gary, and Langche Zeng. 2001. “Logistic Regression in Rare Events Data.” <em>Political Analysis</em> <a href="http://www.jstor.org/stable/25791637" class="uri">http://www.jstor.org/stable/25791637</a>.</li>
</ul></li>
</ul>
</div>
<div id="identifiability" class="section level3">
<h3><span class="header-section-number">9.3.5</span> Identifiability</h3>
<ul>
<li>Weschler et al. 2013. A. Bayesian Look at Nonidentifiability: A Simple Example. <em>Am stat</em> <a href="http://dx.doi.org/10.1080/00031305.2013.778787" class="uri">http://dx.doi.org/10.1080/00031305.2013.778787</a></li>
</ul>
</div>
<div id="time-series" class="section level3">
<h3><span class="header-section-number">9.3.6</span> Time Series</h3>
<ul>
<li>Park, “Changepoint analysis of binary and ordinal probit models: An application to bank rate policy under the interwar gold standard”</li>
</ul>
</div>
<div id="topic-models" class="section level3">
<h3><span class="header-section-number">9.3.7</span> Topic Models</h3>
<ul>
<li>Grimmer and Stewart, “Text as data: Te promise and pitfalls of automatic content analysis methods for political texts”</li>
<li>Quinn, Monroe, Colaresi, Crespin and Radev, “How to analyze political attention with minimal assumptions and costs”</li>
</ul>
</div>
<div id="nonparametric-bayesian-methods" class="section level3">
<h3><span class="header-section-number">9.3.8</span> Nonparametric Bayesian Methods</h3>
<ul>
<li>Gill and Casella, “Nonparametric priors for ordinal Bayesian social science models”</li>
<li>Spirling and Quinn, “Identifying intraparty voting blocs in the U.K. House of Commons”</li>
</ul>
</div>
<div id="prior-elicitation" class="section level3">
<h3><span class="header-section-number">9.3.9</span> Prior Elicitation</h3>
<ul>
<li>Gill, J. and Walker, L. D. (2005). Elicited Priors for Bayesian Model Specifications in Political Science Research. <em>Journal of Politics</em></li>
</ul>
</div>
<div id="variable-selection" class="section level3">
<h3><span class="header-section-number">9.3.10</span> Variable Selection</h3>
<ul>
<li>Ghosh and Ghattas. 2015. Bayesian Variable Selection Under Collinearity. <em>Am Stat</em> <a href="http://dx.doi.org/10.1080/00031305.2015.1031827" class="uri">http://dx.doi.org/10.1080/00031305.2015.1031827</a></li>
</ul>
</div>
<div id="shrinkage" class="section level3">
<h3><span class="header-section-number">9.3.11</span> Shrinkage</h3>
<ul>
<li><p>Efron, B. &amp; Morris, C. 1975. “Data Analysis Using Stein’s Estimator and its Generalizations” <em>JASA</em> <a href="doi:10.1080/01621459.1975.10479864" class="uri">doi:10.1080/01621459.1975.10479864</a></p>
<ul>
<li><a href="https://baseballwithr.wordpress.com/2016/02/15/revisiting-efron-and-morriss-baseball-study/" class="uri">https://baseballwithr.wordpress.com/2016/02/15/revisiting-efron-and-morriss-baseball-study/</a></li>
</ul></li>
</ul>
</div>
<div id="applied-bayes-rule" class="section level3">
<h3><span class="header-section-number">9.3.12</span> Applied Bayes Rule</h3>
<p>Mostly examples of naive Bayes</p>
</div>
</div>
<div id="computation-methods" class="section level2">
<h2><span class="header-section-number">9.4</span> Computation Methods</h2>
<div id="animations" class="section level4">
<h4><span class="header-section-number">9.4.0.1</span> Animations</h4>
<ul>
<li><a href="https://chi-feng.github.io/mcmc-demo/" class="uri">https://chi-feng.github.io/mcmc-demo/</a></li>
<li><a href="https://mimno.infosci.cornell.edu/hmc/" class="uri">https://mimno.infosci.cornell.edu/hmc/</a>; <a href="http://www.mimno.org/articles/hmc/" class="uri">http://www.mimno.org/articles/hmc/</a></li>
<li><a href="http://twiecki.github.io/blog/2014/01/02/visualizing-mcmc/" class="uri">http://twiecki.github.io/blog/2014/01/02/visualizing-mcmc/</a></li>
<li><a href="https://ridlow.wordpress.com/category/animation/" class="uri">https://ridlow.wordpress.com/category/animation/</a></li>
<li><a href="http://people.math.aau.dk/~kkb/Undervisning/Bayes14/sorenh/docs/sampling-notes.pdf" class="uri">http://people.math.aau.dk/~kkb/Undervisning/Bayes14/sorenh/docs/sampling-notes.pdf</a></li>
<li><a href="https://rpubs.com/mv2521/mcmc-animation" class="uri">https://rpubs.com/mv2521/mcmc-animation</a></li>
<li><a href="http://blog.revolutionanalytics.com/2013/09/an-animated-peek-into-the-workings-of-bayesian-statistics.html" class="uri">http://blog.revolutionanalytics.com/2013/09/an-animated-peek-into-the-workings-of-bayesian-statistics.html</a></li>
<li><a href="https://people.duke.edu/~ccc14/sta-663/Animation.html" class="uri">https://people.duke.edu/~ccc14/sta-663/Animation.html</a></li>
<li><a href="https://artax.karlin.mff.cuni.cz/r-help/library/asbio/html/anm.mc.bvn.html" class="uri">https://artax.karlin.mff.cuni.cz/r-help/library/asbio/html/anm.mc.bvn.html</a></li>
<li><a href="https://groups.google.com/forum/#!topic/stan-users/nOk80xTlSyE" class="uri">https://groups.google.com/forum/#!topic/stan-users/nOk80xTlSyE</a></li>
<li><a href="https://www.youtube.com/watch?v=Vv3f0QNWvWQ" class="uri">https://www.youtube.com/watch?v=Vv3f0QNWvWQ</a></li>
<li><a href="https://theclevermachine.wordpress.com/2012/11/18/mcmc-hamiltonian-monte-carlo-a-k-a-hybrid-monte-carlo/" class="uri">https://theclevermachine.wordpress.com/2012/11/18/mcmc-hamiltonian-monte-carlo-a-k-a-hybrid-monte-carlo/</a></li>
<li><a href="https://www.youtube.com/watch?v=pHsuIaPbNbY&amp;list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF&amp;index=11" class="uri">https://www.youtube.com/watch?v=pHsuIaPbNbY&amp;list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF&amp;index=11</a></li>
<li><a href="http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html" class="uri">http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html</a></li>
</ul>
</div>
<div id="gibbs" class="section level4">
<h4><span class="header-section-number">9.4.0.2</span> Gibbs</h4>
<ul>
<li>Gelfand et. al. 1986. “Illustration of Bayesian Inference in Normal Data Models Using Gibbs Sampling” doi: 10.1080/01621459.1990.10474968</li>
<li>Chib and Greenberg. “Understanding the Metropolis-Hastings Algorithm” <a href="doi:10.1080/00031305.1995.10476177" class="uri">doi:10.1080/00031305.1995.10476177</a></li>
<li></li>
</ul>
</div>
<div id="mcmc" class="section level4">
<h4><span class="header-section-number">9.4.0.3</span> MCMC</h4>
<ul>
<li>Casella Berger</li>
<li>Jackman 2000</li>
<li>Allison and Dunkley. 2013. Comparison of sampling techniques for Bayesian parameter estimation. <a href="https://arxiv.org/pdf/1308.2675.pdf" class="uri">https://arxiv.org/pdf/1308.2675.pdf</a></li>
<li><a href="https://courses.cs.washington.edu/courses/cse577/04sp/notes/dellaertUW.pdf" class="uri">https://courses.cs.washington.edu/courses/cse577/04sp/notes/dellaertUW.pdf</a></li>
<li>Geyer. MCMC: Does it work? How can we tell?<a href="http://users.stat.umn.edu/~geyer/jsm09.pdf" class="uri">http://users.stat.umn.edu/~geyer/jsm09.pdf</a></li>
</ul>
</div>
<div id="hmcm" class="section level4">
<h4><span class="header-section-number">9.4.0.4</span> HMCM</h4>
<ul>
<li>Neal. 2011. MCMC using Hamiltonian dynamics. <a href="https://arxiv.org/pdf/1206.1901.pdf" class="uri">https://arxiv.org/pdf/1206.1901.pdf</a></li>
<li><a href="https://www.youtube.com/watch?v=xWQpEAyI5s8&amp;index=12&amp;list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF" class="uri">https://www.youtube.com/watch?v=xWQpEAyI5s8&amp;index=12&amp;list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF</a></li>
<li><a href="https://arxiv.org/pdf/1701.02434.pdf" class="uri">https://arxiv.org/pdf/1701.02434.pdf</a></li>
<li><a href="http://deeplearning.net/tutorial/hmc.html" class="uri">http://deeplearning.net/tutorial/hmc.html</a></li>
</ul>
</div>
<div id="smc" class="section level4">
<h4><span class="header-section-number">9.4.0.5</span> SMC</h4>
<ul>
<li>Liu and Chen. 1998. Sequential Monte Carlo Methods for Dynamic Systems. <em>JASA</em> 10.1080/01621459.1998.10473765</li>
</ul>
</div>
<div id="variational" class="section level4">
<h4><span class="header-section-number">9.4.0.6</span> Variational</h4>
<ul>
<li>Grimmer, “An Introduction to Bayesian Inference via Variational Approximations”</li>
<li>Raganath et al. 2015. “Black Box Variational Inference” <a href="https://arxiv.org/abs/1401.0118" class="uri">https://arxiv.org/abs/1401.0118</a></li>
</ul>
</div>
<div id="expectation-propogation" class="section level4">
<h4><span class="header-section-number">9.4.0.7</span> Expectation Propogation</h4>
<ul>
<li>Gelman et. al. 2017. “Expectation propagation as a way of life: A framework for Bayesian inference on partitioned data.” <a href="https://arxiv.org/pdf/1412.4869.pdf" class="uri">https://arxiv.org/pdf/1412.4869.pdf</a></li>
</ul>
</div>
<div id="importance-resampling" class="section level4">
<h4><span class="header-section-number">9.4.0.8</span> Importance Resampling</h4>
<ul>
<li>Smith and Gelfand. 1992. “Bayesian Statistics without Tears: A Sampling–Resampling Perspective” <em>Am Stat</em> 10.1080/00031305.1992.10475856.</li>
<li>Gelfand and Smith. “Sampling-Based Approaches to Calculating Marginal Densities” <em>JASA</em> 10.1080/01621459.1990.10476213</li>
<li>Lopes, Hedibert F., Nicholas G. Polson, and Carlos M. Carvalho. “Bayesian Statistics with a Smile: A Resampling-sampling Perspective.” <em>Brazilian Journal of Probability and Statistics</em> <a href="http://www.jstor.org/stable/43601224" class="uri">http://www.jstor.org/stable/43601224</a>.</li>
<li>[Simulation-based approaches to modern Bayesian</li>
</ul>
</div>
<div id="approximate-bayesian" class="section level4">
<h4><span class="header-section-number">9.4.0.9</span> Approximate Bayesian</h4>
<ul>
<li>Marin, Pudlo, Robert and Ryder, “Approximate Bayesian computational methods”</li>
</ul>
</div>
<div id="author-attribution" class="section level4">
<h4><span class="header-section-number">9.4.0.10</span> Author attribution</h4>
<ul>
<li>Mosteller. 1964. Inference in an Authorship Problem. <em>JASA</em></li>
<li>Arefin, A. S.; Vimieiro, R.; Riveros, C.; Craig, H. &amp; Moscato, P. Berwick, R. C. (Ed.) An Information Theoretic Clustering Approach for Unveiling Authorship Affinities in Shakespearean Era Plays and Poems PLoS ONE, Public Library of Science (PLoS), 2014. 10.1371/journal.pone.0111445. Not Bayesian per se, but has the corpus of Shakespeare and other plays.</li>
</ul>
</div>
<div id="software" class="section level3">
<h3><span class="header-section-number">9.4.1</span> Software</h3>
<p>Sofware for general purpose Bayesian computation is called <a href="https://en.wikipedia.org/wiki/Probabilistic_programming_language">probablistic programming</a>, though the term is used in CS and not so much in stats, or social science.</p>
<ul>
<li><p><a href="http://mc-stan.org/">Stan</a></p>
<ul>
<li>Joseph Rickert. 2016. <a href="https://www.r-bloggers.com/r-stan-and-bayesian-statistics/">R Stan and Statistics</a></li>
</ul></li>
<li><p>BUGS modeling language. Models are specified in a different language.</p>
<ul>
<li><a href="https://r-nimble.org/">NIMBLE</a> A very new BUGS-like lanugage that works with R.</li>
<li><a href="http://mcmc-jags.sourceforge.net/">JAGS</a> Gibbs/MCMC based</li>
<li><a href="https://www.mrc-bsu.cam.ac.uk/software/bugs/the-bugs-project-winbugs/">WinBUGS</a> Gibbs and MCMC based software. It was one of the first but is now obsolete and unmaintained. Use JAGS or Stan instead.</li>
<li><a href="http://www.openbugs.net/w/FrontPage">OpenBUGS</a> The continuation of the WinBUGS project. Also no longer well maintained. Use JAGS or Stan instead.</li>
</ul></li>
<li><p>R has multiple packages that implement some Bayesian methods. See the <a href="https://cran.r-project.org/web/views/Bayesian.html">Bayesian Task View</a></p>
<ul>
<li><a href="https://cran.r-project.org/web/packages/LearnBayes/index.html">LearnBayes</a></li>
<li><a href="https://cran.r-project.org/web/packages/TeachBayes/index.html">TeachBayes</a></li>
</ul></li>
<li><p>Python</p>
<ul>
<li><a href="https://pymc-devs.github.io/pymc3/">PyMC</a> Very complete general-purpose Python package for Bayesian Analysis</li>
<li>The various Machine learning packages like [SciKit]</li>
</ul></li>
<li><a href="https://github.com/blei-lab/edward">Edward</a>. By David Blei. Deep generative models, variational inference. Runs on Tensorflow. Implements variational and HMC methods, as well as optimization.</li>
<li><p>Church and others. Lisp-based inference programs. These are from the CS side.</p>
<ul>
<li>Church</li>
<li><a href="http://www.robots.ox.ac.uk/~fwood/anglican/index.html">Anglican</a></li>
<li></li>
</ul></li>
<li><p>Stata: Since <a href="http://www.stata.com/new-in-stata/bayesian-analysis/">Stata 14</a> it has some Bayesian capabilities. It is mostly MH with Gibbs for a few models.</p></li>
<li><p>Julia</p>
<ul>
<li><a href="https://mambajl.readthedocs.io/en/latest/">Mamba</a> MCMC supporting multiple methods including Gibbs, MH, HMC, slice</li>
</ul></li>
</ul>
</div>
<div id="stan" class="section level3">
<h3><span class="header-section-number">9.4.2</span> Stan</h3>
<p>Some R packages.</p>
<p>Official <code>stan-dev</code> packages:</p>
<ul>
<li><a href="https://cran.r-project.org/web/packages/rstan/index.html">rstan</a></li>
<li><a href="https://cran.r-project.org/web/packages/rstanarm/index.html">rstanarm</a></li>
<li><a href="https://cran.r-project.org/web/packages/bayesplot/index.html">bayesplot</a></li>
<li><a href="https://cran.r-project.org/web/packages/shinystan/index.html">ShinyStan</a></li>
<li><a href="https://github.com/stan-dev/loo">loo</a></li>
</ul>
<p>Others:</p>
<ul>
<li><a href="https://github.com/paul-buerkner/brms">brms</a> Bayesian generalized non-linear multilevel models using Stan</li>
<li><a href="https://cran.r-project.org/web/packages/ggmcmc/index.html">ggmcmc</a></li>
</ul>
</div>
<div id="diagrams" class="section level3">
<h3><span class="header-section-number">9.4.3</span> Diagrams</h3>
<div id="dags-and-plate-notation" class="section level4">
<h4><span class="header-section-number">9.4.3.1</span> DAGs and Plate Notation</h4>
<p>See <a href="https://en.wikipedia.org/wiki/Plate_notation">Plate notation</a></p>
<ul>
<li><a href="https://github.com/jluttine/tikz-bayesnet">tikz-bayesnet</a> A TiKZ library for drawing Bayesian networks</li>
<li><a href="http://daft-pgm.org/">Daf</a> A python package to draw DAGs</li>
<li><p>Relevant Stackoverflow questions:</p>
<ul>
<li>[Software for drawing bayesian networks (graphical models)] (<a href="http://stats.stackexchange.com/questions/16750/software-for-drawing-bayesian-networks-graphical-models" class="uri">http://stats.stackexchange.com/questions/16750/software-for-drawing-bayesian-networks-graphical-models</a>) Stackoverflow.</li>
<li><a href="http://www.texample.net/tikz/examples/bayes/">Tikz Example</a></li>
<li><a href="http://tex.stackexchange.com/questions/199734/how-to-draw-plate-indices-in-graphical-model-by-tikz">how to draw plate indices in graphical model by tikz</a> Stackexchange</li>
<li><a href="http://tex.stackexchange.com/questions/11751/can-i-have-automatically-adjusted-plates-in-a-graphical-model?rq=1">Can I have automatically adjusted plates in a graphical model?</a></li>
</ul></li>
</ul>
</div>
<div id="kruschke-diagrams" class="section level4">
<h4><span class="header-section-number">9.4.3.2</span> Kruschke Diagrams</h4>
<p>Diagrams in the style of Kruschke’s <em>Doing Bayesian Analysis</em></p>
<ul>
<li>LibreOffice Draw Templates: <a href="http://www.sumsar.net/blog/2013/10/diy-kruschke-style-diagrams/" class="uri">http://www.sumsar.net/blog/2013/10/diy-kruschke-style-diagrams/</a></li>
<li><p>Blog posts</p>
<ul>
<li><a href="http://doingbayesiandataanalysis.blogspot.se/2012/05/graphical-model-diagrams-in-doing.html" class="uri">http://doingbayesiandataanalysis.blogspot.se/2012/05/graphical-model-diagrams-in-doing.html</a></li>
<li><a href="http://doingbayesiandataanalysis.blogspot.se/2012/05/hierarchical-diagrams-read-bottom-to.html" class="uri">http://doingbayesiandataanalysis.blogspot.se/2012/05/hierarchical-diagrams-read-bottom-to.html</a></li>
<li><a href="http://doingbayesiandataanalysis.blogspot.se/2013/10/diagrams-for-hierarchical-models-we.html" class="uri">http://doingbayesiandataanalysis.blogspot.se/2013/10/diagrams-for-hierarchical-models-we.html</a></li>
</ul></li>
<li>R scripts: <a href="https://github.com/rasmusab/distribution_diagrams" class="uri">https://github.com/rasmusab/distribution_diagrams</a></li>
<li><p>Tikz scripts: <a href="https://github.com/yozw/bayesdiagram" class="uri">https://github.com/yozw/bayesdiagram</a></p></li>
</ul>
</div>
<div id="venn-diagramseikosograms" class="section level4">
<h4><span class="header-section-number">9.4.3.3</span> Venn Diagrams/Eikosograms</h4>
<ul>
<li>Oldford and W.H. Cherry. 2006. “Picturing Probability: the poverty of Venn diagrams, the richness of Eikosograms”</li>
</ul>
</div>
</div>
<div id="political-science-bayesian-works" class="section level3">
<h3><span class="header-section-number">9.4.4</span> Political Science Bayesian Works</h3>
<ul>
<li>Darmofal2009a: Darmofal, D. (2009), Bayesian Spatial Survival Models for Political Event Processes. American Journal of Political Science, 53: 241–257. <a href="doi:10.1111/j.1540-5907.2008.00368.x" class="uri">doi:10.1111/j.1540-5907.2008.00368.x</a></li>
<li>RosasShomerHaptonstahl2014a: Rosas, G., Shomer, Y. and Haptonstahl, S. R. (2015), No News Is News: Nonignorable Nonresponse in Roll-Call Data Analysis. American Journal of Political Science, 59: 511–528. <a href="doi:10.1111/ajps.12148" class="uri">doi:10.1111/ajps.12148</a></li>
<li>Joseph Bafumi, Andrew Gelman, David K. Park, Noah Kaplan; Practical Issues in Implementing and Understanding Bayesian Ideal Point Estimation. Polit Anal 2005; 13 (2): 171-187. doi: 10.1093/pan/mpi010</li>
<li>Arthur Spirling; Bayesian Approaches for Limited Dependent Variable Change Point Problems. Polit Anal 2007; 15 (4): 387-405. doi: 10.1093/pan/mpm022</li>
<li>Kari Lock, Andrew Gelman; Bayesian Combination of State Polls and Election Forecasts. Polit Anal 2010; 18 (3): 337-348. doi: 10.1093/pan/mpq002</li>
<li>Jacob M. Montgomery, Brendan Nyhan; Bayesian Model Averaging: Theoretical Developments and Practical Applications. Polit Anal 2010; 18 (2): 245-270. doi: 10.1093/pan/mpq001</li>
<li>Kevin M. Quinn; Bayesian Factor Analysis for Mixed Ordinal and Continuous Responses. Polit Anal 2004; 12 (4): 338-353. doi: 10.1093/pan/mph022</li>
<li>Ryan Bakker, Keith T. Poole; Bayesian Metric Multidimensional Scaling. Polit Anal 2013; 21 (1): 125-140. doi: 10.1093/pan/mps039</li>
<li>Clinton Joshua D, Jackman Simon D, Rivers Douglas. The statistical analysis of roll call data: A unified approach, American Political Science Review , 2004, vol. 98 (pg. 355-70)</li>
<li>Pope Jeremy C, Treier Shawn A. Reconsidering the great compromise at the federal convention of 1787: Deliberation and agenda effects on the senate and slavery, American Journal of Political Science , 2011, vol. 55 (pg. 289-306)</li>
<li>Martin Andrew D, Quinn Kevin M. Dynamic ideal point estimation via Markov chain Monte Carlo for the U.S. Supreme Court, 1953–1999, Political Analysis , 2002, vol. 10 (pg. 134-53)</li>
<li>Justin Grimmer; A Bayesian Hierarchical Topic Model for Political Texts: Measuring Expressed Agendas in Senate Press Releases. Polit Anal 2010; 18 (1): 1-35. doi: 10.1093/pan/mpp034</li>
<li>Jacob M. Montgomery, Florian M. Hollenbach, Michael D. Ward; Improving Predictions Using Ensemble Bayesian Model Averaging. Polit Anal 2012; 20 (3): 271-291. doi: 10.1093/pan/mps002</li>
<li>Stegmueller2013a: Stegmueller, D. (2013), How Many Countries for Multilevel Modeling? A Comparison of Frequentist and Bayesian Approaches. American Journal of Political Science, 57: 748–761. <a href="doi:10.1111/ajps.12001" class="uri">doi:10.1111/ajps.12001</a></li>
<li>HareArmstrongBakkerEtAl2014a: Hare, C., Armstrong, D. A., Bakker, R., Carroll, R. and Poole, K. T. (2015), Using Bayesian Aldrich-McKelvey Scaling to Study Citizens’ Ideological Preferences and Perceptions. American Journal of Political Science, 59: 759–774. <a href="doi:10.1111/ajps.12151" class="uri">doi:10.1111/ajps.12151</a></li>
<li>HonakerKing2010a: Honaker, J. and King, G. (2010), What to Do about Missing Values in Time-Series Cross-Section Data. American Journal of Political Science, 54: 561–581. <a href="doi:10.1111/j.1540-5907.2010.00447.x" class="uri">doi:10.1111/j.1540-5907.2010.00447.x</a></li>
<li>ImaiTingley2011a: Imai, K. and Tingley, D. (2012), A Statistical Method for Empirical Testing of Competing Theories. American Journal of Political Science, 56: 218–236. <a href="doi:10.1111/j.1540-5907.2011.00555.x" class="uri">doi:10.1111/j.1540-5907.2011.00555.x</a></li>
<li>Park2010aL Hee Park, J. (2010), Structural Change in U.S. Presidents’ Use of Force. American Journal of Political Science, 54: 766–782. <a href="doi:10.1111/j.1540-5907.2010.00459.x" class="uri">doi:10.1111/j.1540-5907.2010.00459.x</a></li>
<li>10.1111/j.1540-5907.2012.00590.x</li>
<li>Park2012a: Park, J. H. (2012), A Unified Method for Dynamic and Cross-Sectional Heterogeneity: Introducing Hidden Markov Panel Models. American Journal of Political Science, 56: 1040–1054. <a href="doi:10.1111/j.1540-" class="uri">doi:10.1111/j.1540-</a></li>
<li>WawroKatznelson2013a: Wawro, G. J. and Katznelson, I. (2014), Designing Historical Social Scientific Inquiry: How Parameter Heterogeneity Can Bridge the Methodological Divide between Quantitative and Qualitative Approaches. American Journal of Political Science, 58: 526–546. <a href="doi:10.1111/ajps.12041" class="uri">doi:10.1111/ajps.12041</a></li>
<li>Western, B., &amp; Jackman, S. (1994). Bayesian Inference for Comparative Research. <i>American Political Science Review,</i> <i>88</i>(2), 412-423. <a href="doi:10.2307/2944713" class="uri">doi:10.2307/2944713</a></li>
</ul>
</div>
</div>
<div id="model-checking-1" class="section level2">
<h2><span class="header-section-number">9.5</span> Model Checking</h2>
<ul>
<li>Gelman, Andrew, and Iain Pardoe. 2006. “Bayesian Measures of Explained Variance and Pooling in Multilevel (Hierarchical) Models.” Technometrics 48 (2). Taylor &amp; Francis: 241–51.</li>
<li>Gelman, Andrew. A Bayesian Formulation of Exploratory Data Analysis and Goodness-of-fit Testing. Internat. Statist. Rev. 71 (2003), no. 2, 369–382. <a href="http://projecteuclid.org/euclid.isr/1069172304" class="uri">http://projecteuclid.org/euclid.isr/1069172304</a>.</li>
<li>Kruschke, J. K. (2011). Bayesian assessment of null values via parameter estimation and model comparison. Perspectives on Psychological Science, 6(3) 299–312.</li>
<li>Andrew Gelman Jessica Hwang and Aki Vehtari. 2013. Understanding predictive information criteria for Bayesian models. <a href="http://www.stat.columbia.edu/~gelman/research/published/waic_understand3.pdf" class="uri">http://www.stat.columbia.edu/~gelman/research/published/waic_understand3.pdf</a></li>
<li>Vehtari, Gelman, and Gabry. Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. 2016. <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/loo_stan.pdf" class="uri">http://www.stat.columbia.edu/~gelman/research/unpublished/loo_stan.pdf</a> WAID.</li>
<li>LOO package in R: <a href="https://github.com/stan-dev/loo" class="uri">https://github.com/stan-dev/loo</a></li>
<li>Watanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely application information criterion in singular learning theory. Journal of Machine Learning Research 11, 3571-3594.</li>
<li>Gelfand, A. E. (1996). Model determination using sampling-based methods. In Markov Chain Monte Carlo in Practice, ed. W. R. Gilks, S. Richardson, D. J. Spiegelhalter, 145-162. London: Chapman and Hall.</li>
<li>Gelfand, A. E., Dey, D. K., and Chang, H. (1992). Model determination using predictive distributions with implementation via sampling-based methods. In Bayesian Statistics 4, ed. J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith, 147-167. Oxford University Press.</li>
<li>Gelman, A., Hwang, J., and Vehtari, A. (2014). Understanding predictive information criteria for Bayesian models. Statistics and Computing 24, 997-1016.</li>
<li>Vehtari and Lampinen. 2002. Bayesian model assessment and comparison using cross-validation predictive densities. <a href="https://doi.org/10.1162/08997660260293292" class="uri">https://doi.org/10.1162/08997660260293292</a></li>
<li>Vehtari and Ojanen. 2012. A survey of Bayesian predictive methods for model assessment, selection and comparison. <a href="doi:10.1214/12-SS102" class="uri">doi:10.1214/12-SS102</a></li>
<li>Cook, Gelman, and Rubin. 2006. Validation of Software for Bayesian Models Using Posterior Quantiles. <em>J of Comp. and Graphical Stat</em> <a href="DOI:10.1198/106186006X136976" class="uri">DOI:10.1198/106186006X136976</a></li>
</ul>
</div>
<div id="general-applications-and-models" class="section level2">
<h2><span class="header-section-number">9.6</span> General Applications and Models</h2>
<div id="mixed-methods-and-qualitative-research" class="section level3">
<h3><span class="header-section-number">9.6.1</span> Mixed Methods and Qualitative Research</h3>
<ul>
<li>Macartan Humphreys and Alan M. Jacobs, 2015, “Mixing Methods: A Bayesian Approach”, <em>American Political Science Review</em></li>
</ul>
</div>
</div>
<div id="hierarchical-modeling" class="section level2">
<h2><span class="header-section-number">9.7</span> Hierarchical Modeling</h2>
<ul>
<li>Kruschke and Vanpaeml “Bayesian Estimation in Hierarchical Models” <a href="http://www.indiana.edu/~kruschke/articles/KruschkeVanpaemel2015.pdf" class="uri">http://www.indiana.edu/~kruschke/articles/KruschkeVanpaemel2015.pdf</a></li>
<li>David K. Park, Andrew Gelman, Joseph Bafumi. 2004. “Bayesian Multilevel Estimation with Poststratification: State-Level Estimates from National Polls.” <em>Polit Anal</em> <a href="doi:10.1093/pan/mph024" class="uri">doi:10.1093/pan/mph024</a></li>
<li>Lax, Jeffrey and Justin Phillips. 2009. “How Should We Estimate Public Opinion in the States?” <em>AJPS</em></li>
</ul>
</div>
<div id="shrinkageregularization" class="section level2">
<h2><span class="header-section-number">9.8</span> Shrinkage/Regularization</h2>
<ul>
<li>Piironen and Vehtari. 2016. On the Hyperprior Choice for the Global Shrinkage Parameter in the Horseshoe Prior. <a href="https://arxiv.org/abs/1610.05559" class="uri">https://arxiv.org/abs/1610.05559</a></li>
<li>Lopes. 2015. <a href="http://hedibert.org/wp-content/uploads/2015/12/BayesianRegularization.pdf">Bayesian Regularization</a> slides.</li>
</ul>
<div id="examples" class="section level3">
<h3><span class="header-section-number">9.8.1</span> Examples</h3>
<ul>
<li>Monroe, B. L.; Colaresi, M. P. &amp; Quinn™, K. M. Fightin’ Words: Lexical Feature Selection and Evaluation for Identifying the Content of Political Conflict Political Analysis, Cambridge University Press (CUP), 2008, <a href="https://doi.org/10.1093/pan/mpn018" class="uri">https://doi.org/10.1093/pan/mpn018</a></li>
<li>Beauchamp. 2016. Predicting and Interpolating State-Level Polls Using Twitter Textual Data: Juho Piironen, Aki Vehtari. Projection predictive model selection for Gaussian processes. <a href="https://arxiv.org/abs/1510.04813" class="uri">https://arxiv.org/abs/1510.04813</a></li>
<li>forecasting and predictiing civil war (Fearon / Laitin) Goldstone et al. 2009. “A Global Model for Forecasting Political Instability” <em>AJPS</em> 10.1111/j.1540-5907.2009.00426.x</li>
<li>Ward et al. 2017/ Lessons from near real-time forecasting of irregular leadership changes. <em>JPR</em> <a href="http://dx.doi.org/10.1177%2F0022343316680858">http://dx.doi.org/10.1177%2F0022343316680858</a></li>
<li>Andy Berger. Coup forecasts for 2017. <a href="http://andybeger.com/2017/02/10/coup-forecasts-2017/" class="uri">http://andybeger.com/2017/02/10/coup-forecasts-2017/</a><br />
</li>
<li><a href="http://imai.princeton.edu/research/files/afghan.pdf" class="uri">http://imai.princeton.edu/research/files/afghan.pdf</a></li>
</ul>
</div>
<div id="latent-variable-models" class="section level3">
<h3><span class="header-section-number">9.8.2</span> Latent Variable Models</h3>
<ul>
<li>CLINTON, J., JACKMAN, S., &amp; RIVERS, D. (2004). The Statistical Analysis of Roll Call Data. <i>American Political Science Review,</i> <i>98</i>(2), 355-370. <a href="doi:10.1017/S0003055404001194" class="uri">doi:10.1017/S0003055404001194</a></li>
<li>Pope, J. C. and Treier, S. (2011), Reconsidering the Great Compromise at the Federal Convention of 1787: Deliberation and Agenda Effects on the Senate and Slavery. American Journal of Political Science, 55: 289–306. <a href="doi:10.1111/j.1540-5907.2010.00490.x" class="uri">doi:10.1111/j.1540-5907.2010.00490.x</a></li>
<li>Cai et al. 2016. Item Response Theory. <em>Ann rev of Stat and Its Application</em> DOI: 10.1146/annurev-statistics-041715-033702</li>
</ul>
</div>
</div>
<div id="bayes-theorem-examples" class="section level2">
<h2><span class="header-section-number">9.9</span> Bayes Theorem Examples</h2>
<div id="miscallaneous" class="section level3">
<h3><span class="header-section-number">9.9.1</span> Miscallaneous</h3>
<ul>
<li>Monty Hall Problem: <a href="http://marilynvossavant.com/game-show-problem/" class="uri">http://marilynvossavant.com/game-show-problem/</a></li>
<li><p>Examples from Kahnehman</p></li>
<li>Fenton, Neil, and Berger. 2016. “Bayes and the Law” <em>Ann Rev of Stat and Its Application</em> DOI: 10.1146/annurev-statistics-041715-033428</li>
<li>Taddy. 2013. Multinomial Inverse Regression for Text Analysis. <em>JASA</em> <a href="http://dx.doi.org/10.1080/01621459.2012.734168" class="uri">http://dx.doi.org/10.1080/01621459.2012.734168</a></li>
<li>Taddy. 2015. Document Classification by Inversion of Distributed Language Representations.</li>
<li><p>Laver et al. 2003. Extracting Policy Positions from Political Texts Using Words as Data. Laver, Michael, Kenneth Benoit, and John Garry. “Extracting Policy Positions from Political Texts Using Words as Data.” The American Political Science Review. <a href="http://www.jstor.org/stable/3118211" class="uri">http://www.jstor.org/stable/3118211</a>.</p></li>
</ul>
</div>
<div id="german-tank-problem" class="section level3">
<h3><span class="header-section-number">9.9.2</span> German Tank Problem</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/German_tank_problem" class="uri">https://en.wikipedia.org/wiki/German_tank_problem</a></li>
<li>Goodman 1954. Some Practical Techniques in Serial Number Analysis. <em>JASA</em> <a href="doi:10.1080/01621459.1954.10501218" class="uri">doi:10.1080/01621459.1954.10501218</a></li>
<li>Johnson. 1994. Estimating the Size of a Population. <em>Teaching Stats</em> <a href="DOI:10.1111/j.1467-9639.1994.tb00688.x" class="uri">DOI:10.1111/j.1467-9639.1994.tb00688.x</a></li>
<li>Ruggles and Brodie. 1947. An Empirical Approach to Economic Intelligence in World War II. <a href="doi:10.1080/01621459.1947.10501915" class="uri">doi:10.1080/01621459.1947.10501915</a></li>
</ul>
<p>Other applications</p>
<ul>
<li>Gill and Spirling. 2015. Estimating the Severity of the WikiLeaks U.S. Diplomatic Cables Disclosure. <a href="https://doi.org/10.1093/pan/mpv005" class="uri">https://doi.org/10.1093/pan/mpv005</a>. <em>Political Analysis</em> <a href="doi:10.1093/pan/mpv005" class="uri">doi:10.1093/pan/mpv005</a></li>
</ul>
</div>
</div>
<div id="good-turing-estimator" class="section level2">
<h2><span class="header-section-number">9.10</span> Good-Turing Estimator</h2>
<ul>
<li>Mosteller. 1964. Inference in an Authorship Problem. <em>JASA</em></li>
</ul>
</div>
<div id="reproducibility" class="section level2">
<h2><span class="header-section-number">9.11</span> Reproducibility</h2>
<ul>
<li>Jon Zelner: <a href="http://www.jonzelner.net/statistics/make/docker/reproducibility/2016/05/31/reproducibility-pt-1/">Docker package of an R and Stan project</a></li>
<li><a href="https://github.com/kjhealy/lintscreen" class="uri">https://github.com/kjhealy/lintscreen</a></li>
<li><a href="https://msalganik.wordpress.com/2015/06/09/rapid-feedback-on-code-with-lintr/" class="uri">https://msalganik.wordpress.com/2015/06/09/rapid-feedback-on-code-with-lintr/</a></li>
<li><a href="https://msalganik.wordpress.com/2015/06/07/git-and-github-in-a-data-analysis-class/" class="uri">https://msalganik.wordpress.com/2015/06/07/git-and-github-in-a-data-analysis-class/</a></li>
<li><a href="http://astrofrog.github.io/blog/2013/04/10/how-to-conduct-a-full-code-review-on-github/" class="uri">http://astrofrog.github.io/blog/2013/04/10/how-to-conduct-a-full-code-review-on-github/</a></li>
<li><a href="http://www.princeton.edu/~mjs3/soc504_s2015/submitting_homework.shtml" class="uri">http://www.princeton.edu/~mjs3/soc504_s2015/submitting_homework.shtml</a></li>
<li><a href="https://education.github.com/guide" class="uri">https://education.github.com/guide</a></li>
<li><a href="https://msalganik.wordpress.com/2015/05/04/replication-and-extension-projects-making-class-more-interesting-and-useful/" class="uri">https://msalganik.wordpress.com/2015/05/04/replication-and-extension-projects-making-class-more-interesting-and-useful/</a></li>
<li><a href="https://en.wikipedia.org/wiki/Good%E2%80%93Turing_frequency_estimation">https://en.wikipedia.org/wiki/Good%E2%80%93Turing_frequency_estimation</a></li>
<li><a href="https://dx.doi.org/10.1093%2Fbiomet%2F40.3-4.237">https://dx.doi.org/10.1093%2Fbiomet%2F40.3-4.237</a></li>
<li><a href="http://rstudio-pubs-static.s3.amazonaws.com/165358_78fd356d6e124331bd66981c51f7ad7c.html" class="uri">http://rstudio-pubs-static.s3.amazonaws.com/165358_78fd356d6e124331bd66981c51f7ad7c.html</a></li>
<li><a href="https://www.cs.cornell.edu/courses/cs6740/2010sp/guides/lec11.pdf" class="uri">https://www.cs.cornell.edu/courses/cs6740/2010sp/guides/lec11.pdf</a></li>
<li><a href="https://www.rdocumentation.org/packages/edgeR/versions/3.14.0/topics/goodTuring" class="uri">https://www.rdocumentation.org/packages/edgeR/versions/3.14.0/topics/goodTuring</a></li>
<li><a href="http://kochanski.org/gpk/teaching/0401Oxford/GoodTuring.pdf" class="uri">http://kochanski.org/gpk/teaching/0401Oxford/GoodTuring.pdf</a></li>
<li><a href="http://www.cs.dartmouth.edu/~lorenzo/teaching/cs134/Archive/Spring2010/milestone/20100511-134-milestone-cooley/node5.html" class="uri">http://www.cs.dartmouth.edu/~lorenzo/teaching/cs134/Archive/Spring2010/milestone/20100511-134-milestone-cooley/node5.html</a></li>
<li><a href="https://simons.berkeley.edu/events/openlectures2015-spring-1" class="uri">https://simons.berkeley.edu/events/openlectures2015-spring-1</a></li>
<li><a href="http://www.grsampson.net/D_SGT.c" class="uri">http://www.grsampson.net/D_SGT.c</a></li>
<li><a href="https://courses.engr.illinois.edu/cs498jh/Slides/Lecture03HO.pdf" class="uri">https://courses.engr.illinois.edu/cs498jh/Slides/Lecture03HO.pdf</a></li>
<li><a href="http://ic.epfl.ch/files/content/sites/ic/files/Inka/Orlitsky%20Talk%202016.pdf">http://ic.epfl.ch/files/content/sites/ic/files/Inka/Orlitsky%20Talk%202016.pdf</a></li>
</ul>
<div id="uncategorized" class="section level3">
<h3><span class="header-section-number">9.11.1</span> Uncategorized</h3>
<ul>
<li>Travelling Politician Example: <a href="https://github.com/ctufts/metropolis_hastings_example/tree/master/claydavis" class="uri">https://github.com/ctufts/metropolis_hastings_example/tree/master/claydavis</a></li>
</ul>
</div>
</div>
<div id="empirical-bayes" class="section level2">
<h2><span class="header-section-number">9.12</span> Empirical Bayes</h2>
<ul>
<li>Efron. 2015. Frequentist accuracy of Bayesian estimates. <em>JRSS B</em> <a href="https://dx.doi.org/10.1111%2Frssb.12080">https://dx.doi.org/10.1111%2Frssb.12080</a></li>
</ul>
</div>
<div id="things-to-cover" class="section level2">
<h2><span class="header-section-number">9.13</span> Things to cover</h2>
<ul>
<li>Lindley’s paradox</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references-6.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/bayesian_notes/edit/master/annotated.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
