<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Updating: A Set of Bayesian Notes</title>
  <meta name="description" content="Updating: A Set of Bayesian Notes">
  <meta name="generator" content="bookdown 0.7.7 and GitBook 2.6.7">

  <meta property="og:title" content="Updating: A Set of Bayesian Notes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jrnold.github.io/bayesian_notes" />
  
  
  <meta name="github-repo" content="jrnold/bayesian_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Updating: A Set of Bayesian Notes" />
  <meta name="twitter:site" content="@jrnld" />
  
  

<meta name="author" content="Jeffrey B. Arnold">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="generalized-linear-models.html">
<link rel="next" href="hierarchical-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.0/htmlwidgets.js"></script>
<script src="libs/d3-3.3.8/d3.min.js"></script>
<script src="libs/dagre-0.4.0/dagre-d3.min.js"></script>
<link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet" />
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/chromatography-0.1/chromatography.js"></script>
<script src="libs/DiagrammeR-binding-1.0.0/DiagrammeR.js"></script>
<script src="libs/viz-0.3/viz.js"></script>
<script src="libs/grViz-binding-1.0.0/grViz.js"></script>



<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Bayesian Notes</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>1</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="1.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#bayesian-analysis"><i class="fa fa-check"></i><b>1.1</b> Bayesian Analysis</a></li>
<li class="chapter" data-level="1.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>1.2</b> Posterior Predictive Distribution</a></li>
</ul></li>
<li class="part"><span><b>I Theory</b></span></li>
<li class="chapter" data-level="2" data-path="bayes-theorem.html"><a href="bayes-theorem.html"><i class="fa fa-check"></i><b>2</b> Bayes Theorem</a><ul>
<li class="chapter" data-level="" data-path="bayes-theorem.html"><a href="bayes-theorem.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="2.1" data-path="bayes-theorem.html"><a href="bayes-theorem.html#introduction-to-bayes-theorem"><i class="fa fa-check"></i><b>2.1</b> Introduction to Bayes’ Theorem</a></li>
<li class="chapter" data-level="2.2" data-path="bayes-theorem.html"><a href="bayes-theorem.html#examples"><i class="fa fa-check"></i><b>2.2</b> Examples</a><ul>
<li class="chapter" data-level="2.2.1" data-path="bayes-theorem.html"><a href="bayes-theorem.html#taxi-cab-problem"><i class="fa fa-check"></i><b>2.2.1</b> Taxi-Cab Problem</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="bayes-theorem.html"><a href="bayes-theorem.html#why-most-research-findings-are-false"><i class="fa fa-check"></i><b>2.3</b> Why most research findings are false</a><ul>
<li class="chapter" data-level="2.3.1" data-path="bayes-theorem.html"><a href="bayes-theorem.html#questions"><i class="fa fa-check"></i><b>2.3.1</b> Questions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="bayes-theorem.html"><a href="bayes-theorem.html#measurement-error-and-rare-events-in-surveys"><i class="fa fa-check"></i><b>2.4</b> Measurement Error and Rare Events in Surveys</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html"><i class="fa fa-check"></i><b>3</b> Example: Predicting Names from Ages</a><ul>
<li class="chapter" data-level="" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#prerequisites-1"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="3.1" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#statement-of-the-problem"><i class="fa fa-check"></i><b>3.1</b> Statement of the problem</a></li>
<li class="chapter" data-level="3.2" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#data-wrangling"><i class="fa fa-check"></i><b>3.2</b> Data Wrangling</a></li>
<li class="chapter" data-level="3.3" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#probability-of-age-given-name-and-sex"><i class="fa fa-check"></i><b>3.3</b> Probability of age given name and sex</a><ul>
<li class="chapter" data-level="3.3.1" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#questions-1"><i class="fa fa-check"></i><b>3.3.1</b> Questions</a></li>
<li class="chapter" data-level="3.3.2" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#references"><i class="fa fa-check"></i><b>3.3.2</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>4</b> Naive Bayes</a><ul>
<li class="chapter" data-level="" data-path="naive-bayes.html"><a href="naive-bayes.html#prerequisites-2"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="4.1" data-path="naive-bayes.html"><a href="naive-bayes.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="naive-bayes.html"><a href="naive-bayes.html#examples-1"><i class="fa fa-check"></i><b>4.2</b> Examples</a><ul>
<li class="chapter" data-level="4.2.1" data-path="naive-bayes.html"><a href="naive-bayes.html#federalist-papers"><i class="fa fa-check"></i><b>4.2.1</b> Federalist Papers</a></li>
<li class="chapter" data-level="4.2.2" data-path="naive-bayes.html"><a href="naive-bayes.html#extensions"><i class="fa fa-check"></i><b>4.2.2</b> Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="naive-bayes.html"><a href="naive-bayes.html#details"><i class="fa fa-check"></i><b>4.3</b> Details</a><ul>
<li class="chapter" data-level="4.3.1" data-path="naive-bayes.html"><a href="naive-bayes.html#generative-vs.discriminative-models"><i class="fa fa-check"></i><b>4.3.1</b> Generative vs. Discriminative Models</a></li>
<li class="chapter" data-level="4.3.2" data-path="naive-bayes.html"><a href="naive-bayes.html#estimation"><i class="fa fa-check"></i><b>4.3.2</b> Estimation</a></li>
<li class="chapter" data-level="4.3.3" data-path="naive-bayes.html"><a href="naive-bayes.html#prediction"><i class="fa fa-check"></i><b>4.3.3</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="naive-bayes.html"><a href="naive-bayes.html#references-1"><i class="fa fa-check"></i><b>4.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="priors.html"><a href="priors.html"><i class="fa fa-check"></i><b>5</b> Priors</a><ul>
<li class="chapter" data-level="5.1" data-path="priors.html"><a href="priors.html#levels-of-priors"><i class="fa fa-check"></i><b>5.1</b> Levels of Priors</a></li>
<li class="chapter" data-level="5.2" data-path="priors.html"><a href="priors.html#conjugate-priors"><i class="fa fa-check"></i><b>5.2</b> Conjugate Priors</a><ul>
<li class="chapter" data-level="5.2.1" data-path="priors.html"><a href="priors.html#binomial-beta"><i class="fa fa-check"></i><b>5.2.1</b> Binomial-Beta</a></li>
<li class="chapter" data-level="5.2.2" data-path="priors.html"><a href="priors.html#categorical-dirichlet"><i class="fa fa-check"></i><b>5.2.2</b> Categorical-Dirichlet</a></li>
<li class="chapter" data-level="5.2.3" data-path="priors.html"><a href="priors.html#poisson-gamma"><i class="fa fa-check"></i><b>5.2.3</b> Poisson-Gamma</a></li>
<li class="chapter" data-level="5.2.4" data-path="priors.html"><a href="priors.html#normal-with-known-variance"><i class="fa fa-check"></i><b>5.2.4</b> Normal with known variance</a></li>
<li class="chapter" data-level="5.2.5" data-path="priors.html"><a href="priors.html#exponential-family"><i class="fa fa-check"></i><b>5.2.5</b> Exponential Family</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="priors.html"><a href="priors.html#improper-priors"><i class="fa fa-check"></i><b>5.3</b> Improper Priors</a></li>
<li class="chapter" data-level="5.4" data-path="priors.html"><a href="priors.html#cromwells-rule"><i class="fa fa-check"></i><b>5.4</b> Cromwell’s Rule</a></li>
<li class="chapter" data-level="5.5" data-path="priors.html"><a href="priors.html#asymptotics"><i class="fa fa-check"></i><b>5.5</b> Asymptotics</a></li>
<li class="chapter" data-level="5.6" data-path="priors.html"><a href="priors.html#proper-and-improper-priors"><i class="fa fa-check"></i><b>5.6</b> Proper and Improper Priors</a></li>
<li class="chapter" data-level="5.7" data-path="priors.html"><a href="priors.html#hyperpriors-and-hyperparameters"><i class="fa fa-check"></i><b>5.7</b> Hyperpriors and Hyperparameters</a></li>
<li class="chapter" data-level="5.8" data-path="priors.html"><a href="priors.html#references-2"><i class="fa fa-check"></i><b>5.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimation-1.html"><a href="estimation-1.html"><i class="fa fa-check"></i><b>6</b> Estimation</a><ul>
<li class="chapter" data-level="6.1" data-path="estimation-1.html"><a href="estimation-1.html#point-estimates"><i class="fa fa-check"></i><b>6.1</b> Point Estimates</a></li>
<li class="chapter" data-level="6.2" data-path="estimation-1.html"><a href="estimation-1.html#credible-intervals"><i class="fa fa-check"></i><b>6.2</b> Credible Intervals</a><ul>
<li class="chapter" data-level="6.2.1" data-path="estimation-1.html"><a href="estimation-1.html#compared-to-confidence-intervals"><i class="fa fa-check"></i><b>6.2.1</b> Compared to confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="estimation-1.html"><a href="estimation-1.html#bayesian-decision-theory"><i class="fa fa-check"></i><b>6.3</b> Bayesian Decision Theory</a></li>
</ul></li>
<li class="part"><span><b>II Computation</b></span></li>
<li class="chapter" data-level="7" data-path="bayesian-computation.html"><a href="bayesian-computation.html"><i class="fa fa-check"></i><b>7</b> Bayesian Computation</a><ul>
<li class="chapter" data-level="7.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#how-to-calculate-a-posterior"><i class="fa fa-check"></i><b>7.1</b> How to calculate a posterior?</a></li>
<li class="chapter" data-level="7.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#example-globe-tossing-model"><i class="fa fa-check"></i><b>7.2</b> Example: Globe-tossing model</a></li>
<li class="chapter" data-level="7.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#quadrature"><i class="fa fa-check"></i><b>7.3</b> Quadrature</a><ul>
<li class="chapter" data-level="7.3.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#grid-approximation"><i class="fa fa-check"></i><b>7.3.1</b> Grid approximation</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="bayesian-computation.html"><a href="bayesian-computation.html#functional-approximations"><i class="fa fa-check"></i><b>7.4</b> Functional Approximations</a><ul>
<li class="chapter" data-level="7.4.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#maximum-a-posteriori"><i class="fa fa-check"></i><b>7.4.1</b> Maximum A Posteriori</a></li>
<li class="chapter" data-level="7.4.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#laplace-approximation"><i class="fa fa-check"></i><b>7.4.2</b> Laplace Approximation</a></li>
<li class="chapter" data-level="7.4.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#variational-inference"><i class="fa fa-check"></i><b>7.4.3</b> Variational Inference</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="bayesian-computation.html"><a href="bayesian-computation.html#sampling-methods"><i class="fa fa-check"></i><b>7.5</b> Sampling Methods</a><ul>
<li class="chapter" data-level="7.5.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#numerical-integration"><i class="fa fa-check"></i><b>7.5.1</b> Numerical Integration</a></li>
<li class="chapter" data-level="7.5.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#inverse-transform-sampling"><i class="fa fa-check"></i><b>7.5.2</b> Inverse transform sampling</a></li>
<li class="chapter" data-level="7.5.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#direct-approximation"><i class="fa fa-check"></i><b>7.5.3</b> Direct approximation</a></li>
<li class="chapter" data-level="7.5.4" data-path="bayesian-computation.html"><a href="bayesian-computation.html#rejection-sampling"><i class="fa fa-check"></i><b>7.5.4</b> Rejection sampling</a></li>
<li class="chapter" data-level="7.5.5" data-path="bayesian-computation.html"><a href="bayesian-computation.html#importance-sampling"><i class="fa fa-check"></i><b>7.5.5</b> Importance Sampling</a></li>
<li class="chapter" data-level="7.5.6" data-path="bayesian-computation.html"><a href="bayesian-computation.html#mcmc-methods"><i class="fa fa-check"></i><b>7.5.6</b> MCMC Methods</a></li>
<li class="chapter" data-level="7.5.7" data-path="bayesian-computation.html"><a href="bayesian-computation.html#discarding-early-iterations"><i class="fa fa-check"></i><b>7.5.7</b> Discarding early iterations</a></li>
<li class="chapter" data-level="7.5.8" data-path="bayesian-computation.html"><a href="bayesian-computation.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>7.5.8</b> Monte Carlo Sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>8</b> MCMC Diagnostics</a><ul>
<li class="chapter" data-level="" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#prerequisites-3"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="8.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#reparameterize-models"><i class="fa fa-check"></i><b>8.1</b> Reparameterize Models</a></li>
<li class="chapter" data-level="8.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#convergence-diagnostics"><i class="fa fa-check"></i><b>8.2</b> Convergence Diagnostics</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#potential-scale-reduction-hatr"><i class="fa fa-check"></i><b>8.2.1</b> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</a></li>
<li class="chapter" data-level="8.2.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#references-3"><i class="fa fa-check"></i><b>8.2.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation-effective-sample-size-and-mcse"><i class="fa fa-check"></i><b>8.3</b> Autocorrelation, Effective Sample Size, and MCSE</a><ul>
<li class="chapter" data-level="8.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#effective-sample-size"><i class="fa fa-check"></i><b>8.3.1</b> Effective Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#thinning"><i class="fa fa-check"></i><b>8.4</b> Thinning</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#traceplots"><i class="fa fa-check"></i><b>8.4.1</b> Traceplots</a></li>
<li class="chapter" data-level="8.4.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#monte-carlo-standard-error-mcse"><i class="fa fa-check"></i><b>8.4.2</b> Monte Carlo Standard Error (MCSE)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#hmc-nut-specific-diagnostics"><i class="fa fa-check"></i><b>8.5</b> HMC-NUT Specific Diagnostics</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#divergent-transitions"><i class="fa fa-check"></i><b>8.5.1</b> Divergent transitions</a></li>
<li class="chapter" data-level="8.5.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#maximum-tree-depth"><i class="fa fa-check"></i><b>8.5.2</b> Maximum Tree-depth</a></li>
<li class="chapter" data-level="8.5.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#bayesian-fraction-of-missing-information"><i class="fa fa-check"></i><b>8.5.3</b> Bayesian Fraction of Missing Information</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#debugging-bayesian-computing"><i class="fa fa-check"></i><b>8.6</b> Debugging Bayesian Computing</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>9</b> Model Checking</a><ul>
<li class="chapter" data-level="9.1" data-path="model-checking.html"><a href="model-checking.html#why-check-models"><i class="fa fa-check"></i><b>9.1</b> Why check models?</a></li>
<li class="chapter" data-level="9.2" data-path="model-checking.html"><a href="model-checking.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>9.2</b> Posterior Predictive Checks</a><ul>
<li class="chapter" data-level="9.2.1" data-path="model-checking.html"><a href="model-checking.html#bayesian-p-values"><i class="fa fa-check"></i><b>9.2.1</b> Bayesian p-values</a></li>
<li class="chapter" data-level="9.2.2" data-path="model-checking.html"><a href="model-checking.html#test-quantities"><i class="fa fa-check"></i><b>9.2.2</b> Test quantities</a></li>
<li class="chapter" data-level="9.2.3" data-path="model-checking.html"><a href="model-checking.html#p-values-vs.u-values"><i class="fa fa-check"></i><b>9.2.3</b> p-values vs. u-values</a></li>
<li class="chapter" data-level="9.2.4" data-path="model-checking.html"><a href="model-checking.html#marginal-predictive-checks"><i class="fa fa-check"></i><b>9.2.4</b> Marginal predictive checks</a></li>
<li class="chapter" data-level="9.2.5" data-path="model-checking.html"><a href="model-checking.html#outliers"><i class="fa fa-check"></i><b>9.2.5</b> Outliers</a></li>
<li class="chapter" data-level="9.2.6" data-path="model-checking.html"><a href="model-checking.html#graphical-posterior-predictive-checks"><i class="fa fa-check"></i><b>9.2.6</b> Graphical Posterior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="model-checking.html"><a href="model-checking.html#references-4"><i class="fa fa-check"></i><b>9.3</b> References</a></li>
</ul></li>
<li class="part"><span><b>III Models</b></span></li>
<li class="chapter" data-level="10" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html"><i class="fa fa-check"></i><b>10</b> Introduction to Stan and Linear Regression</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#prerequisites-4"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="10.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#ols-and-mle-linear-regression"><i class="fa fa-check"></i><b>10.1</b> OLS and MLE Linear Regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#bayesian-model-with-improper-priors"><i class="fa fa-check"></i><b>10.1.1</b> Bayesian Model with Improper priors</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#stan-model"><i class="fa fa-check"></i><b>10.2</b> Stan Model</a></li>
<li class="chapter" data-level="10.3" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling-model-with-stan"><i class="fa fa-check"></i><b>10.3</b> Sampling Model with Stan</a><ul>
<li class="chapter" data-level="10.3.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling"><i class="fa fa-check"></i><b>10.3.1</b> Sampling</a></li>
<li class="chapter" data-level="10.3.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#convergence-diagnostics-and-model-fit"><i class="fa fa-check"></i><b>10.3.2</b> Convergence Diagnostics and Model Fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html"><i class="fa fa-check"></i><b>11</b> Heteroskedasticity and Robust Regression</a><ul>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#prerequisites-5"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="11.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#linear-regression-with-student-t-distributed-errors"><i class="fa fa-check"></i><b>11.1</b> Linear Regression with Student t distributed errors</a></li>
<li class="chapter" data-level="11.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity"><i class="fa fa-check"></i><b>11.2</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="11.2.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#covariates"><i class="fa fa-check"></i><b>11.2.1</b> Covariates</a></li>
<li class="chapter" data-level="11.2.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#student-t-error"><i class="fa fa-check"></i><b>11.2.2</b> Student-t Error</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#references-5"><i class="fa fa-check"></i><b>11.3</b> References</a><ul>
<li class="chapter" data-level="11.3.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#quantile-regression"><i class="fa fa-check"></i><b>11.3.1</b> Quantile regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>12</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="12.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#count-models"><i class="fa fa-check"></i><b>12.1</b> Count Models</a><ul>
<li class="chapter" data-level="12.1.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson"><i class="fa fa-check"></i><b>12.1.1</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example-3"><i class="fa fa-check"></i><b>12.2</b> Example</a></li>
<li class="chapter" data-level="12.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#negative-binomial"><i class="fa fa-check"></i><b>12.3</b> Negative Binomial</a></li>
<li class="chapter" data-level="12.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial-categorical-models"><i class="fa fa-check"></i><b>12.4</b> Multinomial / Categorical Models</a></li>
<li class="chapter" data-level="12.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#gamma-regression"><i class="fa fa-check"></i><b>12.5</b> Gamma Regression</a></li>
<li class="chapter" data-level="12.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#beta-regression"><i class="fa fa-check"></i><b>12.6</b> Beta Regression</a></li>
<li class="chapter" data-level="12.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-6"><i class="fa fa-check"></i><b>12.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="binomial-models.html"><a href="binomial-models.html"><i class="fa fa-check"></i><b>13</b> Binomial Models</a><ul>
<li class="chapter" data-level="13.1" data-path="binomial-models.html"><a href="binomial-models.html#link-functions-link-function"><i class="fa fa-check"></i><b>13.1</b> Link Functions {link-function}</a><ul>
<li class="chapter" data-level="13.1.1" data-path="binomial-models.html"><a href="binomial-models.html#stan"><i class="fa fa-check"></i><b>13.1.1</b> Stan</a></li>
<li class="chapter" data-level="13.1.2" data-path="binomial-models.html"><a href="binomial-models.html#example-vote-turnout"><i class="fa fa-check"></i><b>13.1.2</b> Example: Vote Turnout</a></li>
<li class="chapter" data-level="13.1.3" data-path="binomial-models.html"><a href="binomial-models.html#separation"><i class="fa fa-check"></i><b>13.1.3</b> Separation</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="binomial-models.html"><a href="binomial-models.html#rare-events-logit"><i class="fa fa-check"></i><b>13.2</b> Rare Events Logit</a></li>
<li class="chapter" data-level="13.3" data-path="binomial-models.html"><a href="binomial-models.html#case-control"><i class="fa fa-check"></i><b>13.3</b> Case Control</a><ul>
<li class="chapter" data-level="13.3.1" data-path="binomial-models.html"><a href="binomial-models.html#references-7"><i class="fa fa-check"></i><b>13.3.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>14</b> Hierarchical Models</a><ul>
<li class="chapter" data-level="" data-path="hierarchical-models.html"><a href="hierarchical-models.html#prerequisites-6"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="14.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-baseball-hits"><i class="fa fa-check"></i><b>14.1</b> Example: Baseball Hits</a><ul>
<li class="chapter" data-level="14.1.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#references-8"><i class="fa fa-check"></i><b>14.1.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>15</b> Multilevel Models</a><ul>
<li class="chapter" data-level="15.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-radon"><i class="fa fa-check"></i><b>15.1</b> Example: Radon</a><ul>
<li class="chapter" data-level="15.1.1" data-path="multilevel-models.html"><a href="multilevel-models.html#data"><i class="fa fa-check"></i><b>15.1.1</b> Data</a></li>
<li class="chapter" data-level="15.1.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercepts-models"><i class="fa fa-check"></i><b>15.1.2</b> Varying Intercepts Models</a></li>
<li class="chapter" data-level="15.1.3" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercept-model"><i class="fa fa-check"></i><b>15.1.3</b> Varying Intercept Model</a></li>
<li class="chapter" data-level="15.1.4" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-slope-model"><i class="fa fa-check"></i><b>15.1.4</b> Varying Slope Model</a></li>
<li class="chapter" data-level="15.1.5" data-path="multilevel-models.html"><a href="multilevel-models.html#group-level-predictors"><i class="fa fa-check"></i><b>15.1.5</b> Group Level Predictors</a></li>
<li class="chapter" data-level="15.1.6" data-path="multilevel-models.html"><a href="multilevel-models.html#lme4"><i class="fa fa-check"></i><b>15.1.6</b> lme4</a></li>
<li class="chapter" data-level="15.1.7" data-path="multilevel-models.html"><a href="multilevel-models.html#rstanarm"><i class="fa fa-check"></i><b>15.1.7</b> rstanarm</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="multilevel-models.html"><a href="multilevel-models.html#pooling-of-hierarchical-parameters"><i class="fa fa-check"></i><b>15.2</b> Pooling of Hierarchical Parameters</a></li>
<li class="chapter" data-level="15.3" data-path="multilevel-models.html"><a href="multilevel-models.html#anova"><i class="fa fa-check"></i><b>15.3</b> ANOVA</a></li>
<li class="chapter" data-level="15.4" data-path="multilevel-models.html"><a href="multilevel-models.html#time-series-cross-section"><i class="fa fa-check"></i><b>15.4</b> Time-Series Cross Section</a></li>
<li class="chapter" data-level="15.5" data-path="multilevel-models.html"><a href="multilevel-models.html#miscellaneous"><i class="fa fa-check"></i><b>15.5</b> Miscellaneous</a><ul>
<li class="chapter" data-level="15.5.1" data-path="multilevel-models.html"><a href="multilevel-models.html#how-many-groups"><i class="fa fa-check"></i><b>15.5.1</b> How many groups?</a></li>
<li class="chapter" data-level="15.5.2" data-path="multilevel-models.html"><a href="multilevel-models.html#correlation-between-predictors-and-errors"><i class="fa fa-check"></i><b>15.5.2</b> Correlation between Predictors and Errors</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="multilevel-models.html"><a href="multilevel-models.html#references-9"><i class="fa fa-check"></i><b>15.6</b> References</a></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span></li>
<li class="chapter" data-level="16" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>16</b> Distributions</a></li>
<li class="chapter" data-level="17" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html"><i class="fa fa-check"></i><b>17</b> Annotated Bibliography</a><ul>
<li class="chapter" data-level="17.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#textbooks"><i class="fa fa-check"></i><b>17.1</b> Textbooks</a></li>
<li class="chapter" data-level="17.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#syllabi"><i class="fa fa-check"></i><b>17.2</b> Syllabi</a></li>
<li class="chapter" data-level="17.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#topics"><i class="fa fa-check"></i><b>17.3</b> Topics</a></li>
<li class="chapter" data-level="17.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayes-theorem-1"><i class="fa fa-check"></i><b>17.4</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="17.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#article-length-introductions-to-bayesian-statistics"><i class="fa fa-check"></i><b>17.5</b> Article Length Introductions to Bayesian Statistics</a><ul>
<li class="chapter" data-level="17.5.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#why-bayesian"><i class="fa fa-check"></i><b>17.5.1</b> Why Bayesian</a></li>
<li class="chapter" data-level="17.5.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#modern-statistical-workflow"><i class="fa fa-check"></i><b>17.5.2</b> Modern Statistical Workflow</a></li>
<li class="chapter" data-level="17.5.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-philosophy"><i class="fa fa-check"></i><b>17.5.3</b> Bayesian Philosophy</a></li>
<li class="chapter" data-level="17.5.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>17.5.4</b> Bayesian Hypothesis Testing</a></li>
<li class="chapter" data-level="17.5.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-frequentist-debates"><i class="fa fa-check"></i><b>17.5.5</b> Bayesian Frequentist Debates</a></li>
<li class="chapter" data-level="17.5.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#categorical"><i class="fa fa-check"></i><b>17.5.6</b> Categorical</a></li>
<li class="chapter" data-level="17.5.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#variable-selection"><i class="fa fa-check"></i><b>17.5.7</b> Variable Selection</a></li>
<li class="chapter" data-level="17.5.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multiple-testing"><i class="fa fa-check"></i><b>17.5.8</b> Multiple Testing</a></li>
<li class="chapter" data-level="17.5.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#rare-events"><i class="fa fa-check"></i><b>17.5.9</b> Rare Events</a></li>
<li class="chapter" data-level="17.5.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#identifiability"><i class="fa fa-check"></i><b>17.5.10</b> Identifiability</a></li>
<li class="chapter" data-level="17.5.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkage"><i class="fa fa-check"></i><b>17.5.11</b> Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software"><i class="fa fa-check"></i><b>17.6</b> Software</a><ul>
<li class="chapter" data-level="17.6.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#stan-1"><i class="fa fa-check"></i><b>17.6.1</b> Stan</a></li>
<li class="chapter" data-level="17.6.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#diagrams"><i class="fa fa-check"></i><b>17.6.2</b> Diagrams</a></li>
<li class="chapter" data-level="17.6.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#priors-1"><i class="fa fa-check"></i><b>17.6.3</b> Priors</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-model-averaging"><i class="fa fa-check"></i><b>17.7</b> Bayesian Model Averaging</a></li>
<li class="chapter" data-level="17.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multilevel-modeling"><i class="fa fa-check"></i><b>17.8</b> Multilevel Modeling</a></li>
<li class="chapter" data-level="17.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#mixture-models"><i class="fa fa-check"></i><b>17.9</b> Mixture Models</a></li>
<li class="chapter" data-level="17.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#inference"><i class="fa fa-check"></i><b>17.10</b> Inference</a><ul>
<li class="chapter" data-level="17.10.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#discussion-of-bayesian-inference"><i class="fa fa-check"></i><b>17.10.1</b> Discussion of Bayesian Inference</a></li>
</ul></li>
<li class="chapter" data-level="17.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#model-checking-1"><i class="fa fa-check"></i><b>17.11</b> Model Checking</a><ul>
<li class="chapter" data-level="17.11.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#posterior-predictive-checks-1"><i class="fa fa-check"></i><b>17.11.1</b> Posterior Predictive Checks</a></li>
<li class="chapter" data-level="17.11.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#prediction-criteria"><i class="fa fa-check"></i><b>17.11.2</b> Prediction Criteria</a></li>
<li class="chapter" data-level="17.11.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software-validation"><i class="fa fa-check"></i><b>17.11.3</b> Software Validation</a></li>
</ul></li>
<li class="chapter" data-level="17.12" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#hierarchical-modeling"><i class="fa fa-check"></i><b>17.12</b> Hierarchical Modeling</a></li>
<li class="chapter" data-level="17.13" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkageregularization"><i class="fa fa-check"></i><b>17.13</b> Shrinkage/Regularization</a></li>
<li class="chapter" data-level="17.14" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#empirical-bayes"><i class="fa fa-check"></i><b>17.14</b> Empirical Bayes</a></li>
<li class="chapter" data-level="17.15" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#history-of-bayesian-statistics"><i class="fa fa-check"></i><b>17.15</b> History of Bayesian Statistics</a></li>
<li class="chapter" data-level="17.16" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#sampling-difficulties"><i class="fa fa-check"></i><b>17.16</b> Sampling Difficulties</a></li>
<li class="chapter" data-level="17.17" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#complicated-estimation-and-testing"><i class="fa fa-check"></i><b>17.17</b> Complicated Estimation and Testing</a></li>
<li class="chapter" data-level="17.18" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#pooling-polls"><i class="fa fa-check"></i><b>17.18</b> Pooling Polls</a></li>
<li class="chapter" data-level="17.19" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#visualizing-mcmc-methods"><i class="fa fa-check"></i><b>17.19</b> Visualizing MCMC Methods</a></li>
<li class="chapter" data-level="17.20" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-point-estimation-decision"><i class="fa fa-check"></i><b>17.20</b> Bayesian point estimation / Decision</a></li>
<li class="chapter" data-level="17.21" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#stan-modeling-language"><i class="fa fa-check"></i><b>17.21</b> Stan Modeling Language</a></li>
<li class="chapter" data-level="17.22" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayes-factors"><i class="fa fa-check"></i><b>17.22</b> Bayes Factors</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-10.html"><a href="references-10.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Updating: A Set of Bayesian Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\median}{median}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\logistic}{Logistic}
\DeclareMathOperator{\logit}{Logit}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

% This follows BDA
\newcommand{\dunif}{\mathrm{U}}
\newcommand{\dnorm}{\mathrm{N}}
\newcommand{\dlnorm}{\mathrm{lognormal}}
\newcommand{\dmvnorm}{\mathrm{N}}
\newcommand{\dgamma}{\mathrm{Gamma}}
\newcommand{\dinvgamma}{\mathrm{Inv-Gamma}}
\newcommand{\dchisq}[1]{\chi^2_{#1}}
\newcommand{\dinvchisq}[1]{\mathrm{Inv-}\chi^2_{#1}}
\newcommand{\dexp}{\mathrm{Expon}}
\newcommand{\dlaplace}{\mathrm{Laplace}}
\newcommand{\dweibull}{\mathrm{Weibull}}
\newcommand{\dwishart}[1]{\mathrm{Wishart}_{#1}}
\newcommand{\dinvwishart}[1]{\mathrm{Inv-Wishart}_{#1}}
\newcommand{\dlkj}{\mathrm{LkjCorr}}
\newcommand{\dt}[1]{t_{#1}}
\newcommand{\dbeta}{\mathrm{Beta}}
\newcommand{\ddirichlet}{\mathrm{Dirichlet}}
\newcommand{\dlogistic}{\mathrm{Logistic}}
\newcommand{\dllogistic}{\mathrm{Log-logistic}}
\newcommand{\dpois}{\mathrm{Poisson}}
\newcommand{\dBinom}{\mathrm{Bin}}
\newcommand{\dmultinom}{\mathrm{Multinom}}
\newcommand{\dnbinom}{\mathrm{Neg-bin}}
\newcommand{\dnbinomalt}{\mathrm{Neg-bin2}}
\newcommand{\dbetabinom}{\mathrm{Beta-bin}}
\newcommand{\dcauchy}{\mathrm{Cauchy}}
\newcommand{\dhalfcauchy}{\mathrm{Cauchy}^{+}}
\newcommand{\dlkjcorr}{\mathrm{LKJ}^{+}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Reals}{\R}
\newcommand{\RealPos}{\R^{+}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Nats}{\N}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]
<div id="binomial-models" class="section level1">
<h1><span class="header-section-number">13</span> Binomial Models</h1>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;rstanarm&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;rubbish&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;bayz&quot;</span>)</code></pre>
<p>Binomial models are used to an outcome that is a bounded integer,
<span class="math display">\[
y_i \in 0, 1, 2, \dots, n .
\]</span>
The outcome is distributed Binomial,
<span class="math display">\[
\begin{aligned}[t]
y_i \sim \dbin \left(n_i, \pi \right)
\end{aligned}
\]</span></p>
<p>A <em>binary outcome</em> is a common special case,
<span class="math display">\[
y_i \in \{0, 1\},
\]</span>
and
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dbin \left(1, \pi \right) &amp; \text{for all $i$} \\
\end{aligned}
\]</span></p>
<p>Depending on the <a href="#link-functions">link function</a>, these are logit and probit models that appear in the literature.</p>
<div id="link-functions-link-function" class="section level2">
<h2><span class="header-section-number">13.1</span> Link Functions {link-function}</h2>
<p>The parameter <span class="math inline">\(\pi \in (0, 1)\)</span> is often modeled with a link function is and a linear predictor.
<span class="math display">\[
\pi_i = g^{-1}(\vec{x}_i \vec{\beta})
\]</span></p>
<p>There are several common link functions, but they all have to map <span class="math inline">\(R \to (0, 1)\)</span>.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<ul>
<li><p><strong>Logit:</strong> The logistic function,
<span class="math display">\[
\pi_i = \logistic(x_i\T \beta) = \frac{1}{1 + \exp(- x_i\T\beta)} .
\]</span>
Stan function <code>softmax</code>.</p></li>
<li><p><strong>Probit:</strong> The CDF of the normal distribution.
<span class="math display">\[
\pi_i = \Phi(x_i\T \beta)
\]</span>
Stan function <code>normal_cdf</code>.</p></li>
<li><p><strong>cauchit</strong>: The CDF of the Cauchy distribution. Stan function <code>cauchy_cdf</code>.</p></li>
<li><p><strong>cloglog</strong>: The inverse of the conditional log-log function (cloglog) is
<span class="math display">\[
\pi_i = 1 - \exp(-\exp(x_i\T \beta)) .
\]</span>
Stan function <code>inv_cloglog</code>.</p></li>
</ul>
<p>Of these link functions, the probit has the narrowest tails (sensitivity to outliers), followed by the logit, and cauchit.
The <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">cloglog</a> function is different in that it is asymmetric.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>
At zero its value is above 0.5, whereas the cauchit, logit, and probit links all equal 0.5 at 0,</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">make.link</span>(<span class="st">&quot;cloglog&quot;</span>)<span class="op">$</span><span class="kw">linkinv</span>(<span class="dv">0</span>)
<span class="co">#&gt; [1] 0.632</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">map</span>(<span class="kw">c</span>(<span class="st">&quot;logit&quot;</span>, <span class="st">&quot;probit&quot;</span>, <span class="st">&quot;cauchit&quot;</span>, <span class="st">&quot;cloglog&quot;</span>),  make.link) <span class="op">%&gt;%</span>
<span class="kw">map_df</span>(
  <span class="cf">function</span>(link) {
    <span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length.out =</span> <span class="dv">101</span>),
           <span class="dt">y =</span> link<span class="op">$</span><span class="kw">linkinv</span>(x),
           <span class="dt">link_name =</span> link<span class="op">$</span>name)
  }
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">colour =</span> link_name)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>()</code></pre>
<p><img src="binomial_files/figure-html/unnamed-chunk-3-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div id="stan" class="section level3">
<h3><span class="header-section-number">13.1.1</span> Stan</h3>
<p>In Stan, the Binomial distribution has two implementations:</p>
<ul>
<li><code>binomial_lpdf</code></li>
<li><code>binomial_logit_lpdf</code>.</li>
</ul>
<p>The later implementation is for numeric stability.
Taking an exponential of a value can be numerically unstable, and <code>binomial_logit_lpdf</code> input is on the logit scale:
Whereas,
<span class="math display">\[
y_i \sim \mathsf{binomial}(1 / (1 + \exp(x_i \beta)))
\]</span>
the following is true,
<span class="math display">\[
y_i \sim \mathsf{binomial\_logit}(x_i \beta)
\]</span></p>
</div>
<div id="example-vote-turnout" class="section level3">
<h3><span class="header-section-number">13.1.2</span> Example: Vote Turnout</h3>
<p>A general Stan model for estimating logit models is:</p>
<pre class="sourceCode r"><code class="sourceCode r">mod1</code></pre>
<p>prelist(class = “stan”)list(list(name = “code”, attribs = list(), children = list(“// Logit Model//// y ~ Bernoulli(p)// p = a + X B// b0 \sim cauchy(0, 10)// b \sim cauchy(0, 2.5)data {# default scales same as rstanarm# assume data is centered and scaledreal&lt;lower = 0.0&gt; a_scale;vector&lt;lower = 0.0&gt;[K] b_scale;a_scale = 10.0;b_scale = rep_vector(2.5, K);}parameters {vector&lt;lower = 0.0, upper = 1.0&gt;[N] p;p = inv_logit(a + X * b);}quantities {// simulate data from the posteriorvector[N] y_rep;// log-likelihood posteriorvector[N] log_lik;for (i in 1:N) {y_rep[i] = binomial_rng(1, p[i]);log_lik[i] = binomial_lpmf(y[i] | 1, p[i]);}}”)))</p>
<p>Estimate a model of vote turnout in the 1992 from the American National Election Survey (ANES).
The data is from <a href="https://www.rdocumentation.org/packages/Zelig/topics/turnout">Zelig</a>.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;turnout&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;Zelig&quot;</span>)</code></pre>
<p>Vote choice (<code>vote</code>) is modeled as a function of age, income, and race.</p>
<pre class="sourceCode r"><code class="sourceCode r">mod_formula &lt;-<span class="st"> </span>vote <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>educate <span class="op">+</span><span class="st"> </span>race <span class="op">-</span><span class="st"> </span><span class="dv">1</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">mod1_data &lt;-<span class="st"> </span><span class="kw">lm_preprocess</span>(mod_formula, <span class="dt">data =</span> turnout)</code></pre>
</div>
<div id="separation" class="section level3">
<h3><span class="header-section-number">13.1.3</span> Separation</h3>
<p>Separation is when a predictor perfectly predicts a binary response variable <span class="citation">(Rainey 2016, <span class="citation">@Zorn2005a</span>)</span>.</p>
<ul>
<li><em>complete separation</em>: the predictor perfectly predicts both 0’s and 1’s.</li>
<li><em>quasi-complete separation</em>: the predictor perfectly predicts either 0’s or 1’s.</li>
</ul>
<p>This is related and similar to identification in MLE and multicollinearity in OLS.</p>
<p>The general solution is to penalize the likelihood, which in a Bayesian context is equivalent to placing a proper prior on the coefficient of the separating variable.</p>
<p>Using a weakly informative prior such as those suggested by is sufficient to solve separation,
<span class="math display">\[
\beta_k \sim \dnorm(0, 2.5)
\]</span>
where all the columns of <span class="math inline">\(\code{x}\)</span> are assumed to mean zero, unit variance (or otherwise standardized).
The half-Cauchy prior, <span class="math inline">\(\dhalfcauchy(0, 2.5)\)</span>, suggested in <span class="citation">Gelman et al. (2008)</span> is insufficiently informative to to deal with separation <span class="citation">(Ghosh, Li, and Mitra 2015)</span>, but finite-variance weakly informative Student-t or Normal distributions will work.</p>
<p>These are the priors suggested by <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Stan</a> and used by default in <strong>rstanarm</strong> <a href="https://www.rdocumentation.org/packages/rstanarm/topics/stan_glm">rstanarm</a>.</p>
<p><span class="citation">Rainey (2016)</span> provides a mixed MLE/Bayesian simulation based approach to apply a prior to the variable with separation, while keeping the other coefficients at their MLE values.
Since the results are highly sensitive to the prior, multiple priors should be tried (informative, skeptical, and enthusiastic).</p>
<p><span class="citation">Firth (1993)</span> suggests the Jeffreys invariant prior,
<span class="math display">\[
p(\beta_k) \propto |I(\beta)|^{\frac{1}{2}}
\]</span>
where <span class="math inline">\(|I(\beta)|\)</span> is the information matrix,
<span class="math display">\[
\begin{aligned}[t]
I(\beta) &amp;= \mat{X}\T \mat{W} \mat{X} \\
\mat{W} &amp;= \diag(\pi_i (1 - \pi_i))
\end{aligned}
\]</span>
This is the Jeffreys invariant prior. This was also recommended <span class="citation">Zorn (2005)</span>.</p>
<p><span class="citation">Greenland and Mansournia (2015)</span> suggest a log-F prior distribution which has an intuitive interpretation related to the number of observations.</p>
<div id="example-support-of-aca-medicaid-expansion" class="section level4">
<h4><span class="header-section-number">13.1.3.1</span> Example: Support of ACA Medicaid Expansion</h4>
<p>This example is from <span class="citation">Rainey (2016)</span> from the original paper <span class="citation">Barrilleaux and Rainey (2014)</span>
with replication code <a href="https://github.com/carlislerainey/separation">here</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;magrittr&quot;</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;magrittr&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:purrr&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     set_names</span>
<span class="co">#&gt; The following object is masked from &#39;package:tidyr&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     extract</span>
<span class="co">#&gt; The following object is masked from &#39;package:rstan&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     extract</span>

URL &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/carlislerainey/priors-for-separation/master/br-replication/data/need.csv&quot;</span>



f &lt;-<span class="st"> </span>(oppose_expansion <span class="op">~</span><span class="st"> </span>dem_governor <span class="op">+</span><span class="st"> </span>obama_win <span class="op">+</span><span class="st"> </span>gop_leg <span class="op">+</span><span class="st"> </span>percent_uninsured <span class="op">+</span>
<span class="st">      </span>income <span class="op">+</span><span class="st"> </span>percent_nonwhite <span class="op">+</span><span class="st"> </span>percent_metro)

br &lt;-<span class="st"> </span><span class="kw">read_csv</span>(URL) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">oppose_expansion =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>support_expansion,
         <span class="dt">dem_governor =</span> <span class="dv">-1</span> <span class="op">*</span><span class="st"> </span>gop_governor,
         <span class="dt">obama_win =</span> <span class="kw">as.integer</span>(obama_share <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>),
         <span class="dt">percent_nonwhite =</span> percent_black <span class="op">+</span><span class="st"> </span>percent_hispanic) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">gop_leg =</span> legGOP) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># keep only variables in the formula</span>
<span class="st">  </span><span class="kw">model.frame</span>(f, <span class="dt">data =</span> .) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># drop missing values (if any?)</span>
<span class="st">  </span><span class="kw">drop_na</span>()
<span class="co">#&gt; Parsed with column specification:</span>
<span class="co">#&gt; cols(</span>
<span class="co">#&gt;   .default = col_integer(),</span>
<span class="co">#&gt;   state = col_character(),</span>
<span class="co">#&gt;   state_abbr = col_character(),</span>
<span class="co">#&gt;   house12 = col_double(),</span>
<span class="co">#&gt;   sen12 = col_double(),</span>
<span class="co">#&gt;   support_expansion_new = col_character(),</span>
<span class="co">#&gt;   percent_uninsured = col_double(),</span>
<span class="co">#&gt;   ideology = col_double(),</span>
<span class="co">#&gt;   income = col_double(),</span>
<span class="co">#&gt;   percent_black = col_double(),</span>
<span class="co">#&gt;   percent_hispanic = col_double(),</span>
<span class="co">#&gt;   percent_metro = col_double(),</span>
<span class="co">#&gt;   dsh = col_double(),</span>
<span class="co">#&gt;   obama_share = col_double()</span>
<span class="co">#&gt; )</span>
<span class="co">#&gt; See spec(...) for full column specifications.</span>

br_scaled &lt;-<span class="st"> </span>br <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Autoscale all vars but response</span>
<span class="st">  </span><span class="kw">mutate_at</span>(<span class="kw">vars</span>(<span class="op">-</span>oppose_expansion), autoscale)

<span class="kw">glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = f, family = &quot;binomial&quot;, data = br)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -2.374  -0.461  -0.131   0.630   2.207  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)   </span>
<span class="co">#&gt; (Intercept)         4.5103     4.5986    0.98    0.327   </span>
<span class="co">#&gt; dem_governor       -4.1556     1.4794   -2.81    0.005 **</span>
<span class="co">#&gt; obama_win          -2.1470     1.3429   -1.60    0.110   </span>
<span class="co">#&gt; gop_leg            -0.1865     1.2974   -0.14    0.886   </span>
<span class="co">#&gt; percent_uninsured  -0.3072     0.1651   -1.86    0.063 . </span>
<span class="co">#&gt; income             -0.0421     0.0776   -0.54    0.587   </span>
<span class="co">#&gt; percent_nonwhite   17.8505    48.3030    0.37    0.712   </span>
<span class="co">#&gt; percent_metro     -12.4390    32.4446   -0.38    0.701   </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 68.593  on 49  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 37.948  on 42  degrees of freedom</span>
<span class="co">#&gt; AIC: 53.95</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span>

fit1 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)
fit2 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">prior =</span> <span class="ot">NULL</span>, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</code></pre>
</div>
</div>
</div>
<div id="rare-events-logit" class="section level2">
<h2><span class="header-section-number">13.2</span> Rare Events Logit</h2>
</div>
<div id="case-control" class="section level2">
<h2><span class="header-section-number">13.3</span> Case Control</h2>
<p>In binary outcome variables, sometimes it is useful to sample on the dependent variable.
For example, <span class="citation">King and Zeng (2001b)</span> and <span class="citation">King and Zeng (2001a)</span> discuss applications with respect to conflicts in international relations.
For most country-pairs, for most years, there is no conflict.
If some data are costly to gather, it may be cost efficient to get data for conflicts and then randomly select a smaller number of non-conflicts on which to gather data.
The sample will no longer be representative, but the estimates can be corrected.</p>
<p>The reason this works well, is that if there are very few 1’s, additional 0’s have little influence on the estimation (<span class="citation">King and Zeng (2001b)</span>).
This should hold more generally will unbalanced classes; in some sense, the amount of effective observations is not much more than the number in the lowest category.</p>
<p><span class="citation">King and Zeng (2001b)</span> propose two corrections:</p>
<ol style="list-style-type: decimal">
<li>Correcting the intercept (prior correction)</li>
<li>Weighting observations</li>
</ol>
<p>The <em>prior correction</em> notes that
<span class="math display">\[
\pi_i = \frac{1}{1 + \exp(-\mat{X} \vec{beta})}
\]</span></p>
<p>The unbalanced sample only affects the intercept. If <span class="math inline">\(\hat\beta_0\)</span> is the intercept from the MLE, the case-control corrected intercept <span class="math inline">\(\tilde{\beta}\)</span> is,
<span class="math display">\[
\tilde{\vec{\beta}}_0^* = \hat{\vec{\beta}}_0 - \ln \left(\frac{1 - \tau}{\tau} \frac{\bar{y}}{1 - \bar{y}} \right)
\]</span>
In an MLE setting, this can be applied after estimation, but used in any predicted values.
In a Bayesian setting, this correct should be applied within the model by adding the offset to the estimation.</p>
<p>In a Stan model, this could be implemented by directly incrementing these values</p>
<pre class="stan"><code>data {
  int N;
  int y[N];
  real tau;
}
transformed data {
  real offset;
  real y_mean;
  y_mean = mean(y);
  offset = log((1 - tau) / tau * (y_mean) / (1 - y_mean));
}
parameters {
  real alpha0;
}
transformed parameters {
  real alpha;
  alpha &lt;- alpha0 - offset;
}</code></pre>
<p>If there was uncertainty about <span class="math inline">\(\tau\)</span>, then <span class="math inline">\(\tau\)</span> could be modeled as a parameter.
It may also be okay to only correct the intercept in a generated quantities block? (not sure).</p>
<p>An alternative approach is to use a <em>weighted likelihood</em>:</p>
<ul>
<li>ones are weighted by <span class="math inline">\(\tau / \bar{y}\)</span></li>
<li>zeros are weighted by <span class="math inline">\((1 - \tau) / \bar{1 - \bar{y}}\)</span></li>
</ul>
<p>The log likelihood would then be
<span class="math display">\[
\ln L_w(\beta | y) = w_1 \sum_{Y_i = 1} \ln (\pi_i) + w_0 \sum_{Y_i = 0} \ln (1 - \pi_i)
\]</span></p>
<p>In Stan, this can be implemented by directly weighting the log-posterior contributions of each observation.
For example, something like this,</p>
<pre class="stan"><code>if (y[i]) {
  target += w * binomial_lpdf(1, pi[i])
} else {
  target += (1 - w) * binomial_lpdf(1, pi[i])
}</code></pre>
<p>See the example for <a href="http://docs.zeligproject.org/en/latest/zelig-relogit.html"><code>Zelig-relogit</code></a></p>
<div id="references-7" class="section level3">
<h3><span class="header-section-number">13.3.1</span> References</h3>
<ul>
<li><span class="citation">Firth (1993)</span> proposes a penalized likelihood approach using the Jeffreys invariant prior</li>
<li><span class="citation">King and Zeng (2001a)</span> and <span class="citation">King and Zeng (2001b)</span> apply an approach similar to the penalized likelihood approach for the similar problem of rare events</li>
<li><span class="citation">Zorn (2005)</span> also suggests using the Firth logistic regression to avoid perfect separation</li>
<li><span class="citation">Rainey (2016)</span> shows that Cauchy(0, 2.5) priors can be used</li>
<li><span class="citation">Greenland and Mansournia (2015)</span> provide another default prior to for binomial models: log F(1,1) and log F(2, 2) priors. These have the nice property that they are interpretable as additional observations.</li>
</ul>
<p>For general references on binomial models see <span class="citation">Stan Development Team (2016 Sec. 8.5)</span>, <span class="citation">McElreath (2016 Ch 10)</span>, <span class="citation">A. Gelman and Hill (2007)</span> [Ch. 5; Sec 6.4-6.5], <span class="citation">Fox (2016 Ch. 14)</span>, and <span class="citation">Gelman et al. (2013 Ch. 16)</span>.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="9">
<li id="fn9"><p>Since the cumulative distribution function of a distribution maps reals to <span class="math inline">\((0, 1)\)</span>, any CDF can be used as a link function.<a href="binomial-models.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p><span class="citation">Beck, Katz, and Tucker (1998)</span> show that the cloglog link function can be derived from a grouped duration model with binary response variables.<a href="binomial-models.html#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>Example from <a href="http://docs.zeligproject.org/en/latest/zelig-logit.html">Zelig-logit</a>.<a href="binomial-models.html#fnref11" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hierarchical-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/bayesian_notes/edit/master/binomial.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
