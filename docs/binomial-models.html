<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Updating: A Set of Bayesian Notes</title>
  <meta name="description" content="Updating: A Set of Bayesian Notes">
  <meta name="generator" content="bookdown 0.7.1 and GitBook 2.6.7">

  <meta property="og:title" content="Updating: A Set of Bayesian Notes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jrnold.github.io/bayesian_notes" />
  
  
  <meta name="github-repo" content="jrnold/bayesian_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Updating: A Set of Bayesian Notes" />
  <meta name="twitter:site" content="@jrnld" />
  
  

<meta name="author" content="Jeffrey B. Arnold">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="generalized-linear-models.html">
<link rel="next" href="unbounded-count-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Bayesian Notes</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Theory</b></span></li>
<li class="chapter" data-level="1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>1</b> Bayesian Inference</a></li>
<li class="part"><span><b>II Computation</b></span></li>
<li class="chapter" data-level="2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>2</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>2.1</b> Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-sampling"><i class="fa fa-check"></i><b>2.2</b> Markov Chain Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#references"><i class="fa fa-check"></i><b>2.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>3</b> MCMC Diagnostics</a><ul>
<li class="chapter" data-level="3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#reparameterize-models"><i class="fa fa-check"></i><b>3.1</b> Reparameterize Models</a></li>
<li class="chapter" data-level="3.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#convergence-diagnostics"><i class="fa fa-check"></i><b>3.2</b> Convergence Diagnostics</a><ul>
<li class="chapter" data-level="3.2.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#potential-scale-reduction-hatr"><i class="fa fa-check"></i><b>3.2.1</b> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</a></li>
<li class="chapter" data-level="3.2.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#references-1"><i class="fa fa-check"></i><b>3.2.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation-effective-sample-size-and-mcse"><i class="fa fa-check"></i><b>3.3</b> Autocorrelation, Effective Sample Size, and MCSE</a><ul>
<li class="chapter" data-level="3.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#effective-sample-size"><i class="fa fa-check"></i><b>3.3.1</b> Effective Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#thinning"><i class="fa fa-check"></i><b>3.4</b> Thinning</a><ul>
<li class="chapter" data-level="3.4.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#traceplots"><i class="fa fa-check"></i><b>3.4.1</b> Traceplots</a></li>
<li class="chapter" data-level="3.4.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#monte-carlo-standard-error-mcse"><i class="fa fa-check"></i><b>3.4.2</b> Monte Carlo Standard Error (MCSE)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#hmc-nut-specific-diagnostics"><i class="fa fa-check"></i><b>3.5</b> HMC-NUT Specific Diagnostics</a><ul>
<li class="chapter" data-level="3.5.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#divergent-transitions"><i class="fa fa-check"></i><b>3.5.1</b> Divergent transitions</a></li>
<li class="chapter" data-level="3.5.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#maximum-treedepth"><i class="fa fa-check"></i><b>3.5.2</b> Maximum Treedepth</a></li>
<li class="chapter" data-level="3.5.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#bayesian-fraction-of-missing-information"><i class="fa fa-check"></i><b>3.5.3</b> Bayesian Fraction of Missing Information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="posterior-inference.html"><a href="posterior-inference.html"><i class="fa fa-check"></i><b>4</b> Posterior Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#prerequisites"><i class="fa fa-check"></i><b>4.1</b> Prerequisites</a></li>
<li class="chapter" data-level="4.2" data-path="posterior-inference.html"><a href="posterior-inference.html#introduction"><i class="fa fa-check"></i><b>4.2</b> Introduction</a></li>
<li class="chapter" data-level="4.3" data-path="posterior-inference.html"><a href="posterior-inference.html#functions-of-the-posterior-distribution"><i class="fa fa-check"></i><b>4.3</b> Functions of the Posterior Distribution</a></li>
<li class="chapter" data-level="4.4" data-path="posterior-inference.html"><a href="posterior-inference.html#marginal-effects"><i class="fa fa-check"></i><b>4.4</b> Marginal Effects</a><ul>
<li class="chapter" data-level="4.4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#example-marginal-effect-plot-for-x"><i class="fa fa-check"></i><b>4.4.1</b> Example: Marginal Effect Plot for X</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>5</b> Model Checking</a><ul>
<li class="chapter" data-level="5.1" data-path="model-checking.html"><a href="model-checking.html#why-check-models"><i class="fa fa-check"></i><b>5.1</b> Why check models?</a></li>
<li class="chapter" data-level="5.2" data-path="model-checking.html"><a href="model-checking.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2</b> Posterior Predictive Checks</a><ul>
<li class="chapter" data-level="5.2.1" data-path="model-checking.html"><a href="model-checking.html#bayesian-p-values"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian p-values</a></li>
<li class="chapter" data-level="5.2.2" data-path="model-checking.html"><a href="model-checking.html#test-quantities"><i class="fa fa-check"></i><b>5.2.2</b> Test quantities</a></li>
<li class="chapter" data-level="5.2.3" data-path="model-checking.html"><a href="model-checking.html#p-values-vs.u-values"><i class="fa fa-check"></i><b>5.2.3</b> p-values vs. u-values</a></li>
<li class="chapter" data-level="5.2.4" data-path="model-checking.html"><a href="model-checking.html#marginal-predictive-checks"><i class="fa fa-check"></i><b>5.2.4</b> Marginal predictive checks</a></li>
<li class="chapter" data-level="5.2.5" data-path="model-checking.html"><a href="model-checking.html#outliers"><i class="fa fa-check"></i><b>5.2.5</b> Outliers</a></li>
<li class="chapter" data-level="5.2.6" data-path="model-checking.html"><a href="model-checking.html#grapical-posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2.6</b> Grapical Posterior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="model-checking.html"><a href="model-checking.html#sources"><i class="fa fa-check"></i><b>5.3</b> Sources</a></li>
</ul></li>
<li class="part"><span><b>III Models</b></span></li>
<li class="chapter" data-level="6" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Introduction to Stan and Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#prerequites"><i class="fa fa-check"></i><b>6.1</b> Prerequites</a></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#the-statistical-model"><i class="fa fa-check"></i><b>6.2</b> The Statistical Model</a><ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling"><i class="fa fa-check"></i><b>6.2.1</b> Sampling</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#convergence-diagnostics-and-model-fit"><i class="fa fa-check"></i><b>6.2.2</b> Convergence Diagnostics and Model Fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html"><i class="fa fa-check"></i><b>7</b> Heteroskedasticity and Robust Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#prerequisites-1"><i class="fa fa-check"></i><b>7.1</b> Prerequisites</a></li>
<li class="chapter" data-level="7.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#linear-regression-with-student-t-distributed-errors"><i class="fa fa-check"></i><b>7.2</b> Linear Regression with Student t distributed errors</a><ul>
<li class="chapter" data-level="7.2.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#double-exponential-laplace-errors"><i class="fa fa-check"></i><b>7.2.1</b> Double Exponential (Laplace) Errors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity"><i class="fa fa-check"></i><b>7.3</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="7.3.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#covariates"><i class="fa fa-check"></i><b>7.3.1</b> Covariates</a></li>
<li class="chapter" data-level="7.3.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#student-t-error"><i class="fa fa-check"></i><b>7.3.2</b> Student-t Error</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#references-2"><i class="fa fa-check"></i><b>7.4</b> References</a><ul>
<li class="chapter" data-level="7.4.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#robust-regression"><i class="fa fa-check"></i><b>7.4.1</b> Robust regression</a></li>
<li class="chapter" data-level="7.4.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity-1"><i class="fa fa-check"></i><b>7.4.2</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="7.4.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#qunatile-regression"><i class="fa fa-check"></i><b>7.4.3</b> Qunatile regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>8</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="8.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#generalized-linear-models-1"><i class="fa fa-check"></i><b>8.1</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="8.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#count-models"><i class="fa fa-check"></i><b>8.2</b> Count Models</a><ul>
<li class="chapter" data-level="8.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson"><i class="fa fa-check"></i><b>8.2.1</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example"><i class="fa fa-check"></i><b>8.3</b> Example</a></li>
<li class="chapter" data-level="8.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#negative-binomial"><i class="fa fa-check"></i><b>8.4</b> Negative Binomial</a><ul>
<li class="chapter" data-level="8.4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-3"><i class="fa fa-check"></i><b>8.4.1</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial-categorical-models"><i class="fa fa-check"></i><b>8.5</b> Multinomial / Categorical Models</a></li>
<li class="chapter" data-level="8.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#gamma-regression"><i class="fa fa-check"></i><b>8.6</b> Gamma Regression</a></li>
<li class="chapter" data-level="8.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#beta-regression"><i class="fa fa-check"></i><b>8.7</b> Beta Regression</a></li>
<li class="chapter" data-level="8.8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-4"><i class="fa fa-check"></i><b>8.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="binomial-models.html"><a href="binomial-models.html"><i class="fa fa-check"></i><b>9</b> Binomial Models</a><ul>
<li class="chapter" data-level="9.0.1" data-path="binomial-models.html"><a href="binomial-models.html#link-functions-link-function"><i class="fa fa-check"></i><b>9.0.1</b> Link Functions {link-function}</a></li>
<li class="chapter" data-level="9.0.2" data-path="binomial-models.html"><a href="binomial-models.html#stan"><i class="fa fa-check"></i><b>9.0.2</b> Stan</a></li>
<li class="chapter" data-level="9.0.3" data-path="binomial-models.html"><a href="binomial-models.html#example-vote-turnout"><i class="fa fa-check"></i><b>9.0.3</b> Example: Vote Turnout</a></li>
<li class="chapter" data-level="9.0.4" data-path="binomial-models.html"><a href="binomial-models.html#separation"><i class="fa fa-check"></i><b>9.0.4</b> Separation</a></li>
<li class="chapter" data-level="9.1" data-path="binomial-models.html"><a href="binomial-models.html#rare-events-logit"><i class="fa fa-check"></i><b>9.1</b> Rare Events Logit</a></li>
<li class="chapter" data-level="9.2" data-path="binomial-models.html"><a href="binomial-models.html#case-control"><i class="fa fa-check"></i><b>9.2</b> Case Control</a><ul>
<li class="chapter" data-level="9.2.1" data-path="binomial-models.html"><a href="binomial-models.html#references-6"><i class="fa fa-check"></i><b>9.2.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html"><i class="fa fa-check"></i><b>10</b> Unbounded Count Models</a><ul>
<li class="chapter" data-level="10.1" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#poisson-1"><i class="fa fa-check"></i><b>10.1</b> Poisson</a></li>
<li class="chapter" data-level="10.2" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#negative-binomial-1"><i class="fa fa-check"></i><b>10.2</b> Negative Binomial</a><ul>
<li class="chapter" data-level="10.2.1" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#stan-1"><i class="fa fa-check"></i><b>10.2.1</b> Stan</a></li>
<li class="chapter" data-level="10.2.2" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#example-number-of-number-o"><i class="fa fa-check"></i><b>10.2.2</b> Example: Number of Number o</a></li>
<li class="chapter" data-level="10.2.3" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#references-7"><i class="fa fa-check"></i><b>10.2.3</b> References</a></li>
<li class="chapter" data-level="10.2.4" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#link-functions"><i class="fa fa-check"></i><b>10.2.4</b> Link functions</a></li>
<li class="chapter" data-level="10.2.5" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#stan-2"><i class="fa fa-check"></i><b>10.2.5</b> Stan</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#example-bilateral-sanctions"><i class="fa fa-check"></i><b>10.3</b> Example: Bilateral Sanctions</a></li>
<li class="chapter" data-level="10.4" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#negative-binomial-2"><i class="fa fa-check"></i><b>10.4</b> Negative Binomial</a><ul>
<li class="chapter" data-level="10.4.1" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#example-economic-sanctions-ii-ex-econ-sanctions-2"><i class="fa fa-check"></i><b>10.4.1</b> Example: Economic Sanctions II {ex-econ-sanctions-2}</a></li>
<li class="chapter" data-level="10.4.2" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#references-8"><i class="fa fa-check"></i><b>10.4.2</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="categorical-variables.html"><a href="categorical-variables.html"><i class="fa fa-check"></i><b>11</b> Categorical Variables</a><ul>
<li class="chapter" data-level="11.1" data-path="categorical-variables.html"><a href="categorical-variables.html#example-mexico-vote-choice"><i class="fa fa-check"></i><b>11.1</b> Example: Mexico Vote Choice</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html"><i class="fa fa-check"></i><b>12</b> Shrinkage and Regularization</a><ul>
<li class="chapter" data-level="12.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#normal-linear-regression-model"><i class="fa fa-check"></i><b>12.1</b> Normal Linear Regression Model</a></li>
<li class="chapter" data-level="12.2" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#penalized-regression"><i class="fa fa-check"></i><b>12.2</b> Penalized Regression</a><ul>
<li class="chapter" data-level="12.2.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#ridge-regression"><i class="fa fa-check"></i><b>12.2.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="12.2.2" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#lasso"><i class="fa fa-check"></i><b>12.2.2</b> Lasso</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#bayesian-shrinkage-priors"><i class="fa fa-check"></i><b>12.3</b> Bayesian Shrinkage Priors</a></li>
<li class="chapter" data-level="12.4" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#differences-between-bayesian-shrinkage-and-penalized-likelihood"><i class="fa fa-check"></i><b>12.4</b> Differences between Bayesian Shrinkage and Penalized Likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#hierarchical-shrinkage-priors"><i class="fa fa-check"></i><b>12.5</b> Hierarchical Shrinkage Priors</a></li>
<li class="chapter" data-level="12.6" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#example-1"><i class="fa fa-check"></i><b>12.6</b> Example</a><ul>
<li class="chapter" data-level="12.6.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#double-exponential-laplace-prior"><i class="fa fa-check"></i><b>12.6.1</b> Double Exponential (Laplace) Prior</a></li>
<li class="chapter" data-level="12.6.2" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#hierarchical-prior-hs"><i class="fa fa-check"></i><b>12.6.2</b> Hierarchical Prior (HS)</a></li>
<li class="chapter" data-level="12.6.3" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#comparison"><i class="fa fa-check"></i><b>12.6.3</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#shrinkage-parameters"><i class="fa fa-check"></i><b>12.7</b> Shrinkage Parameters</a></li>
<li class="chapter" data-level="12.8" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#choice-of-hyperparameter-on-tau"><i class="fa fa-check"></i><b>12.8</b> Choice of Hyperparameter on <span class="math inline">\(\tau\)</span></a></li>
<li class="chapter" data-level="12.9" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#r-implementations"><i class="fa fa-check"></i><b>12.9</b> R Implementations</a></li>
<li class="chapter" data-level="12.10" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#bayesian-model-averaging"><i class="fa fa-check"></i><b>12.10</b> Bayesian Model Averaging</a><ul>
<li class="chapter" data-level="12.10.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#zellners-g-prior"><i class="fa fa-check"></i><b>12.10.1</b> Zellner’s g-prior</a></li>
</ul></li>
<li class="chapter" data-level="12.11" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#slab-and-spike-priors"><i class="fa fa-check"></i><b>12.11</b> Slab and Spike Priors</a></li>
<li class="chapter" data-level="12.12" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#technical-notes"><i class="fa fa-check"></i><b>12.12</b> Technical Notes</a></li>
<li class="chapter" data-level="12.13" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#multiple-comparisons-and-thresholding-rules"><i class="fa fa-check"></i><b>12.13</b> Multiple Comparisons and Thresholding rules</a></li>
<li class="chapter" data-level="12.14" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#examples-of-applications-of-sensitivity-analysis"><i class="fa fa-check"></i><b>12.14</b> Examples of Applications of Sensitivity Analysis</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>13</b> Hierarchical Models</a><ul>
<li class="chapter" data-level="13.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-baseball-hits"><i class="fa fa-check"></i><b>13.1</b> Example: Baseball Hits</a><ul>
<li class="chapter" data-level="13.1.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#other-examples"><i class="fa fa-check"></i><b>13.1.1</b> Other Examples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>14</b> Multilevel Models</a><ul>
<li class="chapter" data-level="14.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-radon"><i class="fa fa-check"></i><b>14.1</b> Example: Radon</a><ul>
<li class="chapter" data-level="14.1.1" data-path="multilevel-models.html"><a href="multilevel-models.html#data"><i class="fa fa-check"></i><b>14.1.1</b> Data</a></li>
<li class="chapter" data-level="14.1.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercepts-models"><i class="fa fa-check"></i><b>14.1.2</b> Varying Intercepts Models</a></li>
<li class="chapter" data-level="14.1.3" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercept-model"><i class="fa fa-check"></i><b>14.1.3</b> Varying Intercept Model</a></li>
<li class="chapter" data-level="14.1.4" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-slope-model"><i class="fa fa-check"></i><b>14.1.4</b> Varying Slope Model</a></li>
<li class="chapter" data-level="14.1.5" data-path="multilevel-models.html"><a href="multilevel-models.html#group-level-predictors"><i class="fa fa-check"></i><b>14.1.5</b> Group Level Predictors</a></li>
<li class="chapter" data-level="14.1.6" data-path="multilevel-models.html"><a href="multilevel-models.html#lme4"><i class="fa fa-check"></i><b>14.1.6</b> lme4</a></li>
<li class="chapter" data-level="14.1.7" data-path="multilevel-models.html"><a href="multilevel-models.html#rstanarm"><i class="fa fa-check"></i><b>14.1.7</b> rstanarm</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="multilevel-models.html"><a href="multilevel-models.html#pooling-of-hierarchical-parameters"><i class="fa fa-check"></i><b>14.2</b> Pooling of Hierarchical Parameters</a></li>
<li class="chapter" data-level="14.3" data-path="multilevel-models.html"><a href="multilevel-models.html#anova"><i class="fa fa-check"></i><b>14.3</b> ANOVA</a></li>
<li class="chapter" data-level="14.4" data-path="multilevel-models.html"><a href="multilevel-models.html#time-series-cross-section"><i class="fa fa-check"></i><b>14.4</b> Time-Series Cross Section</a></li>
<li class="chapter" data-level="14.5" data-path="multilevel-models.html"><a href="multilevel-models.html#extensions"><i class="fa fa-check"></i><b>14.5</b> Extensions</a></li>
<li class="chapter" data-level="14.6" data-path="multilevel-models.html"><a href="multilevel-models.html#miscellaneous"><i class="fa fa-check"></i><b>14.6</b> Miscellaneous</a><ul>
<li class="chapter" data-level="14.6.1" data-path="multilevel-models.html"><a href="multilevel-models.html#how-many-groups"><i class="fa fa-check"></i><b>14.6.1</b> How many groups?</a></li>
<li class="chapter" data-level="14.6.2" data-path="multilevel-models.html"><a href="multilevel-models.html#correlation-between-predictors-and-errors"><i class="fa fa-check"></i><b>14.6.2</b> Correlation between Predictors and Errors</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="multilevel-models.html"><a href="multilevel-models.html#references-9"><i class="fa fa-check"></i><b>14.7</b> References</a></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span><ul>
<li class="chapter" data-level="14.8" data-path="multilevel-models.html"><a href="multilevel-models.html#parameters"><i class="fa fa-check"></i><b>14.8</b> Parameters</a></li>
<li class="chapter" data-level="14.9" data-path="multilevel-models.html"><a href="multilevel-models.html#miscellaneous-mathematical-background"><i class="fa fa-check"></i><b>14.9</b> Miscellaneous Mathematical Background</a><ul>
<li class="chapter" data-level="14.9.1" data-path="multilevel-models.html"><a href="multilevel-models.html#location-scale-families"><i class="fa fa-check"></i><b>14.9.1</b> Location-Scale Families</a></li>
<li class="chapter" data-level="14.9.2" data-path="multilevel-models.html"><a href="multilevel-models.html#scale-mixtures-of-normal-distributions"><i class="fa fa-check"></i><b>14.9.2</b> Scale Mixtures of Normal Distributions</a></li>
<li class="chapter" data-level="14.9.3" data-path="multilevel-models.html"><a href="multilevel-models.html#covariance-correlation-matrix-decomposition"><i class="fa fa-check"></i><b>14.9.3</b> Covariance-Correlation Matrix Decomposition</a></li>
<li class="chapter" data-level="14.9.4" data-path="multilevel-models.html"><a href="multilevel-models.html#qr-factorization"><i class="fa fa-check"></i><b>14.9.4</b> QR Factorization</a></li>
<li class="chapter" data-level="14.9.5" data-path="multilevel-models.html"><a href="multilevel-models.html#cholesky-decomposition"><i class="fa fa-check"></i><b>14.9.5</b> Cholesky Decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="scaled-and-unscaled-variables.html"><a href="scaled-and-unscaled-variables.html"><i class="fa fa-check"></i><b>15</b> Scaled and Unscaled Variables</a></li>
<li class="chapter" data-level="16" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html"><i class="fa fa-check"></i><b>16</b> Annotated Bibliography</a><ul>
<li class="chapter" data-level="16.0.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#textbooks"><i class="fa fa-check"></i><b>16.0.1</b> Textbooks</a></li>
<li class="chapter" data-level="16.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#syllabi"><i class="fa fa-check"></i><b>16.1</b> Syllabi</a></li>
<li class="chapter" data-level="16.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#topics"><i class="fa fa-check"></i><b>16.2</b> Topics</a></li>
<li class="chapter" data-level="16.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayes-theorem"><i class="fa fa-check"></i><b>16.3</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="16.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#article-length-introductions-to-bayesian-statistics"><i class="fa fa-check"></i><b>16.4</b> Article Length Introductions to Bayesian Statistics</a><ul>
<li class="chapter" data-level="16.4.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#why-bayesian"><i class="fa fa-check"></i><b>16.4.1</b> Why Bayesian</a></li>
<li class="chapter" data-level="16.4.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-philosophy"><i class="fa fa-check"></i><b>16.4.2</b> Bayesian Philosophy</a></li>
<li class="chapter" data-level="16.4.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>16.4.3</b> Bayesian Hypothesis Testing</a></li>
<li class="chapter" data-level="16.4.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-frequentist-debates"><i class="fa fa-check"></i><b>16.4.4</b> Bayesian Frequentist Debates</a></li>
<li class="chapter" data-level="16.4.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#categorical"><i class="fa fa-check"></i><b>16.4.5</b> Categorical</a></li>
<li class="chapter" data-level="16.4.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#variable-selection"><i class="fa fa-check"></i><b>16.4.6</b> Variable Selection</a></li>
<li class="chapter" data-level="16.4.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multiple-testing"><i class="fa fa-check"></i><b>16.4.7</b> Multiple Testing</a></li>
<li class="chapter" data-level="16.4.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#rare-events"><i class="fa fa-check"></i><b>16.4.8</b> Rare Events</a></li>
<li class="chapter" data-level="16.4.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#identifiability"><i class="fa fa-check"></i><b>16.4.9</b> Identifiability</a></li>
<li class="chapter" data-level="16.4.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkage"><i class="fa fa-check"></i><b>16.4.10</b> Shrinkage</a></li>
<li class="chapter" data-level="16.4.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#convergence"><i class="fa fa-check"></i><b>16.4.11</b> Convergence</a></li>
<li class="chapter" data-level="16.4.12" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software"><i class="fa fa-check"></i><b>16.4.12</b> Software</a></li>
<li class="chapter" data-level="16.4.13" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#stan-3"><i class="fa fa-check"></i><b>16.4.13</b> Stan</a></li>
<li class="chapter" data-level="16.4.14" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#diagrams"><i class="fa fa-check"></i><b>16.4.14</b> Diagrams</a></li>
<li class="chapter" data-level="16.4.15" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#priors"><i class="fa fa-check"></i><b>16.4.15</b> Priors</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-model-averaging-1"><i class="fa fa-check"></i><b>16.5</b> Bayesian Model Averaging</a></li>
<li class="chapter" data-level="16.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multilevel-modeling"><i class="fa fa-check"></i><b>16.6</b> Multilevel Modeling</a></li>
<li class="chapter" data-level="16.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#mixture-models"><i class="fa fa-check"></i><b>16.7</b> Mixture Models</a></li>
<li class="chapter" data-level="16.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#model-checking-1"><i class="fa fa-check"></i><b>16.8</b> Model Checking</a><ul>
<li class="chapter" data-level="16.8.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#posterior-predictive-checks-1"><i class="fa fa-check"></i><b>16.8.1</b> Posterior Predictive Checks</a></li>
<li class="chapter" data-level="16.8.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#prediction-criteria"><i class="fa fa-check"></i><b>16.8.2</b> Prediction Criteria</a></li>
<li class="chapter" data-level="16.8.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software-validation"><i class="fa fa-check"></i><b>16.8.3</b> Software Validation</a></li>
</ul></li>
<li class="chapter" data-level="16.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#hierarchical-modeling"><i class="fa fa-check"></i><b>16.9</b> Hierarchical Modeling</a></li>
<li class="chapter" data-level="16.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkageregularization"><i class="fa fa-check"></i><b>16.10</b> Shrinkage/Regularization</a></li>
<li class="chapter" data-level="16.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#empirical-bayes"><i class="fa fa-check"></i><b>16.11</b> Empirical Bayes</a></li>
<li class="chapter" data-level="16.12" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#history-of-bayesian-statistics"><i class="fa fa-check"></i><b>16.12</b> History of Bayesian Statistics</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html"><i class="fa fa-check"></i><b>17</b> Sampling Difficulties</a><ul>
<li class="chapter" data-level="17.1" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#complicated-estimation-and-testing"><i class="fa fa-check"></i><b>17.1</b> Complicated Estimation and Testing</a></li>
<li class="chapter" data-level="17.2" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#pooling-polls"><i class="fa fa-check"></i><b>17.2</b> Pooling Polls</a></li>
<li class="chapter" data-level="17.3" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#numerical-analysis"><i class="fa fa-check"></i><b>17.3</b> Numerical Analysis</a></li>
<li class="chapter" data-level="17.4" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#visualizing-mcmc-methods"><i class="fa fa-check"></i><b>17.4</b> Visualizing MCMC Methods</a></li>
<li class="chapter" data-level="17.5" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#bayesian-point-estimation-decision"><i class="fa fa-check"></i><b>17.5</b> Bayesian point estimation / Decision</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="information-theory.html"><a href="information-theory.html"><i class="fa fa-check"></i><b>18</b> Information Theory</a></li>
<li class="chapter" data-level="19" data-path="stan-modeling-language.html"><a href="stan-modeling-language.html"><i class="fa fa-check"></i><b>19</b> Stan Modeling Language</a></li>
<li class="chapter" data-level="" data-path="references-10.html"><a href="references-10.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Updating: A Set of Bayesian Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\median}{median}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\logistic}{Logistic}
\DeclareMathOperator{\logit}{Logit}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

% This follows BDA
\newcommand{\dunif}{\mathrm{U}}
\newcommand{\dnorm}{\mathrm{N}}
\newcommand{\dlnorm}{\mathrm{lognormal}}
\newcommand{\dmvnorm}{\mathrm{N}}
\newcommand{\dgamma}{\mathrm{Gamma}}
\newcommand{\dinvgamma}{\mathrm{Inv-Gamma}}
\newcommand{\dchisq}[1]{\chi^2_{#1}}
\newcommand{\dinvchisq}[1]{\mathrm{Inv-}\chi^2_{#1}}
\newcommand{\dexp}{\mathrm{Expon}}
\newcommand{\dlaplace}{\mathrm{Laplace}}
\newcommand{\dweibull}{\mathrm{Weibull}}
\newcommand{\dwishart}[1]{\mathrm{Wishart}_{#1}}
\newcommand{\dinvwishart}[1]{\mathrm{Inv-Wishart}_{#1}}
\newcommand{\dlkj}{\mathrm{LkjCorr}}
\newcommand{\dt}[1]{t_{#1}}
\newcommand{\dbeta}{\mathrm{Beta}}
\newcommand{\ddirichlet}{\mathrm{Dirichlet}}
\newcommand{\dlogistic}{\mathrm{Logistic}}
\newcommand{\dllogistic}{\mathrm{Log-logistic}}
\newcommand{\dpois}{\mathrm{Poisson}}
\newcommand{\dbin}{\mathrm{Bin}}
\newcommand{\dmultinom}{\mathrm{Multinom}}
\newcommand{\dnbinom}{\mathrm{Neg-bin}}
\newcommand{\dnbinomalt}{\mathrm{Neg-bin2}}
\newcommand{\dbetabinom}{\mathrm{Beta-bin}}
\newcommand{\dcauchy}{\mathrm{Cauchy}}
\newcommand{\dhalfcauchy}{\mathrm{Cauchy}^{+}}
\newcommand{\dlkjcorr}{\mathrm{LKJ}^{+}}



\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]
<div id="binomial-models" class="section level1">
<h1><span class="header-section-number">9</span> Binomial Models</h1>
<p>Binomial models are used to an outcome that is a bounded integer,
<span class="math display">\[
y_i \in 0, 1, 2, \dots, n .
\]</span>
The outcome is distributed Binomial,
<span class="math display">\[
\begin{aligned}[t]
y_i \sim \dbin \left(n_i, \pi \right)
\end{aligned}
\]</span></p>
<p>A <em>binary outcome</em> is a common special case,
<span class="math display">\[
y_i \in \{0, 1\},
\]</span>
and
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dbin \left(1, \pi \right) &amp; \text{for all $i$} \\
\end{aligned}
\]</span></p>
<p>Depending on the <a href="unbounded-count-models.html#link-functions">link function</a>, these are logit and probit models that appear in the literature.</p>
<div id="link-functions-link-function" class="section level3">
<h3><span class="header-section-number">9.0.1</span> Link Functions {link-function}</h3>
<p>The parameter <span class="math inline">\(\pi \in (0, 1)\)</span> is often modeled with a link function is and a linear predictor.
<span class="math display">\[
\pi_i = g^{-1}(\vec{x}_i \vec{\beta})
\]</span></p>
<p>There are several common link functions, but they all have to map <span class="math inline">\(R \to (0, 1)\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<ul>
<li><strong>Logit:</strong> The logistic function,
<span class="math display">\[
  \pi_i = \logistic(x_i\T \beta) = \frac{1}{1 + \exp(- x_i\T\beta)} .
  \]</span>
Stan function <code>softmax</code>.</li>
<li><p><strong>Probit:</strong> The CDF of the normal distribution.
<span class="math display">\[
  \pi_i = \Phi(x_i\T \beta)
  \]</span>
Stan function <code>normal_cdf</code>.</p></li>
<li><strong>cauchit</strong>: The CDF of the Cauchy distribution. Stan function <code>cauchy_cdf</code>.</li>
<li><p><strong>cloglog</strong>: The inverse of the conditional log-log function (cloglog) is
<span class="math display">\[
  \pi_i = 1 - \exp(-\exp(x_i\T \beta)) .
  \]</span>
Stan function <code>inv_cloglog</code>.</p></li>
</ul>
<p>Of these link functions, the probit has the narrowest tails (sensitivity to outliers), followed by the logit, and cauchit.
The <a href="https://en.wikipedia.org/wiki/Generalized_linear_model#Complementary_log-log_.28cloglog.29">cloglog</a> function is different in that it is asymmetric.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>
At zero its value is above 0.5, whereas the cauchit, logit, and probit links all equal 0.5 at 0,</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1"><span class="kw">make.link</span>(<span class="st">&quot;cloglog&quot;</span>)<span class="op">$</span><span class="kw">linkinv</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb45-2" data-line-number="2"><span class="co">#&gt; [1] 0.632</span></a></code></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1"><span class="kw">map</span>(<span class="kw">c</span>(<span class="st">&quot;logit&quot;</span>, <span class="st">&quot;probit&quot;</span>, <span class="st">&quot;cauchit&quot;</span>, <span class="st">&quot;cloglog&quot;</span>),  make.link) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb46-2" data-line-number="2"><span class="kw">map_df</span>(</a>
<a class="sourceLine" id="cb46-3" data-line-number="3">  <span class="cf">function</span>(link) {</a>
<a class="sourceLine" id="cb46-4" data-line-number="4">    <span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length.out =</span> <span class="dv">101</span>),</a>
<a class="sourceLine" id="cb46-5" data-line-number="5">           <span class="dt">y =</span> link<span class="op">$</span><span class="kw">linkinv</span>(x),</a>
<a class="sourceLine" id="cb46-6" data-line-number="6">           <span class="dt">link_name =</span> link<span class="op">$</span>name)</a>
<a class="sourceLine" id="cb46-7" data-line-number="7">  }</a>
<a class="sourceLine" id="cb46-8" data-line-number="8">  ) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb46-9" data-line-number="9"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">colour =</span> link_name)) <span class="op">+</span></a>
<a class="sourceLine" id="cb46-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_line</span>()</a></code></pre></div>
<p><img src="binomial_files/figure-html/unnamed-chunk-3-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="stan" class="section level3">
<h3><span class="header-section-number">9.0.2</span> Stan</h3>
<p>In Stan, the Binomial distribution has two implementations:</p>
<ul>
<li><code>binomial_lpdf</code></li>
<li><code>binomial_logit_lpdf</code>.</li>
</ul>
<p>The later implementation is for numeric stability.
Taking an exponential of a value can be numerically unstable, and <code>binomial_logit_lpdf</code> input is on the logit scale:
Whereas,
<span class="math display">\[
y_i \sim \mathsf{binomial}(1 / (1 + \exp(x_i \beta)))
\]</span>
the following is true,
<span class="math display">\[
y_i \sim \mathsf{binomial\_logit}(x_i \beta)
\]</span></p>
</div>
<div id="example-vote-turnout" class="section level3">
<h3><span class="header-section-number">9.0.3</span> Example: Vote Turnout</h3>
<p>A general Stan model for estimating logit models is:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" data-line-number="1">mod1</a></code></pre></div>
<pre>
  <code class="stan">// Logit Model
//
// y ~ Bernoulli(p)
// p = a + X B
// b0 \sim cauchy(0, 10)
// b \sim cauchy(0, 2.5)
data {
  // number of observations
  int N;
  // response
  // vectors are only real numbers
  // need to use an array
  int<lower = 0, upper = 1> y[N];
  // number of columns in the design matrix X
  int K;
  // design matrix X
  // should not include an intercept
  matrix [N, K] X;
}
transformed data {
  # default scales same as rstanarm
  # assume data is centered and scaled
  real<lower = 0.0> a_scale;
  vector<lower = 0.0>[K] b_scale;
  a_scale = 10.0;
  b_scale = rep_vector(2.5, K);
}
parameters {
  // regression coefficient vector
  real a;
  vector[K] b;
}
transformed parameters {
  vector<lower = 0.0, upper = 1.0>[N] p;
  p = inv_logit(a + X * b);
}
model {
  // priors
  a ~ normal(0.0, a_scale);
  b ~ normal(0.0, b_scale);
  // likelihood
  y ~ binomial(1, p);
}
generated quantities {
  // simulate data from the posterior
  vector[N] y_rep;
  // log-likelihood posterior
  vector[N] log_lik;
  for (i in 1:N) {
    y_rep[i] = binomial_rng(1, p[i]);
    log_lik[i] = binomial_lpmf(y[i] | 1, p[i]);
  }
}</code>
</pre>
<p>Estimate a model of vote turnout in the 1992 from the American National Election Survey (ANES).
The data is from <a href="https://www.rdocumentation.org/packages/Zelig/topics/turnout">Zelig</a>.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;turnout&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;Zelig&quot;</span>)</a></code></pre></div>
<p>Vote choice (<code>vote</code>) is modeled as a function of age, income, and race.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1">mod_formula &lt;-<span class="st"> </span>vote <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>educate <span class="op">+</span><span class="st"> </span>race <span class="op">-</span><span class="st"> </span><span class="dv">1</span></a></code></pre></div>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1">mod1_data &lt;-<span class="st"> </span><span class="kw">lm_preprocess</span>(mod_formula, <span class="dt">data =</span> turnout)</a></code></pre></div>
</div>
<div id="separation" class="section level3">
<h3><span class="header-section-number">9.0.4</span> Separation</h3>
<p>*<a href="binomial-models.html#separation">Separation</a>(<a href="https://en.wikipedia.org/wiki/Separation_(statistics)*" class="uri">https://en.wikipedia.org/wiki/Separation_(statistics)*</a> is when a predictor perfectly predicts a binary response variable <span class="citation">(Rainey 2016a, <span class="citation">@Zorn2005a</span>)</span></p>
<ul>
<li><em>complete separation:</em> the predictor perfectly predicts both 0’s and 1’s.</li>
<li><em>quasi-complete separation:</em> the predictor perfectly predicts either 0’s or 1’s.</li>
</ul>
<p>This is related and similar to identification in MLE and multicollinearity in OLS.</p>
<p>The general solution is to penalize the likelihood, which in a Bayesian context is equivalent to placing a proper prior on the coefficient of the separating variable.</p>
<p>Using a weakly informative prior such as those suggested by is sufficient to solve separation,
<span class="math display">\[
\beta_k \sim \dnorm(0, 2.5)
\]</span>
where all the columns of <span class="math inline">\(\code{x}\)</span> are assumed to mean zero, unit variance (or otherwise standardized).
The half-Cauchy prior, <span class="math inline">\(\dhalfcauchy(0, 2.5)\)</span>, suggested in <span class="citation">Gelman et al. (2008)</span> is insufficiently informative to to deal with separation <span class="citation">(J. Ghosh, Li, and Mitra 2015)</span>, but finite-variance weakly informative Student-t or Normal distributions will work.</p>
<p>These are the priors suggested by <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Stan</a> and used by default in <strong>rstanarm</strong> <a href="https://www.rdocumentation.org/packages/rstanarm/topics/stan_glm">rstanarm</a>.</p>
<p><span class="citation">Rainey (2016a)</span> provides a mixed MLE/Bayesian simulation based approach to apply a prior to the variable with separation, while keeping the other coefficients at their MLE values.
Since the results are highly sensitive to the prior, multiple priors should be tried (informative, skeptical, and enthusiastic).</p>
<p><span class="citation">Firth (1993)</span> suggests the Jeffreys invariant prior,
<span class="math display">\[
p(\beta_k) \propto |I(\beta)|^{\frac{1}{2}}
\]</span>
where <span class="math inline">\(|I(\beta)|\)</span> is the information matrix,
<span class="math display">\[
\begin{aligned}[t]
I(\beta) &amp;= \mat{X}\T \mat{W} \mat{X} \\
\mat{W} &amp;= \diag(\pi_i (1 - \pi_i))
\end{aligned}
\]</span>
This is the Jeffreys invariant prior. This was also recommended <span class="citation">Zorn (2005)</span>.</p>
<p><span class="citation">Greenland and Mansournia (2015)</span> suggest a log-F prior distribution which has an intuitive interpretation related to the number of observations.</p>
<div id="example-support-of-aca-medicaid-expansion" class="section level4">
<h4><span class="header-section-number">9.0.4.1</span> Example: Support of ACA Medicaid Expansion</h4>
<p>This example is from <span class="citation">Rainey (2016a)</span> from the original paper <span class="citation">Barrilleaux and Rainey (2014)</span>
with replication code <a href="https://github.com/carlislerainey/separation">here</a>.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)</a>
<a class="sourceLine" id="cb51-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</a>
<a class="sourceLine" id="cb51-3" data-line-number="3"><span class="kw">library</span>(<span class="st">&quot;magrittr&quot;</span>)</a>
<a class="sourceLine" id="cb51-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-5" data-line-number="5"><span class="co">#&gt; Attaching package: &#39;magrittr&#39;</span></a>
<a class="sourceLine" id="cb51-6" data-line-number="6"><span class="co">#&gt; The following object is masked from &#39;package:purrr&#39;:</span></a>
<a class="sourceLine" id="cb51-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-8" data-line-number="8"><span class="co">#&gt;     set_names</span></a>
<a class="sourceLine" id="cb51-9" data-line-number="9"><span class="co">#&gt; The following object is masked from &#39;package:tidyr&#39;:</span></a>
<a class="sourceLine" id="cb51-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-11" data-line-number="11"><span class="co">#&gt;     extract</span></a>
<a class="sourceLine" id="cb51-12" data-line-number="12"><span class="co">#&gt; The following object is masked from &#39;package:rstan&#39;:</span></a>
<a class="sourceLine" id="cb51-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-14" data-line-number="14"><span class="co">#&gt;     extract</span></a>
<a class="sourceLine" id="cb51-15" data-line-number="15"></a>
<a class="sourceLine" id="cb51-16" data-line-number="16">URL &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/carlislerainey/priors-for-separation/master/br-replication/data/need.csv&quot;</span></a>
<a class="sourceLine" id="cb51-17" data-line-number="17"></a>
<a class="sourceLine" id="cb51-18" data-line-number="18"></a>
<a class="sourceLine" id="cb51-19" data-line-number="19"></a>
<a class="sourceLine" id="cb51-20" data-line-number="20">f &lt;-<span class="st"> </span>(oppose_expansion <span class="op">~</span><span class="st"> </span>dem_governor <span class="op">+</span><span class="st"> </span>obama_win <span class="op">+</span><span class="st"> </span>gop_leg <span class="op">+</span><span class="st"> </span>percent_uninsured <span class="op">+</span></a>
<a class="sourceLine" id="cb51-21" data-line-number="21"><span class="st">      </span>income <span class="op">+</span><span class="st"> </span>percent_nonwhite <span class="op">+</span><span class="st"> </span>percent_metro)</a>
<a class="sourceLine" id="cb51-22" data-line-number="22"></a>
<a class="sourceLine" id="cb51-23" data-line-number="23">br &lt;-<span class="st"> </span><span class="kw">read_csv</span>(URL) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-24" data-line-number="24"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">oppose_expansion =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>support_expansion,</a>
<a class="sourceLine" id="cb51-25" data-line-number="25">         <span class="dt">dem_governor =</span> <span class="dv">-1</span> <span class="op">*</span><span class="st"> </span>gop_governor,</a>
<a class="sourceLine" id="cb51-26" data-line-number="26">         <span class="dt">obama_win =</span> <span class="kw">as.integer</span>(obama_share <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>),</a>
<a class="sourceLine" id="cb51-27" data-line-number="27">         <span class="dt">percent_nonwhite =</span> percent_black <span class="op">+</span><span class="st"> </span>percent_hispanic) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-28" data-line-number="28"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">gop_leg =</span> legGOP) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-29" data-line-number="29"><span class="st">  </span><span class="co"># keep only variables in the formula</span></a>
<a class="sourceLine" id="cb51-30" data-line-number="30"><span class="st">  </span><span class="kw">model.frame</span>(f, <span class="dt">data =</span> .) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-31" data-line-number="31"><span class="st">  </span><span class="co"># drop missing values (if any?)</span></a>
<a class="sourceLine" id="cb51-32" data-line-number="32"><span class="st">  </span><span class="kw">drop_na</span>()</a>
<a class="sourceLine" id="cb51-33" data-line-number="33"><span class="co">#&gt; Parsed with column specification:</span></a>
<a class="sourceLine" id="cb51-34" data-line-number="34"><span class="co">#&gt; cols(</span></a>
<a class="sourceLine" id="cb51-35" data-line-number="35"><span class="co">#&gt;   .default = col_integer(),</span></a>
<a class="sourceLine" id="cb51-36" data-line-number="36"><span class="co">#&gt;   state = col_character(),</span></a>
<a class="sourceLine" id="cb51-37" data-line-number="37"><span class="co">#&gt;   state_abbr = col_character(),</span></a>
<a class="sourceLine" id="cb51-38" data-line-number="38"><span class="co">#&gt;   house12 = col_double(),</span></a>
<a class="sourceLine" id="cb51-39" data-line-number="39"><span class="co">#&gt;   sen12 = col_double(),</span></a>
<a class="sourceLine" id="cb51-40" data-line-number="40"><span class="co">#&gt;   support_expansion_new = col_character(),</span></a>
<a class="sourceLine" id="cb51-41" data-line-number="41"><span class="co">#&gt;   percent_uninsured = col_double(),</span></a>
<a class="sourceLine" id="cb51-42" data-line-number="42"><span class="co">#&gt;   ideology = col_double(),</span></a>
<a class="sourceLine" id="cb51-43" data-line-number="43"><span class="co">#&gt;   income = col_double(),</span></a>
<a class="sourceLine" id="cb51-44" data-line-number="44"><span class="co">#&gt;   percent_black = col_double(),</span></a>
<a class="sourceLine" id="cb51-45" data-line-number="45"><span class="co">#&gt;   percent_hispanic = col_double(),</span></a>
<a class="sourceLine" id="cb51-46" data-line-number="46"><span class="co">#&gt;   percent_metro = col_double(),</span></a>
<a class="sourceLine" id="cb51-47" data-line-number="47"><span class="co">#&gt;   dsh = col_double(),</span></a>
<a class="sourceLine" id="cb51-48" data-line-number="48"><span class="co">#&gt;   obama_share = col_double()</span></a>
<a class="sourceLine" id="cb51-49" data-line-number="49"><span class="co">#&gt; )</span></a>
<a class="sourceLine" id="cb51-50" data-line-number="50"><span class="co">#&gt; See spec(...) for full column specifications.</span></a>
<a class="sourceLine" id="cb51-51" data-line-number="51"></a>
<a class="sourceLine" id="cb51-52" data-line-number="52">br_scaled &lt;-<span class="st"> </span>br <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-53" data-line-number="53"><span class="st">  </span><span class="co"># Autoscale all vars but response</span></a>
<a class="sourceLine" id="cb51-54" data-line-number="54"><span class="st">  </span><span class="kw">mutate_at</span>(<span class="kw">vars</span>(<span class="op">-</span>oppose_expansion), autoscale)</a>
<a class="sourceLine" id="cb51-55" data-line-number="55"></a>
<a class="sourceLine" id="cb51-56" data-line-number="56"><span class="kw">glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</a>
<a class="sourceLine" id="cb51-57" data-line-number="57"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-58" data-line-number="58"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb51-59" data-line-number="59"><span class="co">#&gt; glm(formula = f, family = &quot;binomial&quot;, data = br)</span></a>
<a class="sourceLine" id="cb51-60" data-line-number="60"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-61" data-line-number="61"><span class="co">#&gt; Deviance Residuals: </span></a>
<a class="sourceLine" id="cb51-62" data-line-number="62"><span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span></a>
<a class="sourceLine" id="cb51-63" data-line-number="63"><span class="co">#&gt; -2.374  -0.461  -0.131   0.630   2.207  </span></a>
<a class="sourceLine" id="cb51-64" data-line-number="64"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-65" data-line-number="65"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb51-66" data-line-number="66"><span class="co">#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)   </span></a>
<a class="sourceLine" id="cb51-67" data-line-number="67"><span class="co">#&gt; (Intercept)         4.5103     4.5986    0.98    0.327   </span></a>
<a class="sourceLine" id="cb51-68" data-line-number="68"><span class="co">#&gt; dem_governor       -4.1556     1.4794   -2.81    0.005 **</span></a>
<a class="sourceLine" id="cb51-69" data-line-number="69"><span class="co">#&gt; obama_win          -2.1470     1.3429   -1.60    0.110   </span></a>
<a class="sourceLine" id="cb51-70" data-line-number="70"><span class="co">#&gt; gop_leg            -0.1865     1.2974   -0.14    0.886   </span></a>
<a class="sourceLine" id="cb51-71" data-line-number="71"><span class="co">#&gt; percent_uninsured  -0.3072     0.1651   -1.86    0.063 . </span></a>
<a class="sourceLine" id="cb51-72" data-line-number="72"><span class="co">#&gt; income             -0.0421     0.0776   -0.54    0.587   </span></a>
<a class="sourceLine" id="cb51-73" data-line-number="73"><span class="co">#&gt; percent_nonwhite   17.8505    48.3030    0.37    0.712   </span></a>
<a class="sourceLine" id="cb51-74" data-line-number="74"><span class="co">#&gt; percent_metro     -12.4390    32.4446   -0.38    0.701   </span></a>
<a class="sourceLine" id="cb51-75" data-line-number="75"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb51-76" data-line-number="76"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a>
<a class="sourceLine" id="cb51-77" data-line-number="77"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-78" data-line-number="78"><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></a>
<a class="sourceLine" id="cb51-79" data-line-number="79"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-80" data-line-number="80"><span class="co">#&gt;     Null deviance: 68.593  on 49  degrees of freedom</span></a>
<a class="sourceLine" id="cb51-81" data-line-number="81"><span class="co">#&gt; Residual deviance: 37.948  on 42  degrees of freedom</span></a>
<a class="sourceLine" id="cb51-82" data-line-number="82"><span class="co">#&gt; AIC: 53.95</span></a>
<a class="sourceLine" id="cb51-83" data-line-number="83"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-84" data-line-number="84"><span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></a>
<a class="sourceLine" id="cb51-85" data-line-number="85"></a>
<a class="sourceLine" id="cb51-86" data-line-number="86">fit1 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb51-87" data-line-number="87"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-88" data-line-number="88"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb51-89" data-line-number="89"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-90" data-line-number="90"><span class="co">#&gt; Gradient evaluation took 8.5e-05 seconds</span></a>
<a class="sourceLine" id="cb51-91" data-line-number="91"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.85 seconds.</span></a>
<a class="sourceLine" id="cb51-92" data-line-number="92"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-93" data-line-number="93"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-94" data-line-number="94"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-95" data-line-number="95"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-96" data-line-number="96"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-97" data-line-number="97"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-98" data-line-number="98"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-99" data-line-number="99"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-100" data-line-number="100"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-101" data-line-number="101"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-102" data-line-number="102"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-103" data-line-number="103"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-104" data-line-number="104"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-105" data-line-number="105"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-106" data-line-number="106"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-107" data-line-number="107"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-108" data-line-number="108"><span class="co">#&gt;  Elapsed Time: 0.224432 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-109" data-line-number="109"><span class="co">#&gt;                0.210568 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-110" data-line-number="110"><span class="co">#&gt;                0.435 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-111" data-line-number="111"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-112" data-line-number="112"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-113" data-line-number="113"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb51-114" data-line-number="114"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-115" data-line-number="115"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb51-116" data-line-number="116"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb51-117" data-line-number="117"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-118" data-line-number="118"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-119" data-line-number="119"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-120" data-line-number="120"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-121" data-line-number="121"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-122" data-line-number="122"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-123" data-line-number="123"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-124" data-line-number="124"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-125" data-line-number="125"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-126" data-line-number="126"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-127" data-line-number="127"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-128" data-line-number="128"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-129" data-line-number="129"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-130" data-line-number="130"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-131" data-line-number="131"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-132" data-line-number="132"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-133" data-line-number="133"><span class="co">#&gt;  Elapsed Time: 0.222537 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-134" data-line-number="134"><span class="co">#&gt;                0.231917 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-135" data-line-number="135"><span class="co">#&gt;                0.454454 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-136" data-line-number="136"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-137" data-line-number="137"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-138" data-line-number="138"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb51-139" data-line-number="139"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-140" data-line-number="140"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb51-141" data-line-number="141"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb51-142" data-line-number="142"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-143" data-line-number="143"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-144" data-line-number="144"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-145" data-line-number="145"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-146" data-line-number="146"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-147" data-line-number="147"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-148" data-line-number="148"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-149" data-line-number="149"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-150" data-line-number="150"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-151" data-line-number="151"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-152" data-line-number="152"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-153" data-line-number="153"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-154" data-line-number="154"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-155" data-line-number="155"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-156" data-line-number="156"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-157" data-line-number="157"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-158" data-line-number="158"><span class="co">#&gt;  Elapsed Time: 0.229284 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-159" data-line-number="159"><span class="co">#&gt;                0.221269 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-160" data-line-number="160"><span class="co">#&gt;                0.450553 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-161" data-line-number="161"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-162" data-line-number="162"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-163" data-line-number="163"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb51-164" data-line-number="164"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-165" data-line-number="165"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb51-166" data-line-number="166"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb51-167" data-line-number="167"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-168" data-line-number="168"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-169" data-line-number="169"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-170" data-line-number="170"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-171" data-line-number="171"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-172" data-line-number="172"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-173" data-line-number="173"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-174" data-line-number="174"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-175" data-line-number="175"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-176" data-line-number="176"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-177" data-line-number="177"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-178" data-line-number="178"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-179" data-line-number="179"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-180" data-line-number="180"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-181" data-line-number="181"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-182" data-line-number="182"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-183" data-line-number="183"><span class="co">#&gt;  Elapsed Time: 0.217782 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-184" data-line-number="184"><span class="co">#&gt;                0.220388 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-185" data-line-number="185"><span class="co">#&gt;                0.43817 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-186" data-line-number="186">fit2 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">prior =</span> <span class="ot">NULL</span>, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb51-187" data-line-number="187"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-188" data-line-number="188"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb51-189" data-line-number="189"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-190" data-line-number="190"><span class="co">#&gt; Gradient evaluation took 2.7e-05 seconds</span></a>
<a class="sourceLine" id="cb51-191" data-line-number="191"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.</span></a>
<a class="sourceLine" id="cb51-192" data-line-number="192"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-193" data-line-number="193"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-194" data-line-number="194"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-195" data-line-number="195"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-196" data-line-number="196"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-197" data-line-number="197"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-198" data-line-number="198"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-199" data-line-number="199"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-200" data-line-number="200"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-201" data-line-number="201"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-202" data-line-number="202"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-203" data-line-number="203"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-204" data-line-number="204"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-205" data-line-number="205"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-206" data-line-number="206"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-207" data-line-number="207"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-208" data-line-number="208"><span class="co">#&gt;  Elapsed Time: 1.55551 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-209" data-line-number="209"><span class="co">#&gt;                0.243953 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-210" data-line-number="210"><span class="co">#&gt;                1.79946 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-211" data-line-number="211"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-212" data-line-number="212"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-213" data-line-number="213"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb51-214" data-line-number="214"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-215" data-line-number="215"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb51-216" data-line-number="216"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb51-217" data-line-number="217"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-218" data-line-number="218"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-219" data-line-number="219"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-220" data-line-number="220"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-221" data-line-number="221"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-222" data-line-number="222"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-223" data-line-number="223"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-224" data-line-number="224"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-225" data-line-number="225"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-226" data-line-number="226"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-227" data-line-number="227"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-228" data-line-number="228"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-229" data-line-number="229"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-230" data-line-number="230"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-231" data-line-number="231"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-232" data-line-number="232"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-233" data-line-number="233"><span class="co">#&gt;  Elapsed Time: 1.39207 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-234" data-line-number="234"><span class="co">#&gt;                0.209127 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-235" data-line-number="235"><span class="co">#&gt;                1.6012 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-236" data-line-number="236"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-237" data-line-number="237"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-238" data-line-number="238"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb51-239" data-line-number="239"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-240" data-line-number="240"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb51-241" data-line-number="241"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb51-242" data-line-number="242"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-243" data-line-number="243"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-244" data-line-number="244"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-245" data-line-number="245"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-246" data-line-number="246"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-247" data-line-number="247"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-248" data-line-number="248"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-249" data-line-number="249"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-250" data-line-number="250"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-251" data-line-number="251"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-252" data-line-number="252"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-253" data-line-number="253"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-254" data-line-number="254"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-255" data-line-number="255"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-256" data-line-number="256"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-257" data-line-number="257"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-258" data-line-number="258"><span class="co">#&gt;  Elapsed Time: 1.06268 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-259" data-line-number="259"><span class="co">#&gt;                0.242076 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-260" data-line-number="260"><span class="co">#&gt;                1.30476 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-261" data-line-number="261"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-262" data-line-number="262"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-263" data-line-number="263"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb51-264" data-line-number="264"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-265" data-line-number="265"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb51-266" data-line-number="266"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb51-267" data-line-number="267"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-268" data-line-number="268"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-269" data-line-number="269"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-270" data-line-number="270"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-271" data-line-number="271"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-272" data-line-number="272"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-273" data-line-number="273"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-274" data-line-number="274"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-275" data-line-number="275"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-276" data-line-number="276"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-277" data-line-number="277"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-278" data-line-number="278"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-279" data-line-number="279"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-280" data-line-number="280"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-281" data-line-number="281"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-282" data-line-number="282"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-283" data-line-number="283"><span class="co">#&gt;  Elapsed Time: 1.21102 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-284" data-line-number="284"><span class="co">#&gt;                0.217264 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-285" data-line-number="285"><span class="co">#&gt;                1.42828 seconds (Total)</span></a></code></pre></div>
</div>
</div>
<div id="rare-events-logit" class="section level2">
<h2><span class="header-section-number">9.1</span> Rare Events Logit</h2>
</div>
<div id="case-control" class="section level2">
<h2><span class="header-section-number">9.2</span> Case Control</h2>
<p>In binary outcome variables, sometimes it is useful to sample on the dependent variable.
For example, <span class="citation">King and Zeng (2001b)</span> and <span class="citation">King and Zeng (2001a)</span> discuss applications with respect to conflicts in international relations.
For most country-pairs, for most years, there is no conflict.
If some data are costly to gather, it may be cost efficient to get data for conflicts and then randomly select a smaller number of non-conflicts on which to gather data.
The sample will no longer be representative, but the estimates can be corrected.</p>
<p>The reason this works well, is that if there are very few 1’s, additional 0’s have little influence on the estimation (<span class="citation">King and Zeng (2001b)</span>).
This should hold more generally will unbalanced classes; in some sense, the amount of effective observations is not much more than the number in the lowest category.</p>
<p><span class="citation">King and Zeng (2001b)</span> propose two corrections:</p>
<ol style="list-style-type: decimal">
<li>Correcting the intercept (prior correction)</li>
<li>Weighting observations</li>
</ol>
<p>The <em>prior correction</em> notes that
<span class="math display">\[
\pi_i = \frac{1}{1 + \exp(-\mat{X} \vec{beta})}
\]</span></p>
<p>The unbalanced sample only affects the intercept. If <span class="math inline">\(\hat\beta_0\)</span> is the intercept from the MLE, the case-control corrected intercept <span class="math inline">\(\tilde{\beta}\)</span> is,
<span class="math display">\[
\tilde{\vec{\beta}}_0^* = \hat{\vec{\beta}}_0 - \ln \left(\frac{1 - \tau}{\tau} \frac{\bar{y}}{1 - \bar{y}} \right)
\]</span>
In an MLE setting, this can be applied after estimation, but used in any predicted values.
In a Bayesian setting, this correct should be applied within the model by adding the offset to the estimation.</p>
<p>In a Stan model, this could be implemented by directly incrementing these values</p>
<pre><code>data {
  int N;
  int y[N];
  real tau;
}
transformed data {
  real offset;
  real y_mean;
  y_mean = mean(y);
  offset = log((1 - tau) / tau * (y_mean) / (1 - y_mean));
}
parameters {
  real alpha0;
}
transformed parameters {
  real alpha;
  alpha &lt;- alpha0 - offset;
}</code></pre>
<p>If there was uncertainty about <span class="math inline">\(\tau\)</span>, then <span class="math inline">\(\tau\)</span> could be modeled as a parameter.
It may also be okay to only correct the intercept in a generated quantities block? (not sure).</p>
<p>An alternative approach is to use a <em>weighted likelihood</em>:</p>
<ul>
<li>ones are weighted by <span class="math inline">\(\tau / \bar{y}\)</span></li>
<li>zeros are weighted by <span class="math inline">\((1 - \tau) / \bar{1 - \bar{y}}\)</span></li>
</ul>
<p>The log likelihood would then be
<span class="math display">\[
\ln L_w(\beta | y) = w_1 \sum_{Y_i = 1} \ln (\pi_i) + w_0 \sum_{Y_i = 0} \ln (1 - \pi_i)
\]</span></p>
<p>In Stan, this can be implemented by directly weighting the log-posterior contributions of each observation.
For example, something like this,</p>
<pre><code>if (y[i]) {
  target += w * binomial_lpdf(1, pi[i])
} else {
  target += (1 - w) * binomial_lpdf(1, pi[i])
}</code></pre>
<p>See the example for <a href="http://docs.zeligproject.org/en/latest/zelig-relogit.html">Zelig-relogit</a></p>
<div id="references-5" class="section level4">
<h4><span class="header-section-number">9.2.0.1</span> References</h4>
<ul>
<li><span class="citation">Firth (1993)</span> proposes a penalized likelihood approach using the Jeffreys invariant prior</li>
<li><span class="citation">King and Zeng (2001a)</span> and <span class="citation">King and Zeng (2001b)</span> apply an approach similar to the penalized likelihood approach for the similar problem of rare events</li>
<li><span class="citation">Zorn (2005)</span> also suggests using the Firth logistic regression to avoid perfect separation</li>
<li><span class="citation">Rainey (2016a)</span> shows that Cauchy(0, 2.5) priors can be used</li>
<li><span class="citation">Greenland and Mansournia (2015)</span> provide another default prior to for binomial models: log F(1,1) and log F(2, 2) priors. These have the nice property that they are interpretable as additional observations.</li>
</ul>
</div>
<div id="references-6" class="section level3">
<h3><span class="header-section-number">9.2.1</span> References</h3>
<p>For general references on binomial models see <span class="citation">Stan Development Team (2016 Sec. 8.5)</span>, <span class="citation">McElreath (2016 Ch 10)</span>, <span class="citation">Gelman and Hill (2007)</span> [Ch. 5; Sec 6.4-6.5], <span class="citation">Fox (2016 Ch. 14)</span>, and <span class="citation">Gelman et al. (2013 Ch. 16)</span>.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>Since the cumulative distribution function of a distribution maps reals to <span class="math inline">\((0, 1)\)</span>, any CDF can be used as a link function.<a href="binomial-models.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p><span class="citation">Beck, Katz, and Tucker (1998)</span> show that the cloglog link function can be derived from a grouped duration model with binary response variables.<a href="binomial-models.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Example from <a href="http://docs.zeligproject.org/en/latest/zelig-logit.html">Zelig-logit</a>.<a href="binomial-models.html#fnref6" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="unbounded-count-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/bayesian_notes/edit/master/binomial.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
