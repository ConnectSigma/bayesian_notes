[
["index.html", "Updating: A Set of Bayesian Notes Preface", " Updating: A Set of Bayesian Notes Jeffrey B. Arnold Preface These notes are unfinished and certainly full of typos and such. However, I’m no longer working on these notes. Notes on Bayesian methods - written to supplement CS&amp;SS/STAT 564: Bayesian Statistics for the Social Sciences. These notes largely focus on the application and theory necessary for quantitative social scientists to successfully apply Bayesian statistical methods. I also don’t hesitate to link to those who have already explained things well, and focus my efforts on places where I haven’t found good explanations (or explanations I understand), or places where I need to write notes to deepen my own understanding. "],
["bayesian-inference.html", "1 Bayesian Inference 1.1 Bayesian Analysis 1.2 Posterior Predictive Distribution", " 1 Bayesian Inference new shit has come to light, man – The Dude (The Big Lebowski) Statistical inference is the process of using observed data to infer properties of the statistical distributions that generated that data. Bayesian inference is the process of fitting a probability model to a set of data and summarizing the result by a probability distribution on the parameters of the model and on unobserved quantities such as predictions for new observations. The motivation of statistical inference is the learn about unknown quantities (parameters) of a process from data that was generated by it. In other words, the quantity of interest in statistical inference is \\[ \\Pr(\\text{parameters} | \\text{data}) . \\] This conditional distribution is called the posterior distribution. Bayesian inference answers this question by appealing to Bayes’ Theorem, \\[ \\underbrace{\\Pr(\\text{parameters} | \\text{data})}_{\\text{posterior}} = \\frac{\\overbrace{\\Pr(\\text{data} | \\text{parameters})}^{\\text{likelihood}} \\overbrace{\\Pr(\\text{parameters})}^{\\text{prior}}}{\\underbrace{\\Pr(\\text{data})}_{evidence}} . \\] The remainder of these notes discusses how to apply this to problems. 1.1 Bayesian Analysis The three steps of Bayesian analysis (A. Gelman, Carlin, et al. 2013, 3) are Modeling: define a full probability model which incorporates all observable and unobservable quantities of the problem. To the extent possible, the model should incorporate all relevant data about the underlying problem and data generating problem. Estimation: given data, estimate the parameters for the posterior distribution defined in the modeling step. Evaluation: given the posterior distribution, evaluate the fit the model to the data, or the prediction of new data. If it is insufficient, go back to step one. One of the nice features of Bayesian analysis is that in theory it clearly separates the modeling step from the estimation step. However, in application, the difficulties of computing the posterior distribution have meant that the computational and modeling steps have often been tightly coupled. Yet, new algorithms, improvements in computational capacity, and new software have started to make it possible to black-box the estimation stage. 1.2 Posterior Predictive Distribution The posterior predictive distribution is the the probability of observing new data (\\(y^{eval}\\)) given the posterior distribution of the model parameters after observing training data, \\(p(\\theta | y^{train})\\). \\[ p(y^{eval} | y^{train}) = \\int p(y^{eval} | \\theta) p(\\theta | y^{train})\\,d \\theta . \\tag{1.1} \\] Many tradition statistical or machine learning methods proceed by estimating a “best” value of the parameters using training data, and then predicting evaluating data using that parameter. For example, we could calculate the maximum a posteriori estimate of of \\(\\theta\\) given the training data, \\[ \\hat{\\theta} = \\arg \\max_{\\theta} p(\\theta | y^{train}) , \\] and then use that for the distribution of evaluation data, \\[ p(y^{eval} | y^{train} \\approx p(y^{eval} | \\hat{\\theta}) . \\] However, this does not incorporate the uncertainty in the estimates of \\(\\theta\\). The full form of the posterior predictive distribution in Equation \\tag{1.1} incorporates the uncertainty about \\(\\theta\\) into the distribution of \\(p(y^{eval} | \\theta)\\). "],
["bayes-theorem.html", "2 Bayes Theorem Prerequisites 2.1 Introduction to Bayes’ Theorem 2.2 Examples 2.3 Why most research findings are false 2.4 Measurement Error and Rare Events in Surveys", " 2 Bayes Theorem This document contains a discussion and several examples of Bayes’ Theorem. Prerequisites library(&quot;tidyverse&quot;) library(&quot;babynames&quot;) 2.1 Introduction to Bayes’ Theorem For events, \\(A\\) and \\(B\\), \\[ \\underbrace{\\Pr(A | B)}_{\\text{posterior}} = \\frac{\\overbrace{\\Pr(B | A)}^{\\text{likelihood}} \\overbrace{\\Pr(A)}^{\\text{prior}}}{\\underbrace{\\Pr(B)}_{\\text{marginal likelihood}}}, \\] where \\(\\Pr(B) \\neq 0\\). For discrete random variables \\(X\\) which takes values in the set \\(\\mathcal{X}\\) and \\(Y\\) which takes values in the set \\(\\mathcal{Y}\\), Bayes’ Theorem can be written as, \\[ p_{Y|X}(X = x|Y = y) = \\frac{p_{Y|X}(Y = y|X = x) p_X(X = x)}{p_Y(Y = y)} = \\frac{p_{Y|X}(Y = y|X = x) p_X(X = x)}{\\sum_{x \\in \\mathcal{x}} p_{Y|X}(Y = y|X = x) p_X(X = x)} \\] For continuous random variables \\(X\\) with support \\(X\\) and \\(Y\\) with support \\(\\mathcal{Y}\\), Bayes’ Theorem can be written as, \\[ p_{Y|X}(x|Y = y) = \\frac{p_{Y|X = x}(y) p_X(x)}{p_Y(y)} = \\frac{p_{Y|X = x}(y) p_X(x)}{\\int_{x \\in \\mathcal{x}} p_{Y|X = x}(y) p_X(x) dx} \\] Though there are deeper differences between discrete and continuous probability theory, the primary difference in the equations for Bayes’ Theorem with discrete or continuous random variables is whether summation or integration is used to calculate the marginal likelihood. 2.2 Examples 2.2.1 Taxi-Cab Problem Suppose you were told that a taxi-cab was involved in a hit-and-run accident one night. Of the taxi-cabs in the city, 85% belonged to the Green company and 15% to the Blue company. You are then asked to estimate the likelihood that the hit-and-run accident involved a green taxi-cab (all else being equal).1 What is the probability that the taxi-cab involved in the hit and run is blue? It is 85%, since we have no other information. You are then told that an eyewitness had identified the cab as a blue cab. But when her ability to identify cabs under appropriate visibility conditions was tested, she was wrong 20% of the time. What is the probability that the cab is blue? Let \\(H_B\\) (\\(H_G\\)) be the event that a blue (green) cab committed the hit and run. Let \\(W_B\\) (\\(W_G\\)) be the event that the witness reported that a blue (green) cab committed the hit and run. We are interested in \\(\\Pr(H_B | W_B)\\), the probability that a blue cab committed the hit and run given that the witness reported a blue cab committing the hit and run. \\[ \\Pr(H_B | W_B) = \\frac{\\Pr(W_B | H_B) \\Pr(H_B)}{\\Pr(W_B)} = \\frac{\\Pr(W_B | H_B) \\Pr(H_B)}{\\Pr(W_B | H_B) \\Pr(H_B) + \\Pr(W_B | H_G) \\Pr(H_G)}. \\] The prior probabilities of the color of the cab come are the proportions of cabs in the city, \\[ \\begin{aligned} \\Pr(H_B) &amp;= 0.15 ,\\\\ \\Pr(H_G) &amp;= 0.85 . \\end{aligned} \\] The conditional probabilities are, \\[ \\begin{aligned}[t] p(W_B | H_B) &amp;= 0.8 , \\\\ p(W_B | H_G) &amp;= 0.2 . \\end{aligned} \\] The marginal likelihood (model evidence) is the overall probability that a cab is reported to be blue. This considers both the probabilities that a witness reports that the cab is blue when it is blue and reports that it is blue when it is green. \\[ \\begin{aligned}[t] \\Pr(W_B) = \\Pr(W_B | H_B) \\Pr(H_B) + \\Pr(W_B | H_G) \\Pr(H_G) \\end{aligned} \\] To calculate the posterior distribution, put the prior and likelihoods into a table. cabs &lt;- tribble( ~ color, ~ prior, ~ likelihood, &quot;blue&quot;, 0.15, 0.8, &quot;green&quot;, 0.85, 0.2 ) Calculate the marginal probability. cabs %&gt;% mutate( marginal = sum(likelihood * prior), posterior = likelihood * prior / marginal ) #&gt; # A tibble: 2 x 5 #&gt; color prior likelihood marginal posterior #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 blue 0.15 0.8 0.29 0.414 #&gt; 2 green 0.85 0.2 0.29 0.586 Suppose that you know that all cabs in the city are blue or green, but you don’t know the proportions of them. You use the principle of indifference to assign prior probabilities of, \\[ \\begin{aligned}[t] p(H_B) = p(H_G) = 0.5 . \\end{aligned} \\] Suppose the witness reports that a blue cab hit the citizen, what is the probability that the cab committing the hit and run was blue. A common answer to this question is “blue”. This mistake is often due to ignoring the prior probability of an event, and interpreting \\(P(H_B | W_B) = P(W_B | H_B)\\). This is called the base-rate fallacy? What prior does the base-rate fallacy correspond to? In other words, what prior is needed such that \\(\\Pr(H_B | W_B) = \\Pr(W_B | H_B)\\). Suppose that there was was perfectly reliable video evidence of the hit and run, such that \\(\\Pr(W_B | H_B) = 1\\) and \\(\\Pr(W_B | H_G) = 0\\). What is the probability that the cab committing the hit and run was blue? Suppose that the witness reports that the cab was “yellow”. You know that there are no yellow cabs in the city, thus \\(\\Pr(H_Y) = 0\\). What is the probability that the cab committing the hit and run was yellow, given that the witness reports it being yellow? What level of accuracy would you require from the witness such that you believed that the cab committing the hit and run was yellow. What level of accuracy would be required from the witness such that it is more probable that a green cab committed the hit and run than a blue cab? There have been various proposals to quantify what is meant by “beyond a reasonable doubt”. But for the purpose of this question, let’s suppose that beyond a reasonable doubt is a probability greater or equal to 0.8. What level of accuracy is required from the witness to meet the reasonable doubt standard? 2.3 Why most research findings are false Consider this simplified mode of scientific research. Let \\(H\\) (\\(\\lnot H\\)) be the event that a hypothesis is true (false). Let \\(D\\) (\\(\\lnot D\\)) be the result of a hypothesis test of \\(H\\).2 Suppose that the test uses statistical significance level of \\(\\alpha = 0.05\\) Since statistical significance controls the presence of type I error, \\[ P(H | \\lnot D) = \\alpha = 0.05 \\] alpha &lt;- 0.05 Suppose that the test uses a power level of \\(\\beta = 0.8\\). Since power is \\(1 - \\Pr(\\text{Type II error})\\), \\[ \\Pr(H | D) = \\beta = 0.8 \\] beta &lt;- 0.8 Given that information, suppose that you observe \\(D\\). Can you calculate \\(\\Pr(H | D)\\)? No. By Bayes’ Theorem, \\[ \\Pr(H | D) = \\frac{\\Pr(D | H) \\Pr(H)}{\\Pr(D)} \\] We cannot calculate this because we do not know \\(\\Pr(H)\\). Suppose that a priori, many hypotheses are false. We will set \\(\\Pr(H)\\) to the following value, but will explore how the posterior changes with respect to different values of it. \\[ \\Pr(H) = 0.1 . \\] With this information we can calculate \\[ \\Pr(H | D) = \\frac{\\Pr(D | H) \\Pr(H)}{\\Pr(D | H) \\Pr(H) + \\Pr(D | \\lnot H) \\Pr(\\lnot H)} \\] p_theta &lt;- 0.1 science &lt;- tribble( ~ theta, ~ x, ~ prior, ~ likelihood, TRUE, TRUE, p_theta, beta, TRUE, FALSE, p_theta, 1 - beta, FALSE, TRUE, 1 - p_theta, alpha, FALSE, FALSE, 1 - p_theta, 1 - alpha ) Calculate the posterior probability for each value of theta, for the different cases of x: group_by(science, x) %&gt;% mutate(marginal = sum(likelihood * prior), posterior = likelihood * prior / marginal ) %&gt;% arrange(x) #&gt; # A tibble: 4 x 6 #&gt; # Groups: x [2] #&gt; theta x prior likelihood marginal posterior #&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 TRUE FALSE 0.1 0.200 0.875 0.0229 #&gt; 2 FALSE FALSE 0.9 0.95 0.875 0.977 #&gt; 3 TRUE TRUE 0.1 0.8 0.125 0.64 #&gt; 4 FALSE TRUE 0.9 0.05 0.125 0.36 2.3.1 Questions \\(p\\)-value hacking is a process by which a research ensures that their test has a statistically significant result? What term does this affect? If you know a study was p-value hacked, what is the posterior distribution Suppose a paper finds support for a novel and counter-intuitive theory. What parameter would that affect? Would it result in a higher or lower posterior probability? Suppose a paper conducts a test of a well-established theory. What parameter would that affect? Would it result in a higher or lower posterior probability? There are some arguments that the \\(p\\)-value threshold should be reduced to \\(\\alpha = 0.005\\). What is the posterior probability of \\(\\Pr(H | D)\\) in that case? Given the other parameters, what value of \\(\\alpha\\) would you need so that \\(\\Pr(H | D) \\geq 0.95\\) ? Many studies are under-powered. For example, this paper finds that empirically, many neuroscience experiments have powers of 8% to 31%. Suppose that the experiment has a power of 20%. What is the posterior probability \\(\\Pr(H | D)\\)? Given the other parameters, what value of \\(\\beta\\) would you need so that \\(\\Pr(H | D) \\geq 0.95\\) ? Given the original parameters, how many times would you have to replicate a study to get \\(P(H | D_1, \\dots, D_k) \\geq 0.95\\)? Suppose you run a study twice. Does \\(P(H | D_1, \\lnot D_2) = P(H | D_1, \\lnot D_2)\\)? In other words, does the order in which evidence is received matter? A study produces a statistically significant result, with a \\(p\\)-value of 0.01. The PI explains the results to the press saying that there is only a 1% chance that the findings are false. Is that interpretation of the p-value correct? If not, why not? Calculate the Kullback-Leibler divergence between \\[ KL(\\Pr(H|D) || \\Pr(H)) = \\sum \\Pr(H | D) \\log \\frac{\\Pr(H | D)} \\] Which event has more information, \\(D\\) or \\(\\lnot D\\)? 2.4 Measurement Error and Rare Events in Surveys Suppose a survey includes 20,000 respondents.3 Of them 19,500 are citizens and 500 are not. Suppose that 99.9% of the time, the survey question response is correct (citizens respond that they are citizens, and non-citizens respond that they are non-citizens). The survey against voting records, which provides the estimate \\(P(v = 1 | c = 0) = 0.7\\) What is the probability of being a non-citizen given that a person reported being a non-citizen? sample_size &lt;- 20000 non_citizens &lt;- 500 p_non_citizen &lt;- non_citizens / 20000 accuracy &lt;- 0.999 prior_citizen &lt;- 0.5 tribble( ~ citizen_reported, ~ citizen, ~ prior, ~ likelihood, TRUE, TRUE, prior_citizen, accuracy, TRUE, FALSE, prior_citizen, 1 - accuracy, FALSE, TRUE, 1 - prior_citizen, accuracy, FALSE, FALSE, 1 - prior_citizen, 1 - accuracy ) #&gt; # A tibble: 4 x 4 #&gt; citizen_reported citizen prior likelihood #&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 TRUE TRUE 0.5 0.999 #&gt; 2 TRUE FALSE 0.5 0.001 #&gt; 3 FALSE TRUE 0.5 0.999 #&gt; 4 FALSE FALSE 0.5 0.001 Given a respondent responded that they were a non-citizen, what is the probability that they are actually a non-citizen? How many citizens do you expect to respond that they are non-citizens? How many non-citizens do you expect to respond that they are citizens? Is the prior reasonable? How would you choose a better prior? How much would it affect the results? Suppose that citizens vote with 70% probability, and non-citizens never vote. With these assumptions, what is the probability that they are a non-citizen given that they voted? What is the probability that someone voted given that they reported being a non-citizen in the survey? What is the implication for studying rare events, such as non-citizen voting using surveys (not designed for that)? Example from Tversky, D. Kahneman, Evidential impact of base rates, in Judgment under uncertainty: Heuristics and biases, D. Kahneman, P. Slovic, A. Tversky (editors), Cambridge University Press, 1982.↩ This example is derived from Ioannides, John P. A. (2005) “Why Most Published Research Findings Are False”, PLOS Medicine.↩ This example is from Stephen Ansolabehere, Samantha Luks, Brian F. Schaffner, The Perils of Cherry Picking Low Frequency Events in Large Sample Surveys.↩ "],
["example-predicting-names-from-ages.html", "3 Example: Predicting Names from Ages Prerequisites 3.1 Statement of the problem 3.2 Data Wrangling 3.3 Probability of age given name and sex", " 3 Example: Predicting Names from Ages Prerequisites This analysis uses these packages. library(&quot;tidyverse&quot;) library(&quot;babynames&quot;) 3.1 Statement of the problem Suppose I know your sex and name, can I guess you age? The probability of an age given a name and sex, \\[ P(\\text{age} | \\text{name}, \\text{sex}) \\propto P(\\text{name} | \\text{age}, \\text{sex}) P(\\text{age} | \\text{sex}) \\] 3.2 Data Wrangling The source of our data is the babynames package in R. YEAR &lt;- 2015 We’ll consider a single year in our analysis 2015, which is the last year in the babynames package. The life tables are only provided for the decades from 1900 to 2010. We need to fill in the full life table for all birth years. For years between 1900 and 2010, we will linearly impute the probability of being alive at each age for non-decadal birth years. We’ll use 2010 for all birth-years after 2010. life_table &lt;- babynames::lifetables %&gt;% group_by(year) %&gt;% mutate(px = lx / 1e+05) %&gt;% rename(age = x) %&gt;% select(year, age, sex, p_alive = px) %&gt;% ungroup() %&gt;% complete(sex, year = seq(min(year), YEAR, by = 1), age) %&gt;% rename(birthyear = year) %&gt;% group_by(sex, age) %&gt;% arrange(sex, age, birthyear) %&gt;% mutate(p_alive = zoo::na.approx(p_alive, na.rm = FALSE)) %&gt;% fill(p_alive, .direction = &quot;down&quot;) %&gt;% ungroup() %&gt;% arrange(sex, age, birthyear) For this analysis, we only need the age distribution in 2015. age_distr &lt;- life_table %&gt;% mutate(year = birthyear + age, # convert sex to character to avoid join warning sex = as.character(sex)) %&gt;% filter(year == YEAR) %&gt;% select(-year) glimpse(life_table) #&gt; Observations: 27,840 #&gt; Variables: 4 #&gt; $ sex &lt;fct&gt; M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M... #&gt; $ birthyear &lt;dbl&gt; 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908... #&gt; $ age &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... #&gt; $ p_alive &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... However, the p_alive column of age_distr only provides the probability of being alive in 2015 conditional on having been born in a given year (and sex), ggplot(age_distr, aes(x = birthyear, y = p_alive, color = sex)) + geom_point() + geom_line() + labs(y = expression(paste(&quot;P&quot;, group(&quot;(&quot;, paste(alive, &quot;|&quot;, year), &quot;)&quot;))), x = &quot;Year of Birth&quot;) Figure 3.1: Probability We need the number born each year to be able to calculate the number alive in each year, and the age distribution. Suppose that the number born in each year was equal, the age distribution would be: age_distr %&gt;% group_by(sex) %&gt;% mutate(p = p_alive / sum(p_alive)) %&gt;% ggplot(aes(x = age, y = p, color = sex)) + geom_point() + geom_line() + labs(x = &quot;Age&quot;, y = &quot;P(age)&quot;) + theme(legend.pos = &quot;bottom&quot;) As a proxy for the number born each year we’ll use the proportion of Social Security applicants each year, provided by the babynames::applicants. Since the baby-name information will also come from the Social Security data this is no less restrictive. ggplot(babynames::applicants, aes(x = year, y = n_all / 1e6, color = sex)) + geom_point() + geom_line() + labs(x = &quot;&quot;, y = &quot;SSA Applicants (mn)&quot;) + theme(legend.pos = &quot;bottom&quot;) Clearly, the number of births is not constant per year. Join the SSA applicant numbers and calculate the probability of each age by sex in 2015. age_distr &lt;- left_join(age_distr, rename(babynames::applicants, n_apps = n_all), by = c(&quot;sex&quot;, &quot;birthyear&quot; = &quot;year&quot;)) %&gt;% mutate(n_alive = p_alive * n_apps) %&gt;% group_by(sex) %&gt;% mutate(p_age = n_alive / sum(n_alive)) %&gt;% ungroup() %&gt;% arrange(sex, age) After accounting for different numbers of births in each year, the age distribution is different. ggplot(age_distr, aes(x = age, y = p_age, color = sex)) + geom_point() + geom_line() + labs(x = &quot;Age&quot;, y = &quot;P(age)&quot;) + theme(legend.pos = &quot;bottom&quot;) The babynames dataset has the number in each sex born each year with a given name (and registered by the SSA). glimpse(babynames) #&gt; Observations: 1,858,689 #&gt; Variables: 5 #&gt; $ year &lt;dbl&gt; 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 188... #&gt; $ sex &lt;chr&gt; &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F... #&gt; $ name &lt;chr&gt; &quot;Mary&quot;, &quot;Anna&quot;, &quot;Emma&quot;, &quot;Elizabeth&quot;, &quot;Minnie&quot;, &quot;Margaret&quot;... #&gt; $ n &lt;int&gt; 7065, 2604, 2003, 1939, 1746, 1578, 1472, 1414, 1320, 128... #&gt; $ prop &lt;dbl&gt; 0.07238, 0.02668, 0.02052, 0.01987, 0.01789, 0.01617, 0.0... The column prop is the proportion of people of that gender with that name born in each year, \\(P(\\text{name} | \\text{age}, \\text{sex})\\). baby_names &lt;- babynames::babynames Also, since the SSA only releases names with &gt; 5 individuals in a year, add an additional entry for each year for babies born and given rare names. babynames_other &lt;- baby_names %&gt;% group_by(sex, year) %&gt;% summarise(p_named = sum(prop), n_named = sum(n)) %&gt;% mutate(prop = 1 - p_named, n = n_named / p_named * prop, name = &quot;OTHER&quot;) %&gt;% select(sex, year, prop, name, n, prop) %&gt;% ungroup() baby_names &lt;- bind_rows(baby_names, babynames_other) 3.3 Probability of age given name and sex Consider someone with the name of “Emma” and sex is “female”. What is the posterior distribution of their age, \\[ p(\\text{age} | \\text{name} = \\text{&quot;Emma&quot;}, \\text{sex} = \\text{&quot;F&quot;}) = p(\\text{name} = \\text{&quot;Emma&quot;} | \\text{age}, \\text{sex} = \\text{&quot;F&quot;}) p(\\text{age} | \\text{sex} = \\text{&quot;F&quot;}) . \\] name &lt;- &quot;Emma&quot; sex &lt;- &quot;F&quot; Filter babynames to only include observations for the name “Emma” and sex “Emma”: p_name_age &lt;- baby_names %&gt;% filter(name == !!name, sex == !!sex) %&gt;% select(-sex, -name) %&gt;% mutate(age = YEAR - year) ggplot(p_name_age, aes(x = year, y = prop)) + geom_line() + labs(x = &quot;&quot;, y = &quot;Proportion births&quot;) The popularity of the name Emma first declined, then increased. However, very few of those born when Emma was first popular are likely to still be alive. posterior &lt;- left_join(p_name_age, select(filter(age_distr, sex == !!sex), birthyear, prior = p_age), by = c(year = &quot;birthyear&quot;)) %&gt;% rename(likelihood = prop) %&gt;% # fill in missing values with 0 mutate(prior = if_else(is.na(prior), 0, prior), # postrior post = likelihood * prior, # normalize posterior to sum to 1 post = post / sum(post)) Let’s plot the prior (\\(P(age)\\)), likelihood (\\(P(name | age)\\)), and posterior (\\(P(name | age)\\)). posterior %&gt;% select(age, post, likelihood, prior) %&gt;% gather(variable, value, -age) %&gt;% mutate(variable = recode(variable, post = &quot;P(age | name)&quot;, likelihood = &quot;P(name | age)&quot;, prior = &quot;P(age)&quot;), variable = factor(variable, levels = c(&quot;P(age)&quot;, &quot;P(name | age)&quot;, &quot;P(age | name)&quot;))) %&gt;% ggplot(aes(y = value, x = age)) + geom_line() + facet_wrap(~ variable, ncol = 1, scales = &quot;free_y&quot;) Alternatively, instead of calculating \\(p(age | name, sex)\\) from Bayes’ Theorem, we can calculate it directly from the joint distribution of name, age, and sex. \\[ p(age | name, sex) = p(age, name, sex) / p(name, sex) \\] baby_names_joint &lt;- baby_names %&gt;% # add probability that the person is alive left_join(select(age_distr, age, sex, birthyear, p_alive), by = c(&quot;sex&quot;, year = &quot;birthyear&quot;)) %&gt;% # calculate number alive filter(year &gt;= 1900) %&gt;% mutate(n_alive = p_alive * n) %&gt;% # calculate p(sex, age, name) # number alive with sex, age, name / total estimated to be alive mutate(prop = n_alive / sum(n_alive)) Calculate \\(p(name, sex)\\) by summing the probabilities of all combinations of age and sex. p_name_sex &lt;- baby_names_joint %&gt;% group_by(name, sex) %&gt;% summarise(prop = sum(prop)) Calculate, \\[ p(\\text{age} | \\text{name}, \\text{sex}) = \\frac{p(\\text{age}, \\text{name}, \\text{sex})}{p(\\text{name}, \\text{sex})} \\] inner_join(baby_names_joint, select(p_name_sex, name, sex, p_name_sex = prop), by = c(&quot;name&quot;, &quot;sex&quot;)) %&gt;% mutate(p_age = prop / p_name_sex) #&gt; # A tibble: 1,806,656 x 10 #&gt; year sex name n prop age p_alive n_alive p_name_sex p_age #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1900 F Mary 16707 0 115 0 0 0.00782 0 #&gt; 2 1900 F Helen 6343 0 115 0 0 0.00115 0 #&gt; 3 1900 F Anna 6114 0 115 0 0 0.00165 0 #&gt; 4 1900 F Margaret 5304 0 115 0 0 0.00216 0 #&gt; 5 1900 F Ruth 4765 0 115 0 0 0.00108 0 #&gt; 6 1900 F Elizabeth 4096 0 115 0 0 0.00421 0 #&gt; # ... with 1.807e+06 more rows 3.3.1 Questions Which name provides the most information about a person’s age? Which provides the least? Consider a rare name - what is the probability in years in which there is no sample. How does that affect the analysis? What would you do about it? filter(baby_names, sex == &quot;M&quot;) %&gt;% count(name) %&gt;% filter(nn == 1) %&gt;% sample_n(1) #&gt; # A tibble: 1 x 2 #&gt; name nn #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Jvier 1 How would you calculate \\(p(age | name)\\) if you don’t know the sex of the individual? 3.3.2 References This example is derived from How to Tell Someone’s Age When All You Know Is Her Name. Inferring characteristics of individuals given their name are common. See these related packages: gender: An R package for predicting gender from a name using historical name data. genderizeR Another package for predicting gender from first names. wru: R package to predict race/ethnicity from surnames and geolocation information, based on this paper "],
["naive-bayes.html", "4 Naive Bayes Prerequisites 4.1 Introduction 4.2 Examples 4.3 Details 4.4 References", " 4 Naive Bayes Prerequisites This example will use the following libraries. library(&quot;tidyverse&quot;) 4.1 Introduction Bayes’ theorem can almost immediately be supervised classification algorithms. The Naive Bayes classifiers are a family of classifiers which apply Bayes’ Rule to classify a discrete response \\(y\\) using observed features \\((x_1, \\dots, x_K)\\), with a simplifying assumption of independence. Suppose that \\(y\\) is the class of an observation; i.e., it is a discrete variable taking values \\(j \\in 1, \\dots, J\\). Suppose that \\((x_1, \\dots, x_k)\\) is a vector of \\(K\\) observed features (predictors) for an observation. These can be discrete or continuous. We are interested in the probabilities of each class after having observed its features, which we can reformulate in Bayes’ rule. \\[ p(y | x_1, \\dots, x_k) = \\frac{p(x_1, \\dots, x_k | y) p(y)}{\\sum_{j = 1}^{J} p(x_1, \\dots, x_k | y = j) p(y = j)} \\] The “naive” modifier in “naive Bayes” comes from an additional assumption that distributions of features are independent conditional on the class, \\[ p(x_k | y, x_1, \\dots, x_K) = p(x_k | y) \\] for all \\(k \\in 1, \\dots, K\\). This means that we can write \\[ p(x | y) = p(x_1 | y) p(x_2 | y) \\cdots p(x_K | y) \\] This independence is a strong one, but will make this problem much more tractable. It is much easier to model and estimate the univariate \\(p(x_k | y)\\) probabilities, but much harder to model and estimate a \\(K\\)-variate distribution, \\(p(x_1, \\dots, x_K | y)\\) Using independence, we can rewrite the posterior distribution as, \\[ \\begin{aligned}[t] p(y | x_1, \\dots, x_k) &amp;= \\frac{p(y) p(x_1 | y) \\cdots p(x_K | y)}{\\sum_{j = 1}^{J} p(y) p(x_1 | y) \\cdots p(x_K | y)} \\\\ &amp;= \\frac{p(y) \\prod_{k = 1}^K p(x_k | y)}{\\sum_{j = 1}^{J} p(y) \\prod_{k = 1}^K p(x_k | y)} \\\\ &amp;\\propto p(y) \\prod_{k = 1}^K p(x_k | y) \\end{aligned} \\] To apply Naive Bayes to predict the class of data: Choose the distributional form of \\(p(y)\\) and the \\(k\\) distributions \\(p(x_k | y)\\) Find the maximum a posteriori (MAP) estimates of \\(\\hat{p}(y)\\) and \\(\\hat{p}(x_k | y)\\) for all \\(k \\in 1, \\dots, K\\) using training data. Predict the most likely class for new data with features \\(x_1, \\dots, x_K\\), \\[ \\hat{y} = \\arg \\max_y \\hat{p}(y) \\prod_{k = 1}^K \\hat{p}(x_k | y) \\] 4.2 Examples 4.2.1 Federalist Papers The Federalist Papers comprise 85 articles published under the pseudonym “Publius” in New York newspapers between 1787 and 1788. It was written by Alexander Hamilton, James Madison, and John Jay to persuade the public to ratify the Constitution. John Jay wrote five papers, and Alexander Hamilton wrote 51, and James Madison 14. The authorship of the remaining 15 papers is (was) disputed between Hamilton and Madison. In an early example of empirical Bayesian statistics and computational NLP, F. Mosteller and D. L. Wallace used naive Bayes to classify the disputed articles and conclude that there is strong evidence to suggest that Madison wrote all the disputed articles. Data on the federalist papers is contained in two datasets included in the jrnold.bayes.notes package. The dataset federalist$docs contains metadata on each document, including the author and title. The dataset federalist$wordcounts contains word counts of 70 function words used by Mosteller and Wallace in their analysis, and the count of all other tokens (\"OTHER\"). data(&quot;federalist&quot;, package = &quot;jrnold.bayes.notes&quot;) The objective is to estimate the author of a document given features of that document. For this example, we will only use the counts of the 70 function words (and other) provided in the data. For a single document, let \\(y\\) be the author of the document. Let \\(w\\) be the total number of words in the document. Let \\(x_1, \\dots, x_K \\geq 0, \\sum x_k = w\\) be the counts of each word in our vocabulary. These word counts are our features. We need to choose distributional forms of \\(p(x_1, \\dots, x_K | y)\\) and \\(p(y)\\). Since \\(y\\) is a discrete unordered categorical variable, we will use a categorical distribution, \\[ p(y | \\pi) = \\mathrm{Categorical}(\\pi) . \\] There are \\(\\pi_j\\) for \\(j \\in 1, \\dots, J\\) parameters, which represent the probability of category \\(j\\), where \\(\\pi_j | 0\\), and \\(\\sum \\pi = 1\\). For the distribution \\(p(x_1, \\dots, x_K | y)\\), we will use the multinomial distribution, \\[ p(x | y = j, \\theta) = \\mathrm{Multinomial}(x | \\theta^{(j)}) . \\] The parameter \\(\\theta^{(j)}\\) is length \\(K\\) vector, such that \\(\\sum_{k = 1}^K \\theta_k^{(j)} = 1\\). The superscript \\((j)\\) indicates that \\(\\theta^{(j)}\\) is specific to a particular class. Thus there are \\(\\text{classes} \\times \\text{features} = J \\times K\\) parameters to estimate for this model. \\[ p(y | x_1, \\dots, x_K) \\propto \\mathrm{Multinomial}(x | \\theta, y) \\mathrm{Categorical}(y | \\pi) . \\] This model is called a multinomial Naive Bayes model. To use a multinomial model to classify new observations we need to estimate \\(\\theta\\) (\\(J \\times K\\) parameters) and \\(\\pi\\) (\\(J\\) parameters). For these, we will use the maximum a posteriori estimator. The MAP estimator for the prior probability of class \\(y\\) is \\[ \\hat{\\pi}_j = \\frac{ \\sum_i I(y_i = j) + 1}{n + J} . \\] This is the number of documents in class \\(j\\) divided by the total number of documents in the training data. Calculate the proportion of documents written by Hamilton and Madison: p_author &lt;- federalist$docs %&gt;% filter(author %in% c(&quot;Hamilton&quot;, &quot;Madison&quot;)) %&gt;% count(author) %&gt;% mutate(pi = (n + 1) / sum(n + 1)) p_author #&gt; # A tibble: 2 x 3 #&gt; author n pi #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Hamilton 51 0.776 #&gt; 2 Madison 14 0.224 The MAP estimator for the conditional probability of \\(p(x | y)\\) is \\[ \\hat{\\theta}_k^{(j)} = \\frac{(\\sum_i I(y_i = j) \\cdot x_k) + 1}{(\\sum_i I(y_i = u)\\cdot w) + K} . \\] The estimator \\(\\hat{\\theta}_{k}^{(j)}\\) is the fraction of times that word \\(k\\) appears among all words in all documents in category \\(j\\). p_words_author &lt;- federalist$wordcounts %&gt;% # keep only Hamilton and Madison filter(author %in% c(&quot;Hamilton&quot;, &quot;Madison&quot;)) %&gt;% # count terms used by each author group_by(author, term) %&gt;% summarise(count = sum(count)) %&gt;% ungroup() %&gt;% # calculate p(w | c) for each author group_by(author) %&gt;% mutate(theta = (count + 1) / sum(count + 1)) %&gt;% ungroup() head(p_words_author) #&gt; # A tibble: 6 x 4 #&gt; author term count theta #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Hamilton a 2496 0.0199 #&gt; 2 Hamilton all 436 0.00347 #&gt; 3 Hamilton also 35 0.000286 #&gt; 4 Hamilton an 636 0.00507 #&gt; 5 Hamilton and 2702 0.0215 #&gt; 6 Hamilton any 365 0.00291 Note that in our MAP estimators of both \\(\\theta\\) and \\(\\pi\\), we add one to the observed counts in order to keep the probabilities strictly greater than 0. These can be justified using as conjugate prior distributions for the categorical and multinomial distributions. Now that we’ve estimated \\(\\hat{p}(y | x)\\) and \\(\\hat{p}(y)\\) we can predict the classes for both the papers where the author was observed, and those that it wasn’t observed. Calculate the probability of each class, \\(p(y_{test} | x_{test}, \\hat{\\theta})\\), for all documents given the learned parameters \\(\\theta\\). pred_doc_author &lt;- federalist$wordcounts %&gt;% # keep only Hamilton, Madison, and undetermined filter(!author %in% &quot;Jay&quot;) %&gt;% # remove actual author select(-author) %&gt;% # merge with p(y | x, theta) probabilities # note - this works because words includes 0 counts left_join(select(p_words_author, term, author, theta), by = &quot;term&quot;) %&gt;% # calculate the total probability of the document group_by(number, author) %&gt;% # note: + 1 only used in the estimation # log probabilties are used because probabilityes are small summarise(logp_doc_author = dmultinom(count, prob = theta, log = TRUE)) Calculate the posterior distribution by adding the prior probabilities of each author: p_author_doc &lt;- left_join(pred_doc_author, select(p_author, author, pi), by = &quot;author&quot;) %&gt;% # do calculations on the log scale mutate(logp_author = log(pi), logp_author_doc = logp_doc_author + logp_author) %&gt;% select(-pi) %&gt;% # calculate p_author_doc group_by(number) %&gt;% mutate(p_author_doc = exp(logp_author_doc - log(sum(exp(logp_author_doc))))) Dataset with the probability that the document was written by Hamilton. predictions &lt;- p_author_doc %&gt;% filter(author == &quot;Hamilton&quot;) %&gt;% select(number, p_author_doc) %&gt;% mutate(pred = if_else(p_author_doc &gt; 0.5, &quot;Hamilton&quot;, &quot;Madison&quot;)) %&gt;% # add actual authors left_join(select(federalist$docs, author, number), by = &quot;number&quot;) %&gt;% # for those with authors, is it correct mutate(correct = (author == pred)) %&gt;% # no missing values in author mutate(author = if_else(is.na(author), &quot;Unknown&quot;, author)) For documents with known authors, the Naive Bayes method predicts the actual author in all cases. filter(predictions, author != &quot;Unknown&quot;) %&gt;% group_by(author) %&gt;% summarise(accuracy = mean(correct)) #&gt; # A tibble: 2 x 2 #&gt; author accuracy #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Hamilton 1 #&gt; 2 Madison 1 For the documents with an unknown author, it predicts most of them to have been written by Madison. filter(predictions, author == &quot;Unknown&quot;) %&gt;% ungroup() %&gt;% count(pred) #&gt; # A tibble: 2 x 2 #&gt; pred n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Hamilton 1 #&gt; 2 Madison 14 ggplot(predictions, aes(x = number, colour = author, y = p_author_doc)) + geom_point() + labs(y = expression(paste(&quot;P&quot;, group(&quot;(&quot;, paste(&quot;Hamilton&quot;, &quot;|&quot;, &quot;.&quot;), &quot;)&quot;))), x = &quot;Federalist Number.&quot;, title = &quot;Predicted Author of Federalist Papers&quot;) + theme(legend.position = &quot;bottom&quot;) 4.2.2 Extensions Evaluate the effectiveness of this model using \\(\\hat{p}(y)\\) that gives equal weight to each author? Do any predictions change? Instead of a multinomial model for \\(p(x | y)\\) use independent Poisson distributions for each \\(p(x_k | y, \\lambda)\\). For an MAP estimator of the rate parameter of the Poisson distribution use the following: \\[ \\hat{\\lambda}^{(j)}_k = \\frac{\\sum_i I(y_i = j) x_k + 1}{\\sum_i I(y_i = j) w_i + K} \\] So, \\[ p(x_k | y) = \\mathrm{Poisson}(\\lambda_k) + \\mathrm{Poisson}(w) . \\] Instead of a multinomial model for \\(p(x | y)\\) use independent binomial distributions for each \\(p(x_k | y, \\lambda)\\), \\[ p(x_1, \\dots, x_k| y) = \\prod_{k = 1}^K \\textrm{Binomial}(x_k | w, \\theta_k) \\] Take the word count of each document as given. A MAP estimator of the frequency parameter of the Binomial distribution is \\[ \\hat{\\theta}^{(j)}_k = \\frac{\\sum_i I(y_i = j) x_k + 1}{\\sum_i I(y_i = j) w_i + K} \\] Instead of a multinomial model for \\(p(x | y)\\) use independent Poisson distributions for each \\(p(x_k | y)\\), \\[ p(x_k | w, \\theta) = \\mathrm{Poisson}(w * \\lambda^{-1}) \\] The parameter \\(\\theta\\) is the rate at which the word \\(k\\) is used in text. A MAP estimator for \\(\\theta_k^{(j)}\\) is, \\[ \\hat{\\theta}^{(j)}_k = \\frac{\\sum_i I(y_i = j) x_k + 1}{\\sum_i I(y_i = j) w_i + K} \\] This is the same equation as the Binomial distribution MAP estimator for \\(\\theta\\), and have the same interpretation (frequency of appearance of a term). However, the likelihoods are slightly different. Use cross-validation to evaluate the Naive Bayes models that use multinomial, Poisson, and binomial likelihoods using cross-validation. There are several reasonable ways to proceed with cross validation. Choose a reasonable one associated with the prediction task. Classify the documents in the [spam](https://www.rdocumentation.org/packages/kernlab/versions/0.9-25/topics/spam) dataset included in the kernlab R package into “spam” and “not spam” using a Naive Bayes model. Choose the appropriate distributions for the likelihoods of the features. Estimate this model “manually”, without using an existing implementation of Naive Bayes. 4.3 Details 4.3.1 Generative vs. Discriminative Models Naive Bayes is a generative model. Generative models are distinguished from discriminative models. A generative model estimates the join-distribution \\(p(x, y)\\), and is so-called because it generate new data for both \\(x\\) and \\(y\\). A discriminative model only estimates the conditional distribution \\(p(y | x)\\); it cannot generate new \\(x\\) values, but can only predict \\(y\\) given \\(x\\). Naive Bayes is a generative model. The distributions of \\(p(x | y)\\) and \\(p(y)\\) are specified, and \\[ p(x, y) = p(x | y) p(y) . \\] Regression models only estimate \\(p(y | x)\\) are discriminative models. If we estimate the parameters of a regression model, we can cannot estimate the distribution of new \\(x\\). Note that a discriminative model can be used to estimate the conditional distribution \\(p(y | x)\\) since \\[ \\begin{aligned} p(y | x) = \\frac{p(x, y)}{p(x)} = \\frac{p(x | y) p(y)}{p(x)} . \\end{aligned} \\] 4.3.2 Estimation With Naive Bayes we want to classify observations (\\(\\tilde{y}\\)) given the features (\\(\\tilde{x}\\)) of those new observations, and training data (\\(y\\), \\(x\\)). Naive Bayes models define \\(p(x | y)\\) and \\(p(y)\\). Let \\(p(x | y, \\theta)\\) be the conditional distribution of a feature given the class \\(y\\). Let \\(p(y | \\pi)\\) is the prior distribution of the classes \\(y\\). By the definition of conditional distributions, \\[ p(x, y | \\theta, \\pi) = p(x | y, \\theta) p(y | \\pi) . \\] Note: we also make the assumption that \\(\\theta\\) and \\(\\pi\\) are independent. The posterior distribution of \\(\\theta\\), \\(\\pi\\) is \\[ \\begin{aligned}[t] p(\\theta, \\pi | y, x) &amp;= \\frac{p(y, x | \\theta, \\pi) p(\\theta, \\pi)}{p(y, x)} &amp; \\text{Bayes&#39; Theorem} \\\\ &amp;= \\frac{p(x | y, \\theta) p(y | \\pi) p(\\theta) p(\\pi)}{p(y, x)} &amp; \\text{conditional distribution}\\\\ &amp;\\propto p(x | y, \\theta) p(y | \\pi) p(\\theta) p(\\pi) \\end{aligned} \\] The maximum a posteriori (MAP) estimator of \\((\\theta, \\pi)\\) is \\[ \\begin{aligned}[t] \\hat{\\theta}, \\hat{\\pi} = \\arg \\max_{\\theta, \\pi} p( y | x, \\theta, \\pi) &amp;= \\arg \\max_{\\theta, \\pi} p( x | y, \\theta) p(y | \\pi ) p(\\theta) p(\\pi) \\end{aligned} \\] Since \\(\\theta\\) and \\(\\pi\\) are conditionally independent, we can maximize the parameters separately, \\[ \\begin{aligned}[t] \\hat{\\theta} &amp;= \\arg \\max_{\\theta} p( x | y, \\theta) p(\\theta) \\\\ \\hat{\\pi} &amp;= \\arg \\max_{\\pi} p(y | \\pi ) p(\\pi) \\\\ \\end{aligned} \\] For many distributions, the MAP estimators of their parameters has a closed form, and thus easy to estimate. That we factor \\(p(x | y, \\theta)\\) into conditionally independent distributions \\(p(x_1 | y, \\theta_1)\\), \\(p(x_2 | y, \\theta_2)\\), …, allows us to choose these distributions to allow for particularly easy MAP estimators. 4.3.3 Prediction Suppose that we would like to classify new observations \\(\\tilde{y}\\) after observing features of those observations, \\(\\tilde{x}\\). We would use the same likelihood function as we estimation, \\[ \\begin{aligned}[t] p(\\tilde{y} | \\tilde{x}, \\theta, \\pi) &amp;= \\frac{p(\\tilde{x} | \\tilde{y}, \\theta) p(\\tilde{y} | \\pi) }{p(\\tilde{x} | \\theta, \\pi)} \\\\ &amp;\\propto p(\\tilde{x} | \\tilde{y}, \\theta) p(\\tilde{y} | \\pi) \\end{aligned} \\] However, the values of \\(\\theta\\) and \\(\\pi\\) are unknown. Generally, in Bayesian inference we would calculate the posterior predictive distribution by using the posterior distribution of \\(p(\\theta, \\pi | x, y)\\). \\[ \\begin{aligned}[t] p(\\tilde{y} | \\tilde{x}, x, y) &amp;= \\int_{\\pi}\\int_{\\theta} p(\\tilde{y} | \\tilde{x}, \\theta, \\pi) p(\\theta, \\pi | y, x)\\, d\\theta \\,d\\pi \\\\ &amp;= \\int_{\\pi}\\int_{\\theta} \\frac{p(\\tilde{x} | \\tilde{y}, \\theta) p(\\tilde{y} | \\pi)}{p(\\tilde{x} | \\pi)} p(\\theta, \\pi | y, x)\\, d\\theta \\,d\\pi &amp; \\text{Bayes&#39; Theorem} \\\\ &amp;= \\int_{\\pi}\\int_{\\theta} \\frac{p(\\tilde{x} | \\tilde{y}, \\theta) p(\\tilde{y} | \\pi)}{p(\\tilde{x} | \\theta, \\pi)} p(\\theta, \\pi | y, x)\\, d\\theta \\,d\\pi \\end{aligned} \\] However, in this case we will ignore the uncertainty inherent in estimating \\(\\theta\\) and \\(\\pi\\), and simply plug in the MAP estimators, \\[ \\begin{aligned}[t] p(\\tilde{y} | \\tilde{x}, x, y) &amp;= p(\\tilde{y} | \\tilde{x}, \\hat{\\theta}, \\hat{\\pi}) \\\\ &amp;=\\frac{p(\\tilde{x} | \\tilde{y}, \\hat{\\theta}) p(\\tilde{y} | \\hat{\\pi})}{p(\\tilde{x} | \\hat{\\pi}, \\hat{\\theta})} \\\\ &amp;\\propto p(\\tilde{x} | \\tilde{y}, \\hat{\\theta}) p(\\tilde{y} | \\hat{\\pi}) \\end{aligned} \\] Commonly we would like to estimate the most likely class. The most likely class of an observation given its features, \\(\\tilde{x}\\), and training data \\(x\\) and \\(y\\) is, \\[ \\hat{y} = \\arg \\max_{\\tilde{y}} p(\\tilde{y} | \\tilde{x}, x, y) = \\arg \\max_{\\tilde{y}} p(\\tilde{x} | \\tilde{y}, \\hat{\\theta}) p(\\tilde{y} | \\hat{\\pi}). \\] 4.4 References Scikit-Learn, Naive Bayes Harry Zhang (2004) The Optimality of Naive Bayes. Jurafsky slides on Text Classification and Naive Bayes R package klaR contains an implementation of naive Bayes. "],
["priors.html", "5 Priors 5.1 Levels of Priors 5.2 Conjugate Priors 5.3 Improper Priors 5.4 Cromwell’s Rule 5.5 Asymptotics 5.6 Proper and Improper Priors 5.7 Hyperpriors and Hyperparameters 5.8 References", " 5 Priors Yeah, well, you know, that’s just, like, your opinion, man. — The Dude (The Big Lebowski) 5.1 Levels of Priors The levels of Flat prior Vague but proper prior, e.g. \\(\\dnorm(. | 0, 1e6)\\) Weakly informative prior, but very weak \\(\\dnorm(0, 10)\\) Generic weakly informative prior: \\(\\dnorm(0, 1)\\) Specific informative prior 5.2 Conjugate Priors In a few cases, the posterior distribution, \\[ p(\\theta | y) = \\frac{p(y | \\theta) p(\\theta)}{\\int p(y | \\theta&#39;) p(\\theta&#39;) d\\theta&#39;}, \\] has a closed-form solution and can be calculated exactly. In those cases, the posterior distribution is calculated exactly, and more costly numerical approximation methods do not need to be used. Unfortunately, these cases are few. Most of those cases involve conjugate priors. In the case of a conjugate prior, the posterior distribution is in the same family as the prior distribution. Here is a diagram of a few common conjugate priors.4 The table in the Wikipedia page for Conjugate priors is as complete as any out there. Fink (1997) for a compendium of references. Also see Distributions for more information about probability distributions. 5.2.1 Binomial-Beta Binomial distribution: If \\(N \\in \\Nats\\) (number of trials), \\(\\theta \\in (0, 1)\\) (success probability in each trial), then for \\(n \\in \\{0, \\dots, N\\}\\), \\[ \\dBinom(n | N, \\theta) = \\binom{N}{n} \\theta^{n} (1 - \\theta)^{N - n} . \\] Beta distribution: If \\(\\alpha \\in \\RealPos\\) (shape) and \\(\\beta \\in \\RealPos\\) (shape), then for \\(\\theta \\in (0, 1)\\), \\[ \\dbeta(\\theta | \\alpha, \\beta) = \\frac{1}{\\mathrm{B}(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\] where \\(\\mathrm{B}\\) is the beta function, \\[ \\mathrm{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)} . \\] Then, \\[ \\begin{aligned}[t] p(\\theta | \\alpha, \\beta) &amp;= \\dbeta(\\theta | \\alpha, \\beta) &amp;&amp; \\text{Beta prior} \\\\ p(y | \\theta) &amp;= \\dBinom(y | n, \\theta) &amp;&amp; \\text{Binomial likelihood} \\\\ p(\\theta | y, \\alpha, \\beta) &amp;= \\dbeta(\\theta | \\alpha + y, \\beta + n - y) &amp;&amp; \\text{Beta posterior} \\end{aligned} \\] 5.2.2 Categorical-Dirichlet The Dirichlet distribution is a multivariate generalization of the Beta, If \\(K \\in \\N\\) and \\(\\alpha \\in (\\R^{+})^{K}\\), then for the \\(\\theta \\in K-\\text{simplex}\\) and \\(\\theta_k &gt; 0\\) for all \\(k\\), \\[ \\ddirichlet(\\theta | \\alpha) = \\frac{\\Gamma(\\sum_{k = 1}^K \\alpha_k)}{\\prod_{k = 1}^K \\Gamma(\\alpha_k)} \\prod_{k = 1}^K \\theta_{k}^{\\alpha_k - 1} \\] The multinomial distribution is a generalization of the binomial distribution with \\(K\\) categories instead of 2. If \\(K \\in \\n\\), \\(N \\in \\N\\), and \\(\\theta \\in K-\\text{simplex}\\), then for \\(y \\in \\N^{K}\\) such that \\(\\sum_{k = 1}^K y_k = N\\), \\[ \\dmultinom(y | \\theta) = \\binom{N}{y_1, \\dots, y_K} \\prod_{k = 1}^{K} \\theta_k^{y_k}, \\] where the multinomial coefficient is defined as, \\[ \\binom{N}{y_1, \\dots, y_K} = \\frac{N!}{\\prod_{k = 1}^K y_k!} \\] \\[ \\begin{aligned}[t] p(\\theta | \\alpha) &amp;= \\ddirichlet(\\theta | \\alpha) &amp;&amp; \\text{Dirichlet prior} \\\\ p(y | \\theta) &amp;= \\dmultinom(y | n, \\theta) &amp;&amp; \\text{Multinomial likelihood} \\\\ p(\\theta | y, \\alpha) &amp;= \\ddirichlet(\\theta | \\alpha + y) &amp;&amp; \\text{Dirichlet posterior} \\end{aligned} \\] 5.2.3 Poisson-Gamma Let \\(\\lambda\\) be the rate parameter of the Poisson distribution. If \\(\\lambda \\in \\R^+\\) (rate parameter), then for \\(n \\in \\N\\), \\[ \\dpois(n|\\lambda) = \\frac{1}{n!} \\lambda^n \\exp(-\\lambda) \\] If \\(\\alpha \\in \\R^{+}\\) (shape parameter), \\(\\beta \\in \\R^{+}\\) (inverse scale parameter), then for \\(y \\in \\R^{+}\\), \\[ \\dgamma(y | \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} y^{\\alpha - 1} \\exp(- \\beta y) \\] Then, \\[ \\begin{aligned}[t] p(\\lambda) &amp;= \\dgamma(\\lambda | \\alpha, \\beta) \\\\ p(n | \\lambda) &amp;= \\dpois(n | \\lambda) \\\\ p(\\lambda | n, \\alpha, \\beta) &amp;= \\dgamma(\\lambda | \\alpha + n, \\beta + 1) \\end{aligned} \\] 5.2.4 Normal with known variance \\[ \\begin{aligned}[t] p(\\mu | \\mu_0, \\sigma_0) &amp;= \\dnorm(\\mu | \\mu, \\sigma_0^2) &amp;&amp; \\text{Normal prior} \\\\ p(y | \\mu) &amp;= \\dnorm(y | \\mu, \\sigma^2) &amp;&amp; \\text{Normal likelihood} \\\\ p(\\mu | y, \\mu, \\sigma^2, \\mu_0, \\sigma_0^2) &amp;= \\dbeta(\\mu | \\tilde{\\mu}, \\tilde{\\sigma}^2) &amp;&amp; \\text{Normal posterior} \\\\ \\tilde{\\mu} &amp;= \\tilde{\\sigma}^{2} \\left(\\frac{\\mu_0}{\\sigma_0^2} + \\frac{y}{\\sigma^2} \\right) \\\\ \\tilde{\\sigma}^2 &amp;= \\left(\\frac{1}{\\sigma_0^2} +\\frac{1}{\\sigma^2}\\right)^{-1} \\\\ \\end{aligned} \\] 5.2.5 Exponential Family Likelihood functions in the exponential family have conjugate priors, often also in the exponential family.5 5.3 Improper Priors If prior distributions are given an improper uniform prior, \\(p(\\theta) \\propto 1\\), then the posterior distribution is proportional to the likelihood, \\[ p(\\theta | y) \\propto p(y | \\theta) p(\\theta) \\propto p(y | \\theta) \\] 5.4 Cromwell’s Rule The use of priors should placing a probability of 0 or 1 on events be avoided except where those events are excluded by logical impossibility. If a prior places probabilities of 0 or 1 on an event, then no amount of data can update that prior. The name, Cromwell’s Rule, comes from a quote of Oliver Cromwell, I beseech you, in the bowels of Christ, think it possible that you may be mistaken. Lindley (1991) describes it as Leave a little probability for the moon being made of green cheese; it can be as small as 1 in a million, but have it there since otherwise an army of astronauts returning with samples of the said cheese will leave you unmoved. If \\(p(\\theta = x) = 0\\), then for a value of \\(x\\), then the posterior distribution is always zero. \\[ p(\\theta = x | y) \\propto p(y | \\theta = x) p(\\theta = x) = 0 \\] 5.5 Asymptotics As the sample size increases, the Bayesian distribution converges to a normal distribution centered on the true value of the parameter. Suppose data \\(y_1, \\dots, y_n \\sim\\) are an iid sample from the distribution \\(f(y)\\). Suppose that the data are modeled with a parametric family \\(p(y | \\theta)\\) and a prior distribution \\(p(\\theta)\\). If the data distribution is included in the parametric family, meaning that there exists a \\(\\theta_0\\) such that \\(p(y | \\theta_0) = f(y)\\), then the posterior distribution is consistent in that it converges to the true parameter value \\(\\theta_0\\) as \\(n \\to \\infty\\). Otherwise, the posterior convergences to the distribution \\(p(y | \\theta)\\) closes to the true distribution. As \\(n \\to infty\\), the likelihood dominates the posterior distribution. There are cases in which the normal approximation is incorrect. parameters are non-identified the number of parameters increases with sample size aliasing or non-identified parameters due to label switching unbounded likelihoods. This can happen if variance parameters go to zero. improper posterior distributions prior distributions that exclude the point of convergence. See Cromwell’s Rule. convergence to the edge of the parameter space tails of the distribution can be inaccurate even if the normal approximation converges to the correct value; e.g. the normal approximation will still place a non-zero density on negative values of a non-negative parameter. 5.6 Proper and Improper Priors A prior distribution \\(p(\\theta)\\) is an improper when it is not a probability distribution, meaning \\[ \\int p(\\theta) \\,d\\theta = \\infty . \\] Perhaps the most common improper distribution is an unbounded uniform distribution, \\[ p(\\theta) \\propto 1 \\] for \\(-\\infty &lt; \\theta &lt; \\infty\\). Improper priors can be used, because in some cases, the posterior distribution can still be proper even if the prior is not. Prior Posterior Improper ? Proper Proper One common case of this is a linear regression model with improper priors. \\[ p(\\beta, \\sigma | y, X) = \\begin{cases} y &amp;\\sim \\dnorm(X \\beta, \\sigma^{2} I) \\end{cases} \\] If the number of observations (rows of \\(X\\)) is less than the number of independent columns in \\(X\\) (variables plus the constant), then the MLE of \\(\\beta\\) is undefined, and also the posterior distribution is improper. But if alter that model to include a proper prior, \\[ p(\\beta, \\sigma | y, X) = \\begin{cases} y &amp;\\sim \\dnorm(X \\beta, \\sigma^{2} I) \\\\ \\beta &amp; \\sim \\dnorm(\\mu_\\beta, \\Sigma_\\beta) \\\\ \\gamma &amp;\\sim p(\\gamma) \\end{cases} \\] then we can estimate \\(p(\\beta, \\sigma | y, X)\\) even if the number of observations is less than the number of variables. Consider the case if we observe no data; then the posterior distribution is equal to the prior, and since the prior is a proper distribution, so is the posterior. However, because a proper posterior allows for estimating a posterior, does imply that the posterior distribution is any “good”. But that is the role of the evaluation step in Bayesian analysis. In the cases where an improper prior would lead to an improper posterior, the choice of the prior is important because the prior will dominate the shape of the posterior distribution. One way of thinking about many “identification” assumptions in MLE models is that they can loosely be considered “priors”. What is called the likelihood and what is called the the prior is not well-defined, and often the choice of of likelihood functions is both subjective and the most important part of the analysis. Regarding improper priors, also see the asymptotic results that the posterior distribution increasingly depends on the likelihood as sample size increases. Stan: If no prior distributions is specified for a parameter, it is given an improper prior distribution on \\((-\\infty, +\\infty)\\) after transforming the parameter to its constrained scale. 5.7 Hyperpriors and Hyperparameters A hyperparameter is a parameter in a prior. A hyperprior is a term for a prior on Consider the case of a binomial likelihood with a beta prior on the proportion parameter \\(\\theta\\). The observed value of \\(n\\) and the \\(N\\) \\[ \\begin{aligned}[t] p(n | \\theta) &amp;\\sim \\dBinom(N, \\theta) &amp;&amp; \\text{likelihood for } n \\\\ p(\\theta) &amp;\\sim \\dbeta(a, b) &amp;&amp; \\text{prior on } \\theta \\\\ \\end{aligned} \\] This is a model of the posterior distribution of \\(\\theta\\) given the data, where the data consists of the \\(n\\) successes, the total number of trails \\(N\\), and \\(a\\) and \\(b\\), the assumed shape parameters of the beta prior on \\(\\theta\\). Thus our posterior distribution is, \\[ p(\\theta | n, N, a, b) . \\] However, suppose we decided that since we did not have a good reason to choose any particular values of \\(a\\) and \\(b\\) for the prior distribution, we would treat the shape parameters of the beta distribution as parameters and assign them their own prior distributions, \\[ \\begin{aligned}[t] p(n | \\theta) &amp;\\sim \\dBinom(N, \\theta) &amp;&amp; \\text{likelihood for } n \\\\ p(\\theta) &amp;\\sim \\dbeta(\\alpha, \\beta) &amp;&amp; \\text{prior on } \\theta \\\\ p(\\alpha) &amp;\\sim \\dexp(a^*) &amp;&amp; \\text{hyperprior} \\\\ p(\\beta) &amp;\\sim \\dexp(b^*) &amp;&amp; \\text{hyperprior} \\end{aligned} \\] Now the parameters of the model are \\(\\theta\\), \\(\\alpha\\), and \\(\\beta\\), and the data are \\(n\\), \\(N\\), \\(a^{*}\\), and \\(b^{*}\\). Since one parameter in the model (\\(\\theta\\)) is a function of other parameters, \\(\\alpha\\) and \\(\\beta\\), we call \\(\\alpha\\) and \\(\\beta\\) hyperparameters. 5.8 References Stan Wiki and the rstanarm vignette includes comprehensive advice for prior choice recommendations. Betancourt (2017) provides numerical simulation of how the shapes of weakly informative priors affects inferences. Stan Development Team (2016) for discussion of some types of priors in regression models Chung et al. (2013) discuss scale priors in penalized MLE models Gelman et al. (2008) discusses using Cauchy(0, 2.5) for prior distributions Gelman (2006) provides a prior distribution on variance parameters in hierarchical models. Polson and Scott (2012) on using Half-Cauchy priors for scale parameters Based on John Cook’s a Diagram of Conjugate Prior distributions.↩ https://en.wikipedia.org/wiki/Exponential_family#Bayesian_estimation:_conjugate_distributions↩ "],
["estimation-1.html", "6 Estimation 6.1 Point Estimates 6.2 Credible Intervals 6.3 Bayesian Decision Theory", " 6 Estimation 6.1 Point Estimates Bayesian point estimators use the following recipe: define a loss function that penalizes guesses take the expected value of that loss function over the parameter of interest Let \\(\\theta\\) be a parameter with a prior distribution \\(\\pi\\). Let \\(L(\\theta, \\hat{\\theta})\\) be a loss function. Examples of loss-functions include squared error: \\((\\theta - \\hat{\\theta})^2\\) absolute error: \\(|\\theta - \\hat{\\theta}|\\) Let \\(\\hat{\\theta}(x)\\) be an estimator. The Bayes risk of \\(\\hat{\\theta}\\) is the expected value of the loss function over the probability distribution of \\(\\theta\\). \\[ \\E_{\\pi}(L(\\theta, \\hat{\\theta})) = \\int L(\\theta, \\hat{\\theta}) \\pi(\\theta) d\\,\\theta \\] An estimator is a Bayes estimator if it minimizes the the Bayes risk over all estimators. Estimator Loss Function Mean \\((\\theta - \\hat{\\theta})^2\\) Median \\(|\\theta - \\hat{\\theta}|\\) \\(p\\)-Quantile \\(\\begin{cases} p | \\theta - \\hat{\\theta} | &amp; \\text{for } \\theta - \\hat{\\theta} \\geq 0 \\\\ (1 - p) |\\theta - \\hat{\\theta} | &amp; \\text{for } \\theta - \\hat{\\theta} &lt; 0 \\end{cases}\\) Mode \\(\\begin{cases} 0 &amp; \\text{for } | \\theta = \\hat{\\theta} | &lt; \\epsilon \\\\ 1 | &amp; \\text{for } |\\theta - \\hat{\\theta}| &gt; \\epsilon \\end{cases}\\) \\end{cases}$ The posterior mode can often be directly estimated by maximizing the posterior distribution, \\[ \\hat{\\theta}_{\\text{mode}} = \\arg \\max_{\\theta} \\int \\theta(\\theta | y) . \\] This is called maximum a posteriori (MAP) estimation. Given a estimation could be used by including that loss function into that function, \\[ \\hat\\theta = \\arg \\min_{\\theta^*} \\int L(theta, \\theta^*) p(\\theta) \\,d\\theta . \\] However, since that still requires integrating over the distribution of \\(\\theta\\). In cases where the form of \\(p(\\theta)\\) is known, this may have a closed form. In the cases of most posterior distributions, this would require some sort of approximation of the distribution of \\(p(\\theta)\\). \\[ p(\\theta | ) \\] 6.2 Credible Intervals A \\(p \\times 100\\) credible interval of a parameter \\(\\theta\\) with distribution \\(f(\\theta)\\) is an interval \\((a, b)\\) such that, \\[ CI(\\theta | p) = (a, b) s.t. \\int_{a}^{b} f(\\theta) \\,d\\theta = p. \\] The credible interval is not uniquely defined. There may be multiple intervals that satisfy the definition of a credible interval. The most common are the equal-tailed interval: \\((F^{-1}(p / 2), F^{-1}((1 - p) / 2))\\) where \\(F^{-1}\\) is the quantile function of \\(\\theta\\). The 95% credible interval would use the 2.5% and 97.5% quantiles. highest posterior density interval: The shortest credible interval. If the distribution is not unimodal and symmetric, the HPD interval is not the same as the equal-tailed interval. Generally it is fine to use the equal-tailed interval. This is what Stan reports by default. The HPD is harder to calculate. may not be a convex interval if it is a multimodal distribution. (Though that may be a desirable feature.) unlike the central interval, not invariant under transformation. For some function \\(g\\), if \\(CI_{HPD}(\\theta) = (a, b)\\), then generally \\(CI(g(\\theta)) \\neq (g(a), g(b))\\). However, for the equal-tailed interval, \\(CI(g(\\theta)) = (g(a), g(b))\\). How to calculate? For the equal-tailed credible interval: If the quantile function is known, use that. Otherwise, calculate the quantiles of the sample. For example, the 95% credible interval for a standard normal distribution is, p &lt;- 0.95 qnorm(c( (1 - p) / 2, 1 - (1 - p) / 2)) #&gt; [1] -1.96 1.96 The 95% credible interval for a sample drawn from a normal distribution is, quantile(rnorm(100), prob = c( (1 - p) / 2, 1 - (1 - p) / 2)) #&gt; 2.5% 97.5% #&gt; -1.78 1.79 There are multiple functions in multiple packages that calculate the HPD interval. coda::HPDitnterval. 6.2.1 Compared to confidence intervals TODO 6.3 Bayesian Decision Theory One aspect of Bayesian inference is that it separates inference from decision. Estimate a posterior distribution \\(p(\\theta | y)\\) Define a loss function for an action (\\(a\\)) and parameter (\\(\\theta\\)), \\(L(a, \\theta)\\). Choose that action that minimizes the loss function In this framework, inference is a subset of decisions and estimators are a subset of decision rules. Choosing an estimate is an action that aims the minimize the loss of function of guessing a parameter value. Given \\(theta\\) and its distribution \\(p(\\theta)\\) and a loss function \\(L(a, \\theta)\\), the optimal action \\(a^*\\) from a set of actions \\(\\mathcal{A}\\) is \\[ a^* \\arg \\min_{a \\in \\mathcal{A}} \\int p(\\theta) L(a, \\theta) \\,d \\theta . \\] If we only have a sample of size \\(S\\) from \\(p(\\theta)\\) (as in a posterior distribution estimated by MCMC), the optimal decision would be calculated as: \\[ a^* \\arg \\min_{a \\in \\mathcal{A}} \\sum_{s = 1}^S L(a, \\theta_s) . \\] The introductions of the Talking Machines episodes The Church of Bayes and Collecting Data and have a concise discussion by Neil Lawrence on the pros and cons of Bayesian decision making. "],
["bayesian-computation.html", "7 Bayesian Computation 7.1 How to calculate a posterior? 7.2 Example: Globe-tossing model 7.3 Quadrature 7.4 Functional Approximations 7.5 Sampling Methods", " 7 Bayesian Computation This is a very complicated case Maude. You know, a lotta ins, a lotta outs, lotta what-have-yous.” — The Dude (The Big Lebowski) 7.1 How to calculate a posterior? Bayesian inference requires calculating the posterior distribution, \\[ p(\\theta | y) = \\frac{p(y | \\theta) p(\\theta)}{\\int_{\\theta&#39; \\in \\Theta} p(y | \\theta&#39;) p(\\theta&#39;)\\, d\\theta&#39; } . \\] However, calculating this quantity is difficult. The denominator (marginal likelihood) is an integral. Additionally, and function of the distribution, e.g. the mean is \\(\\int \\theta p(\\theta | y) \\,d\\theta\\) also requires calculating an integral. In general there are several strategies for this. Symbolic/Analytic: in a few cases, the posterior distribution can be derived symbolically and has a closed-form solution that corresponds distribution that can be sampled from. Conjugate priors are the most common case of this. Functional: find a function that approximates the true posterior. e.g. maximum a posteriori, Laplace/quadratic approximation. Grid/Quadrature. approximate the posterior with a discrete distribution evaluated at a fixed set of points. Sampling. draw a sample from the posterior. Additionally, methods an incorporate and combine various parts of these approaches. 7.2 Example: Globe-tossing model Suppose that we want to estimate the proportion of the Earth’s surface that is water. Suppose that you don’t have any idea what proportion of the Earth’s surface (\\(\\theta\\)) is covered in water, so you think any proportion is equally likely: \\[ \\theta \\sim \\dbeta(1, 1) = \\dunif(0, 1) \\] Alas, the internet is down so you cannot look it up on Wikipedia. Luckily, you do have a globe. Since it would be hard to directly calculate the area on the globe, you estimate the proportion that is water by repeatedly choosing a random point on the globe by spinning it, and marking whether that point is water (\"W\") or land (\"L\"). After 10 spins you have the following sequence of water and land. smpls &lt;- c(&quot;L&quot;, &quot;W&quot;, &quot;L&quot;, &quot;L&quot;, &quot;L&quot;, &quot;L&quot;, &quot;L&quot;, &quot;L&quot;, &quot;L&quot;, &quot;W&quot;) Given that data, what is your estimate about the proportion of the earth’s surface that is water? y &lt;- sum(smpls == &quot;W&quot;) n &lt;- length(smpls) To summarize, this model is \\[ \\begin{aligned}[t] y &amp;\\sim \\dBinom(n, \\theta) \\\\ \\theta &amp;\\sim beta(1, 1) \\\\ \\end{aligned} \\] Suppose we use \\[ \\theta \\sim beta(1, 1) \\] We will calculate this posterior distribution in multiple ways. For now, save the parameters of this model in some object for later reuse. The prior on \\(\\theta\\) is, prior &lt;- list(a = 1, b = 1) Since the beta is a conjugate distribution of the binomial likelihood, we can analytically calculate the posterior distribution. posterior &lt;- list(a = prior$a + y, b = prior$b + n - y) The posterior distribution is \\[ p(\\theta | y) = \\dbeta(3, 9) \\] 7.3 Quadrature 7.3.1 Grid approximation tl;dr: Approximate the posterior distribution by taking a grid of points in \\(\\theta\\) and calculating \\(p(\\theta|y)\\). Doesn’t work well in large dimensions, or if the grid does not include many points in the area with high posterior density. library(&quot;tidyverse&quot;) #&gt; ── Attaching packages ───────────────────────────────────── tidyverse 1.2.1 ── #&gt; ✔ ggplot2 2.2.1 ✔ purrr 0.2.4 #&gt; ✔ tibble 1.4.2 ✔ dplyr 0.7.4 #&gt; ✔ tidyr 0.8.0 ✔ stringr 1.3.0 #&gt; ✔ readr 1.1.1 ✔ forcats 0.3.0 #&gt; ── Conflicts ──────────────────────────────────────── tidyverse_conflicts() ── #&gt; ✖ dplyr::filter() masks stats::filter() #&gt; ✖ dplyr::lag() masks stats::lag() grid &lt;- tibble( theta = seq(0, 1, length.out = 10), prior = dbeta(theta, shape1 = prior$a, shape2 = prior$b), likelihood = dbinom(y, size = n, prob = theta)) %&gt;% mutate(posterior_unst = prior * likelihood, posterior = posterior_unst / sum(posterior_unst)) See A. Gelman, Carlin, et al. (2013 Sec 10.1) 7.4 Functional Approximations See A. Gelman, Carlin, et al. (2013 Sec 10.3, 13.3) 7.4.1 Maximum A Posteriori tl;dr: approximate the posterior distribution with a point mass at the Maximum a posteriori estimation finds value of \\(\\theta\\) that maximizes the posterior distribution, \\[ \\hat{\\theta} = \\arg\\max_{\\theta} p(\\theta |y) . \\] The MAP is best thought of a Bayesian point estimate of the mode of the posterior distribution. However, unlike (most?) other point estimates it does not require first computing the posterior distribution. However, we can consider it a functional approximation of the posterior distribution, in which the approximating distribution is a point mass at \\(\\hat{\\theta}\\). Notes: often the maximum of the posterior is much easier to calculate than the entire posterior distribution when the prior is improper, \\(p(\\theta | y) \\propto p(y | theta)\\) and the MAP and maximum likelihood (MLE) estimators produce the same point estimate. 7.4.2 Laplace Approximation tl;dr: approximate the posterior distribution with a normal distribution centered at the maximum. The Laplace or quadratic approximation to the posterior distribution uses a normal approximation to the posterior distribution. Find maximum of \\(p(\\theta | y)\\). Take the Taylor expansion around the maximum \\(\\hat{\\theta}\\), \\[ \\begin{aligned}[t] p(\\theta | y) &amp; \\approx p(\\widehat{\\theta}) + (\\theta - \\widehat{\\theta}) \\left[ \\frac{d}{d \\theta} p(\\theta | y) \\right]_{\\theta = \\hat{\\theta}} + \\frac{1}{2} (\\theta - \\hat{\\theta})^2 \\left[\\frac{d^2 }{d \\theta^2} p(\\theta| y) \\right]_{\\theta = \\hat{\\theta}} \\\\ &amp;= p(\\widehat{\\theta}) + \\frac{1}{2} (\\theta - \\hat{\\theta})^2 \\left[\\frac{d^2 }{d \\theta^2} p(\\theta| y) \\right]_{\\theta = \\hat{\\theta}} \\\\ \\end{aligned} \\] where the second term is zero since \\(\\hat{\\theta}\\) is the maximum of \\(p(\\theta | y)\\), \\(d / d\\theta p(\\theta | y) = 0\\). The first term \\(p(\\theta)\\) is a constant. The second term is proportional to the logarithm of a normal density, \\[ p(\\theta | y) \\approx dnorm\\left(\\hat{\\theta},\\left[ - \\frac{d^2}{d \\theta^2} \\log p(\\theta | y) \\middle|_{\\theta = \\hat{\\theta}} \\right] \\right) \\] Extensions of this approach include: Fitting a mixture of normal densities. This is especially useful for multi-modal densities. (A. Gelman, Carlin, et al. 2013, 319) Using a multivariate Students-\\(t\\) distribution instead of a normal distribution (A. Gelman, Carlin, et al. 2013, 319) Using the the normal or Laplace approximation as a proposal distribution with importance sampling (A. Gelman, Carlin, et al. 2013, 319) 7.4.2.1 Example Rather than deriving the second derivative for the posterior distribution, I will use numerical derivatives in this example. The idea is the same, although the numerical derivatives are slower than symbolic derivatives. Use the R function optimize to calculate the maximum of the posterior. We will need to use the option hessian = TRUE in order to calculate the second derivatives needed for the variance parameter of the normal distribution. Write a function that takes a single parameter par and returns the log posterior value. calc_posterior &lt;- function(par) { lprior &lt;- dbeta(par, prior$a, prior$b, log = TRUE) lpost &lt;- dbinom(y, size = n, prob = par, log = TRUE) - (lprior + lpost) } Find \\(\\hat{\\theta}\\) and the second derivative using optim: ret &lt;- optim(0.5, fn = calc_posterior, hessian = TRUE, method = &quot;Brent&quot;, lower = 0, upper = 1) The Hessian is a matrix of the second partial derivatives, which is what we need. theta_max &lt;- ret$par theta_var &lt;- 1 / drop(ret$hessian) Let’s plot the value of the Laplace approximation and the true posterior distribution. tibble( theta = ppoints(100), approx = dnorm(theta, theta_max, sqrt(theta_var)), actual = dbeta(theta, shape1 = posterior$a, shape2 = posterior$b) ) %&gt;% ggplot(aes(x = theta)) + geom_line(aes(y = approx)) + geom_line(aes(y = actual), colour = &quot;red&quot;) 7.4.3 Variational Inference tl;dr: approximate the posterior distribution with a simple(r) distribution that is close to the posterior distribution. TODO See Grimmer (2011), Ranganath, Gerrish, and Blei (2014), Kucukelbir et al. (2015), and Blei, Kucukelbir, and McAuliffe (2017). 7.5 Sampling Methods 7.5.1 Numerical Integration Numerical integration calculates a expectation of a function using samples \\(\\theta^1, \\dots, \\theta^S\\) from a distribution \\(p(\\theta)\\), \\[ \\E(h(\\theta) | y) = \\int h(\\theta) p(\\theta | y) d\\theta \\approx \\frac{1}{S} \\sum_{s = 1}^S h(\\theta^s) . \\] The estimation error improves with the number of (independent) samples. Deterministic numerical integration is based on evaluating \\(h(\\theta) p(\\theta | y)\\) at a set of points \\(\\theta^1, \\dots, \\theta^S\\). \\[ \\E(h(\\theta) | y) = \\int h(\\theta) p(\\theta | y) \\approx \\frac{1}{S} w_s h(\\theta^s) p(\\theta^s | y) , \\] with weights \\(w_s\\) for the volume of each point. The accuracy of this method can improve with smarter choices of the grid and also better interpolation between points. The simplest method is a grid with equal weights, but more sophisticated quadrature methods also exist. 7.5.2 Inverse transform sampling A common method of random sampling is inverse-transformation sampling. Suppose we want to sample from random variable \\(X\\) which has a distribution with a CDF of \\(P(X)\\). We can draw a sample as follows, Draw \\(u\\) from \\(unif(0, 1)\\) Let \\(x = P^{-1}(u)\\), where \\(P^{-1}(X)\\) is the inverse of the CDF (quantile) function for \\(X\\). p &lt;- runif(100) post_inverse &lt;- qbeta(p, shape1 = posterior$a, shape2 = posterior$b) ggplot(tibble(x = post_inverse), aes(x = x)) + geom_density() This generally only works on a univariate distribution We would have to CDF of the posterior distribution analytically, but in hard problems that is something we don’t know. 7.5.3 Direct approximation Compute the target density at the set of of evenly spaced values \\(\\theta_1, \\dots, \\theta_S\\) that cover (most of) the parameter space for \\(\\theta\\). Approximate \\(p(\\theta | y)\\) by the density at these values with \\[ p(\\theta | y) \\approx \\left\\{ \\frac{p(\\theta_s| y)}{ \\sum_{j = 1}^S p(\\theta_{j} | y)} \\right\\}_{s = 1}^S \\] This will also work with an un-normalized density function. To draw a random sample from this, sample from the discrete approximation with weights proportional to the \\(p(\\theta_s | y)\\). 7.5.3.1 Example In the water example, there is no reason to do this. However, there could be cases where it is possible to calculate the theta_grid &lt;- seq(0, 1, length.out = 512) w &lt;- (dbeta(theta_grid, prior$a, prior$b) * dbinom(y, size = n, prob = theta_grid)) theta_direct &lt;- sample(theta_grid, size = 512, replace = TRUE, prob = w) mean(theta_direct) #&gt; [1] 0.254 7.5.4 Rejection sampling tl;dr: Sample from a proposal density and reject with a probability proportional to the ratio of the target density to the proposal density. Works best if the proposal density is close to the target density. Rejection sampling consists of the following: Sample from a proposal density, e.g. the prior \\(p(\\theta)\\) Accept with probability \\(p(\\theta | y) / p(\\theta)\\) Suppose there is a positive function \\(g(\\theta)\\) for all \\(\\theta\\) for which \\(p(\\theta | y) &gt; 0\\), Draw from a probability density proportional to \\(g\\) Importance ratio \\(p(\\theta | y) / g(\\theta)\\) must have a known bound, which means that there exists a constant \\(M\\) such that \\(p(\\theta | y) / g(\\theta) \\leq M\\) for all \\(\\theta\\). The algorithm proceeds as follows Sample \\(\\theta\\) at random from the probability proportional to \\(g(\\theta)\\) With probability \\(p(\\theta | y) / M g(\\theta)\\) accept \\(\\theta\\) as a draw from \\(p\\). If rejected, return to 1. Need to choose \\(M\\) so that the probability in step 2 is not greater than 1. This can be \\(M = \\max p(\\theta | y)\\). But in general, the efficiency of the algorithm depends on \\(M\\), but it may be hard to find a good value. Since the probability of success is \\(1 / M\\), the expected number of draws from proposal density to get a single draw from the The ideal case is that the approximate density \\(g(\\theta)\\) is roughly proportional to \\(p(\\theta | y)\\). univariate distributions truncated distributions, e.g. normal truncated distribution 7.5.5 Importance Sampling tl;dr: Draw a sample from a target distribution from an approximate distribution weight those samples by the ratio of target distribution to the approximate distribution. Works best if the proposal density is close to the target density, or at least wider than the target density. Suppose that we want to know \\(\\E(h(\\theta) | y)\\) but cannot directly sample from \\(p(\\theta | y)\\). However, we can sample from a distribution \\(g(\\theta)\\). Then, \\[ \\E(h(\\theta | y)) = \\frac{\\int h(\\theta) q(\\theta | y) d\\theta}{\\int q(\\theta | y) d\\theta} = \\frac{\\int \\left[h(\\theta) q(\\theta | y) / g(\\theta) \\right] g(\\theta) d\\theta}{\\int \\left[ q(\\theta | y) / g(\\theta) \\right] g(\\theta) d\\theta} \\] This can be estimated using \\(S\\) draws \\(\\theta^1, \\dots, \\theta^S\\) from \\(g(\\theta)\\), \\[ \\frac{\\frac{1}{S} \\sum_{s = 1}^s h(\\theta^s) w(\\theta^s)}{\\frac{1}{S} \\sum_{s = 1}^S w(\\theta^s)} , \\] where \\[ w(\\theta^s) = \\frac{q(\\theta^s | y)}{g(\\theta^s)} \\] are called the importance ratios or importance weights. use the same set of random draws for the numerator and denominator to reduce sampling error. worst case: importance ratio are small with high probability, but with a low probability are very high. This occurs when the \\(q\\) has wide tails relative to \\(g\\). Can use a \\(t_4\\) distribution as a proposal distribution for a normal distribution, but not a normal distribution for a proposal distribution of a \\(t_4\\) distribution. The values of the importance weights can be used to discover problems with the method. If any ratios are too large, estimates will be poor. If the variance of the weights is finite, the effective sample size is \\[ S_{eff} = \\frac{1}{\\sum_{s = 1}^S (\\tilde{w}(\\theta^s))^2} . \\] where \\(\\tilde{w}\\) are the normalized weights, \\[ \\tilde{w}(\\theta^s) = \\frac{w(\\theta^S)}{\\sum_{s&#39; = 1}^S w(\\theta^{s&#39;})}. \\] The loo package uses a method to smooth these importance weights as well as diagnostics for overly large sample weights (Vehtari, Gelman, and Gabry 2015, 2017). Importance resampling (or sampling-importance resampling) obtains independent samples with equal weights. Draw \\(S\\) draws \\(\\theta^1, \\dots, \\theta^S\\) from the approximate distribution \\(g\\). Then to draw a sample of size \\(k &lt; S\\), sample without replacement where sampling \\(\\theta^s\\) is proportional to its weight, \\[ \\Pr(\\theta^s) \\propto w(\\theta^s) = \\frac{q(\\theta^s | y)}{g(\\theta^s)} . \\] Sampling without replacement helps to prevent a degenerate case where all or most of the \\(k\\) samples are the same \\(\\theta^s\\) due to large importance ratios. If the proposal distribution is the prior, then the weights are proportional to the likelihood, \\[ w(\\theta^S) = \\frac{p(\\theta | y)}{p(\\theta)} = \\frac{p(y | \\theta) p(\\theta)}{p(\\theta)} = p(y | \\theta) \\] Other notes Similar to both rejection sampling and the Metropolis algorithm Sequential Monte Carlo (SMC) is a variant that is particularly useful for updating posterior distributions when the data arrives sequentially—either real time or because it involves time series data (Carvalho et al. 2010). To update a model when a similar posterior is available. E.g. the posterior distribution for leave-one-out cross validation (Vehtari, Gelman, and Gabry 2015). The distribution \\(p(\\theta | y_{-i})\\) is likely to be similar to \\(p(\\theta | y)\\), so if we have already calculated \\(p(\\theta | y)\\) we can use the later as the proposal distribution for \\(p(\\theta | y)\\). See A. Gelman, Carlin, et al. (2013 Sec 10.4), Gelfand and Smith (1990), Lopes, Polson, and Carvalho (2012), and Smith and Gelfand (1992) for more on importance sampling. 7.5.5.1 Example Use the prior as the proposal distribution. S &lt;- 512 theta &lt;- rbeta(S, prior$a, prior$b) w &lt;- dbinom(y, size = n, prob = theta) The mean value of the posterior is sum(theta * w) / sum(w) #&gt; [1] 0.246 The effective sample size of this sample is, w_tilde &lt;- w / sum(w) 1 / sum(w_tilde ^ 2) #&gt; [1] 215 Finally, to draw a new sample from this, we can draw without replacement (works if the new sample size is much smaller than the original), post_sir1 &lt;- sample(theta, size = S / 2, replace = TRUE, prob = w) or with replacement, post_sir2 &lt;- sample(theta, size = S, replace = TRUE, prob = w) depending on our purposes. 7.5.6 MCMC Methods See A. Gelman, Carlin, et al. (2013 Ch 11–12) for more on MCMC methods. 7.5.6.1 Metropolis-Hastings The Metropolis-Hastings algorithm is a family of MCMC methods useful for sampling from posterior distributions. Draw a starting value \\(\\theta^0\\) for which \\(p(\\theta^0 | y) &gt; 0\\). This can be specified manually or sampled from a crude approximation. For iterations *t = 1, 2, …$: Sample a proposal value \\(\\theta^{*}\\) from a jumping distribution (proposal distribution) at time \\(t\\), \\(J_t(\\theta^{*} | \\theta^{t - 1})\\). Calculate the ratio of the density of the proposal and target distributions, \\[ r = \\frac{p(\\theta^{*} | y) / J_t(\\theta^* | \\theta^{t - 1})}{p(\\theta^{t - 1} | y) / J_t(\\theta^{t - 1} | \\theta^{*})} . \\] Set \\[ \\theta^t = \\begin{cases} \\theta^* &amp; \\text{with probability } \\min(r, 1) \\theta^{t - 1} &amp; \\text{otherwise.} \\end{cases} \\] Thus the transition distribution \\(T_t(\\theta^t | \\theta^{t - 1})\\) is a mixture distribution of point mass at \\(\\theta^t = \\theta^{t - 1}\\) jumping distribution $J_t(^t | ^{t - 1}), with the weights adjusting for the acceptance rates. The main requirements for this algorithm are Be able to draw samples from the jumping distribution \\(J_t(\\theta^* | \\theta)\\) Be able to calculate the density ratio \\(r\\), usually meaning that both \\(p(\\theta^* | y)\\) and \\(p(\\theta^{t - 1} | y)\\) must be able to be calculated for all \\(\\theta\\). The jumping distribution can be asymmetric. However, it if is symmetric (Metropolis algorithm), then the ratio acceptance ratio simplifies to, \\[ r = \\frac{p(\\theta^* | y)}{p(\\theta^{t - 1} | y)} . \\] Notes: For this to work the Markov chain this produces must have stationary distribution that (A. Gelman, Carlin, et al. 2013, 279). MH is similar is like a stochastic optimization algorithm. Instead of always moving towards the region of higher density, it only stochastically moves towards the region of higher density. It tunes how often it moves towards the region of higher density in order to ensure that it samples from the distribution in proportion to the density. MH is similar to a dynamic form of rejection sampling or importance sampling. However, whereas those methods have a static proposal distribution, the jumping distribution, while fixed in its parameters, of the HM algorithm is re-centered around the last draw, so it can move to areas of higher density. When does MH not work well? Posterior distributions with wide tails. Multimodal distributions 7.5.6.2 Gibbs Sampler The Gibbs sampler has been one of the most common methods used to sample from posterior distributions. The Gibbs sampler is a special case of the Metropolis-Hastings sampler. Suppose that the parameter vector \\(\\theta\\) can be divided into \\(d\\) subvectors. For iterations, \\(t = 1, \\dots\\): For \\(j \\in 1, \\dots, d\\) Draw a value from the conditional distribution of \\(\\theta_j\\) given all the other parameters, \\[ \\theta_{j}^t \\sim p(\\theta_j | \\theta^{t - 1}_{-j}, y), \\] where \\(\\theta^{t - 1}_{-j}\\) has consists of updated parameters for all parameters preceding \\(j\\) and the previous iteration’s values for all succeeding parameters, \\[ \\theta_{-j}^{t - 1} = \\left(\\theta_1^t, \\dots, \\theta_{j - 1}^t, \\theta_{j - 1}^{t - 1}, \\dots, \\theta_d^{t - 1}\\right) . \\] Gibbs sampler is a special case of MH algorithm. It is appealing because the use of full-conditional distributions means that draws are never rejected. The use of full-conditional distributions often results in highly correlated iterations. Many applications adjust the method to reduce these correlations. It can be difficult to derive the full-conditional distributions in many cases. 7.5.6.3 Hamiltonian Monte Carlo (HMC) 7.5.6.3.1 Assessing Convergence Iterative simulation methods have two additional issues above and beyond those of simulations (A. Gelman, Carlin, et al. 2013, 282): The iterations have not proceeded long enough to find the typical set and are not drawing samples from the target distribution. The samples have within-sequence correlations. Serial correlation is not a fatal problem. How to monitor and assess iterative simulation Design simulations to allow monitoring of convergence by running multiple chains from dispersed starting points. Monitor convergence by comparing within chain variation and between variation using the \\(\\hat{R}\\) statistic. Only when the between and within variations are approximately equal will the multiple chains appear to be sampling from the same distribution. Require a certain level of efficiency in the output in terms of acceptable sample size. If that that efficiency is too costly to obtain, it may require tweaking the model or the algorithm to be more efficient. See A. Gelman, Carlin, et al. (2013 Ch. 12) for methods to speed up MCMC. 7.5.7 Discarding early iterations Because iterative algorithms may take time to find the typical set of the target distribution, sometimes the early iterations are discarded. In Gibbs sampling, it is common to have a “burn-in” period which is discarded. The algorithm is theoretically still sampling from the posterior distribution, but in the burn-in period it may not have wandered into the typical yet and thus those draws are unrepresentative. In HMC methods, there is a “warmup” period of each chain. In this period the algorithm is not sampling using a method guaranteed to draw a sample from the posterior distribution. Instead it is searching for values of the tuning-parameters of the algorithm. Only after these turning-parameters are set are samples used for analysis. This is similar to the burn-in period of Gibbs sampling in that those iterations are discarded. However, it is serving a fundamentally different role in that the Generally, the issue with MCMC algorithms is not in finding the typical set. In application, they tend to find typical set quickly (FIND CITE – Jackman?). Generally, the larger issue is that the draws are correlated and it may take a long time to explore the posterior distribution. See A. Gelman, Carlin, et al. (2013, 282). 7.5.8 Monte Carlo Sampling Monte Carlo methods are used to numerically approximate integrals, when the integral function is not tractable but the function being integrated is. In Bayesian stats, the mean of a probability density \\(p(\\theta)\\) is \\[ \\mu = \\int_{\\Theta} \\theta p(\\theta) \\, d \\theta . \\] Except for cases in which the distribution \\(p(\\theta)\\) has a known form (not the case for most applied models) for functional form of the integral isn’t known, but \\(p(\\theta)\\) is The Monte Carlo estimate of \\(\\mu\\) is. Draw \\(N\\) independent samples, \\(\\theta^{(1)}, \\dots, \\theta^{(N)}\\), from \\(p(\\theta)\\). Estimate \\(\\hat{\\mu}\\) with \\[ \\hat{\\mu} = \\frac{1}{N} \\sum_{n = 1}^N \\theta^{(N)} . \\] If \\(p(\\theta)\\) has finite mean and variance, the law of large numbers ensures that the Monte Carlo estimate converges to the true value \\[ \\lim_{N \\to \\infty} \\hat\\mu \\to \\mu \\] and the estimation error is governed by the CLT, \\[ | \\mu - \\hat{\\mu} | \\propto \\frac{\\sigma}{\\sqrt{N}} \\] Example: The mean of \\(Y = X^2\\) where \\(X \\sim \\dnorm(0, 1)\\). Draw a sample from \\(Y\\), x &lt;- rnorm(1024, 0, 1) ^ 2 The Monte Carlo estimates of the mean is mean(x) #&gt; [1] 1.07 with standard error, sd(x) / sqrt(length(x)) #&gt; [1] 0.0486 "],
["mcmc-diagnostics.html", "8 MCMC Diagnostics Prerequisites 8.1 Reparameterize Models 8.2 Convergence Diagnostics 8.3 Autocorrelation, Effective Sample Size, and MCSE 8.4 Thinning 8.5 HMC-NUT Specific Diagnostics 8.6 Debugging Bayesian Computing", " 8 MCMC Diagnostics There are two parts of checking a Bayesian model: diagnostics: Is the sampler working? Is it adequately approximating the specified posterior distribution: \\(p(\\theta | D)\\). model fit: Does the model adequately represent the data? This chapter covers the former. Also see the bayesplot vignette Visual MCMC diagnostics using the bayesplot package, which though specific to the provides, provides a good overview of these diagnostics. Prerequisites library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) 8.1 Reparameterize Models Reduce correlation between parameters (e.g. see mcmc_pairs) Put parameters on the same scale. The samplers work best when all parameters are roughly on the same scale, e.g. \\(\\approx 1\\). Try to avoid situations where parameters are orders of magnitude different, e.g. 1e-5 and 1e+10. Increase the informativeness of priors. If parameters are too uninformative, the posterior distribution may have wide tails that hamper sampling. One way of thinking about it is that the model is only “weakly identified” and requires either more data or more informative priors to estimate. 8.2 Convergence Diagnostics Under certain conditions, MCMC algorithms will draw a sample from the target posterior distribution after it has converged to equilibrium. However, since in practice, any sample is finite, there is no guarantee about whether its converged, or is close enough to the posterior distribution. In general there is no way to prove that the sampler has converged.6 However, there are several statistics that indicate that a sampler has not converged. 8.2.1 Potential Scale Reduction (\\(\\hat{R}\\)) In equilibrium, the distribution of samples from chains should be the same regardless of the initial starting values of the chains (Stan Development Team 2016, Sec 28.2). One way to check this is to compare the distributions of multiple chains—in equilibrium they should all have the same mean. Additionally, the split \\(\\hat{R}\\) tests for convergence by splitting the chain in half, and testing the hypothesis that the means are the same in each half. This tests for non-stationarity within a chain. See Stan Development Team (2016 Sec 28.2) for the equations to calculate these. TODO: Examples of passing and non-passing \\(\\hat{R}\\) chains using fake data generated from known functions with a given autocorrelation. Rule of Thumb: The rule of thumb is that R-hat values for all less than 1.1 source. Note that all parameters must show convergence. This is a necessary but not sufficient condition for convergence. 8.2.2 References A. Gelman, Carlin, et al. (2013, 267) Stan Development Team (2016 Ch 28.) for how Stan calculates Hat, autocorrelations, and ESS. Gelman and Rubin (1992) introduce the R-hat statistic 8.3 Autocorrelation, Effective Sample Size, and MCSE MCMC samples are dependent. This does not effect the validity of inference on the posterior if the samplers has time to explore the posterior distribution, but it does affect the efficiency of the sampler. In other words, highly correlated MCMC samplers requires more samples to produce the same level of Monte Carlo error for an estimate. 8.3.1 Effective Sample Size The effective sample size (ESS) measures the amount by which autocorrelation in samples increases uncertainty (standard errors) relative to an independent sample. Suppose that the \\(\\rho^2_t\\) is the ACF function of a sample of size \\(N\\), the effective sample size, \\(N_eff\\), is \\[ N_{eff} = \\frac{N}{\\sum_{t = -\\infty}^\\infty \\rho_t} = \\frac{N}{1 + 2 \\sum_{t = -\\infty}^\\infty \\rho_t}. \\] TODO show that if \\(\\rho_t = 1\\) for all \\(t\\) then \\(N_eff = 1\\), and if \\(\\rho_t = 0\\) for all \\(t\\) then \\(N_eff = N\\) Computing the effective sample size requires calculating an autocorrelation. A multi-chain estimate of the autocorrelation is found by computing the variogram with the correlations for all lags, \\[ V_t = \\frac{1}{m(n - t)} \\sum_{j = 1}^m \\sum_{i = t + 1}^n (\\psi_{i,j} - \\psi_{i - t,j})^2 \\] The estimate of the autocorrelations \\(\\hat{\\rho}_t\\) is \\[ \\hat{\\rho}_t = 1 - \\frac{V_t}{2 \\widehat{\\mathrm{var}}^+} \\] The estimates of the autocorrelations can be noisy, so \\(\\hat{\\rho}_t\\) are summed from 0, to the last \\(t\\) such that \\(\\rho\\) is positive (\\(T\\)), \\[ \\hat{n}_{eff} = \\frac{mn}{1 + 2 \\sum_{t = 1}^T \\hat{\\rho}_t} \\] See also Stan Development Team (2016 Sec 28.4), Geyer (2011), and A. Gelman, Carlin, et al. (2013 Sec 11.5). This isn’t the only way to calculate the effective sample size. The coda package function coda uses a different method. The differences are due to how the autocorrelation is calculated. Example: Comparison of the effective sample sizes for data generated with various levels of autocorrelation. The package rstan does not directly expose the function it uses to calculate ESS, so this ess function does so (for a single chain). ess &lt;- function(x) { N &lt;- length(x) V &lt;- map_dbl(seq_len(N - 1), function(t) { mean(diff(x, lag = t) ^ 2, na.rm = TRUE) }) rho &lt;- head_while(1 - V / var(x), ~ . &gt; 0) N / (1 + sum(rho)) } n &lt;- 1024 sims &lt;- map_df(c(0, 0.5, 0.75, 0.99), function(ar) { tibble(ar = ar, y = if (ar == 0) { rnorm(n) } else { as.numeric(arima.sim(list(ar = ar), n)) }, x = seq_along(y), n_eff = ess(y), label = sprintf(&quot;AR = %.2f (n_eff = %.0f)&quot;, ar, n_eff)) } ) ggplot(sims, aes(x = x, y = y)) + geom_line() + facet_wrap(~ label, scales = &quot;free_y&quot;) + labs(x = &quot;&quot;, y = &quot;&quot;) 8.4 Thinning Since the autocorrelation tends to decrease as the lag increases, thinning samples will reduce the final autocorrelation in the sample while also reducing the total number of samples saved. Due to the autocorrelation, the reduction in the number of effective samples will often be less than number of samples removed in thinning. Both of these will produce 1,000 samples from the posterior, but effective sample size of \\(B\\) will be greater than the effective sample size of \\(A\\), since after thinning g the autocorrelation in \\(B\\) will be lower. A Generating 1,000 samples after convergence and save all of them B Generating 10,000 samples after convergence and save every 10th sample In this case, A produces 10,000 samples, and B produces 1,000. The effective sample size of A will be higher than B. However, due to autocorrelation, the proportional reduction in the effective sample size in B will be less than the thinning: \\(N_{eff}(A) / N_{eff}(B) &lt; 10\\). A Generating 10,000 samples after convergence and save all of them B Generating 10,000 samples after convergence and save every 10th sample Thinning trades off sample size for memory, and due to autocorrelation in samples, loss in effective sample size is less than the loss in sample size. Thinning has become less of an issue as memory has become less of a computational constraint, and samplers have become more efficient. The following example simulates random values from an autocorrelated series, and applies different levels of thinning. Thinning is always decreasing the effective sample size. However, the number of effective samples per sample (n_eff / n) increases until the thinning is large enough that the thinned samples are uncorrelated. thin_ess &lt;- function(thin, x) { if (thin &gt; 1) { # keep only thinned rows x_thinned &lt;- x[(seq_len(length(x)) %% thin) == 1] } else { x_thinned &lt;- x } tibble(thin = thin, n = length(x_thinned), n_eff = ess(x_thinned), `n_eff / n` = n_eff / n) } map_df(c(1, 2, 4, 8, 16, 32), thin_ess, x = arima.sim(list(ar = .9), 4096)) #&gt; # A tibble: 6 x 4 #&gt; thin n n_eff `n_eff / n` #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 4096 1266. 0.309 #&gt; 2 2 2048 1087. 0.531 #&gt; 3 4 1024 791. 0.773 #&gt; 4 8 512 512 1 #&gt; 5 16 256 256 1 #&gt; 6 32 128 128 1 A. Gelman, Carlin, et al. (2013, 282–83) Stan Development Team (2016, 354–55) 8.4.1 Traceplots Trace plots are a time series of sampler iterations, e.g. as produced by bayesplot. These can, but should not, be used to assess convergence, such visual inspection is ‘notoriously unreliable’ (A. Gelman, Carlin, et al. 2013, 285) it cannot scale to many parameters Trace plots may be useful for diagnosing convergence problems after \\(\\hat{R}\\) or or \\(n_eff\\) indicates problems. Some possible issues to check in these plots are multimodality (the traceplot jumps between different distributions) wide posterior tails (the traceplot shows regions where the sampler will reach and have difficulty returning to the main distribution) 8.4.2 Monte Carlo Standard Error (MCSE) The Monte Carlo standard error is the uncertainty about a statistic in the sample due to sampling error. With a independent sample of size \\(N\\), the MCSE for the sample mean is \\[ MCSE(\\bar{\\theta}) = \\frac{s}{\\sqrt{N}} \\] where \\(s\\) is the sample standard deviation. However, MCMC are generally not independent, and the MCSE will be higher than that of an independent sample. One way to calculate the MCSE with autocorrelated samples is to use the effective sample size instead of the sample size, \\[ MCSE(\\bar{\\theta}) = \\frac{s}{\\sqrt{N_{eff}}} \\] An MCSE estimator for the mean is \\[ \\mathrm{MCSE}(\\hat{\\theta}) = \\frac{\\sd(\\theta)}{\\sqrt{n_{neff}}} \\] An MCSE estimator for any posterior probability, where \\(\\hat{p} = \\Pr(f(\\theta))\\), follows from the standard error of a proportion, but using the effective sample size, \\[ MCSE(\\hat{p}) = \\sqrt{\\hat{p} (1 - \\hat{p}) / n_{eff}} \\] See Flegal, Haran, and Jones (2008) and the mcmcse for methods to calculate MCMC standard errors for means and quantiles using sub-sampling methods. Flegal, Haran, and Jones (2008) argues for using ESS as a stopping rule and convergence diagnostic for Bayesian inference. The estimation of standard errors for quantiles, as would be used in is more complicated. See the package mcmcse for Monte Carlo standard errors of quantiles (though calculated in a different method than rstan). A. Gelman, Carlin, et al. (2013 Sec. 10.5) Flegal, Haran, and Jones (2008) Talk by Geyer on MCSE 8.5 HMC-NUT Specific Diagnostics Hamiltonian Monte Carlo (HMC), and the No-U-Turn Sampler (HMC-NUTS) in particular, produce several diagnostics that indicate that the sampler is breaking and, thus, not sampling from the posterior distribution. This is unusual, as most Bayesian sampling methods do not give indication of whether they are working well, and all that can be checked are the properties of the samples themselves with methods such \\(\\hat{R}\\). Three specific HMC-NUTS diagnostics are divergent transitions maximum tree-depth Bayesian fraction of missing information The general way to fix these issues is the manually adjust the HMC-NUTS sampler parameters.n Stepsize: Length of the steps to take Tree-depth: Number of steps to take During the warmup period, Stan tunes these values, however these auto-tuned parameters may not always be optimal. The other alternative is to reparameterize the models. 8.5.1 Divergent transitions The details of the HMC are technical and can be found TODO. The gist of the problem is that Stan is using a discrete approximation of a continuous function when integrating. If the step sizes are too large, the discrete approximation does not work. Helpfully, when the approximation is poor it does not fail without any indication but will produce “divergent transitions”. If there are too many divergent transitions, then the sampler is not drawing samples from the entire posterior and inferences will be biased. Reduce the step size. This can be done by increasing the the adapt_delta parameter. This is the target average proposal acceptance probability in the adaptation, which is used to determine the step size during warmup. A higher desired acceptance probability (closer to 1) reduces the the step size. A smaller step size means that it will require more steps to explore the posterior distribution. See Stan Development Team (2016, 380) 8.5.2 Maximum Tree-depth NUTS is an intelligent method to select the number of steps to take in each iteration. However, there is still a maximum number of steps that NUTS will try. If the sampler is often hitting the maximum number of steps, it means that the optimal number of steps to take in each iteration is higher than the maximum. While divergent transitions bias inference, a too-small maximum tree-depth only affects efficiency. The sampler is still exploring the posterior distribution, but the exploration will be slower and the autocorrelation higher (effective sample size lower) than if the maximum tree-depth were set higher. Increase the maximum tree-depth. 8.5.3 Bayesian Fraction of Missing Information This is rather technical. See Betancourt (2016). 8.6 Debugging Bayesian Computing See A. Gelman, Carlin, et al. (2013, 270), … Pick a reasonable value for the “true” parameter vector \\(\\theta^* \\sim p(\\theta)\\). This should be a random draw from the prior, but if \\(\\theta\\) is uninformative, then any reasonable value of \\(\\theta\\) should work. Draw all other parameters that are conditional on \\(\\theta^*\\). Simulate a large fake dataset \\(y^{fake}\\) from the data distribution \\(p(y | \\theta^*)\\) Calculate the posterior \\(p(\\theta | y^{rep})\\). Compare the posterior distribution \\(p(\\theta | y)\\) to its true value \\(\\theta^*\\). For example there should be a 50% probability that the 50% posterior interval of \\(p(\\theta | y)\\) contains \\(\\theta^*\\). Notes for large number of parameters: calculate the proportion of 50% credible intervals that contain the true value. residual plot: for all scalar parameters \\(\\theta_j\\), calculate the residual \\(\\E[\\theta_j] - \\theta^*\\). The residuals should have mean 0. for models with few parameters, perform many fake data simulations. convergence and posterior predictive tests may also indicate issues with the model. it could be either a problem with the model, or a problem in computation. simplify the model by removing parameters or setting them to fixed values Start with a simple model and build complexity. This is useful both because the simple model may be “good enough” for your purposes, and because adding one part at a time makes it easier to catch and fix bugs. This is also the case in optimization with non-convex objective functions.↩ "],
["model-checking.html", "9 Model Checking 9.1 Why check models? 9.2 Posterior Predictive Checks 9.3 References", " 9 Model Checking 9.1 Why check models? In theory, a Bayesian model should include all relevant substantive knowledge and subsume all possible theories. In practice, it won’t. We need to check how the model fits data. The question is not whether a model is “true”; it isn’t (Box 1976). The question is whether it is good enough for the purposes of the analysis. The problem is how we can specify “good enough” criteria, and how we can check those criteria. See Gelman, Meng, and Stern (1996), A. Gelman (2007), Gelman (2009), A. Gelman, Carlin, et al. (2013 Ch. 6), A. Gelman and Shalizi (2012b), Kruschke (2013), A. Gelman and Shalizi (2012a), Gelman (2014) for a more discussion of the motivation and use of posterior predictive checks. 9.2 Posterior Predictive Checks One method evaluate the fit of a model is to use posterior predictive checks Fit the model to the data to get the posterior distribution of the parameters: \\(p(\\theta | D)\\) Simulate data from the fitted model: \\(p(\\tilde{D} | \\theta, D)\\) Compare the simulated data (or a statistic thereof) to the observed data and a statistic thereof. The comparison between data simulated from the model can be formal or visual. Within a Stan function, this is done in the generated quantities block using a _rng distribution functions. The package bayesplot includes multiple functions for posterior predictive checks; see the help for PPC-overview for a summary of these functions. 9.2.1 Bayesian p-values A posterior predictive p-value is a the tail posterior probability for a statistic generated from the model compared to the statistic observed in the data. Let \\(y = (y_1, \\dots, y_n)\\) be the observed data. Suppose the model has been fit and there is a set of simulation \\(\\theta^(s)\\), \\(s = 1, \\dots, n_sims\\). In replicated dataset, \\(y^{rep(s)\\), has been generated from the predictive distribution of the data, \\(p(y^{(rep)} | \\theta = \\theta^{(s)}\\). Then the ensemble of simulated datasets, \\((y^{rep(s)}, \\dots, y^{rep(nsims)})\\), is a sample from the posterior predictive distribution, \\(p(y^{(rep)} | y)\\) The model can be tested by means of discrepancy statistics, which are some function of the data and parameters, \\(T(y, \\theta)\\). If \\(\\theta\\) was known, then compare discrepancy by \\(T(y^{(rep)}, \\theta)\\). The statistical significance is \\(p = \\Pr(T(y^{(rep)}, \\theta) &gt; T(y, \\theta) | y, \\theta)\\). If \\(\\theta\\) is unknown, then average over the posterior distribution of \\(\\theta\\), \\[ \\begin{aligned}[t] p &amp;= \\Pr(T(y^{(rep)}, \\theta) &gt; T(y, \\theta) | y) \\\\ &amp;= \\int Pr(T(y^{(rep)}, \\theta) &gt; T(y, \\theta) | y, \\theta) p(\\theta | y) d\\,\\theta , \\end{aligned} \\] which is easily estimated from the MCMC samples as, \\[ p = \\frac{1}{n_{sims}}\\sum_{s = 1}^{n_{sims}} 1( T(y^{rep(s)}, \\theta(s)) &gt; T(y, \\theta(s))) \\] 9.2.2 Test quantities The definition of a posterior p-value does not specify a particular test-statistic, \\(T\\), to use. The best advice is that \\(T\\) depends on the application. A. Gelman, Carlin, et al. (2013, 146) Speed of light example uses the 90% interval (61st and 6th order statistics). A. Gelman, Carlin, et al. (2013, 147) binomial trial example uses the number of switches (0 to 1, or 1 to 0) in order to test independence. A. Gelman, Carlin, et al. (2013, 148) hierarchical model for adolescent smoking uses. percent of adolescents in the sample who never smoked percentage in the sample who smoked in all waves percentage of “incident smoker”: adolescents who began the study and non-smokers and ended as smokers. 9.2.3 p-values vs. u-values A posterior predictive p-value is different than a classical p-value. Posterior predictive \\(p\\)-value distributed uniform if the model is true. Classical \\(p\\)-value distributed uniform if the null hypothesis (\\(H_0\\)) is true. A \\(u\\)-value* is any function of the data that has a \\(U(0, 1)\\) sampling distribution (A. Gelman, Carlin, et al. 2013, 151) a \\(u\\)-value can be averaged over \\(\\theta\\), but it is not Bayesian, and is not a probability distribution posterior p-value: probability statement, conditional on model and data, about future observations 9.2.4 Marginal predictive checks Compare statistics for each observation. Conditional Predictive Ordinate (CPO): The CPO (Gelfand 1995) is the leave-one-out cross-validation predictive density: \\[ p(y_i | y_{-i}) = \\int p(y_i | \\theta) p(\\theta | y_{-i}) d\\,\\theta \\] The pointwise predicted LOO probabilities can be calculated using PSIS-LOO or WAIC in the loo package. Predictive Concordance and Predictive Quantiles Gelfand (1995) classifies any \\(y_i\\) that is outside the central 95% predictive posterior of \\(y^{rep}_i\\) is an outlier. Let the predictive quantile (\\(PQ_i\\)) be \\[ PQ_i = p(y_i^{(rep)} &gt; y_i) . \\] Then the predictive concordance be the proportion of \\(y_i\\) that are not outliers. Gelfand (1995) argues that the predictive concordance should match 95%. In other words that the posterior predictive distribution should have the correct coverage. 9.2.5 Outliers Can be identified by the inverse-CPO. larger than 40 are possible outliers, and those higher than 70 are extreme values (Ntzoufras 2009, 376). Congdon (2014) scales CPO by dividing each by its individual max and considers observations with scaled CPO under 0.01 as outliers. 9.2.6 Graphical Posterior Predictive Checks Visualization can surprise you, but it doesn’t scale well. Modeling scales well, but it can’t surprise you. – paraphrase of Hadley Wickham Instead of calculating posterior probabilities, plot simulated data and observed data and visually compare them. See A. Gelman, Carlin, et al. (2013, 154). plot simulated data and real data (A. Gelman, Carlin, et al. 2013, 154). This is similar to ideas in Wickham et al. (2010). plot summary statistics or inferences residual plots Bayesian residuals have a distribution \\(r_i^{(s)} = y_i - \\E(y_i \\theta^{s})\\) Bayesian residual graph plots single realization of the residuals, or a summary of their posterior distributions binned plots are best for discrete data (A. Gelman, Carlin, et al. 2013, 157) 9.3 References See A. Gelman and Shalizi (2012b), A. Gelman and Shalizi (2012a), Kruschke (2013). "],
["model-comparison.html", "10 Model Comparison 10.1 Models 10.2 Classes of Model Spaces 10.3 Continuous model expansion 10.4 Discrete Model Expansion 10.5 Out-of-sample predictive accuracy 10.6 Stacking 10.7 Posterior Predictive Criteria 10.8 Bayesian Model Averaging 10.9 Pseudo-BMA 10.10 LOO-CV via importance sampling 10.11 Selection induced Bias", " 10 Model Comparison Don’t check, but compare. Information criteria Predictive accuracy Model comparison based on predictive performance 10.1 Models Model comparison: defining criteria to rank models for which is best. Model selection: choose the best model Model averaging: combine models into a single meta-model. 10.2 Classes of Model Spaces See Vehtari and Ojanen (2012) and Piironen and Vehtari (2015). Let \\(\\mathcal{M} = \\{M_1, \\dots M_K\\}\\) be a set of \\(K\\) models. Let \\(M_T\\) be the model for the true data generating process. Let \\(M_R\\) be a reference model which is not the true model, but is the best available model to predict future observations. Generalization utility estimation | \\(\\mathcal{M}-open\\) | \\(M_T, M_R \\notin \\mathcal{M}\\) | Model Space approach | \\(\\mathcal{M}-closed\\) | \\(M_T \\in \\mathcal{M}\\) | Reference Model approach | \\(\\mathcal{M}-completed\\) | \\(M_R \\in \\mathcal{M}\\) | The \\(\\mathcal{M}\\)-closed view asserts that there is a true DGP model and that model is in the set of models under consideration. The \\(\\mathcal{M}\\)-open view either asserts that there is no true DGP or does not care. It only compares models in the set against each other. The \\(\\mathcal{M}\\)-complete view does not believe there is a true model in the set of models, but still uses a reference model which is believed be the best available description of the future observations. 10.3 Continuous model expansion Continuous model expansion is embedding the current model in a more general model in which it is a special case. add new parameters broaden the class of models, e.g. normal to a \\(t\\) combine different models into a super-model that includes both as special cases add new data. For example, embed the data into a hierarchical model to draw strength from other data. More formally, suppose that the old model is a \\(p(y, \\theta)\\) is embedded or replaced by \\(p(y, y^*, \\theta, \\phi)\\), where \\[ p(\\theta, \\phi | y, y^*) \\propto p(\\phi) p(\\theta | \\phi) p(y, y^* | \\theta, \\phi) . \\] This will require a specifying \\(p(\\theta | \\phi)\\): a new prior on \\(\\theta\\) that is conditional on the new parameters, \\(\\phi\\). \\(p(\\phi)\\): a prior for the new parameters, \\(\\phi\\). Continuous model expansion can also be used to fit Some examples of continuous model expansion: The normal distribution can be expanded to the Student-t distribution since \\[ \\dnorm(\\mu, \\sigma^2) = \\dt(\\nu = \\infty, ) . \\] Let \\(\\nu\\) be a parameter to be estimated instead of imposing \\(\\nu = \\infty\\) as in the normal distribution. Any case where a distribution is a special case of a more general distribution: Normal to skew normal Student-t to skew Student-t Normal and Laplace to the [Exponential Power Distribution(https://en.wikipedia.org/wiki/Generalized_normal_distribution#Version_1) Binomial to Beta-Binomial Poisson to Negative-Binomial … and many others Linear regression can be thought of a case of model expansion, where a model where all observations have the same mean, \\[ y_i \\sim \\dnorm(\\mu, \\sigma^2) , \\] is replaced by one in which each observation has a different mean, \\[ y_i \\sim \\dnorm(\\mu_i, \\sigma^2) \\] with a particular model, \\[ \\mu_i = x_i \\beta . \\] Given a regression where observation \\(i\\) is a group \\(k \\in \\{1, \\dots, K \\}\\), a regression where the slope an intercept coefficients are assumed to be the same across groups, \\[ y_{i,k} \\sim \\dnorm(\\alpha + x_i \\beta, \\sigma^2) , \\] can be generalized to a model in which the intercepts and slopes vary across groups, \\[ y_{i,k} \\sim \\dnorm(\\alpha_k + x_i \\beta_k, \\sigma^2) . \\] A linear regression with heterskedastic errors, \\[ y_i \\sim \\dnorm(\\alpha + x_i \\beta, \\sigma_i^2) \\] is a continuous model expansion of a homoskedastic regression model which assumes \\(\\sigma_i = \\sigma\\) for all \\(i\\). The regression model which adds a variable(s) is a continuous model expansion. For example, the regression, \\[ y_i \\sim \\dnorm(\\alpha + x_1 \\beta_1, \\sigma_i^2), \\] is a special case of the larger regression model, \\[ y_i \\sim \\dnorm(\\alpha + x_1 \\beta_1 + x_2 \\beta_2, \\sigma_i^2) , \\] where \\(\\beta_2 = 0\\). Adding a variable to a regression is estimating the coefficient of that new variable rather than assuming it is zero. Continuous model expansion can also apply to cases where several models can be subsumed into a larger model in which they are all special cases. There are several issues with continuous model expansion: Model selection choices can lead to overfitting. Embedding a model inside a larger model, incorporates some, but not all sources of uncertainty. Using continuous model expansion is better than choosing one, “best” model. However, the choice of how to expand the model will be but one of many possibilities and that choice can subtly overfit the data. Specifying a more general model can be costly in both researcher time and computational time. Even disregarding computational constraints, no useful model can be completely general. See the No Free Lunch Theorem. 10.4 Discrete Model Expansion Suppose that you are considering \\(\\mathcal{M} = \\{M_1, \\dots, M_K\\}\\) models, estimate a model that is a weighted average of those models. \\[ p(\\theta | y) = \\sum_{k = 1}^K \\pi_k p(\\theta_k | y), \\] where \\(\\pi_k \\geq 0\\) and \\(\\sum \\pi_k = 1\\). Like continuous model expansion this embeds models in a larger meta-model. However, whereas the continuous model expansion generally involves models being specific cases of a continuous parameter value in the meta-model, the discrete model expansion is a brute-force approach that treats models as discrete and independent, and averages them. There are two general approaches to this, Mixture models estimate \\(\\pi_k\\) simultaneously with \\(p(\\theta_k | y)\\). Bayesian model averaging is a two step process. Estimate each \\(p(\\theta_k | y)\\) Define weights \\(\\pi_k\\) and average the models. 10.5 Out-of-sample predictive accuracy Consider data \\(y_1, \\dots, y_n\\), which is independnet given parameters \\(\\theta\\). Thus the likelihood can be decomposed into a product of pointwise likelihoods, \\[ p(y | \\theta) = \\prod_{i = 1}^n p(y_i | \\theta) . \\] Suppose a prior distribution \\(p(\\theta)\\) and a posterior predictive distribution for new data \\(\\tilde{y}\\), \\[ p(\\tilde{y} | y) = \\int p(\\tilde{y}_i | \\theta) p(\\theta | y)\\,d\\theta . \\] The expected log-predictive accuracy for a new point is, \\[ \\begin{aligned}[t] \\text{elpd} &amp;= \\text{expected log pointwise predictive density for a new dataset} \\\\ &amp;= \\sum_{i = 1}^n \\int p_t(\\tilde{y}_i) \\log p(\\tilde{y}_i | y)\\,d\\tilde{y}_i , \\end{aligned} \\] where \\(p_t(\\tilde{y}_i)\\) is the distribution of the true DGP for \\(\\tilde{y}_i\\). Since the true DGP is unknown, it will be needed to be approximated. The most common way to approximate \\(p_t(\\tilde{y}_i)\\) is via either cross-validation or information criteria. \\[ \\begin{aligned}[t] \\text{lpd} &amp;= \\text{log pointwise predictive density} \\\\ &amp;= \\sum_{i = 1}^n \\log p(y_i | y) \\\\ &amp;= \\sum_{i = 1}^n \\log \\int p(y_i | \\theta) p(\\theta | y) \\,d\\theta . \\end{aligned} \\] The lpd of observed data is overly optimistic for future data. To compute the lpd from \\(S\\) draws from a posterior distribution \\(p_{post}(\\theta)\\), \\[ \\begin{aligned}[t] \\widehat{\\text{lpd}} &amp;= \\text{computed log pointwise predictive density} \\\\ &amp;= \\sum_{i = 1}^n \\log \\left( \\frac{1}{S} \\sum_{s = 1}^S p(y_i | \\theta^s) \\right) . \\end{aligned} \\] The Bayesian LOO-CV estimate of elpd is, \\[ \\text{elpd}_{\\text{loo}} = \\sum_{i = 1}^n \\log p(y_i | y_{-i}) , \\] where \\[ p(y_i | y_{-i}) = \\int p(y_i | \\theta) p(\\theta | y_{-i})\\,d\\theta . \\] The value of \\(\\text{elpd}_{\\text{loo}}\\) can be calculated by cross-validation (running the model \\(n\\) times) or by an approximation of LOO-CV using importance sampling, which PSIS-LOO being the best implementation of this approach. 10.6 Stacking Stacking is a method for averaging (point) estimates from models. It proceeds in two steps. Fit \\(K\\) models where each model where \\(\\hat{y}_i\\) is predicted value of \\(y_i\\) from a model trained on data not including \\(y\\) (e.g. LOO-CV). Calculate a weight for each model by minimizing the LOO-mean squared error, \\[ \\hat{w} = \\arg \\min_{w} \\sum_{i = 1}^n \\left( y_i - \\sum_{k} w_k \\hat{y}_i \\right)^2 \\] The pint prediction for a new point is, \\[ \\hat{\\tilde{y}} = \\sum_{k = 1}^K \\hat{w}_k f_k\\left(\\tilde{x} | \\tilde{\\theta}_k, y_{1:n} \\right) \\] Whereas stacking is typically used with point estimates, CITE generalize stacking to use proper scoring rules. In particular, CITE use the logarithmic scoring rule (e.g. the log predictive distribution). This is implemented in the loo package. 10.7 Posterior Predictive Criteria Most of these notes summarize the more complete treatment in A. Gelman, Hwang, and Vehtari (2013) and Vehtari, Gelman, and Gabry (2015). 10.7.1 Summary and Advice Models can be compared using its expected predictive accuracy on new data. Ways to evaluate predictive accuracy: log posterior predictive density: \\(\\log p_post(\\tilde{y})\\). The log probability of observing new scoring rules or loss functions specific to the problem/research question Several methods to estimate expected log posterior predictive density (elpd) within-sample log-posterior density (biased, too optimistic) information criteria: WAIC, DIC, AIC with correct the bias within-sample log-posterior density with a penalty (number of parameters) cross-validation: estimate it using heldout data What should you use? Use the Pareto Smoothed Importance Sampling LOO (Vehtari, Gelman, and Gabry 2015) implemented in the loo package: It is computationally efficient as it doesn’t require completely re-fitting the model, unlike actual cross-validation it is fully Bayesian, unlike AIC and DIC it often perform better than WAIC it provides indicators for when it is a poor approximation (unlike AIC, DIC, and WAIC) next best approximation would be the WAIC. No reason to use AIC or DIC ever. For observations which the PSIS-LOO has \\(\\hat{k} &gt; 0.7\\) (the estimator has infinite variance) and there aren’t too many, use LOO-CV. If PSIS-LOO has many observations with with \\(k &gt; 0.7\\), then use LOO-CV or k-fold CV If the likelihood doesn’t easily partition into observations or LOO is not an appropriate prediction task, use the appropriate CV method (block k-fold, partitioned k-fold, time-series k-fold, rolling forecasts, etc.) Note that AIC/DIC/WAIC/CV vs. BIC/Bayes Factors are not different estimators of the same estimand. They are answering fundamentally different questions. Cross validations and its IC approximations are asking a question in a \\(\\mathcal{M}\\)-open world as to which model predict the best (w.r.t. a loss function). Bayes factors, BIC, and marginal likelihood-based measures are used to find the true model, with the assumption that the true model is one of the models under consideration (which unless another human computationally generated the data is unlikely to be the case). 10.7.2 Expected Log Predictive Density Let \\(f\\) be the true model, \\(y\\) be the observed data, and \\(\\tilde{y}\\) be future data or alternative data not used in fitting the model. The out-of-sample predictive fit for new data is \\[ \\log p_{post}(\\tilde{y}_i) = -\\log \\E_{post}(p(\\tilde{y}_i)) = \\log \\int p(\\tilde{y}_i | \\theta) p_{post}(\\theta) d\\,\\theta \\] where \\(p_{post}(\\tilde{y}_i)\\) is the predictive density for \\(\\tilde{y}_i\\) from \\(p_{post}(\\theta)\\). \\(\\E_{post}\\) is an expectation that averages over the values posterior distribution of \\(\\theta\\). Since the future data \\(\\tilde{y}_i\\) are unknown, the expected out-of-sample log predictive density (elpd) is, \\[ \\begin{aligned}[t] \\mathrm{elpd} &amp;= \\text{expected log predictive density for a new data point} \\\\ &amp;= E_f(\\log p_{post}(\\tilde{y}_i)) \\\\ &amp;= \\int (\\log p_{post}(\\tilde{y}_i)) f(\\tilde{y}_i) \\,d\\tilde{y}_i \\end{aligned} \\] 10.8 Bayesian Model Averaging Suppose there is an exhaustive list of candidate models, \\(\\{M_k\\}_{k = 1}^K\\), the distribution over the model space is, \\[ p(M | D) \\propto p(D | M) p(M). \\] The predictions from Bayesian Model Averaging (BMA) are \\[ p(\\tilde{y} | D) = \\sum_{k = 1}^{K} p(\\tilde{y} | D, M_k) p(M_k | D) \\] In BMA each model is weighted by its marginal likelihood, \\[ p(M_k | y) = \\frac{p(y | M_k) p(M_k)}{\\sum_{k = 1}^K p(y | M_k) p(M_K)}, \\] where \\[ p(y | M) = \\int p(y | \\theta_k, M_k) p(\\theta_k| M_k) \\,d\\theta_k. \\] In the \\(\\mathcal{M}\\)-closed case, BMA will asymptotically select the correct model. In the \\(\\mathcal{M}\\)-open and -complete cases, it will asympmtotically select the closest, in terms of KL-divergence, model to the true model. Since the BMA weights by marginal likelihood, these weights extremely sensitive to the choices of the priors \\(p(\\theta_k)\\) for each model. The sensitivity to prior distributions make the BMA weights suspect. The difficulty of computing marginal likelihood generally make the BMA hard to generalize. BMA has been most successfully implemented in (generalized) linear regression, where a particular choice of prior (Zellner’s g-prior) provides an analytical solution to the Bayes’ Factor with respect to the null model. However, this is also the area where methods using regularization and sparse shrinkage priors have made extensive progress recently. Sparse shrinkage priors, e.g. horseshoe priors, and the use of methods that provide a sparse summarization of the prior, e.g. projection-prediction, provide a competitive and more coherent solution to the variable selection problem in regression than BMA. 10.9 Pseudo-BMA Pseudo-BMA is similar to Bayesian model averaging, but instead of using weighting models by marginal likleihoods, it weights models using an approximation of the predictive distribution: e.g. AIC, DIC, or WAIC. The use of the predictive distribution rather than the marginal likelihood makes the weights less sensitive to the prior distributions of the priors. CITE propose using the expected log-pointwise predictive density (elpd) PSIS-LOO weights to weight each model. \\[ w_k = \\frac{\\exp\\left( \\widehat{\\text{elpd}}_{\\text{loo}}^k \\right)}{ \\sum_{k = 1}^K \\exp \\left( \\widehat{\\text{elpd}}_{\\text{loo}}^k \\right)} \\] where \\(\\widehat{\\text{elpd}}_{\\text{loo}}^k\\) is estimated using PSIS-LOO. These point-estimates of the elpd are adjusted by estimates of the uncertainty calculated via a log-normal approximation or Bayesian bootstrap [CITE]. The effect of adjusting for uncertainty is to regularize weights by adjusting them towards equal weighting for each model, and away from weights of 0 or 1. This is implemented in the loo package. 10.10 LOO-CV via importance sampling Leave-one-out cross validation (LOO-CV) is costly because it requires re-estimating the model \\(n\\) times. The LOO predictive density is, \\[ p(y_{i} | y_{-i}) = \\int p(y_i | \\theta) p(\\theta | y_{-i})\\,d\\theta . \\] However, if the model was computed for \\(y_{1:n}\\) it seems wasteful to ignore it when calculating LOO posterior distributions since \\(p(\\theta | y_{1:n}) \\approx p(\\theta | y_{-i})\\). Importance sampling can be used to sample from the LOO predictive density using the already estimated posterior density as a proposal distribution. Suppose that there a \\(S\\) simulation draws from the full-posterior \\(p(\\theta | y)\\), the importance sampling weights are \\[ r^{s}_i = \\frac{1}{p(y_i | \\theta^s)} \\propto \\frac{p(\\theta^s | y_{-i})}{p(\\theta^{s} | y)} \\] The LOO predictive distribution is approximated by, \\[ \\begin{aligned}[t] p(y_i | y_{-i}) &amp;= \\int p(y_i | \\theta) \\frac{p(\\theta|y_{-i})}{p(\\theta |y)} p(\\theta | y)\\,d \\theta \\\\ &amp;\\approx \\frac{\\sum_{s = 1}^S r^s_i p(y_i | \\theta^{s})}{\\sum_{s = 1}^S r_i^s } . \\end{aligned} \\] An issue with these proposal weights it that the full posterior distribution is likely to be narrower than the LOO posterior distribution. This causes problems for importance sampling, and the weights can be unstable. Vehtari, Gelman, and Gabry (2017) propose a method to regularize the importance weights called Pareto-Smoothed Importance Sampling (PSIS-LOO). A useful side-effect of this method for smoothing these importance weights is that it also provides an indicator for when these weights are unstable. The PSIS is so-called because it estimates a generalized Pareto distribution. Observations where the estimated shape parameter of that Pareto distribution is \\(\\hat{k} &gt; 0.7\\) are unstable, and the PSIS-LOO approximation is poor (Vehtari, Gelman, and Gabry 2017). If a few observations have \\(\\hat{k} &gt; 0.7\\), each of those should be re-estimated with LOO-CV. If many observations have \\(\\hat{k} &gt; 0.7\\), then it may be worth re-estiamting the model using a \\(k\\)-fold cross validation. 10.11 Selection induced Bias See Pirronen and Vehtari (2015), p. 10 Using the training set to select models produces an optimistic estimate. High variance. The model selection process needs to be CV in order to get good estimate of generalization error. CV/WAIC/DIC are highly variable MPP/BMA less so Projection methods are the least. "],
["introduction-to-stan-and-linear-regression.html", "11 Introduction to Stan and Linear Regression Prerequisites 11.1 OLS and MLE Linear Regression 11.2 Stan Model 11.3 Sampling Model with Stan", " 11 Introduction to Stan and Linear Regression This chapter is an introduction to writing and running a Stan model in R. Also see the rstan vignette for similar content. Prerequisites library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) library(&quot;recipes&quot;) For this section we will use the duncan dataset included in the carData package. Duncan’s occupational prestige data is an example dataset used throughout the popular Fox regression text, Applied Regression Analysis and Generalized Linear Models (Fox 2016). It is originally from Duncan (1961) consists of survey data on the prestige of occupations in the US in 1950, and several predictors: type of occupation, income, and education of that data(&quot;Duncan&quot;, package = &quot;carData&quot;) 11.1 OLS and MLE Linear Regression The first step in running a Stan model is defining the Bayesian statistical model that will be used for inference. We will model prestige of each occupation as a function of its education, occupation, and type. A standard way to do this is with the OLS estimator: \\[ \\begin{multline} y_i = \\beta_0 + \\beta_1 I(\\mathtt{type} = \\mathtt{&quot;prof&quot;}) + \\beta_2 I(\\mathtt{type} = \\mathtt{&quot;wc&quot;}) \\\\ \\quad + \\beta_3 \\mathtt{income} + \\beta_4 \\mathtt{education} + \\epsilon_i \\end{multline} \\] duncan_lm &lt;- lm(prestige ~ type + income + education, data = Duncan) \\[ y_i = x_i&#39; \\beta + \\epsilon_i \\] OLS finds \\(\\hat{\\beta}_{OLS}\\) by minimizing the squared errors, \\[ \\hat{\\beta}_{\\text{OLS}} = \\arg \\min_{b} \\sum_{i = 1}^n (y_i - x_i&#39; b)^2 . \\] OLS is an estimator of the (linear approximation of) the conditional expectation function, \\[ \\mathrm{CEF}(y_i | x_i) = E(y_i, x_i&#39; \\beta) . \\] For valid inference we need to make assumptions about \\(\\epsilon_i\\), namely that they are uncorrelated with \\(X\\), \\(\\Cov(\\epsilon, X) = 0\\), and that they are i.i.d, \\(\\Cov(\\epsilon_i, \\epsilon_j) = 0\\), \\(\\Var(\\epsilon_i) = \\sigma^2\\) for all \\(i\\). However, no specific distributional form is or needs to be assumed for \\(\\epsilon\\) since CLT results show that, asymptotically the sampling distribution of \\(\\beta\\) approaches the normal. Additionally, although \\(\\hat\\sigma^2 = \\sum_{i = 1}^n \\epsilon_i / (n - k - 1)\\) is a estimator of \\(\\sigma^2\\), standard errors of the standard error of the regression are not directly provided. However, the OLS estimator is also the same as the MLE estimator for \\(\\beta\\) (but not \\(\\sigma\\)): \\[ \\begin{aligned}[t] p(y_1, \\dots, y_n | \\beta, \\sigma, x_1, \\dots, x_n) &amp;= \\prod_{i = 1}^n p(y_i | \\beta, x_i) \\\\ &amp;= \\prod_{i = 1}^n N(y_i | x_i&#39; \\beta) \\\\ &amp;= \\prod_{i = 1}^n \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\left( \\frac{-(y_i - x_i&#39; \\beta)}{2 \\sigma^2} \\right) \\end{aligned} \\] so, \\[ \\hat{\\beta}_{MLE}, \\hat{\\sigma}_{MLE} = \\arg\\max_{b,s} \\prod_{i = 1}^n N(y_i | x_i&#39; b, s^2) . \\] And \\(\\hat{\\beta}_{MLE} = \\hat{\\beta}_{OLS}\\). Note that the OLS estimator is equivalent to the MLE estimator of \\(\\beta\\), \\[ \\begin{aligned}[t] \\hat{\\beta}_{MLE} &amp;= \\arg \\max_{b} \\prod_{i = 1}^n N(y_i | x_i&#39; b, \\sigma^2) \\\\ &amp;= \\arg \\max_{b} \\prod_{i = 1}^n \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left( \\frac{-(y_i - x_i&#39; \\beta)^2}{2 \\sigma^2} \\right) \\\\ &amp;= \\arg \\max_{b} \\log \\left( \\prod_{i = 1}^n \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left( \\frac{-(y_i - x_i&#39; \\beta)}{2 \\sigma^2} \\right) \\right) \\\\ &amp;= \\arg \\max_{b} \\sum_{i = 1}^n - \\log \\sigma - \\frac{1}{2} \\log 2 \\pi + \\frac{-(y_i - x_i&#39; \\beta)^2}{2 \\sigma^2} \\\\ &amp;= \\arg \\max_{b} \\sum_{i = 1}^n -(y_i - x_i&#39; \\beta)^2 \\\\ &amp;= \\arg \\min_{b} \\sum_{i = 1}^n (y_i - x_i&#39; \\beta)^2 \\\\ &amp;= \\hat{\\beta}_{OLS} \\end{aligned} \\] However, the estimator of \\(\\sigma^2_{MLE} \\neq \\sigma^2_{OLS}\\). 11.1.1 Bayesian Model with Improper priors In Bayesian inference, our target is the posterior distribution of the parameters, \\(\\beta\\) and \\(\\sigma\\): \\(p(\\beta, \\sigma^2 | y, X)\\). \\[ p(\\beta, \\sigma | y, X) \\propto p(y | \\beta, \\sigma) p(\\beta, \\sigma) \\] For a Bayesian linear regression model, we’ll need to specify distributions for \\(p(y | \\beta, \\sigma)\\) and \\(p(\\beta, \\sigma)\\). Likelihood: \\(p(y_i | x_i, \\beta, \\sigma)\\) suppose that the observations are distributed independent normal: \\[ y_i \\sim \\dnorm(\\beta&#39;x_i, \\sigma^2) \\] Priors: The model needs to specify a prior distribution for the parameters \\((\\beta, \\sigma)\\). Rather than specify a single distribution for \\(\\beta\\) and \\(\\sigma\\), it will be easier to specify independent (separate) distributions for \\(\\beta\\) and \\(\\sigma\\). We will use what are called an improper uniform priors. An improper prior is, \\[ p(\\theta) \\propto C \\] where \\(C\\) is some constants. This function puts an equal density on all values of the support of \\(\\theta\\). This function is not a proper probability density function since \\(\\int_{\\theta \\in \\Theta} C d \\theta = \\infty\\). However, for some Bayesian models, the prior does not need to be a proper probability function for the posterior to be a probability function. In this example we will put improper prior distributions on \\(\\beta\\) and \\(\\sigma\\). \\[ p(\\beta, \\sigma) = C \\] \\[ \\begin{aligned} p(\\beta, \\sigma | x, y) &amp;\\propto p(y| \\beta, \\sigma, x) p(\\beta, \\sigma, x) \\\\ &amp;= \\prod_{i = 1}^n N(y_i | x_i&#39; \\beta, \\sigma^2) \\cdot C \\\\ &amp;\\propto \\prod_{i = 1}^n N(y_i | x_i&#39; \\beta, \\sigma^2) \\end{aligned} \\] Note that under the improper priors, the posterior is proportional to the likelihood, \\[ p(\\beta, \\sigma | x, y) \\propto p(y | x, \\beta, \\sigma) \\] Thus the MAP (maximum a posterior) estimator is the same as the MLE, \\[ \\hat{\\beta}_{MAP}, \\hat{\\sigma}_{MAP} = \\arg\\max_{\\beta, \\sigma} p(\\beta, \\sigma | x, y) = \\arg \\max_{\\beta, \\sigma} p(y | x, \\beta, \\sigma) = \\hat{\\beta}_{MLE}, \\hat{\\sigma}_{MLE} \\] 11.2 Stan Model Let’s write and estimate our model in Stan. Stan models are written in its own domain-specific language that focuses on declaring the statistical model (parameters, variables, distributions) while leaving the details of the sampling algorithm to Stan. A Stan model consists of blocks which contain declarations of variables and/or statements. Each block has a specific purpose in the model. 11.3 Sampling Model with Stan functions { // OPTIONAL: user-defined functions } data { // read in data ... } transformed data { // Create new variables/auxiliary variables from the data } parameters { // Declare parameters that will be estimated } transformed parameters { // Create new variables/auxiliary variables from the parameters } model { // Declare your probability model: priors, hyperpriors &amp; likelihood } generated quantities { // Declare any quantities other than simulated parameters to be generated } The file lm0.stan is a Stan model for the linear regression model previously defined. // lm_normal_1.stan // Linear Model with Normal Errors data { // number of observations int N; // response vector[N] y; // number of columns in the design matrix X int K; // design matrix X // should not include an intercept matrix [N, K] X; // priors on alpha real scale_alpha; vector[K] scale_beta; real loc_sigma; // keep responses int use_y_rep; int use_log_lik; } parameters { // regression coefficient vector real alpha; vector[K] beta; real sigma; } transformed parameters { vector[N] mu; mu = alpha + X * beta; } model { // priors alpha ~ normal(0., scale_alpha); beta ~ normal(0., scale_beta); sigma ~ exponential(loc_sigma); // likelihood y ~ normal(mu, sigma); } generated quantities { // simulate data from the posterior vector[N * use_y_rep] y_rep; // log-likelihood posterior vector[N * use_log_lik] log_lik; for (i in 1:num_elements(y_rep)) { y_rep[i] = normal_rng(mu[i], sigma); } for (i in 1:num_elements(log_lik)) { log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); } } mod1 &lt;- stan_model(&quot;stan/lm_normal_1.stan&quot;) See the Stan Modeling Language User’s Guide and Reference Manual for details of the Stan Language. NoteSince a Stan model compiles to C++ code, you may receive some warning messages such as /Library/Frameworks/R.framework/Versions/3.3/Resources/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function] static void set_zero_all_adjoints() { ^ In file included from file1d4a4d50faa.cpp:8: In file included from /Library/Frameworks/R.framework/Versions/3.3/Resources/library/StanHeaders/include/src/stan/model/model_header.hpp:4: As long as your model compiles, you can ignore these compiler warnings (On the other hard, warnings that occur during sampling should not be ignored). If the Stan model does not give you a syntax error when parsing the model, it should compile to valid C++.[^bugs][^c-warnings] See [bugs]: In the rare case that the Stan parser transpiles the Stan model to C++ but cannot compile the C++ code, it is a bug in Stan. Follow the instructions on how to inform the Stan developers about bugs. [c-warnings]: The extended installation instructions for MacOS/Linux and Windows have instructions for adding compiler options to the R Makevars file. 11.3.1 Sampling In order to sample from the model, we need to at least give it the values for the data to use: `,k,y,X`, and the data associated with the priors. The data types in Stan are all numeric (either integers or reals), but they include matrices and vectors. However, there is nothing like a data frame in Stan. Whereas in the R function lm we can provide a formula and a data set for where to look for objects, and the function will create the appropriate \\(X\\) matrix for the regression, we will need to create that matrix ourselves—expanding categorical variables to indicator variables, and expanding interactions and other functions of the predictors. rec &lt;- recipe(prestige ~ income + education + type, data = Duncan) %&gt;% step_dummy(type) %&gt;% prep(data = Duncan, retain = TRUE) X &lt;- juice(rec, all_predictors(), composition = &quot;matrix&quot;) y &lt;- drop(juice(rec, all_outcomes(), composition = &quot;matrix&quot;)) mod1_data &lt;- list( X = X, K = ncol(X), N = nrow(X), y = y, use_y_rep = FALSE, use_log_lik = FALSE ) We still need to provide the values for the prior distributions. For specific values of the prior distributions, assume uninformative priors for beta by setting the mean to zero and the variances to large numbers. mod1_data$scale_alpha &lt;- sd(y) * 10 mod1_data$scale_beta &lt;- apply(X, 2, sd) * sd(y) * 2.5 mod1_data$loc_sigma &lt;- sd(y) Now, sample from the posterior, using the function sampling: mod1_fit &lt;- sampling(mod1, data = mod1_data) summary(mod1_fit) 11.3.2 Convergence Diagnostics and Model Fit Convergence Diagnostics: Is this the posterior distribution that you were looking for? These don’t directly say anything about how “good” the model is in terms representing the data, they are only evaluating how well the sampler is doing at sampling the posterior distribution of the given model. If there are problems with these, then the sample results do not represent the posterior distribution, and your inferences will be biased. mcse: n_eff: Rhat divergences Model fit: Is this statistical model appropriate for the data? Or better than other models? Posterior predictive checks Information criteria: WAIC Leave-one-out Cross-Validation "],
["generalized-linear-models.html", "12 Generalized Linear Models Prerequisites 12.1 Introduction 12.2 Count Models 12.3 Example 12.4 Negative Binomial 12.5 Multinomial / Categorical Models 12.6 Gamma Regression 12.7 Beta Regression 12.8 References", " 12 Generalized Linear Models Prerequisites library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) 12.1 Introduction Generalized linear models (GLMs) are a class of commonly used models. In GLMs, the mean is specified as a function of a linear model of predictors, \\[ E(Y) = \\mu = g^{-1}(\\mat{X} \\vec{\\beta}) . \\] GLMs are a generalization of linear regression from an unbounded continuous outcome variable to other types of data: binary, count, categorical, bounded continuous. A GLM consists of three components: A probability distribution (family) specifying the conditional distribution of the response variable. In GLMs, the distribution is in the exponential family: Normal, Binomial, Poisson, Categorical, Multinomial, Poisson, Beta. A linear predictor, which is a linear function of the predictors, \\[ \\eta = \\mat{X} \\vec{\\beta}. \\] A link function (\\(g(.)\\)) which maps the expected value to the the linear predictor, \\[ g(\\mu) = \\eta . \\] The link function is smooth and invertible, and the inverse link function or mean function maps the linear predictor to the mean, \\[ \\mu = g^{-1}(\\eta) . \\] The link function (\\(g\\)) and its inverse ($g^{-1}) translate \\(\\eta\\) from \\((\\-infty, +\\infty)\\) to the proper range for the probability distribution and back again. These models are often estimated with MLE, as with the function stats. These are also easily estimated in a Bayesian setting. See the help for stats for common probability distributions, stats for common links, and the Wikipedia page for a table of common GLMs. See the function VGAM for even more examples of link functions and probability distributions. 12.2 Count Models 12.2.1 Poisson The Poisson model is used for unbounded count data, \\[ Y = 0, 1, \\dots, \\infty \\] The outcome is modeled as a Poisson distribution \\[ y_i \\sim \\dpois(\\lambda_i) \\] with positive mean parameter \\(\\lambda_i \\in (0, \\infty)\\). Since \\(\\lambda_i\\) has to be positive, the most common link function is the log, \\[ \\log(\\lambda_i) = \\exp(\\vec{x}_i&#39; \\vec{\\beta}) \\] which has the inverse, \\[ \\lambda_i = \\log(\\vec{x}_i \\vec{\\beta}) \\] In Stan, the Poisson distribution has two implementations: poisson_lpdf poisson_log_lpdf: Poisson with a log link. This is for numeric stability. Also, rstanarm supports the Poisson. 12.3 Example A regression model of bilateral sanctions for the period 1939 to 1983. The outcome variable is the number of countries imposing sanctions. data(&quot;sanction&quot;, package = &quot;Zelig&quot;) TODO 12.4 Negative Binomial The Negative Binomial model is also used for unbounded count data, \\[ Y = 0, 1, \\dots, \\infty \\] The Poisson distribution has the restriction that the mean is equal to the variance, \\(\\E(X) = \\Var(X) = \\lambda\\). The Negative Binomial distribution has an additional parameter that allows the variance to vary (though it is always larger than the mean). The outcome is modeled as a negative binomial distribution, \\[ y_i \\sim \\dBinom(\\alpha_i, \\beta) \\] with shape \\(\\alpha \\in \\R^{+}\\) and inverse scale \\(\\beta \\in \\R^{+}\\), and \\(\\E(y) = \\alpha_i / \\beta\\) and \\(\\Var(Y) = \\frac{\\alpha_i}{\\beta^2}(\\beta + 1)\\). Then the mean can be modeled and transformed to the \\[ \\begin{aligned}[t] \\mu_i &amp;= \\log( \\vec{x}_i \\vec{\\gamma} ) \\\\ \\alpha_i &amp;= \\mu_i / \\beta \\end{aligned} \\] Important The negative binomial distribution has many different parameterizations. An alternative parameterization of the negative binomial uses the mean and a over-dispersion parameter. \\[ y_i \\sim \\dnbinomalt(\\mu_i, \\phi) \\] with location parameter \\(\\mu \\in \\R^{+}\\) and over-dispersion parameter \\(\\phi \\in \\R^{+}\\), and \\(\\E(y) = \\mu_i\\) and \\(\\Var(Y) = \\mu_i + \\frac{\\mu_i^2}{\\phi}\\). Then the mean can be modeled and transformed to the \\[ \\begin{aligned}[t] \\mu_i &amp;= \\log( \\vec{x}_i \\vec{\\gamma} ) \\\\ \\end{aligned} \\] In Stan, there are multiple parameterizations of the neg_binomial_lpdf(y | alpha, beta)with shape parameter alpha and inverse scale parameter beta. neg_binomial_2_lpdf(y | mu, phi) with mean mu and over-dispersion parameter phi. neg_binomial_2_log_lpdf(y | eta, phi) with log-mean eta and over-dispersion parameter phi Also, rstanarm supports Poisson and negative binomial models. A. Gelman, Carlin, et al. (2013 Ch 16) 12.5 Multinomial / Categorical Models 12.6 Gamma Regression The response variable is continuous and positive. In gamma regression, the coefficient of variation is constant rather than the variance. \\[ y_i \\sim \\dgamma(\\alpha_i, \\beta) \\] and \\[ \\begin{aligned}[t] \\alpha_i &amp;= \\mu_i / \\beta \\\\ \\mu_i &amp;= \\vec{x}_i \\vec{\\gamma} \\end{aligned} \\] In Stan, gamma(y | alpha, beta) with shape parameter \\(\\alpha &gt; 0\\) and inverse scale parameter \\(\\beta &gt; 0\\). Then \\(\\E(Y) = \\alpha / \\beta\\) and \\(\\Var(Y) = \\alpha / \\beta^2\\). 12.7 Beta Regression This is for a response variable that is a proportion, \\(y_i \\in (0, 1)\\), \\[ y_i \\sim \\dbeta(\\alpha_i, \\beta_i) \\] and \\[ \\begin{aligned}[t] \\mu_i &amp;= g^{-1}(\\vec{x}_i&#39; \\vec{\\gamma}) \\\\ \\alpha_i &amp;= \\mu_i \\phi \\\\ \\beta_i &amp;= (1 - \\mu_i) \\phi \\end{aligned} \\] Additionally, the \\(\\phi\\) parameter could also be modeled. In Stan: beta(y | alpha, beta) with positive prior successes plus one, \\(\\alpha &gt; 0\\), and negative prior failures plus one, \\(\\beta &gt; 0\\). Then \\(\\E(Y) = \\alpha / (\\alpha + \\beta)\\) and \\(\\Var(Y) = \\alpha\\beta / ((\\alpha + \\beta)^2 (\\alpha + \\beta + 1))\\). rstanarm function rstasnarm See: Ferrari and Cribari-Neto (2004), Cribari-Neto and Zeileis (2010), and Grün, Kosmidis, and Zeileis (2012) on beta regression. rstanarm documentation Modeling Rates/Proportions using Beta Regression with rstanarm 12.8 References For general references on count models see A. Gelman and Hill (2007, 109–16) McElreath (2016 Ch 10) Fox (2016 Ch. 14) A. Gelman, Carlin, et al. (2013 Ch. 16) A. Gelman, Carlin, et al. (2013 Ch 16), A. Gelman and Hill (2007 Ch. 5-6), McElreath (2016 Ch. 9). King (1998) discusses MLE estimation of many common GLM models. Many econometrics/statistics textbooks, e.g. Fox (2016), discuss GLMs. Though they are not derived from a Bayesian context, they can easily transferred. "],
["binomial-models.html", "13 Binomial Models Prerequisites 13.1 Introduction 13.2 Link Functions {link-function} 13.3 References", " 13 Binomial Models Prerequisites library(&quot;rstan&quot;) library(&quot;rstanarm&quot;) library(&quot;tidyverse&quot;) library(&quot;recipes&quot;) library(&quot;bayz&quot;) 13.1 Introduction Binomial models are used to an outcome that is a bounded integer, \\[ y_i \\in 0, 1, 2, \\dots, n . \\] The outcome is distributed Binomial, \\[ \\begin{aligned}[t] y_i \\sim \\dBinom \\left(n_i, \\pi \\right) \\end{aligned} \\] A binary outcome is a common special case, \\[ y_i \\in \\{0, 1\\}, \\] and \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dBinom \\left(1, \\pi \\right) &amp; \\text{for all $i$} \\\\ \\end{aligned} \\] Depending on the link function, these are logit and probit models that appear in the literature. 13.2 Link Functions {link-function} The parameter \\(\\pi \\in (0, 1)\\) is often modeled with a link function is and a linear predictor. \\[ \\pi_i = g^{-1}(\\vec{x}_i \\vec{\\beta}) \\] There are several common link functions, but they all have to map \\(R \\to (0, 1)\\).7 Logit: The logistic function, \\[ \\pi_i = \\logistic(x_i\\T \\beta) = \\frac{1}{1 + \\exp(- x_i\\T\\beta)} . \\] Stan function softmax. Probit: The CDF of the normal distribution. \\[ \\pi_i = \\Phi(x_i\\T \\beta) \\] Stan function normal_cdf. cauchit: The CDF of the Cauchy distribution. Stan function cauchy_cdf. cloglog: The inverse of the conditional log-log function (cloglog) is \\[ \\pi_i = 1 - \\exp(-\\exp(x_i\\T \\beta)) . \\] Stan function inv_cloglog. Of these link functions, the probit has the narrowest tails (sensitivity to outliers), followed by the logit, and cauchit. The cloglog function is different in that it is asymmetric.8 At zero its value is above 0.5, whereas the cauchit, logit, and probit links all equal 0.5 at 0, make.link(&quot;cloglog&quot;)$linkinv(0) #&gt; [1] 0.632 map(c(&quot;logit&quot;, &quot;probit&quot;, &quot;cauchit&quot;, &quot;cloglog&quot;), make.link) %&gt;% map_df( function(link) { tibble(x = seq(-4, 4, length.out = 101), y = link$linkinv(x), link_name = link$name) } ) %&gt;% ggplot(aes(x = x, y = y, colour = link_name)) + geom_line() Notes: The logistic distribution is approximately a Student-t with df=7. 13.2.1 Stan In Stan, the Binomial distribution has two implementations: binomial_lpdf binomial_logit_lpdf. The later implementation is for numeric stability. Taking an exponential of a value can be numerically unstable, and binomial_logit_lpdf input is on the logit scale: Whereas, \\[ y_i \\sim \\mathsf{binomial}(1 / (1 + \\exp(x_i \\beta))) \\] the following is true, \\[ y_i \\sim \\mathsf{binomial\\_logit}(x_i \\beta) \\] 13.2.2 Example: Vote Turnout Estimate a model of vote turnout in the 1992 from the American National Election Survey (ANES) as a function of race, age, and education. The data and example is from the Zelig library Zelig.9 You can load it with data(&quot;turnout&quot;, package = &quot;ZeligData&quot;) 13.2.3 Stan A general Stan model for estimating logit models is: // bernoulli_logit_1.stan data { // number of observations int N; // response // vectors are only real numbers // need to use an array int y[N]; // number of columns in the design matrix X int K; // design matrix X // should not include an intercept matrix [N, K] X; // priors on regression coefficients real scale_alpha; vector[K] scale_beta; // keep responses int use_y_rep; int use_log_lik; } parameters { // regression coefficient vector real alpha; vector[K] beta; } transformed parameters { vector[N] eta; eta = alpha + X * beta; } model { // priors alpha ~ normal(0., scale_alpha); beta ~ normal(0., scale_beta); // likelihood y ~ bernoulli_logit(eta); } generated quantities { // simulate data from the posterior vector[N * use_y_rep] y_rep; // log-likelihood posterior vector[N * use_log_lik] log_lik; for (i in 1:num_elements(y_rep)) { y_rep[i] = bernoulli_rng(inv_logit(eta[i])); } for (i in 1:num_elements(log_lik)) { log_lik[i] = bernoulli_logit_lpmf(y[i] | eta[i]); } } data(&quot;turnout&quot;, package = &quot;ZeligData&quot;) Vote choice (vote) is modeled as a function of age, age-squared, income, and race. Preprocess the data to create the design matrix, X, and the response y using the recipes package. We will need to center and scale the design matrix. turnout &lt;- mutate(turnout, white = as.numeric(race == &quot;white&quot;)) rec_turnout &lt;- recipe(vote ~ income + age + white, data = turnout) %&gt;% step_poly(age, options = list(degree = 2)) %&gt;% prep(data = turnout, retain = TRUE) X &lt;- juice(rec_turnout, all_predictors(), composition = &quot;matrix&quot;) y &lt;- juice(rec_turnout, all_outcomes(), composition = &quot;matrix&quot;) %&gt;% drop() mod1_data &lt;- list( X = X, N = nrow(X), K = ncol(X), y = y, scale_alpha = 10, scale_beta = 2.5 * apply(X, 2, sd), use_y_rep = FALSE, use_log_lik = TRUE ) 13.2.3.1 rstanarm The rstanarm package can estimate binomial models using the function stan_glm: fit2 &lt;- stan_glm(vote ~ income + age + white, data = turnout) 13.3 References For general references on binomial models see Stan Development Team (2016 Sec. 8.5), McElreath (2016 Ch 10), A. Gelman and Hill (2007) [Ch. 5; Sec 6.4-6.5], Fox (2016 Ch. 14), and A. Gelman, Carlin, et al. (2013 Ch. 16). Since the cumulative distribution function of a distribution maps reals to \\((0, 1)\\), any CDF can be used as a link function.↩ Beck, Katz, and Tucker (1998) show that the cloglog link function can be derived from a grouped duration model with binary response variables.↩ Example from Zelig-logit.↩ "],
["separtion.html", "14 Separation Prerequisites 14.1 Introduction 14.2 Complete Separation 14.3 Quasi-Separation 14.4 Weak Priors 14.5 Example: Support of ACA Medicaid Expansion 14.6 Questions 14.7 References", " 14 Separation Prerequisites library(&quot;rstan&quot;) library(&quot;rstanarm&quot;) library(&quot;tidyverse&quot;) library(&quot;recipes&quot;) library(&quot;jrnold.bayes.notes&quot;) 14.1 Introduction Separation is when a predictor perfectly predicts a binary response variable (Rainey 2016, @Zorn2005a). For classification problems, there are three cases. complete separation: the predictor perfectly predicts both 0’s and 1’s. quasi-complete separation: the predictor perfectly predicts either 0’s or 1’s. overlap: the predictor does not perfectly predict either 0’s or 1’s. Both complete separation and quasi-complete separation cause problems for binomial maximum likelihood estimators. 14.2 Complete Separation The following data is an example of data with complete separation.10 CompleteSeparation #&gt; # A tibble: 8 x 3 #&gt; y x1 x2 #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 1 3 #&gt; 2 0 2 2 #&gt; 3 0 3 -1 #&gt; 4 0 3 -1 #&gt; 5 1 5 2 #&gt; 6 1 6 4 #&gt; # ... with 2 more rows count(CompleteSeparation, y, x1) %&gt;% group_by(x1) %&gt;% mutate(p = n / sum(n)) %&gt;% select(-n) %&gt;% spread(y, p, fill = 0) #&gt; # A tibble: 7 x 3 #&gt; # Groups: x1 [7] #&gt; x1 `0` `1` #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 0 #&gt; 2 2 1 0 #&gt; 3 3 1 0 #&gt; 4 5 0 1 #&gt; 5 6 0 1 #&gt; 6 10 0 1 #&gt; # ... with 1 more row The variable x1 perfectly separates y, since when x1 &lt;= 3, y = 0, and when x1 &gt; 3, y = 1. The MLE of the binomial likelihood with a logistic link function for this data has a finite log-likelihood, but the optimal line is a step function. This pushes the coefficient for the separating variable to \\(\\infty\\). ggplot(CompleteSeparation, aes(x = x1, y = y)) + geom_point() + geom_smooth(method = &quot;glm&quot;, formula = y ~ x, se = FALSE, method.args = list(family = binomial()), colour = &quot;gray&quot;) #&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred If we estimate a binomial model with this data, it will warn that some observations have predicted probabilities close to zero or one. fit_cs1 &lt;- glm(y ~ x1 + x2, data = CompleteSeparation, family = binomial()) #&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred summary(fit_cs1) #&gt; #&gt; Call: #&gt; glm(formula = y ~ x1 + x2, family = binomial(), data = CompleteSeparation) #&gt; #&gt; Deviance Residuals: #&gt; 1 2 3 4 5 6 #&gt; -2.10e-08 -1.40e-05 -2.52e-06 -2.52e-06 1.56e-05 2.10e-08 #&gt; 7 8 #&gt; 2.10e-08 2.10e-08 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) -66.10 183471.72 0 1 #&gt; x1 15.29 27362.84 0 1 #&gt; x2 6.24 81543.72 0 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 1.1090e+01 on 7 degrees of freedom #&gt; Residual deviance: 4.5454e-10 on 5 degrees of freedom #&gt; AIC: 6 #&gt; #&gt; Number of Fisher Scoring iterations: 24 Additionally, the standard errors are implausibly large. 14.3 Quasi-Separation The following generated data is an example of quasi-separation.[^quasi-separation] knitr::kable(QuasiSeparation) y x1 x2 0 1 3 0 2 0 0 3 -1 0 3 4 1 3 1 1 4 0 1 5 2 1 6 7 1 10 3 1 11 4 The variable x1 almost separates y. When x1 &lt; 3, y = 0, and when x1 &gt; 3, y = 1. Only when x1 = 3, does y takes values of both 0 and 1. count(QuasiSeparation, y, x1) %&gt;% group_by(x1) %&gt;% mutate(p = n / sum(n)) %&gt;% select(-n) %&gt;% spread(y, p, fill = 0) #&gt; # A tibble: 8 x 3 #&gt; # Groups: x1 [8] #&gt; x1 `0` `1` #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 0 #&gt; 2 2 1 0 #&gt; 3 3 0.667 0.333 #&gt; 4 4 0 1 #&gt; 5 5 0 1 #&gt; 6 6 0 1 #&gt; # ... with 2 more rows In the quasi-separation case, like the complete separation case, the best line is something close to a step function. Unlike the complete separation case, the coefficient for the separating variable takes a finite, but very large value. ggplot(QuasiSeparation, aes(x = x1, y = y)) + geom_point() + geom_smooth(method = &quot;glm&quot;, formula = y ~ x, se = FALSE, method.args = list(family = binomial()), colour = &quot;gray&quot;) #&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred fit_qs1 &lt;- glm(y ~ x1 + x2, data = QuasiSeparation, family = binomial()) #&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred summary(fit_qs1) #&gt; #&gt; Call: #&gt; glm(formula = y ~ x1 + x2, family = binomial(), data = QuasiSeparation) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -1.0042 -0.0001 0.0000 0.0000 1.4689 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) -58.076 17511.903 0.0 1.00 #&gt; x1 19.178 5837.301 0.0 1.00 #&gt; x2 -0.121 0.610 -0.2 0.84 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 13.4602 on 9 degrees of freedom #&gt; Residual deviance: 3.7792 on 7 degrees of freedom #&gt; AIC: 9.779 #&gt; #&gt; Number of Fisher Scoring iterations: 21 14.4 Weak Priors While the likelihood is unidentified, weakly informative priors on the regression coefficients will deal with separation. \\[ \\beta_k \\sim \\dnorm(0, 2.5) \\] where all the columns of \\(\\code{x}\\) are assumed to have unit variance (or be otherwise standardized). The half-Cauchy prior, \\(\\dhalfcauchy(0, 2.5)\\), suggested in Gelman et al. (2008) is insufficiently informative to to deal with separation (J. Ghosh, Li, and Mitra 2015), but finite-variance weakly informative Student-t or Normal distributions will work. These are the priors suggested by Stan and used by default in rstanarm rstanarm. When estimated with stan_glm(), the coefficients of both the complete separation and quasi-separated data are finite. fit_cs2 &lt;- stan_glm(y ~ x1 + x2, data = CompleteSeparation, family = binomial()) summary(fit_cs2) #&gt; #&gt; Model Info: #&gt; #&gt; function: stan_glm #&gt; family: binomial [logit] #&gt; formula: y ~ x1 + x2 #&gt; algorithm: sampling #&gt; priors: see help(&#39;prior_summary&#39;) #&gt; sample: 4000 (posterior sample size) #&gt; observations: 8 #&gt; predictors: 3 #&gt; #&gt; Estimates: #&gt; mean sd 2.5% 25% 50% 75% 97.5% #&gt; (Intercept) -6.2 2.7 -12.1 -7.8 -5.9 -4.3 -1.6 #&gt; x1 1.1 0.4 0.3 0.8 1.0 1.3 2.1 #&gt; x2 0.9 0.8 -0.5 0.3 0.8 1.3 2.5 #&gt; mean_PPD 0.5 0.1 0.2 0.4 0.5 0.6 0.8 #&gt; log-posterior -8.4 1.4 -11.8 -9.1 -8.1 -7.4 -6.9 #&gt; #&gt; Diagnostics: #&gt; mcse Rhat n_eff #&gt; (Intercept) 0.1 1.0 2090 #&gt; x1 0.0 1.0 2114 #&gt; x2 0.0 1.0 2412 #&gt; mean_PPD 0.0 1.0 3796 #&gt; log-posterior 0.0 1.0 1641 #&gt; #&gt; For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). fit_qs2 &lt;- stan_glm(y ~ x1 + x2, data = QuasiSeparation, family = binomial()) summary(fit_qs2) #&gt; #&gt; Model Info: #&gt; #&gt; function: stan_glm #&gt; family: binomial [logit] #&gt; formula: y ~ x1 + x2 #&gt; algorithm: sampling #&gt; priors: see help(&#39;prior_summary&#39;) #&gt; sample: 4000 (posterior sample size) #&gt; observations: 10 #&gt; predictors: 3 #&gt; #&gt; Estimates: #&gt; mean sd 2.5% 25% 50% 75% 97.5% #&gt; (Intercept) -3.7 1.9 -7.6 -4.9 -3.6 -2.3 -0.2 #&gt; x1 1.1 0.5 0.2 0.7 1.1 1.4 2.2 #&gt; x2 0.0 0.4 -0.7 -0.2 0.0 0.3 0.9 #&gt; mean_PPD 0.6 0.2 0.3 0.5 0.6 0.7 0.9 #&gt; log-posterior -10.5 1.3 -13.8 -11.1 -10.2 -9.5 -9.0 #&gt; #&gt; Diagnostics: #&gt; mcse Rhat n_eff #&gt; (Intercept) 0.0 1.0 2746 #&gt; x1 0.0 1.0 1596 #&gt; x2 0.0 1.0 2469 #&gt; mean_PPD 0.0 1.0 3688 #&gt; log-posterior 0.0 1.0 1509 #&gt; #&gt; For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). 14.5 Example: Support of ACA Medicaid Expansion This example is from Rainey (2016) from the original paper Barrilleaux and Rainey (2014) with replication code here. Load the data included in the jrnold.bayes.notes package: data(&quot;politics_and_need&quot;, package = &quot;jrnold.bayes.notes&quot;) The observations are the governors of the US states. The outcome variable is their votes on the Affordable Care Act (ACA) Medicaid Expansion. The dataset includes multiple predictors, including whether the governor is a Republican (gop_governor). Add Democratic governors supported the expansion (gop_governor == 0), and only Republican governors (gop_governor == 1) opposed it (though not all). # count(politics_and_need, gop_governor, oppose_expansion) This is a case of quasi-separation. What happens when this model is estimated with MLE by glm()? aca_fmla &lt;- oppose_expansion ~ gop_governor + percent_favorable_aca + gop_leg + percent_uninsured + bal2012 + multiplier + percent_nonwhite + percent_metro fit_aca1 &lt;- glm(aca_fmla, data = politics_and_need, family = binomial()) summary(fit_aca1) #&gt; #&gt; Call: #&gt; glm(formula = aca_fmla, family = binomial(), data = politics_and_need) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -1.738 -0.455 0.000 0.591 2.350 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) -1.94e+01 3.22e+03 -0.01 1.00 #&gt; gop_governor 2.03e+01 3.22e+03 0.01 0.99 #&gt; percent_favorable_aca 7.31e-03 8.88e-02 0.08 0.93 #&gt; gop_leg 2.43e+00 1.48e+00 1.64 0.10 #&gt; percent_uninsured 1.12e-01 2.72e-01 0.41 0.68 #&gt; bal2012 -7.12e-04 1.14e-02 -0.06 0.95 #&gt; multiplier -3.22e-01 1.08e+00 -0.30 0.77 #&gt; percent_nonwhite 4.52e-02 8.25e-02 0.55 0.58 #&gt; percent_metro -7.75e-02 4.74e-02 -1.64 0.10 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 62.687 on 49 degrees of freedom #&gt; Residual deviance: 31.710 on 41 degrees of freedom #&gt; AIC: 49.71 #&gt; #&gt; Number of Fisher Scoring iterations: 19 Now estimate with rstanarm using the default weakly informative priors. fit_aca2 &lt;- stan_glm(aca_fmla, data = politics_and_need, family = &quot;binomial&quot;, show_messages = FALSE, refresh = -1, verbose = FALSE) summary(fit_aca2) #&gt; #&gt; Model Info: #&gt; #&gt; function: stan_glm #&gt; family: binomial [logit] #&gt; formula: oppose_expansion ~ gop_governor + percent_favorable_aca + gop_leg + #&gt; percent_uninsured + bal2012 + multiplier + percent_nonwhite + #&gt; percent_metro #&gt; algorithm: sampling #&gt; priors: see help(&#39;prior_summary&#39;) #&gt; sample: 4000 (posterior sample size) #&gt; observations: 50 #&gt; predictors: 9 #&gt; #&gt; Estimates: #&gt; mean sd 2.5% 25% 50% 75% 97.5% #&gt; (Intercept) -3.6 5.1 -13.6 -6.9 -3.6 -0.2 6.5 #&gt; gop_governor 3.9 1.6 1.2 2.8 3.8 4.9 7.2 #&gt; percent_favorable_aca 0.0 0.1 -0.2 -0.1 0.0 0.0 0.1 #&gt; gop_leg 2.4 1.3 0.0 1.5 2.3 3.2 5.1 #&gt; percent_uninsured 0.1 0.2 -0.2 0.0 0.1 0.2 0.5 #&gt; bal2012 0.0 0.0 0.0 0.0 0.0 0.0 0.0 #&gt; multiplier -0.3 1.0 -2.3 -0.9 -0.3 0.4 1.8 #&gt; percent_nonwhite 0.0 0.1 -0.1 0.0 0.0 0.1 0.1 #&gt; percent_metro -0.1 0.0 -0.1 -0.1 -0.1 0.0 0.0 #&gt; mean_PPD 0.3 0.1 0.2 0.3 0.3 0.4 0.4 #&gt; log-posterior -33.3 2.4 -38.9 -34.6 -32.9 -31.6 -29.8 #&gt; #&gt; Diagnostics: #&gt; mcse Rhat n_eff #&gt; (Intercept) 0.1 1.0 2754 #&gt; gop_governor 0.0 1.0 2598 #&gt; percent_favorable_aca 0.0 1.0 3106 #&gt; gop_leg 0.0 1.0 3302 #&gt; percent_uninsured 0.0 1.0 2520 #&gt; bal2012 0.0 1.0 2774 #&gt; multiplier 0.0 1.0 3142 #&gt; percent_nonwhite 0.0 1.0 2253 #&gt; percent_metro 0.0 1.0 3371 #&gt; mean_PPD 0.0 1.0 4000 #&gt; log-posterior 0.1 1.0 1385 #&gt; #&gt; For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). 14.6 Questions Estimate the model using stan_glm() with a flat prior, and a Student-t distribution with df = 3. Compare the coefficient estimates and the efficiency (\\(\\hat{R}\\), ESS). J. Ghosh, Li, and Mitra (2015) suggest that a Half-Cauchy prior distribution is insufficient for dealing with separation. Try estimating this model with a Cauchy prior with a scale of 2.5. Compare the coefficient estimates and efficiency (\\(\\hat{R}\\), ESS). See the other application in Rainey (2016) on nuclear proliferation and war. Replicate the analysis with the informative, skeptical, and enthusiastic priors. The data can be found at carlislerainey/priors-for-separation. 14.7 References See Albert and Anderson (1984), Heinze and Schemper (2002), and Heinze (2006) for discussion about separation. Rainey (2016) provides a mixed MLE/Bayesian simulation based approach to apply a prior to the variable with separation, while keeping the other coefficients at their MLE values. Since the results are highly sensitive to the prior, multiple priors should be tried (informative, skeptical, and enthusiastic). Firth (1993) suggests a data-driven Jeffreys invariant prior. This prior was also recommended in Zorn (2005). Greenland and Mansournia (2015) suggest a log-F prior distribution which has an intuitive interpretation related to the number of observations. FAQ: What is Complete or Quasi-Complete Separation in Logistic/Probit Regression and How do We Deal With Them?↩ "],
["robust-regression.html", "15 Robust Regression Prerequisites 15.1 Wide Tailed Distributions 15.2 Student-t distribution 15.3 Robit 15.4 Quantile regression 15.5 References", " 15 Robust Regression Prerequisites library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) library(&quot;rstanarm&quot;) library(&quot;bayz&quot;) library(&quot;loo&quot;) library(&quot;jrnold.bayes.notes&quot;) library(&quot;recipes&quot;) 15.1 Wide Tailed Distributions Like OLS, Bayesian linear regression with normally distributed errors is sensitive to outliers. This is because the normal distribution has narrow tail probabilities, with approximately 99.8% of the probability within three standard deviations. Robust regression refers to regression methods which are less sensitive to outliers. Bayesian robust regression uses distributions with wider tails than the normal instead of the normal. This plots the normal, Double Exponential (Laplace), and Student-t (\\(df = 4\\)) distributions all with mean 0 and scale 1, and the surprise (\\(- log(p)\\)) at each point. Both the Student-\\(t\\) and Double Exponential distributions have surprise values well below the normal in the ranges (-6, 6).11 This means that outliers will have less of an affect on the log-posterior of models using these distributions. The regression line would need to move less incorporate those observations since the error distribution will not consider them as unusual. 15.2 Student-t distribution The most commonly used Bayesian model for robust regression is a linear regression with independent Student-\\(t\\) errors (Geweke 1993; A. Gelman, Carlin, et al. 2013, Ch. 17): \\[ y_i \\sim \\dt\\left(\\nu, \\mu_i, \\sigma \\right) \\] where \\(\\nu \\in \\R^{+}\\) is a degrees of freedom parameter, \\(\\mu_i \\in \\R\\) are observation specific locations often modeled with a regression, and and \\(\\sigma \\in R^{+}\\) is a the scale parameter. Note that as \\(\\nu \\to \\infty\\), this model approaches an independent normal model, since the Student-t distribution asymptotically approaches the normal distribution as the degrees of freedom increases. For the value of \\(\\nu\\), either a low degrees of freedom \\(\\nu \\in (4, 6)\\) can be used, or it can be given a prior distribution. For the Student-t distribution, the existence of various moments depends on the value of \\(\\nu\\): the mean exists for \\(\\nu &gt; 1\\), variance for \\(\\nu &gt; 2\\), and kurtosis for \\(\\nu &gt; 3\\). As such, it is often useful to restrict the support of \\(\\nu\\) to at least 1 or 2 (or even higher) ensure the existence of a mean or variance. A reasonable prior distribution for the degrees of freedom parameter is a Gamma distribution with shape parameter 2, and an inverse-scale (rate) parameter of 0.1 (Juárez and Steel 2010,@Stan-prior-choices), \\[ \\nu \\sim \\dgamma(2, 0.1) . \\] This density places the majority of the prior mass for values \\(\\nu &lt; 50\\), in which the Student-\\(t\\) distribution is substantively different from the Normal distribution, and also allows for all prior moments to exist. The Stan model that estimates this is lm_student_t_1.stan: // lm_student_t_1.stan // Linear Model with Student-t Errors data { // number of observations int N; // response vector[N] y; // number of columns in the design matrix X int K; // design matrix X // should not include an intercept matrix [N, K] X; // priors on alpha real scale_alpha; vector[K] scale_beta; real loc_sigma; // keep responses int use_y_rep; int use_log_lik; } parameters { // regression coefficient vector real alpha; vector[K] beta; real sigma; // degrees of freedom; // limit df = 2 so that there is a finite variance real nu; } transformed parameters { vector[N] mu; mu = alpha + X * beta; } model { // priors alpha ~ normal(0.0, scale_alpha); beta ~ normal(0.0, scale_beta); sigma ~ exponential(loc_sigma); // see Stan prior distribution suggestions nu ~ gamma(2, 0.1); // likelihood y ~ student_t(nu, mu, sigma); } generated quantities { // simulate data from the posterior vector[N * use_y_rep] y_rep; // log-likelihood posterior vector[N * use_log_lik] log_lik; for (i in 1:num_elements(y_rep)) { y_rep[i] = student_t_rng(nu, mu[i], sigma); } for (i in 1:num_elements(log_lik)) { log_lik[i] = student_t_lpdf(y[i] | nu, mu[i], sigma); } } As noted in Heteroskedasticity, the Student-t distribution can be represented as a scale-mixture of normal distributions, where the inverse-variances (precisions) follow a Gamma distribution, \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm\\left(\\mu_i, \\omega^2 \\lambda_i^2 \\right) \\\\ \\lambda^{-2} &amp;\\sim \\dgamma\\left(\\nu / 2, \\nu / 2\\right) \\end{aligned} \\] The scale mixture distribution of normal parameterization of the Student t distribution is useful for computational reasons. A Stan model that implements this scale mixture of normal distribution representation of the Student-t distribution is lm_student_t_2.stan: // lm_student_t_2.stan // Linear Model with Student-t Errors data { // number of observations int N; // response vector[N] y; // number of columns in the design matrix X int K; // design matrix X // should not include an intercept matrix [N, K] X; // priors on alpha real scale_alpha; vector[K] scale_beta; real loc_sigma; // keep responses int use_y_rep; int use_log_lik; } parameters { // regression coefficient vector real alpha; vector[K] beta; // regression scale real sigma; // 1 / lambda_i^2 vector[N] inv_lambda2; // degrees of freedom; // limit df = 2 so that there is a finite variance real nu; } transformed parameters { vector[N] mu; vector[N] omega; // observation variances for (n in 1:N) { omega[n] = sigma / sqrt(inv_lambda2[n]); } mu = alpha + X * beta; } model { real half_nu; // priors alpha ~ normal(0.0, scale_alpha); beta ~ normal(0.0, scale_beta); sigma ~ exponential(loc_sigma); nu ~ gamma(2, 0.1); half_nu = 0.5 * nu; inv_lambda2 ~ gamma(half_nu, half_nu); // likelihood with obs specific scales y ~ normal(mu, sigma); } generated quantities { // simulate data from the posterior vector[N * use_y_rep] y_rep; // log-likelihood posterior vector[N * use_log_lik] log_lik; for (n in 1:num_elements(y_rep)) { y_rep[n] = student_t_rng(nu, mu[n], omega[n]); } for (n in 1:num_elements(log_lik)) { log_lik[n] = student_t_lpdf(y[n] | nu, mu[n], omega[n]); } } Another reparameterization of these models that is useful computationally is The variance of the Student-t distribution is a function of the scale and the degree-of-freedom parameters. Suppose \\(X \\sim \\dt(\\nu, \\mu, \\sigma)\\), then \\[ \\Var(X) = \\frac{\\nu}{\\nu - 2} \\sigma^2. \\] So variance of data can be fit better by either increasing \\(\\nu\\) or increasing the scale \\(\\sigma\\). This will create posterior correlations between the parameters, and make it more difficult to sample the posterior distribution. We can reparameterize the model to make \\(\\sigma\\) and \\(\\nu\\) less correlated by multiplying the scale by the degrees of freedom. \\[ \\begin{aligned} y_i \\sim \\dt\\left(\\nu, \\mu_i, \\sigma \\sqrt{\\frac{\\nu - 2}{\\nu}} \\right) \\end{aligned} \\] In this model, changing the value of \\(\\nu\\) has no effect on the variance of \\(y\\), since \\[ \\Var(y_i) = \\frac{\\nu}{\\nu - 2} \\sigma^2 \\frac{\\nu - 2}{\\nu} = \\sigma^2 . \\] 15.2.1 Examples Estimate some examples with known outliers and compare to using a normal See the data examples income_ineq, unionization, and econ_growth in the associated jrnold.bayes.notes package. data(&quot;econ_growth&quot;, package = &quot;jrnold.bayes.notes&quot;) rec_union &lt;- recipe(union_density ~ left_government + labor_force_size + econ_conc, data = unionization) %&gt;% step_center(everything()) %&gt;% step_scale(everything()) %&gt;% prep(retain = TRUE) union_data &lt;- lst( X = juice(rec_union, all_predictors(), composition = &quot;matrix&quot;), y = drop(juice(rec_union, all_outcomes(), composition = &quot;matrix&quot;)), N = nrow(X), K = ncol(X), scale_alpha = 10, scale_beta =rep(2.5, K), loc_sigma = 1, use_y_rep = 1, use_log_lik = 1, d = 4 ) rec_econ_growth &lt;- recipe(econ_growth ~ labor_org + social_dem, data = econ_growth) %&gt;% step_interact(~ labor_org * social_dem, sep = &quot;:&quot;) %&gt;% step_center(everything()) %&gt;% step_scale(everything()) %&gt;% prep(retain = TRUE) econ_growth_data &lt;- lst( X = juice(rec_econ_growth, all_predictors(), composition = &quot;matrix&quot;), y = drop(juice(rec_econ_growth, all_outcomes(), composition = &quot;matrix&quot;)), N = nrow(X), K = ncol(X), scale_alpha = 10, scale_beta =rep(2.5, K), loc_sigma = 1, use_y_rep = 1, use_log_lik = 1, d = 4 ) models &lt;- list() models[[&quot;lm_normal_1&quot;]] &lt;- stan_model(&quot;stan/lm_normal_1.stan&quot;) fits &lt;- list() fits[[&quot;econ_normal&quot;]] &lt;- sampling(models[[&quot;lm_normal_1&quot;]], data = econ_growth_data) models[[&quot;lm_student_t_0&quot;]] &lt;- stan_model(&quot;stan/lm_student_t_0.stan&quot;) fits[[&quot;econ_t0&quot;]] &lt;- sampling(models[[&quot;lm_student_t_0&quot;]], data = econ_growth_data, refresh = -1) models[[&quot;lm_student_t_1&quot;]] &lt;- stan_model(&quot;stan/lm_student_t_1.stan&quot;) #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:1: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Core:531: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:2: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/LU:47: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Jacobi:29: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/QR:17: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Householder:27: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:5: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SVD:48: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Geometry:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:7: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Eigenvalues:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:26: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCore:66: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:27: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/OrderingMethods:71: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:29: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:32: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseQR:35: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from file199a4ffb80c1.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:33: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/IterativeLinearSolvers:46: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; 13 warnings generated. #&gt; ld: warning: directory not found for option &#39;-L/usr/local/opt/llvm/lib/clang/5.0.0/lib/darwin/&#39; fits[[&quot;mod_student_t_1&quot;]] #&gt; NULL fit_econ_t1 &lt;- sampling(models[[&quot;lm_student_t_1&quot;]], data = econ_growth_data, refresh = -1) models[[&quot;lm_student_t_2&quot;]] &lt;- stan_model(&quot;stan/lm_student_t_2.stan&quot;) fits[[&quot;econ_t2&quot;]] &lt;- sampling(models[[&quot;lm_student_t_2&quot;]], data = econ_growth_data, refresh = -1) #&gt; Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See #&gt; http://mc-stan.org/misc/warnings.html#bfmi-low #&gt; Warning: Examine the pairs() plot to diagnose sampling problems calc_loo &lt;- function(x) { ll &lt;- extract_log_lik(x, &quot;log_lik&quot;, merge_chains = FALSE) r_eff &lt;- relative_eff(exp(ll)) loo(ll, r_eff = r_eff) } model_loo &lt;- map(fits, calc_loo) #&gt; Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-diagnostic&#39;) for details. #&gt; Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-diagnostic&#39;) for details. #&gt; Warning: Some Pareto k diagnostic values are slightly high. See help(&#39;pareto-k-diagnostic&#39;) for details. map(model_loo, ~ .x[[&quot;estimates&quot;]][&quot;elpd_loo&quot;, &quot;Estimate&quot;]) #&gt; $econ_normal #&gt; [1] -22.7 #&gt; #&gt; $econ_t0 #&gt; [1] -22.8 #&gt; #&gt; $econ_t2 #&gt; [1] -22.2 pars &lt;- imap_dfr(fits, ~ mutate(tidyMCMC(.x, conf.int = TRUE), model = .y)) ggplot() + geom_pointrange(data = filter(pars, str_detect(term, &quot;^y_rep&quot;)) %&gt;% mutate(id = as.integer(str_extract(term, &quot;\\\\d+&quot;))), mapping = aes(x = id, y = estimate, ymin = conf.low, ymax = conf.high, colour = model), position = position_dodge(width = 0.2)) + geom_point(data = tibble(y = econ_growth_data$y, x = seq_along(y)), mapping = aes(x = x, y = y)) + coord_flip() ggplot() + geom_pointrange(data = filter(pars, str_detect(term, &quot;^beta&quot;)), mapping = aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high, colour = model), position = position_dodge(width = 0.2)) + coord_flip() 15.3 Robit The “robit” is a “robust” bivariate model.(A. Gelman and Hill 2007, 125; Liu 2005) For the link-function the robit uses the CDF of the Student-t distribution with \\(d\\) degrees of freedom. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dBinom \\left(n_i, \\pi_i \\right) \\\\ \\pi_i &amp;= \\int_{-\\infty}^{\\eta_i} \\mathsf{StudentT}(x | \\nu, 0, (\\nu - 2)/ \\nu) dx \\\\ \\eta_i &amp;= \\alpha + X \\beta \\end{aligned} \\] Since the variance of a random variable distributed Student-\\(t\\) is \\(d / d - 2\\), the scale fixes the variance of the distribution at 1. Fixing the variance of the Student-\\(t\\) distribution is not necessary if \\(d\\) is fixed, but is necessary if \\(d\\) were modeled as a parameter. Where \\(\\nu\\) is given a low degrees of freedom \\(\\nu \\in [3, 7]\\), or a prior distribution. 15.4 Quantile regression A different form of robust regression and one that often serves a different purpose is quantile regression. Least absolute deviation (LAD) regression minimizes the following objective function, \\[ \\hat{\\beta}_{LAD} = \\arg \\min_{\\beta} \\sum | y_i - \\alpha - X \\beta | . \\] The Bayesian analog is the Laplace distribution, \\[ \\dlaplace(x | \\mu, \\sigma) = \\frac{1}{2 \\sigma} \\left( - \\frac{|x - \\mu|}{\\sigma} \\right) . \\] The Laplace distribution is analogous to least absolute deviations because the kernel of the distribution is \\(|x - \\mu|\\), so minimizing the likelihood will also minimize the least absolute distances. Thus, a linear regression with Laplace errors is analogous to a median regression. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dlaplace\\left( \\alpha + X \\beta, \\sigma \\right) \\end{aligned} \\] This can be generalized to other quantiles using the asymmetric Laplace distribution (Benoit and Poel 2017, @YuZhang2005a). 15.4.1 Questions OLS is a model of the conditional mean \\(E(y | x)\\). A linear model with normal errors is a model of the outcomes \\(p(y | x)\\). How would you estimate the conditional mean, median, and quantile functions from the linear-normal model? What role would quantile regression play? Hint: See Benoit and Poel (2017 Sec. 3.4). Implement the asymmetric Laplace distribution in Stan in two ways: Write a user function to calculate the log-PDF Implement it as a scale-mixture of normal distributions 15.5 References For more on robust regression see A. Gelman and Hill (2007 sec 6.6), A. Gelman, Carlin, et al. (2013 ch 17), and Stan Development Team (2016 Sec 8.4). For more on heteroskedasticity see A. Gelman, Carlin, et al. (2013 Sec. 14.7) for models with unequal variances and correlations. Stan Development Team (2016) discusses reparameterizing the Student t distribution as a mixture of gamma distributions in Stan. The Double Exponential distribution still has a thinner tail than the Student-t at higher values.↩ "],
["heteroskedasticity.html", "16 Heteroskedasticity Prerequisites 16.1 Introduction 16.2 Weighted Regression 16.3 Modeling the Scale with Covariates 16.4 Prior Distributions 16.5 Exercises 16.6 References", " 16 Heteroskedasticity Prerequisites library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) 16.1 Introduction Consider the linear regression model with normal errors, \\[ y_i \\sim \\dnorm\\left(\\ X \\beta, \\sigma_i^2 \\right) . \\] Note that since the term \\(\\sigma_i\\) is indexed by the observation, it can vary by observation. If \\(\\sigma_i = 1\\) for all \\(i\\), then this corresponds to the classical homoskedastic linear regression. If \\(\\sigma_i\\) differs for each \\(i\\), then it is a heteroskedastic regression. In frequentist estimation linear regressions with heteroskedastic are often estimated using OLS with heteroskedasticity-consistent (HC) standard errors.12 However, HC standard errors are not a generative model, and in the Bayesian setting it is preferable to write a generative model that specifies a model for \\(\\sigma^2\\). 16.2 Weighted Regression A common case is “weighted” regression, where each \\(y_i\\) represents the mean of \\(n_i\\) observations. Then the scale of each observation is \\[ \\sigma_i = \\omega / n_i , \\] where \\(\\omega\\) is a global scale. Alternatively, suppose each observation represents the sum of each \\(n_i\\) observations. Then the scale of each observation is, \\[ \\sigma_i = n_i \\omega . \\] 16.3 Modeling the Scale with Covariates The scale can also be modeled with covariates. It is common to model the log-transformation of the scale or variance to transform it to \\(\\R\\), \\[ \\log \\sigma_i = \\dnorm(Z_i \\gamma, \\omega) \\] where \\(Z_i\\) are covariates used to the model the variance, which may or may not be the same as \\(X_i\\). Another common model is the variance as a function of the mean, \\[ \\begin{align} \\log \\sigma_i = f(\\mu_i). \\end{align} \\] Consider the well-known normal approximation of the binomial distribution, \\[ \\dnorm(n_i | N_i, \\pi_i) \\approx \\dnorm(n_i | \\pi N_i, \\pi (1 - \\pi) N_i) . \\] At the cost of treating the outcome as continuous rather than discrete, this approximation can provide a flexible model for over- or under-dispersion, by adding a dispersion term \\(\\delta \\in R^{+}\\), \\[ n_i \\sim \\dnorm(\\pi N_i, \\delta \\pi (1 - \\pi)) . \\] A similar approximation can be applied to unbounded count models using the normal approximation to the Poisson, \\(\\dpois(y_i | \\lambda_i) \\approx \\dnorm(y_i | \\lambda_i \\lambda_i)\\). 16.4 Prior Distributions A reparameterization that will be used quite often is to rewrite a normal distributions with unequal scale parameters as the product of a common global scale parameter (\\(\\omega\\)), and observation specific local scale parameters, \\(\\lambda_i\\),13 \\[ y_i \\sim \\dnorm(X\\beta, \\lambda_i \\omega) . \\] If the local variance parameters are distributed inverse-gamma, \\[ \\lambda^2 \\sim \\dinvgamma(\\nu / 2, \\nu / 2) \\] then the above is equivalent to a regression with errors distributed Student-t errors with \\(\\nu\\) degrees of freedom, \\[ y_i \\sim \\dt\\left(\\nu, X \\beta, \\sigma \\right) . \\] Note that if a random variable \\(X\\) is distributed inverse-gamma, it is equivalent to \\(1 / X\\) being distributed gamma. In this example, \\[ \\dinvgamma(\\lambda^2 | \\nu / 2, \\nu / 2) = \\dgamma\\left(\\frac{1}{\\lambda^2} \\middle| \\nu / 2, \\nu / 2\\right) = \\] Example: Simulate Student-\\(t\\) distribution with \\(\\nu\\) degrees of freedom as a scale mixture of normal. For *s in 1:S$, Simulate \\(z_s \\sim \\dgamma(\\nu / 2, \\nu / 2)\\) \\(x_s = 1 / \\sqrt{z_s}\\) is draw from \\(\\dt(\\nu, 0, 1)\\). When using R, ensure that you are using the correct parameterization of the gamma distribution. Left to reader We can also model heteroskedasticity by placing a prior distribution on the variances. \\[ \\sigma_i = \\omega \\lambda_i . \\] Thus, the heteroskedastic likelihood is, \\[ y_i \\sim \\dnorm\\left( \\mu_i, \\omega^2 \\lambda_i^2\\right) \\] Note that since the number of \\(\\lambda_i\\) parameters are equal to the number of observations, this model will not have a proper posterior distribution without a proper prior distribution. However, if a proper prior is placed on \\(\\lambda_i\\), then the posterior distribution for this model exists. Suppose \\(1 / \\lambda_i^2\\) is distributed with a specific gamma distribution, \\[ 1 / \\lambda_i^2 \\sim \\dgamma(d / 2, d / 2) . \\] This \\[ \\dt(y_i | \\nu, \\mu_i, \\omega) = \\int \\dnorm(y | \\mu_i, \\omega^2 \\lambda^2) \\dinvgamma(\\nu / 2, \\nu / 2) d \\lambda^2 \\] This is equivalent to a regression model with Student-t errors. \\[ y_i \\sim \\dt\\left(d, ., \\omega \\right) . \\] Thus, “robust” regression models with Student-\\(t\\) errors can be derived from a particular model of heteroskedastic normal errors. The Stan model that estimates this is lm_student_t_1.stan: // lm_student_t_1.stan // Linear Model with Student-t Errors data { // number of observations int N; // response vector[N] y; // number of columns in the design matrix X int K; // design matrix X // should not include an intercept matrix [N, K] X; // priors on alpha real scale_alpha; vector[K] scale_beta; real loc_sigma; // keep responses int use_y_rep; int use_log_lik; } parameters { // regression coefficient vector real alpha; vector[K] beta; real sigma; // degrees of freedom; // limit df = 2 so that there is a finite variance real nu; } transformed parameters { vector[N] mu; mu = alpha + X * beta; } model { // priors alpha ~ normal(0.0, scale_alpha); beta ~ normal(0.0, scale_beta); sigma ~ exponential(loc_sigma); // see Stan prior distribution suggestions nu ~ gamma(2, 0.1); // likelihood y ~ student_t(nu, mu, sigma); } generated quantities { // simulate data from the posterior vector[N * use_y_rep] y_rep; // log-likelihood posterior vector[N * use_log_lik] log_lik; for (i in 1:num_elements(y_rep)) { y_rep[i] = student_t_rng(nu, mu[i], sigma); } for (i in 1:num_elements(log_lik)) { log_lik[i] = student_t_lpdf(y[i] | nu, mu[i], sigma); } } We could also apply other prior distributions to the Another flexible model of heteroskedasticity is to apply a Dirichlet model to the local scales, \\[ \\begin{aligned}[t] \\lambda_i &amp;\\sim \\ddirichlet(a, w), &amp; \\lambda_i \\geq 0, \\sum_i \\lambda_i = 1 . \\end{aligned} \\] 16.4.1 Examples: Duncan Estimate the linear regression with the Duncan data using heteroskedastic errors. data(&quot;Duncan&quot;, package = &quot;carData&quot;) mod_norm &lt;- stan_model(&quot;stan/lm_normal_1.stan&quot;, verbose = FALSE) mod_t &lt;- stan_model(&quot;stan/lm_student_t_1.stan&quot;, verbose = FALSE) 16.5 Exercises Estimate examples in the hett package with Stan. 16.6 References For more on heteroskedasticity see A. Gelman, Carlin, et al. (2013 Sec. 14.7) for models with unequal variances and correlations. Stan Development Team (2016) discusses reparameterizing the Student t distribution as a mixture of gamma distributions in Stan. See https://arxiv.org/pdf/1101.1402.pdf and http://econ.ucsb.edu/~startz/Bayesian%20Heteroskedasticity-Robust%20Regression.pdf.↩ See this for a visualization of a Student-t distribution a mixture of Normal distributions, and this for a derivation of the Student t distribution as a mixture of normal distributions. This scale mixture of normal representation will also be used with shrinkage priors on the regression coefficients.↩ "],
["rare-events.html", "17 Rare Events Prerequisites 17.1 Introduction 17.2 Finite-Sample Bias 17.3 Case Control 17.4 Questions", " 17 Rare Events Prerequisites library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) 17.1 Introduction There are two issues when estimating model with a binary outcomes and rare events. Bias due to an effective small sample size: The solution to this is the same as quasi-separation, a weakly informative prior on the coefficients, as discussed in the Separation chapter. Case-control: Adding additional observations to the majority class adds little additional information. If it is costly to acquire training data, it is better to acquire something closer to a balanced training set: approximately equal numbers of 0’s and 1’s. The model can be adjusted for this bias. 17.2 Finite-Sample Bias The finite-sample size bias can handled by the use of weakly informative priors as discussed in the chapter on separation. The current best-practice in Stan is to use the following weakly informative priors for the intercept and coefficients: \\[ \\begin{aligned} \\alpha &amp;\\sim \\dnorm(0, 10)\\\\ \\beta_k &amp;\\sim \\dnorm(0, 2.5) \\end{aligned} \\] The Normal priors could be replaced by Student-\\(t\\) priors with finite variance. 17.3 Case Control In binary outcome variables, sometimes it is useful to sample on the dependent variable. For example, King and Zeng (2001b) and King and Zeng (2001a) discuss applications with respect to conflicts in international relations. For most country-pairs, for most years, there is no conflict. If some data are costly to gather, it may be cost efficient to gather data for conflict-years and then randomly select a smaller number of non-conflict years on which to gather data. The sample will no longer be representative, but the estimates can be corrected to account for the data-generating process. The reason this works well, is that if there are few 1’s, additional 0’s have little influence on the estimation (King and Zeng (2001b)). King and Zeng (2001b) propose two corrections: Prior correction Weighting observations The prior correction model adjust the intercept of the logit model to account for the difference between the sample and population proportions. Note that \\[ \\pi_i = \\frac{1}{1 + \\exp(-\\alpha + \\mat{X} \\beta)} \\] An unbalanced sample only affects the intercept. If \\(\\alpha\\) is the intercept estimated on the sample, the prior corrected intercept \\(\\tilde{\\alpha}\\) is, \\[ \\tilde{\\alpha} = \\alpha - \\ln \\left(\\frac{1 - \\tau}{\\tau} \\frac{\\bar{y}}{1 - \\bar{y}} \\right) \\] This is a special case of using an offset in a generalized linear model. Since this constant is added to all observations it will not affect the estimation of \\(\\alpha\\) and \\(\\beta\\), but it will adjust the predicted probabilities for observations in the sample and new observations. Thus the complete specification of a prior-correction rare event logits with standard weakly informative priors is: \\[ \\begin{aligned}[t] y_i&amp; \\sim \\dbernoulli(\\pi_i) \\\\ \\pi_i &amp;= \\invlogit(\\eta_i) \\\\ \\eta_i &amp;= \\tilde{\\alpha} + X \\beta \\\\ \\tilde{\\alpha} &amp;= \\alpha - \\ln \\left(\\frac{(1 - \\tau) \\bar{y}}{\\tau (1 - \\bar{y})} \\right) \\\\ \\alpha &amp;\\sim \\dnorm(0, 10) \\\\ \\beta &amp;\\sim \\dnorm(0, 2.5) \\end{aligned} \\] This is implemented in relogit1.stan: // relogit1.stan // Rare-Events Logit Model with Prior Correction data { // number of observations int N; // response // vectors are only real numbers // need to use an array int y[N]; // need to pass mean of y since it is hard to cast integer to real types // in stan real y_mean; // number of columns in the design matrix X int K; // design matrix X // should not include an intercept matrix [N, K] X; // priors on alpha real scale_alpha; real scale_beta; // rare-event logit correction // population proportion of outcomes real tau; // keep responses int use_y_rep; int use_log_lik; } transformed data { real correction; // log((y_mean) / (1 - ymean) * tau / (1 - tau)) correction = log(y_mean) - log1m(y_mean) + log1m(tau) - log(tau); } parameters { // regression coefficient vector real alpha_raw; vector[K] beta; } transformed parameters { // sampling corrected intercept real alpha; // logit-scale means vector[N] eta; alpha = alpha_raw - correction; eta = alpha + X * beta; } model { // priors alpha_raw ~ normal(0., scale_alpha); beta ~ normal(0., scale_beta); // likelihood y ~ bernoulli_logit(eta); } generated quantities { // simulate data from the posterior // actually simulate proportions rather than the outcomes - these are easy // enough to create. vector[N * use_y_rep] y_rep; // log-likelihood posterior vector[N * use_log_lik] log_lik; for (i in 1:num_elements(y_rep)) { y_rep[i] = bernoulli_rng(inv_logit(eta[i])); } for (i in 1:num_elements(log_lik)) { log_lik[i] = bernoulli_lpmf(y[i] | inv_logit(eta[i])); } } The weighted likelihood model weights the contributions of each observation to the likelihood with its probability of selection. As before, let \\(\\mean{y}\\) be the sample proportion of 1s in outcome, and \\(\\tau\\) be the known population proportion. The probability of selection, conditional on the outcome is, \\[ w_i = \\begin{cases} \\tau / \\bar{y} &amp; \\text{if } y_i = 1 \\text{,} \\\\ (1 - \\tau) / (1 - \\bar{y}) &amp; \\text{if } y_i = 0 \\text{.} \\end{cases} \\] The log-likelihood is written as a weighted log-likelihood: \\[ \\begin{aligned}[t] \\log L_w(\\beta | y) &amp;= \\sum_i w_i \\log \\dbern (\\pi_i) \\end{aligned} \\] In Stan, this can be implemented by directly weighting the log-posterior contributions of each observation. This is implemented in relogit2.stan: // relogit2.stan // Rare-Events Logit Model with Prior Correction data { // number of observations int N; // response // vectors are only real numbers // need to use an array int y[N]; // number of columns in the design matrix X int K; // design matrix X // should not include an intercept matrix [N, K] X; // priors on alpha real scale_alpha; real scale_beta; // rare-event logit correction // population proportion of outcomes real tau; // need to pass mean of y since it is hard to cast integer to real types // in stan real y_mean; // keep responses int use_y_rep; int use_log_lik; } transformed data { // weights vector[N] w; for (n in 1:N) { if (y[n]) { w[n] = tau / y_mean; } else { w[n] = (1. - tau) / (1. - y_mean); } } } parameters { // regression coefficient vector real alpha; vector[K] beta; } transformed parameters { // logit-scale means vector[N] eta; eta = alpha + X * beta; } model { // priors alpha ~ normal(0.0, scale_alpha); beta ~ normal(0.0, scale_beta); // manually calculate the weighted log-likelihood for (n in 1:N) { target += w[n] * bernoulli_logit_lpmf(y[n] | eta[n]); } } generated quantities { // simulate data from the posterior // actually simulate proportions rather than the outcomes - these are easy // enough to create. vector[N * use_y_rep] y_rep; // log-likelihood posterior vector[N * use_log_lik] log_lik; for (i in 1:num_elements(y_rep)) { y_rep[i] = bernoulli_rng(inv_logit(eta[i])); } // we don't need to weight the individual log-likelihoods for (i in 1:num_elements(log_lik)) { log_lik[i] = bernoulli_lpmf(y[i] | inv_logit(eta[i])); } } 17.4 Questions Compare the estimates and efficiency of the two methods. How would you evaluate the predictive distributions using cross-validation in case of unbalanced classes? Suppose that there is uncertainty about the population proportion, \\(\\tau\\). Incorporate that uncertainty into the model by making \\(\\tau\\) a parameter and giving it a prior distribution. In the prior correction method, instead of adjust the intercept prior to sampling, it could be done after sampling. Calculate the corrected intercept to the generated quantities block. Does it change the estimates? Does it change the efficiency of sampling? See the example for Zelig-relogit "],
["shrinkage-and-hierarchical-models.html", "18 Shrinkage and Hierarchical Models 18.1 Hierarchical Models 18.2 Baseball Hits", " 18 Shrinkage and Hierarchical Models library(&quot;tidyverse&quot;) library(&quot;rstan&quot;) library(&quot;loo&quot;) 18.1 Hierarchical Models Hierarchical models: often groups of parameters, \\(\\{\\theta_1, \\dots, \\theta_J\\}\\), are related. E.g. countries, states, counties, years, etc. Even the regression coefficients, \\(\\beta_1, \\dots, \\beta_k\\) seen the in the [Shrinkage and Regularization] chapter. We can treat those \\(\\theta_j\\) as drawn from a population distribution, \\(\\theta_j \\sim p(\\theta)\\). The prior distribution \\(p(\\theta)\\) is called a hyperprior and its parameters are hyperparameters Exchangeability: parameters \\((\\theta_1, \\dots, \\theta_J)\\) are exchangeable if \\(p(\\theta_1, \\dots, \\theta_J)\\) don’t depend on the indexes. i.i.d. models are a special case of exchangeability. 18.2 Baseball Hits Efron and Morris (1975) analyzed data from 18 players in the 1970 season. The goal was to predict the batting average of these 18 players from their first 45 at-bats for the remainder of the 1970 season. The following example is based on Carpenter, Gabry, and Goodrich (2017) and the rstanarm vignette Hierarchical Partial Pooling for Repeated Binary Trials. The hitting data used in Efron and Morris (1975) is included in rstanarm as rstanarm: data(&quot;bball1970&quot;, package = &quot;rstanarm&quot;) bball1970 &lt;- mutate(bball1970, BatAvg1 = Hits / AB, BatAvg2 = RemainingHits / RemainingAB) head(bball1970) #&gt; Player AB Hits RemainingAB RemainingHits BatAvg1 BatAvg2 #&gt; 1 Clemente 45 18 367 127 0.400 0.346 #&gt; 2 Robinson 45 17 426 127 0.378 0.298 #&gt; 3 Howard 45 16 521 144 0.356 0.276 #&gt; 4 Johnstone 45 15 275 61 0.333 0.222 #&gt; 5 Berry 45 14 418 114 0.311 0.273 #&gt; 6 Spencer 45 14 466 126 0.311 0.270 Let \\(y_i\\) be the number of hits in the first 45 at bats for player \\(i\\), \\[ \\begin{aligned}[t] y_i &amp; \\sim \\dBinom(45, \\mu_i), \\end{aligned} \\] where \\(\\mu_i \\in (0, 1)\\) is the player-specific batting average. Priors will be placed on the log-odds parameter, \\(\\eta \\in \\R\\), \\[ \\begin{aligned}[t] \\mu_i &amp;\\sim \\frac{1}{1 + \\exp(-\\eta_i)} . \\\\ \\end{aligned} \\] This example considers three ways of modeling \\(\\mu_i\\): Complete Pooling: All players have the same batting average parameter. \\[ \\eta_i = \\eta . \\] The common (log-odds) batting average is given a weakly informative prior, \\[ \\eta \\sim \\dnorm(0, 2.5) \\] On the log odds scale, this places 95% of the probability mass between 0.7 and 99.3 on the proportion scale. Non-pooled: Each players (log-odds) batting average is independent, with each assigned a separate weak prior. \\[ \\begin{aligned}[t] \\eta_i &amp;\\sim \\dnorm(0, 2.5) \\end{aligned} \\] Partial-pooling: Each player has a separate (log-odds) batting average, but these batting average parameters are drawn from a common normal distribution. \\[ \\begin{aligned}[t] \\eta_i &amp;\\sim \\dnorm(0, \\tau) \\\\ \\tau &amp;\\sim \\dnorm(0, 1) \\end{aligned} \\] bball1970_data &lt;- list( N = nrow(bball1970), k = bball1970$AB, y = bball1970$Hits, k_new = bball1970$RemainingAB, y_new = bball1970$RemainingHits ) Create a list to store models: models &lt;- list() models[[&quot;nopool&quot;]] &lt;- stan_model(&quot;stan/binomial-no-pooling.stan&quot;) /* Binomial Model (No pooling) A binomial model for $i = 1, \\dots, N$, no pooling: $$ p(y_i | n_i, \\mu_i) &amp;\\sim \\mathsf{Binomial}(y_i | n_i, \\mu_i) \\\\ \\mu_i &amp;= \\logit^{-1}(\\eta_i) \\\\ p(\\eta_i) &amp;\\sim \\mathsf{Normal}^+(0, 10) $$ */ data { int N; int y[N]; int k[N]; // new data int y_new[N]; int k_new[N]; } parameters { vector[N] eta; } model { eta ~ normal(0., 10.); y ~ binomial_logit(k, eta); } generated quantities { int y_rep[N]; vector[N] log_lik; vector[N] log_lik_new; vector&lt;lower = 0., upper = 1.&gt;[N] mu; mu = inv_logit(eta); for (n in 1:N) { y_rep[n] = binomial_rng(k[n], mu[n]); log_lik[n] = binomial_logit_lpmf(y[n] | k[n], eta[n]); log_lik_new[n] = binomial_logit_lpmf(y_new[n] | k_new[n], eta[n]); } } models[[&quot;pool&quot;]] &lt;- stan_model(&quot;stan/binomial-complete-pooling.stan&quot;) /* Binomial Model A binomial model for $i = 1, \\dots, N$, with complete pooling $$ \\begin{aligned}[t] p(y_i | n_i, \\mu) &amp;\\sim \\mathsf{Binomial}(n_i, \\mu) \\\\ \\mu &amp;= \\logit^{-1}(\\eta) \\\\ p(\\eta) &amp;\\sim \\mathsf{Normal}^+(0, 10) \\end{aligned} $$ */ data { int N; int y[N]; int k[N]; // new data int y_new[N]; int k_new[N]; } parameters { real eta; } model { eta ~ normal(0., 10.); y ~ binomial_logit(k, eta); } generated quantities { int y_rep[N]; vector[N] log_lik; vector[N] log_lik_new; real&lt;lower = 0., upper = 1.&gt; mu; mu = inv_logit(eta); for (n in 1:N) { // y_rep[n] = binomial_rng(k[n], mu); log_lik[n] = binomial_logit_lpmf(y[n] | k[n], eta); log_lik_new[n] = binomial_logit_lpmf(y_new[n] | k_new[n], eta); } } models[[&quot;partial&quot;]] &lt;- stan_model(&quot;stan/binomial-partial-pooling.stan&quot;) /* Binomial Model A binomial model for $i = 1, \\dots, N$, with partial pooling $$ \\begin{aligned}[t] p(y_i | n_i, \\mu_i) &amp;\\sim \\mathsf{Binomial}(y_i | n_i, \\mu_i) \\\\ \\mu_i &amp;= \\logit^{-1}(\\eta_i) \\\\ p(\\eta_i | \\tau) &amp;\\sim \\mathsf{Normal}(alpha, \\tau) \\\\ p(\\tau) &amp;\\sim \\mathsf{Normal}^+(0, 1) \\\\ p(alpha) &amp; \\sim \\mathsf{Normal}(0, 2.5) \\\\ \\end{aligned} $$ */ data { int N; int y[N]; int k[N]; // new data int y_new[N]; int k_new[N]; } parameters { vector[N] eta; real alpha; real&lt;lower = 0.&gt; tau; } model { alpha ~ normal(0., 10.); tau ~ normal(0., 1); eta ~ normal(alpha, tau); y ~ binomial_logit(k, eta); } generated quantities { int y_rep[N]; vector[N] log_lik; vector[N] log_lik_new; vector&lt;lower = 0., upper = 1.&gt;[N] mu; mu = inv_logit(eta); for (n in 1:N) { // y_rep[n] = binomial_rng(k[n], mu[n]); log_lik[n] = binomial_logit_lpmf(y[n] | k[n], eta[n]); log_lik_new[n] = binomial_logit_lpmf(y_new[n] | k_new[n], eta[n]); } } Draw a sample for all three models: fits &lt;- map(models, sampling, data = bball1970_data, refresh = -1) %&gt;% set_names(names(models)) For each model calculate the posterior mean of \\(\\mu\\) for each player: bball1970 &lt;- map2_df(names(fits), fits, function(nm, fit) { mu &lt;- broom::tidy(fit) %&gt;% filter(str_detect(term, &quot;^mu&quot;)) if (nrow(mu) == 1) { out &lt;- tibble(estimate = rep(mu$estimate, 18L)) } else { out &lt;- select(mu, estimate) } out$model &lt;- nm out$.id &lt;- seq_len(nrow(out)) out }) %&gt;% spread(model, estimate) %&gt;% bind_cols(bball1970) The partially pooled estimates are shrunk towards the overall average, and are between the no-pooling and pooled estimates. select(bball1970, Player, nopool, partial, pool) %&gt;% mutate(Player = factor(Player, levels = Player)) %&gt;% gather(variable, value, -Player) %&gt;% ggplot(aes(y = value, x = factor(variable), group = Player)) + geom_point() + geom_line() + labs(x = &quot;&quot;, y = expression(mu)) We can plot the actual batting averages (BatAvg1 and BatAvg2) and the model estimates: select(bball1970, Player, nopool, partial, pool, BatAvg1, BatAvg2) %&gt;% mutate(Player = factor(Player, levels = Player)) %&gt;% gather(variable, value, -Player) %&gt;% ggplot(aes(y = Player, x = value, colour = variable)) + geom_point() + labs(x = expression(mu), y = &quot;&quot;) The estimates of the no-pooling model is almost exactly the same as BatAvg1. The out-of-sample batting averages BatAvg2 show regression to the mean. For these models, compare the overall out-of-sample performance by calculating the actual average out-of-sample log-pointwise predictive density (lppd), and the expected lppd using LOO-PSIS. The LOO-PSIS estimates of the out-of-sample lppd are optimistic. However, they still show the pooling and partial estimates as superior to the no-pooling estimates. The actual out-of-sample average lppd for the partial pooled model is the best fitting. map2_df(names(fits), fits, function(nm, fit) { loo &lt;- loo(extract_log_lik(fit, &quot;log_lik&quot;)) ll_new &lt;- rstan::extract(fit)[[&quot;log_lik_new&quot;]] tibble(model = nm, loo = loo$elpd_loo / bball1970_data$N, ll_out = mean(log(colMeans(exp(ll_new))))) }) #&gt; # A tibble: 3 x 3 #&gt; model loo ll_out #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 nopool -3.23 -4.62 #&gt; 2 pool -2.58 -4.06 #&gt; 3 partial -2.59 -4.00 To see why this is the case, plot the average errors for each observation in- and out-of-sample. In-sample for the no-pooling model is zero, but it over-estimates (under-estimates) the players with the highest (lowest) batting averages in their first 45 at bats—this is regression to the mean. In sample, the partially pooling model shrinks the estimates towards the mean and reducing error. Out of sample, the errors of the partially pooled model are not much different than the no-pooling model, except that the extreme observations have lower errors. select(bball1970, Player, nopool, partial, pool, BatAvg1, BatAvg2) %&gt;% mutate(Player = as.integer(factor(Player, levels = Player))) %&gt;% gather(variable, value, -Player, -matches(&quot;BatAvg&quot;)) %&gt;% mutate(`In-sample Errors` = value - BatAvg1, `Out-of-sample Errors` = value - BatAvg2) %&gt;% select(-matches(&quot;BatAvg&quot;), -value) %&gt;% gather(sample, error, -variable, -Player) %&gt;% ggplot(aes(y = error, x = Player, colour = variable)) + geom_hline(yintercept = 0, colour = &quot;white&quot;, size = 2) + geom_point() + geom_line() + facet_wrap(~ sample, ncol = 1) + theme(legend.position = &quot;bottom&quot;) Extensions: Use a beta distribution for the prior of \\(\\mu_i\\). How would you specify the prior beta distribution so that it is uninformative? If you used the beta distribution, how would you specify the beta distribution as a function of the mean? The lowest batting average of the modern era is approximately 0.16 and the highest is approximately 0.4. Use this information for an informative prior distribution. There may be some truly exceptional players. Model this by replacing the normal prior for \\(\\eta\\) with a wide tailed distribution. The distribution of batting averages may be asymmetric - since there may be a few great players, but a player can only be so bad before they are relegated to the minor league. Find a skewed distribution to use as a prior. 18.2.1 References Albert, Jim. Revisiting Efron and Morris’s Baseball Study Feb 15, 2016 Bob Carpenter. Hierarchical Bayesian Batting Ability, with Multiple Comparisons. November 4, 2009. John Kruschke. Shrinkage in multi-level hierarchical models. November 27, 2012. "],
["shrinkage-and-regularized-regression.html", "19 Shrinkage and Regularized Regression Prerequisites 19.1 Introduction 19.2 Shrinkage Estimators 19.3 Sparse Shrinkage 19.4 19.5 Differences between Bayesian and Penalized ML 19.6 Examples 19.7 Shrinkage with Correlated Variables 19.8 Variable Selection", " 19 Shrinkage and Regularized Regression Prerequisites library(&quot;rstan&quot;) library(&quot;rstanarm&quot;) # rstanarm automatically sets the theme theme_set(theme_gray()) library(&quot;bayz&quot;) library(&quot;tidyverse&quot;) library(&quot;broom&quot;) library(&quot;glmnet&quot;) library(&quot;recipes&quot;) 19.1 Introduction In this chapter, we will discuss shrinkage and regularization in regression problems. These methods are useful for improving prediction, estimating regression models with many variables, and as an alternative to model selection methods. Shrinkage estimation deliberately increases the bias of the model in order to reduce variance and improve overall model performance, often at the cost of individual estimates (Efron and Hastie 2016, 91). Maximum likelihood estimation will produce asymptotically unbiased (consistent) estimates, given certain regularity conditions. However, the bias-variance tradeoff implies that generalization error can be decreased with a non-zero amount of bias. By adding bias to the model, shrinkage estimators provide a means to adjust the bias-variance in the model in order to achieve lower generalization error. In the Bayesian estimation, shrinkage occurs as a result of hierarchical models. When parameters are modeled as exchangeable and given a proper prior, it induces some amount of shrinkage. Likewise, Bayesian models with non- or weakly-informative priors will produce similar to the MLE. But stronger priors can produce estimate much different estimtes than MLE. Regularization describes any method that reduces variability in high dimensional estimation or prediction problems to allow estimation of unidentified or ill-posed questions or decrease overfitting or generalization error (Efron and Hastie 2016). Regularization can be thought of as the why and what of these methods, and shrinkage can be thought of as the how. A particularly important case of shrinkage is sparse shrinkage. Sparse shrinkage estimators produce solutions that can be sparse, containing zeros. In the optimizatization case, shrinkage The most well known of these is the lasso. For all of these examples we will be considering a linear regression with normal errors, \\[ y_i \\sim \\dnorm(\\alpha + x&#39;_i \\beta, \\sigma) \\] where there are \\(i = 1, \\dots, n\\) observations, \\(x_i\\) is a \\(k \\times 1\\) vector of predictors, \\(\\alpha\\) and \\(\\sigma\\) are scalars, and \\(beta\\) is a \\(k \\times 1\\) vector of predictors. 19.2 Shrinkage Estimators 19.2.1 Penalized Maximum Likelihood Regression OLS finds the \\(\\beta\\) that minimize the in-sample sum of squared errors, \\[ \\hat{\\beta}_{\\text{OLS}} = \\arg\\min_{\\beta} \\sum_{i = 1}^n (\\vec{x}_i\\T \\vec{\\beta} - y_i)^2 \\] Penalized regressions add a penalty term increasing in the magnitude of \\(\\beta\\) to the minimization function. \\[ \\hat{\\beta}_{\\text{penalized}} = \\argmin_{\\beta} \\sum_{i = 1}^n (\\vec{x}_i\\T \\vec{\\beta} - y_i)^2 + \\underbrace{f(\\beta)}_{\\text{shrinkage penalty}}, \\] where \\(f\\) is some sort of penalty function on \\(\\beta\\) that penalizes larger (in magnitude) values of \\(\\beta\\). Penalized regression purposefully introduces bias into the regression in order to reduce variance and improve out-of-sample prediction. The penalty term, when chosen by cross-validation or an approximation thereof, allows for trading off bias and variance. Different penalized regression methods use different choices of \\(f(\\beta)\\). The two most commonly penalty functions are Ridge and Lasso. Ridge regression uses the following penalty (Hoerl and Kennard 1970): \\[ \\hat{\\beta}_{\\text{ridge}} = \\arg\\min_{\\beta} \\underbrace{\\sum_{i = 1}^n (\\vec{x}_i\\T \\vec{\\beta} - y_i)^2}_{\\text{RSS}} + \\underbrace{\\lambda}_{\\text{tuning parameter}} \\underbrace{\\sum_{k} \\beta_k^2}_{\\ell_2 \\text{ norm}^2} \\] The \\(\\ell_2\\) norm of \\(\\beta\\) is, \\[ ||\\beta||_{2} = \\sqrt{\\sum_{k = 1}^K \\beta_k^2} . \\] The ridge regression coefficients are smaller in magnitude than the OLS coefficients, \\(|\\hat{\\beta}_{ridge}| &lt; |\\hat{\\beta}_{OLS}|\\). However, this bias in the coefficients can be offset by a lower variance, better MSE, and better out-of-sample performance than the OLS estimates. Unlike many other penalized regression estimators, ridge regression has a close-form solution. The expected value and variance-covariance matrix of the ridge regression coefficients is, \\[ \\begin{aligned}[t] \\E[\\hat{\\beta}_{\\text{ridge}}] &amp;= W X&#39; y \\\\ \\Var[\\hat{\\beta}_{\\text{ridge}}] &amp;= \\sigma^2 W&#39; X&#39; X W , \\\\ W &amp;= (X&#39; X + \\lambda I)^{-1} . \\end{aligned} \\] The solution is similar to the least squares solution, with the addition of the \\(\\lambda I\\) term to \\(X&#39; X\\). As \\(\\lambda \\to 0\\), \\(\\hat{\\beta}_{\\text{ridge}} \\to \\hat{\\beta}_{\\text{OLS}}\\). As \\(\\lambda \\to \\infty\\), \\(\\hat{\\beta}_{\\text{ridge}} \\to 0\\). The bias of ridge regression is, \\[ \\mathrm{Bias}(\\hat{\\beta}_{\\text{ridge}}) = -\\lambda W \\beta \\] Thus, \\(\\mathrm{Bias}(\\hat{\\beta}_{\\text{ridge}})\\) is decreasing in the shrinkage factor \\(\\lambda\\). The bias of ridge regression is non-zero, \\(\\mathrm{Bias}(\\hat{\\beta}_{\\text{ridge}}) \\neq 0\\) when \\(\\lamba &gt; 0\\). When \\(\\lambda \\to 0\\), then \\(\\mathrm{Bias}(\\hat{\\beta}_{\\text{ridge}}) \\to 0\\). Additionally, \\[ \\Var(\\hat{\\beta}_{\\text{ridge}}) &lt; \\Var(\\hat{\\beta}_{\\text{OLS}}) \\] and \\(\\Var(\\hat{\\beta}_{\\text{ridge}})\\) is decreasing as \\(\\lambda \\to \\infty\\). The most important result with respect to ridge regression is that there always exists a \\(\\lambda\\) such that, \\[ MSE(\\hat{\\beta}_{\\text{ridge}}(\\lambda)) &lt; MSE(\\hat{\\beta}_{\\text{OLS}}) . \\] The complexity of the model is the degrees of freedom. In OLS, the degrees of freedom is the trace of the hat matrix, \\[ \\tr(H_{\\text{OLS}}) = k \\] where \\[ H_{\\text{OLS}} = (X&#39; X)^{-1} X&#39; . \\] In ridge regression, the degrees of freedom is the trace of the analagous hat matrix, \\[ df_{\\text{ridge}} = \\tr(H_{\\text{ridge}}) = \\sum \\frac{\\lambda_i}{\\lambda_i + \\lambda} \\] where \\[ H_{\\text{ridge}} = X W X&#39; , \\] and \\(\\lambda_i\\) are the eigenvalues of \\(X&#39; X\\). When \\(\\lambda \\to 0\\), then \\(df = k\\), and when \\(\\lambda \\to \\infty\\), then \\(df = 0\\). As expected, as the penalty factor increases the model complexity decreases. Some other implications: \\(\\hat{\\vec{\\beta}}\\) exists even if \\(\\hat{\\vec{\\beta}}_{\\text{OLS}}\\) (\\((\\mat{X}\\T\\mat{X})^{-1}\\)), i.e. cases of \\(n &gt; p\\) and collinearity, does not exist. If \\(\\mat{X}\\) is orthogonal (mean 0, unit variance, zero correlation), \\(\\mat{X}\\T \\mat{X} = n \\mat{I}_p\\) then \\[ \\hat{\\vec{\\beta}}_{\\text{ridge}} = \\frac{n}{n + \\lambda} \\hat{\\vec{\\beta}}_{\\text{ols}} \\] meaning, \\[ |\\hat{\\vec{\\beta}}_{\\text{ols}}| &gt; |\\hat{\\vec{\\beta}}_{\\text{ridge}}| \\geq 0 \\] Ridge does not produce sparse estimates, since \\((n / (n + \\lambda)) \\vec{\\vec{\\beta}}_{ols} = 0\\) iff \\(\\vec{\\vec{\\beta}}_{ols} = 0\\) If \\(\\lambda = 0\\), then the ridge coefficients are the same as the OLS coefficients, \\(\\lambda \\to 0 \\Rightarrow \\hat{beta}_{\\text{ridge}} \\to \\hat{beta}_{OLS}\\) As \\(\\lambda\\) increases the coefficients are shrunk to 0, \\(\\lambda \\to \\infty \\Rightarrow \\hat{\\beta}_{\\text{ridge}} = 0\\). 19.2.2 Bayesian Shrinkage As shown in the hierarchical chapter, modeling parameters hierarchically can shrink them. Consider the regression model, \\[ y_i \\sim \\dnorm(\\alpha + x&#39;_i \\beta_k) . \\] In the case of shrinkage in regularization, a hierarchical prior is applied to the regression coefficients \\(\\beta\\). The intercept, \\(\\alpha\\), is generally not shrunk. In all these cases, it can be given a weakly-informative prior such as, \\[ y_i \\sim \\dnorm(0, 10) . \\] 19.2.2.1 Normal Priors Unlike the weakly informative priors, the prior distributions all share a scale parameter \\(\\tau\\). \\[ \\beta_k | \\tau \\sim \\dnorm(0, \\tau) \\] We need to assign a prior to \\(\\tau\\). Often this is assigned an “uninformative” gamma or inverse-gamma prior because it has conjugacy properties. Analagous to later priors and current advice about scale parameter choices in Stan, a Student-t distribution with location 0, and a user-specified degrees of freedom \\(d_\\tau\\) and \\(s_\\tau\\) is reasonable, \\[ \\tau \\sim \\dt(d_\\tau, 0, s_\\tau) . \\] 19.2.2.1.1 Relationship to Ridge Regression For a given \\(\\lamba\\), the ridge regression estimator is a MAP estimator of the model, \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha + x&#39; \\beta, \\sigma) \\\\ \\beta_k &amp;\\sim \\dnorm(0, (2 \\lambda)^{-1/2} ) . \\end{aligned} \\] Recall that although OLS does not require normal errors, the OLS coefficients are equivalent to the MLE of a probability model with normal errors, \\[ \\begin{aligned} \\hat{\\beta}_{MLE} &amp;= \\arg \\max_{\\beta} \\dnorm(y | x \\beta, \\sigma) \\\\ &amp; = \\arg \\max_{\\beta} {(2 \\pi \\sigma^2)}^{n / 2} \\prod_{i = 1}^{n} \\exp\\left(-\\frac{(y_i - x_i&#39; \\beta)^2}{2 \\sigma^2}\\right) \\\\ &amp;= \\arg \\max_{\\beta} \\frac{n}{2} (\\log 2 + \\log \\pi) + n \\log \\sigma + \\sum_{i = 1}^{n} \\left( -\\frac{(y_i - x_i&#39; \\beta)^2}{2 \\sigma^2} \\right) \\\\ &amp; = \\arg \\max_{\\beta} \\sum_{i = 1}^{n} - (y_i - x&#39;_i \\beta)^2 \\\\ &amp;= \\arg \\min_{\\beta} \\sum_{i = 1} (y_i - x&#39;_i \\beta)^2 \\\\ &amp;= \\hat{\\beta}_{OLS} \\end{aligned} \\] Likewise the shrinkage prior can be represented as a normal distribution with mean 0 and scale \\(1 / \\lambda\\), since the \\(\\beta\\) that maximize the probability of that, minimize the \\(\\ell_2\\) norm of \\(\\beta\\), \\[ \\begin{aligned} \\arg \\max_{\\beta} \\dnorm(\\beta | 0, \\tau) &amp;= \\arg \\max_{\\beta} {(2 \\pi \\sigma^2)}^{K / 2} \\prod_{k = 1}^{K} \\exp\\left(- \\frac{(0 - \\beta_k)^2}{2 \\tau^2} \\right) \\\\ &amp;= \\arg \\max_{\\beta} \\sum_{k = 1}^{K} \\left(-\\frac{\\beta_k^2}{2 \\tau^2}\\right) \\\\ &amp;= \\arg \\min_{\\beta} \\frac{1}{2 \\tau^2} \\sum_{k = 1}^K \\beta_k^2 , \\end{aligned} \\] where \\(\\tau^2 = 1 / 2 \\lambda\\). 19.2.2.2 Student-t Distribution We can generalize the previous case and use Student-t distributions as a prior for the coefficients. The Cauchy distribution is a special case of the Student t distribution where the degrees of freedom is one. The prior distribution for each coefficient \\(\\beta_k\\) is a Student-t distribution with degrees of freedom \\(\\nu\\), location 0, and scale \\(\\tau\\), \\[ \\beta_k | \\tau \\sim \\dt(\\nu, 0, \\tau) . \\] Like many priors that have been proposed and used for coefficient shrinkage, this can be represented as a local-global scale-mixture of normal distributions. \\[ \\begin{aligned} \\beta_k | \\tau, \\lambda &amp;\\sim \\dnorm(0, \\tau \\lambda_k) \\\\ \\lambda_k^{-2} &amp;\\sim \\dgamma(\\nu/2, \\nu/2) \\end{aligned} \\] The degrees of freedom parameter \\(\\nu\\) can be fixed to a particular value or estimated. If fixed, then common values are 1 for a Cauchy distribution, 2 to ensure that there is a finite mean, 3 to ensure that there is a finite variance, and 4 ensure that there is a finite kurtosis. If the degrees of freedom is not specified, then use the prior, \\[ \\nu \\sim \\dgamma(2, 0.1) \\] Additionally, it may be useful to truncate the values of \\(\\nu\\) to be greater than 2 to ensure a finite variance of the Student t distribution. The following figure plots the probability density functions for normal, Cauchy, and Student-t (\\(df = 4\\)) distributions. Relative to a normal distribution, Student-t distributions will place more prior probability mass closer to zero, and also more mass that the distribution can be far large. tibble(x = seq(-5, 5, length.out = 100), `Normal` = dnorm(x), `Cauchy` = dcauchy(x), `Student-t (df = 4)` = dt(x, 4)) %&gt;% gather(Distribution, Density, -x) %&gt;% ggplot(aes(x = x, y = Density, colour = Distribution)) + geom_line() + xlab(expression(beta)) + ylab(expression(paste(&quot;p&quot;, &quot;(&quot;, beta, &quot;)&quot;))) Note that, the use of a Student \\(t\\) distribtion in the regression here is different than the use of the Student-t distribution for robustness. In the robustness case, \\(y_i\\) is distributed Student-t, \\[ y_i \\sim \\dt(\\nu_y, \\alpha + x_i&#39; \\beta, \\sigma), \\] or equivalently, the errors, \\(\\epsilon_i\\), are distributed Student-t, \\[ y_i = \\alpha + x&#39;_i \\beta + \\epsilon_i \\\\ \\epsilon_i \\sim \\dt(\\nu, 0, \\sigma) \\] In regularized regression with Student-t priors, the \\(\\beta\\) are distributed Student-t. These models could be combined, with a \\(\\epsilon_i\\) distributed Student-t and \\(\\beta\\) given Student-t priors, for a regularized robust regression. 19.3 Sparse Shrinkage A sparse shrinkage estimator is one that produces point estimates exactly equal to zero (in MAP), or posterior distributions where for some parameters, the probability density mass concentrates around zero (in full Bayes). Ridge regression and the prior distributions covered thus far are not sparse shrinkage estimators. Many of the proofs and results regarding the performance of these methods are for the case that the true parameters are sparse, usually defined as \\[ n \\to \\infty \\Rightarrow k / n \\to 0 , \\] where \\(k\\) is the true number of non-zero parameters, and \\(n\\) is the number of observations. Of sparse shrinkage estimators for regression coefficients, the most popular optimization MAPS There are two main approaches to sparsity in Bayesian statistics [CarvalhoPolsonScott2009a]: discrete mixtures that place a point mass at \\(\\beta_k = 0\\) (Beauchamp 1988, George and McCulloch 1993). THis is called a spike-and-slab prior. shrinkage solution which uses an absolutely continuous prior that places a large mass of its density near zero. The horseshoe prior is an example of this. Using Laplace (double exponential) priors, although analagous to the the lasso, is not an example. 19.3.1 Penalized Likelihood The lasso (Least Absolute Shrinkage and Selection Operator) uses an \\(\\ell_1\\) norm of \\(\\beta\\) as a penalty (Tibshirani 1996), \\[ \\hat{\\beta}_{\\text{lasso}} = \\arg\\min_{\\beta} \\frac{1}{2 \\sigma} \\sum_{i = 1}^n (\\vec{x}_i\\T \\vec{\\beta} - y_i)^2 + \\lambda \\sum_{k} |\\beta_k| \\] where \\(\\lambda \\geq 0\\) is a tuning or shrinkage parameter chosen by cross-validation or a plug-in statistic. The \\(\\ell_1\\) norm of \\(\\beta\\) is the sum of the absolute values of its elements, \\[ ||\\beta||_{1} = \\sum_{k = 1}^K |\\beta_k| . \\] Properties: Unlike ridge regression, it sets some coefficients exactly to 0, producing sparse solutions. If variables are perfectly correlated, there is no unique solution (unlike the ridge regression). Used as the best convex approximation of the “best subset selection” regression problem, which finds the number of nonzero entries in a vector. Unlike ridge regression, there is no closed-form solution. Since \\(|\\beta_k|\\) does not have a derivative, it was a more difficult iterative problem than many other regression functions. However, now there are several algorithms to estimate it. 19.3.2 Bayesian Sparse Shrinkage Models 19.3.2.1 Mixture Models This is a “gold standard” for sparse Bayesian estimation. It directly represents sparsity with a point mass on \\(\\beta_k\\). The prior is a two-component mixture of normal distributions \\[ \\begin{aligned}[t] \\beta_k | \\lambda_k, c, \\epsilon &amp;\\sim \\lambda_k N(0, c^2), + (1 - \\lambda_j) N(0, \\epsilon^2) \\\\ \\lambda_k &amp;\\sim \\dbern(\\pi), \\end{aligned} \\] for \\(k = 1, \\dots, K\\), and \\(\\epsilon &lt;&lt; c\\). The indicator variable \\(\\lambda_{k} \\in \\{0, 1}\\) denotes whether \\(\\beta_j\\) is close to zero; \\(\\lambda_k = 0\\) means that the coefficient came from the spike, and \\(\\lambda_k = 1\\) means that the coefficient came from the slab. The value of \\(\\epsilon\\) can be either 0, implying a delta spike at 0, or \\(\\epsilon &gt; 0\\), but small. The values of \\(c\\) and \\(\\pi\\) need to be chosen or assigned priors. If \\(\\epsilon = 0\\), then \\[ \\begin{aligned} \\beta_k | \\lambda_k, c &amp;\\sim \\dnorm(0, c^2 \\lambda^2_k), \\\\ \\lambda_k &amp;\\sim \\dbern(\\pi) \\end{aligned} \\] The shrinkage parameter only takes two values, \\[ \\kappa = \\begin{cases} 1 &amp; \\lambda_k = 0 \\\\ \\frac{1}{1 + n \\sigma^{-2} s^2_k c^2} &amp; \\lambda_k = 1 \\end{cases} \\] As \\(c \\to \\infty\\), then \\(\\kappa = \\{0, 1}\\), with shrinkage occurring either completely or not at all. In the case of the linear regression, an alternative to BMA is to use a spike-and-slab prior (Mitchell and Beauchamp 1988, @GeorgeMcCulloch1993a, @IshwaranRao2005a), which is a prior that is a discrete mixture of a point mass at 0 and a non-informative distribution. The posterior distribution of \\(w\\) is the probability that \\(\\beta_k \\neq 0\\), and the conditional posterior distribution \\(p(\\beta_k | y, w = 1)\\) is the distribution of \\(\\beta_k\\) given that \\(\\beta_k \\neq 0\\). See the R package spikeslab and he accompanying article (Ishwaran, Kogalur, and Rao 2010) for an implementation and review of spike-and-slab regressions. 19.3.2.2 Bayesian Lasso Similarly, the \\(\\beta\\) that minimize the \\(\\ell_1\\) norm also maximize the probability of random variables iid from the Laplace distribution, \\(\\dlaplace(\\beta_k | 0, 1 / \\lambda)\\). \\[ \\begin{aligned} \\arg \\max_{\\beta} \\dlaplace(\\beta | 0, 1 / \\lambda) &amp;= \\arg \\max_{\\beta} \\left(\\frac{\\lambda}{2}\\right)^{K} \\prod_{k = 1}^{K} \\exp\\left(- \\lambda |0 - \\beta_k)| \\right) \\\\ &amp;= \\arg \\max_{\\beta} \\sum_{k = 1}^{K} - \\lambda |\\beta_k| \\\\ &amp;= \\arg \\min_{\\beta} \\lambda \\sum_{k = 1}^K |\\beta_k| . \\end{aligned} \\] Thus lasso regression can be thought of as a MAP estimator of the model, \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha + x&#39; \\beta, \\sigma) , \\\\ \\beta_k &amp;\\sim \\dlaplace(0, 1 / \\lambda) . \\end{aligned} \\] The only difference in the lasso is the penalty term, which uses an absolute value penalty for \\(\\beta_k\\). That term corresponds to a sum of log densities of i.i.d. double exponential (Laplace) distributions. The double exponential distribution density is similar to a normal distribution, \\[ \\log p(y | \\mu, \\sigma) \\propto - \\frac{|y - \\mu|}{\\sigma} \\] So the LASSO penalty is equivalent to the log density of a double exponential distribution with location \\(0\\), and scale \\(1 / \\lambda\\). \\[ \\beta_k \\sim \\dlaplace(0, \\tau) \\] 19.3.2.3 Horseshore Prior The Horseshoe prior is defined solely in terms of a global-local mixture. \\[ \\begin{aligned} \\beta_k | \\tau, \\lambda &amp;\\sim \\dnorm(0, \\tau \\lambda_k) \\\\ \\lambda_k &amp;\\sim \\dhalfcauchy(0, 1) \\\\ \\tau &amp;\\sim \\dhalfcauchy(0, \\tau_0) \\end{aligned} \\] The heavy-tailed Cauchy prior on \\(\\lambda_k\\) allows individual coefficients to offset and global shrinkage, \\(\\tau\\), and take large values with little shrinkage. However, the horseshoe prior has computational issues. The heavy-tails can produce a posterior which does not sufficiently identify large slope coefficients, making it hard to sample. In HMC-NUTS, these issues will reveal themselves as divergences and often require increase the value of adapt or increasing the value of the treedepth. The hierarchical shrinkage prior replaces the half-Cauchy prior on \\(\\lambda_k\\) with a half-Student-t distribution with degrees of freedom \\(\\nu\\). \\[ \\lambda_k \\sim \\dhalft(\\nu, 0, 1) \\] The \\(\\nu\\) parameter is generally not estimated and fixed to a low value, with \\(\\nu = 4\\) being suggested. The problem with estimating the horseshoe prior is that the wide tails of the Cauchy prior produced a posterior distribution with problematic geometry that was hard to sample. Increasing the degrees of freedom helped to regularize the posterior. The downside of this method is that by increasing the degrees of freedom of the Student-t distribution it would also shrink large parameters, which the horseshoe prior was designed to avoid. The regularized horseshoe prior (or Finnish horseshoe prior) is defined as \\[ \\begin{aligned} \\beta_k | \\tau, \\lambda &amp;\\sim \\dnorm(0, \\tau \\tilde{\\lambda}_k) \\\\ \\tilde{\\lambda}_k &amp;= \\frac{c \\lambda}{\\sqrt{c^2 + \\tau \\lambda^2}} \\\\ \\lambda_k &amp;\\sim \\dhalfcauchy(1) \\\\ c^2 &amp;\\sim \\invgamma(d_{\\text{slab}} / 2, d_{\\text{slab}} s_{\\text{slab}}^2 / 2) \\\\ \\tau &amp;\\sim \\dhalfcauchy(0, \\tau_0^2) \\end{aligned} \\] Where \\(d_{\\text{slab}}\\) is the degrees of freedom for the slab, and \\(s_{\\text{slab}}\\) is the scale of the slab. For defaults rstanarm uses \\(d_{\\text{slab}} = 4\\) and \\(s_{\\text{slab}} = 2.5\\). Like using a Student-t distribution, this regularizes the posterior distribution of a Horseshoe prior. However, it is less problematic than using the Student-t distribution because it shrinks large coefficients less. The value of \\(\\tau\\) and the choice of its hyper-parameter has a big influence on the sparsity of the coefficients. 19.4 Piironen and Vehtari (2017) treat the prior on \\(\\tau\\) as the implied prior on the number of effective parameters. The shrinkage can be understood as its influence on the number of effective parameters, \\(m_{eff}\\), \\[ m_{\\text{eff}} = \\sum_{j = 1}^K (1 - \\kappa_j) . \\] This is a measure of effective model size. Piironen and Vehtari (2017) show that for a given \\(n\\) (data standard deviation), \\(\\tau\\), \\(\\lambda_k\\), and \\(\\sigma\\), the and variance of \\(m_{eff}\\) \\[ \\begin{aligned}[t] \\E[m_{eff} | \\tau, \\sigma] &amp;= \\frac{\\sigma^{-1} \\tau \\sqrt{n}}{1 + \\sigma^{-1} \\tau \\sqrt{n}} K , \\\\ \\Var[m_{eff} | \\tau, \\sigma] &amp;= \\frac{\\sigma^{-1} \\tau \\sqrt{n}}{2 (1 + \\sigma^{-1} \\tau \\sqrt{n})2} K . \\end{aligned} \\] Given a prior guess about the sparsity \\(\\beta\\), a prior should be chosen such that it places mass near that guess. Let \\(k_0 \\in [0, K]\\) be the expected number of non-zero elements of \\(\\beta\\), then choose \\(\\tau_0\\) such that \\[ \\tau_0 = \\frac{k_0}{K - k_0}\\frac{\\sigma}{\\sqrt{n}} \\] This prior depends on the expected sparsity of the solution, which depends on the problem. PiironenVehtari2017a provide no guidence on how to select \\(p_0\\). Perhaps a simpler model, e.g. lasso could be used to estimate \\(p_0\\). Datta and Ghosh (2013) warn against empirical Bayes estimators of \\(\\tau\\) for the horseshoe prior as it can collapse to 0. Scott and Berger (2010) consider marginal maximum likelihood estimates of \\(\\tau\\). –&gt; Pas, Kleijn, and Vaart (2014) suggest that an empirical Bayes estimator truncated below at \\(1 / n\\). 19.4.1 Shrinkage Factor Suppose that \\(X\\) is a \\(n \\times K\\) matrix of predictors, and \\(y\\) is a \\(n \\times 1\\) vector of outcomes. The conditional posterior for \\(\\beta\\) given \\((X, y)\\) is \\[ \\begin{aligned}[t] p(\\beta | \\Lambda, \\tau, \\sigma^2, D) &amp;= \\dnorm(\\beta | \\bar{\\beta}, \\Sigma), \\\\ \\bar{\\beta} &amp;= \\tau^2 \\Lambda (\\tau^2 \\Lambda + \\sigma^2 (X&#39;X)^{-1})^{-1} \\hat{\\beta}, \\\\ \\Sigma &amp;= (\\tau^{-2} \\Lambda^{-1} + \\frac{1}{\\sigma^{2}} X&#39;X)^{-1}, \\\\ \\Lambda &amp;= \\diag(\\lambda_1^{2}, \\dots, \\lambda^{2}_D), \\\\ \\hat{\\beta} &amp;= (X&#39;X)^{-1} X&#39;y . \\end{aligned} \\] If the predictors are uncorrelated with zero mean and variances \\(\\Var(x_k) = s_k^2\\), then \\[ X&#39;X \\approx n \\diag(s_1^2, \\dots, s^2_K) , \\] and we can use the approximations, \\[ \\bar{\\beta}_k = (1 - \\kappa_k) \\hat{\\beta}_k, \\\\ \\kappa_k = \\frac{1}{1 + n \\sigma^{-2} \\tau^2 s_k^2 \\lambda_k^2} . \\] The value \\(\\kappa_k\\) is called the shrinkage factor for coefficient \\(\\beta_k\\). When \\(\\kappa_k = 0\\), then there is no shrinkage and the posterior coefficient is the same as the MLE solution, \\(\\bar{\\beta} = \\hat{\\beta}\\). When \\(\\kappa_k = 1\\), then there is complete shrinkage and the posterior coefficient is zero, \\(\\bar{\\beta} = 0\\). It also follows that \\(\\bar{\\beta} \\to 0\\) as \\(\\tau \\to 0\\), and \\(\\bar{\\beta} \\to \\hat{\\beta}\\) as \\(\\tau \\to \\infty\\). shrinkage_factor &lt;- function(n, sigma = 1, tau = 1, sd_x = 1, lambda = 1) { 1 / 1 + n * tau ^ 2 * sd_x ^ 2 * lambda ^ 2 / sigma ^ 2 } 19.4.2 Prior on the Global Scale The value of \\(\\tau\\) and the choice of its hyper-parameter has a big influence on the sparsity of the coefficients. However, there are varying suggestions for how to set this. (Carvalho, Polson, and Scott 2009, @PolsonScott2011a, @PasKleijnVaart2014a). Shrinkage can be understood as its influence on the number of effective parameters, \\(m_{eff}\\) (Piironen and Vehtari 2016), \\[ m_{\\text{eff}} = \\sum_{j = 1}^K (1 - \\kappa_j) . \\] This is a measure of model complexity or model size However, the interpretation as the “number of non-zero parameters” is less meaningful when the The values of \\(\\kappa_i\\) can be used for thresholding. Carvalho et al suggest a decision rule of selecting variables where \\(\\kappa_k &gt; 1 / 2\\). I have not seen it described elsewhere, but the level of sparsification can be summarized by comparing the variance of \\(\\kappa_k\\) given \\(m_eff\\) to the case where all \\(kappa_k \\in \\{0, 1\\}\\). If all \\(\\kappa_k\\) are zero or one, then \\[ s_{\\text{eff}} = \\frac{\\sum(\\kappa_k - m_{\\text{eff}} / K)^2}{(m_{\\text{eff}} / K) (1 - m_{\\text{eff}} / K)} \\] If \\(s_{eff} = 1\\), then all \\(\\kappa_{k}\\) are one or zero; if \\(s_{eff} = 0\\), the all \\(\\kappa_{k} = m_{eff} / K\\) (uniform shrinkage as with a normal prior). If the prior can be represented as a scale mixture of normal distributions, then the the mean and variance of \\(m_{eff}\\) are \\[ \\begin{aligned}[t] \\E[m_{\\text{eff}} | \\tau, \\sigma] &amp;= \\sum_{k = 1}^{K} \\frac{a_k}{1 + a_k} , \\\\ \\Var[m_{\\text{eff}} | \\tau, \\sigma] &amp;= \\sum_{k = 1}^{K} \\frac{a_k}{2 \\left(1 + a_k \\right)^2} . \\end{aligned} \\] where \\(a_k = \\sigma^{-1} \\tau \\sqrt{n} s_k\\) (Piironen and Vehtari 2017). The prior should be chosen so that the prior mass is located near \\[ \\tau_0 = \\frac{k_0}{K - k_0}\\frac{\\sigma}{\\sqrt{n}} . \\] where \\(k_0\\) is a guess as to the number of non-zero coefficients. Note that the choice of \\(\\tau\\) must scale with the observation noise \\(\\sigma\\) and the number of observations \\(n\\). Calculate the shrinkage factor \\(\\kappa_k\\) given \\(n\\), \\(\\sigma\\), \\(\\tau\\), \\(sd_x\\), and \\(\\lambda_k\\). shrinkage_factor &lt;- function(n, lambda = 1, tau = 1, sigma = 1, sd_x = 1) { 1 / (1 + n * tau ^ 2 * sd_x ^ 2 * lambda ^ 2 / sigma ^ 2) } Choose $ optimal_tau &lt;- function(k0, K, n, sigma = 1) { k0 / (K - k0) * sigma / sqrt(n) } 19.5 Differences between Bayesian and Penalized ML There are several differences between Bayesian approaches to shrinkage and penalized ML approaches. The point estimates: ML: mode Bayesian: posterior mean (or median) In Lasso ML: the mode produces exact zeros and sparsity Bayesian: posterior mean is not sparse (zero) Choosing the shrinkage penalty: ML: cross-validation Bayesian: a prior is placed on the shrinkage penalty, and it is estimated as part of the posterior. 19.6 Examples 19.6.1 Diabetes data(&quot;diabetes&quot;, package = &quot;lars&quot;) The diabetes data has 442 observations (from Efron, Hastie, Johnston, Tibshirani 2003 LARS paper). The data are provided as matrices, with x a matrix with 10 columns, y a numeric vector with the response, and and x2 a matrix with 64 columns (x plus interactions. The matrix x has been standardized to have zero mean and unit variance. 19.6.1.1 Penalized Regression Before turning to full Bayesian estimation, we can produce MAP estimates for the model for the following: Flat priors Ridge regression/Normal priors/L2 penalty Lasso regresssion/Laplace (double exponential) priors/L1 penalty diabetes_map_lm &lt;- lm(y ~ x, data = diabetes) diabetes_map_ridge &lt;- glmnet(diabetes$x, diabetes$y, alpha = 1) diabetes_map_lasso &lt;- glmnet(diabetes$x, diabetes$y, alpha = 0) Note that even x was a matrix, we can use it on the right-hand-side of the formula, and the formula object knows to use the columns of it. By default glmnet estimates the coefficients for the range of the shrinkage penalty \\(\\lambda\\). The sequence of values of a coefficient for values of \\(\\lambda\\) from \\(\\lambda = 0\\) (no shrinkage) to \\(\\lambda \\approx \\infty\\) (large enough that all coefficients are zero) is called the coefficient path. The plot method for the glmnet objects returned by glmnet() will plot coefficient paths. Here I will extract the data using broom::tidy() and plot them with ggplot(). diabetes_coefpaths &lt;- bind_rows( mutate(tidy(diabetes_map_lasso), model = &quot;Lasso (L1)&quot;), mutate(tidy(diabetes_map_ridge), model = &quot;Ridge (L2)&quot;)) %&gt;% filter(term != &quot;(Intercept)&quot;) diabetes_coefpaths %&gt;% ggplot(aes(x = -log(lambda), y = estimate, group = term)) + geom_line() + facet_wrap(~ model, ncol = 1, scales = &quot;free_x&quot;) + labs(x = expression(-log(lambda)), y = expression(beta)) Note that the \\(\\lambda\\) penalties are on different scales in the Lasso and ridge regession. Nevertheless we see that the ridge regression coefficients smoothly converge towards zero as \\(- \\log(\\lambda) \\to 0\\), while the lasso coefficients eventually hit zero and then are set to zero. To put them on the same scale, instead of plotting the coefficient paths vs. \\(\\lambda\\) we could instead plot it against the percent of deviance explained. diabetes_coefpaths %&gt;% ggplot(aes(x = dev.ratio, y = estimate, group = term)) + geom_line() + facet_wrap(~ model, ncol = 1, scales = &quot;free_x&quot;) + labs(x = expression(&quot;% Deviance&quot;), y = expression(beta)) However, glmnet does not choose a value of lambda. To choose a particular value of lambda using K-fold cross-validation, use cv.glmnet. I will use the default value of 10 folds. diabetes_ridge_cv &lt;- cv.glmnet(diabetes$x, diabetes$y, alpha = 0, nfolds = 10, parallel = TRUE) #&gt; Warning: executing %dopar% sequentially: no parallel backend registered This plots the values of \\(\\lambda\\), the MSE (and its standard error) and the lines indicate the \\(\\lambda\\) with the lowest MSE and the one chosen by the 1-standard deviation rule. plot(diabetes_ridge_cv) Similarly for lasso. diabetes_lasso_cv &lt;- cv.glmnet(diabetes$x, diabetes$y, alpha = 1, nfolds = 10, parallel = TRUE) plot(diabetes_lasso_cv) For the optimal \\(\\lambda\\), Lasso produces the following number of non-zero coefficients: lasso_nonzeros &lt;- function(x, se = TRUE) { lambdahat &lt;- if (se) &quot;lambda.1se&quot; else &quot;lambda.min&quot; unname(x$nzero[which(x$lambda == x[[lambdahat]])]) } lasso_nonzeros(diabetes_lasso_cv) #&gt; [1] 5 get_glmnet_coef &lt;- function(x) { lambdahat &lt;- &quot;lambda.1se&quot; coefpaths &lt;- tidy(x[[&quot;glmnet.fit&quot;]]) filter(coefpaths, lambda == x[[lambdahat]]) } OLS, lasso, and ridge point estimates. Coefficients are ordered in descending value of \\(|\\hat{\\beta}_{OLS}|\\). bind_rows( mutate(tidy(diabetes_map_lm), model = &quot;OLS&quot;), mutate(get_glmnet_coef(diabetes_ridge_cv), model = &quot;ridge&quot;), mutate(get_glmnet_coef(diabetes_lasso_cv), model = &quot;lasso&quot;)) %&gt;% mutate(term = if_else(model %in% c(&quot;OLS&quot;), str_replace(term, &quot;^x&quot;, &quot;&quot;), term)) %&gt;% select(model, term, estimate) %&gt;% complete(model, term, fill = list(estimate = 0)) %&gt;% filter(!term %in% &quot;(Intercept)&quot;) %&gt;% mutate(term = fct_reorder(term, if_else(model == &quot;OLS&quot;, abs(estimate), NA_real_), mean, na.rm = TRUE)) %&gt;% ggplot(aes(x = term, y = estimate, colour = model)) + geom_hline(yintercept = 0, colour = &quot;white&quot;, size = 2) + geom_point() + coord_flip() + labs(y = expression(hat(beta)), x = &quot;&quot;) Note that while tc has the largest OLS point estimate, both ridge and lasso estimate it to be approximately zero. For the hdl coefficient, the lasso and ridge estimates have a different sign than OLS and are larger in magnitude. 19.6.1.2 Full Bayes We can estimate this with Stan models and rstanarm. The rstanarm models are faster. However, at the moment rstanarm does not provide ridge regression. Additionally, the Stan models provided will also return the shrinkage parameters, effective number of parameters, and local scales. 19.6.1.2.1 Stan models Weakly informative priors Shrinkage with normal priors Shrinkage with Student t priors Shrinkage with Laplace priors Shrinkage with Horseshoe priors model_names &lt;- c(&quot;lm_normal_1&quot;, &quot;lm_shrinkage_normal_1&quot;, &quot;lm_shrinkage_student_t_1&quot;, &quot;lm_shrinkage_laplace_1&quot;, &quot;lm_shrinkage_hs&quot;) models &lt;- map(model_names, function(nm) { stan_model(file.path(&quot;stan&quot;, str_c(nm, &quot;.stan&quot;))) }) #&gt; hash mismatch so recompiling; make sure Stan code ends with a blank line #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:1: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Core:531: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:2: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/LU:47: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Jacobi:29: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/QR:17: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Householder:27: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:5: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SVD:48: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Geometry:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:7: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Eigenvalues:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:26: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCore:66: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:27: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/OrderingMethods:71: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:29: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:32: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseQR:35: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb12469916.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:33: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/IterativeLinearSolvers:46: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; 13 warnings generated. #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:1: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Core:531: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:2: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/LU:47: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Jacobi:29: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/QR:17: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Householder:27: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:5: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SVD:48: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Geometry:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:7: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Eigenvalues:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:26: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCore:66: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:27: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/OrderingMethods:71: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:29: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:32: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseQR:35: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbdf0834b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:33: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/IterativeLinearSolvers:46: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; 13 warnings generated. #&gt; hash mismatch so recompiling; make sure Stan code ends with a blank line #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:1: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Core:531: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:2: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/LU:47: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Jacobi:29: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/QR:17: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Householder:27: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:5: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SVD:48: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Geometry:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:7: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Eigenvalues:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:26: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCore:66: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:27: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/OrderingMethods:71: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:29: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:32: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseQR:35: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cbfb1fc8b.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:33: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/IterativeLinearSolvers:46: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; 13 warnings generated. #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:1: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Core:531: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:2: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/LU:47: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Jacobi:29: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/QR:17: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Householder:27: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:5: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SVD:48: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Geometry:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:7: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Eigenvalues:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:26: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCore:66: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:27: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/OrderingMethods:71: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:29: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:32: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseQR:35: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb6808c138.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:33: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/IterativeLinearSolvers:46: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; 13 warnings generated. #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:1: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Core:531: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:2: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/LU:47: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Jacobi:29: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/QR:17: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Householder:27: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:5: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SVD:48: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Geometry:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:7: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Eigenvalues:58: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:26: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCore:66: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:27: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/OrderingMethods:71: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:29: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCholesky:43: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:32: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseQR:35: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; In file included from filed8cb7e83cc69.cpp:8: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:33: #&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/IterativeLinearSolvers:46: #&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas] #&gt; #pragma clang diagnostic pop #&gt; ^ #&gt; 13 warnings generated. names(models) &lt;- model_names This preprocesses the data that will be used by all the models. diabetes_standata &lt;- lst( X = scale(diabetes$x), K = ncol(X), N = nrow(X), y = as.numeric(scale(diabetes$y)), scale_alpha = 10, rate_sigma = 1, use_log_lik = 1, use_y_rep = 1 ) diabetes_standata_winf &lt;- within(diabetes_standata, { scale_beta &lt;- rep(2.5, K) }) fit_normal &lt;- sampling(models[[&quot;lm_normal_1&quot;]], data = diabetes_standata_winf) diabetes_standata_normal &lt;- within(diabetes_standata, { df_tau &lt;- 4 scale_tau &lt;- 2.5 }) fit_normal &lt;- sampling(models[[&quot;lm_shrinkage_normal_1&quot;]], data = diabetes_standata_normal, control = list(adapt_delta = 0.95)) diabetes_standata_student_t &lt;- within(diabetes_standata, { df_tau &lt;- 4 scale_tau &lt;- 1 df_lambda &lt;- 2 }) fit_student &lt;- sampling(models[[&quot;lm_shrinkage_student_t_1&quot;]], data = diabetes_standata_student_t, control = list(adapt_delta = 0.99, max_treedepth = 13)) #&gt; Warning: There were 6 divergent transitions after warmup. Increasing adapt_delta above 0.99 may help. See #&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #&gt; Warning: Examine the pairs() plot to diagnose sampling problems diabetes_nonzero &lt;- lasso_nonzeros(diabetes_lasso_cv) diabetes_standata_hs &lt;- within(diabetes_standata, { scale_tau &lt;- diabetes_nonzero / (K - diabetes_nonzero) / sqrt(N) df_tau &lt;- 1 df_slab &lt;- 25 scale_slab &lt;- 4 df_lambda &lt;- 1 }) fit_hs &lt;- sampling(models[[&quot;lm_shrinkage_hs&quot;]], data = diabetes_standata_hs, control = list(adapt_delta = 0.99)) #&gt; Warning: There were 10 divergent transitions after warmup. Increasing adapt_delta above 0.99 may help. See #&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #&gt; Warning: Examine the pairs() plot to diagnose sampling problems 19.6.1.2.2 rstanarm Estimate a model with a weakly informative prior. fit_diabetes &lt;- list() fit_diabetes[[&quot;weak_inf&quot;]] &lt;- stan_glm(y ~ x, family = gaussian(), prior = normal(location = 0, scale = 2.5, autoscale = TRUE), prior_intercept = normal(location = 0, scale = 10, autoscale = TRUE), prior_aux = exponential(rate = 1, autoscale = TRUE), data = diabetes, refresh = -1) Estimate a model using the hierarchical shrinkage prior included in rstanarm. tau0 &lt;- 4 / (ncol(diabetes$x) - 4) / sqrt(nrow(diabetes$x)) fit_diabetes[[&quot;hs&quot;]] &lt;- stan_glm(y ~ x, family = gaussian(), prior = hs(df = 1, global_df = 1, global_scale = tau0, slab_df = 25, slab_scale = 2.5 * sd(diabetes$y)), data = diabetes) stan_glmdoes not adjust for the scale of the outcome or covariates in the slab. However, if slab_df is set to a low value, such as the default slab_df = 4, the tails of the Student-t distribution are wid enough that the data can overcome the likelihood even if slab_scale is narrow. If slab_df is set to a higher number, the narrow tails mean that slab_scale must be set to the a reasonable value. Estimate a model with Laplace priors. fit_diabetes[[&quot;lasso&quot;]] &lt;- stan_glm(y ~ x, family = gaussian(), prior = lasso(df = 1, location = 0, scale = 2.5, autoscale = TRUE), prior_intercept = normal(location = 0, scale = 10), prior_aux = exponential(rate = 1, autoscale = TRUE), data = diabetes) 19.6.2 Example Some fake sparse data[^sparse-fake] n &lt;- 100 p &lt;- 100 # number of variables s &lt;- 3 # number of variables with non-zero coefficients X &lt;- matrix(rnorm(n * p), ncol = p) beta &lt;- c(rep(5, s), rep(0, p - s)) Y &lt;- X %*% beta + rnorm(n) 19.7 Shrinkage with Correlated Variables Up until now, the various approaches modeled regression coefficients hieararchically, but did not account for correlations between them. In many cases, theoretical results for them rely upon assuming uncorrelated predictors. In the MAP case: ridge regression will shrink both correlated variables lasso will arbitrary shrink one regression In full Bayes, highly correlated variables can produce posteriors that are harder to sample from. For example, producing divergences. Some alternative models for correlated variables. using the PCA transformation of \\(X\\) and using the previous rstanarm::stan_lm will shrink the regression QR decomposition by a Zellner’s g-prior 19.8 Variable Selection Variable selection is closely related to sparse shrinkage methods. Sparse shrinkage methods can be seen as offering an alternative. Can sparse shrinkage estimators do variable selection? It depends on the what estimator is being used. MAP - posterior mode. Yes, it can se some coefficients to zero. Posterior mean. No, it only shrinks them. Note that the shrinkage/not selection properties of the posterior mean also applied to BMA and the mixture methods. They will assign some probability to both zero and non-zero values of each coefficient values, so the posterior mean will (almost certainly) be non-zero, even if the posterior includes a point mass at zero. However, we can calculate the posterior distribution and then use a second step to decide on the “sparse” model. HPD: select the combination of coefficients with the highest posterior density (BMA, spike-and-slab). MPD: select any variables where the median of the probability of inclusion is greater than 0.5 (BMA, spike-and-slab). Ad hoc-rule for horseshoe priro: select if \\(\\kappa_k &lt; 0.5\\) (Datta and Ghosh). This is the equivalent of the MPD rule. Decision problem: e.g. projpred, and Hahn and Carvalho. "],
["multilevel-models.html", "20 Multilevel Models 20.1 Terminology 20.2 Normal 20.3 Example: Radon 20.4 Radon Example 20.5 With Individual Covariates 20.6 With Group-Level Covariates 20.7 Pooling of Hierarchical Parameters 20.8 lme4 20.9 Priors for Covariances 20.10 Cetered and Non-centered Parameterizations 20.11 Extensions 20.12 Miscellaneous 20.13 References", " 20 Multilevel Models library(&quot;rstan&quot;) library(&quot;rstanarm&quot;) library(&quot;tidyverse&quot;) library(&quot;broom&quot;) Multilevel models are a commonly used hierarchical model. They extend (generalized) linear models to include coefficients that vary by discrete groups. 20.1 Terminology These models go by different names in different literatures: hierarchical (generalized) linear models, nested data models, mixed models, random coefficients, random-effects, random parameter models, split-plot designs.14 There are further names for specific types of these models including varying-intercept, varying-slope,rando etc. In classical statistics there two main approaches to these models: Maximum likelihood (and variations): See the lme4 package. This is more common in statistics and many social sciences (except economics). OLS and adjusted standard errors: See the plm packge. This is the stanard econometric approach. See “Some false friends” in the plm vignette and A. Gelman and Hill (2007, 245, fn. 5) for discussion of the differences between these approaches. 20.2 Normal Notation: Units: \\(i = 1, \\dots, n\\). Outcomes: \\(y = (y_1, \\dots, y_n)\\) Predictors: \\(X\\) is a \\(n \\times p\\) matrix; \\(x_i\\) is the \\(K \\times 1\\) column vector of individual \\(i\\)’s predictors. Groups: \\(j = 1, \\dots, m\\). Each observation is in a group. Let \\(j[i]\\) indicate the group that observation \\(i\\) is in. Suppose we want to estimate a regression for these data, where thet data generating process is \\(y_i = \\alpha_i + X_i \\beta_i\\) with normal errors. Depending on how we model differences between groups we can approach this in three ways Pooled model Individual models Partially pooled model In the pooled model we ignore differences between groups and use common coefficients. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha + x_i&#39; \\beta, \\sigma) \\\\ \\end{aligned} \\] The pooled model estimates one model, with three parameters: \\(\\alpha\\), \\(\\beta\\), and \\(\\sigma\\). In an individual or non-pooled model, a sepearate model is estimated for each group. For each \\(j&#39; \\in 1, \\dots, m\\), estimate the model \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]} + x_i&#39; \\beta_{j[i]}, \\sigma_{j[i]}) &amp; \\text{ where } j[i] = j&#39; . \\end{aligned} \\] The non-pooled model estimates \\(m\\) separate models with \\(m \\times 3\\) parameters, one \\(\\alpha\\), \\(\\beta\\), and \\(\\sigma\\) for each group. Note that in this model, no information is shared between groups. The data from another group and its estimates of \\(\\alpha\\) or \\(\\beta\\) do not help in the estimation of another group. However, if these are in any way similar problems we may think that the values of \\(\\alpha\\) and \\(\\beta\\) differ between groups, but that they should be similar. We should think that there must be a way to share that information via a prior. This insight will lead to the partially pooled model. In a partially pooled model, different groups have different parameters, but these group parameters share common hyperpriors—priors in which the distribution is a function of parameters estimated from the data. This is an example of a partially pooled model, \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]} + \\beta_{j[i]} x_i, \\sigma_{j[i]}) \\\\ \\begin{bmatrix} \\alpha_j \\\\ \\beta_j \\end{bmatrix} &amp; \\sim \\dnorm \\left( \\begin{bmatrix} \\mu_\\alpha \\\\ \\mu_\\beta \\end{bmatrix}, \\Omega \\right) \\\\ \\sigma_{j[i]} &amp;\\sim p(.) \\end{aligned} . \\] The imporant feature of this model, is that the priors for the parameters \\(\\alpha_j\\), \\(\\beta_j\\) are functions of other parameters, often called hyperparmeters, \\(\\mu_{\\alpha}\\), \\(\\mu_{\\beta}\\), and \\(\\Omega\\). This is allows for sharing information between groups. The observations from one group help to estimate \\(\\mu_{\\alpha}\\), \\(\\mu_{\\beta}\\), and \\(\\Sigma\\), which in turn help to estimate the \\(\\alpha_j\\) and \\(\\beta_j\\) in another group. If the parameters of the prior distribution of \\(\\alpha\\) and \\(\\beta\\) were fixed (data) and not themselves parameters, this sharing of information would not occur. Figure 20.1: Visual representation of hierarchical models We can also allow some parameters to vary between groups, but pool other parameters. Group-heteroskedastic: Assume that the intercept (\\(\\alpha\\)) and slope (\\(\\beta\\)) are the same across groups, but allow the scale of the regression error to vary between groups. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha + x&#39;_i \\beta, \\sigma_{j[i]}) \\\\ \\log \\sigma_j &amp;\\sim \\dnorm(\\tau, \\psi) \\end{aligned} \\] The prior on the \\(\\log \\sigma_j\\) has two parameters, \\(\\tau\\) (the average log-standard deviation of the errors) and \\(\\psi\\), which determines the level of heteroskedasticity. In a varying-intercept model keep the slope coefficients (\\(\\beta\\)) common between groups, but allow the intercepts (\\(\\alpha_j\\)) to vary by group. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]} + \\beta x_i, \\sigma) \\\\ \\alpha_{j} &amp;\\sim \\dnorm(\\mu_\\alpha, \\omega_{\\alpha}) \\end{aligned} \\] In a varying-slope model, the groups share a common intercept, \\(\\alpha\\), but the slope coefficient (\\(\\beta\\)), varies between groups. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha + \\beta_{j[i]} x_i, \\sigma^2) \\\\ \\beta_{j} &amp; \\sim \\dnorm(\\mu_{\\beta}, \\omega_{\\beta}) \\end{aligned} \\] This is less common since it is hard to think of cases when it is appropriate. More often, if the slope coefficient is allowed to vary between groups, the the intercepts should as well. This is the more-general varying-slope varying-intercept model, \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha + \\beta_{j[i]} x_i, \\sigma^2) \\\\ \\begin{bmatrix} \\alpha_j \\\\ \\beta_j \\end{bmatrix} &amp; \\sim \\dnorm \\left( \\begin{bmatrix} \\mu_\\alpha \\\\ \\mu_\\beta \\end{bmatrix}, \\Omega \\right) \\end{aligned} \\] 20.3 Example: Radon This example models the presence of radon in houses in Minnesota which appears in A. Gelman and Hill (2007) and A. Gelman, Carlin, et al. (2013). This is partly derived from a Stan Case Study, which uses PyStan instead of rstan. 20.3.1 Data The radon data is included in the rstanarm package. data(&quot;radon&quot;, package = &quot;rstanarm&quot;) glimpse(radon) #&gt; Observations: 919 #&gt; Variables: 4 #&gt; $ floor &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... #&gt; $ county &lt;fct&gt; AITKIN, AITKIN, AITKIN, AITKIN, ANOKA, ANOKA, ANOK... #&gt; $ log_radon &lt;dbl&gt; 0.8329, 0.8329, 1.0986, 0.0953, 1.1632, 0.9555, 0.... #&gt; $ log_uranium &lt;dbl&gt; -0.689, -0.689, -0.689, -0.689, -0.847, -0.847, -0... The data consist of 919 observations of radon levels of houses from 85 counties. radon_county &lt;- radon %&gt;% group_by(county) %&gt;% summarise(log_radon_mean = mean(log_radon), log_radon_sd = sd(log_radon), log_uranium = mean(log_uranium), n = length(county)) %&gt;% mutate(log_radon_se = log_radon_sd / sqrt(n)) ggplot() + geom_boxplot(data = radon, mapping = aes(y = log_radon, x = fct_reorder(county, log_radon, mean)), colour = &quot;gray&quot;) + geom_point(data = radon, mapping = aes(y = log_radon, x = fct_reorder(county, log_radon, mean)), colour = &quot;gray&quot;) + geom_point(data = radon_county, mapping = aes(x = fct_reorder(county, log_radon_mean), y = log_radon_mean), colour = &quot;black&quot;) + coord_flip() + labs(y = &quot;log(radon)&quot;, x = &quot;&quot;) The observations in counties vary in size, ggplot(radon_county, aes(x = log2(n))) + geom_density() + geom_rug() Unsurprisingly, there is more variation in county means among counties with smaller numbers of observations. ggplot(radon_county, aes(y = log_radon_mean, x = log2(n))) + geom_point() Much of this can be explained simply by sampling error. 20.4 Radon Example In this example we want to model the amount of radon (log scale) in a home. Let \\(y_i\\) be the centered and scaled log amount of radon in home \\(i\\). The simplest model is a pooled model, where all homes are modeled as iid draws from a common distribution. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha, \\sigma) &amp; \\text{for } i \\in 1, \\dots, n \\\\ \\alpha &amp;\\sim \\dnorm(0, 10) \\\\ \\sigma &amp;\\sim \\dexp(1) \\end{aligned} \\] where \\(\\alpha\\) and \\(\\sigma\\) are given weakly informative priors. We will estimate these models rstanarm functions stan_glm and stan_glmer. fit_radon_1 &lt;- stan_glm(log_radon ~ 1, data = radon, refresh = -1) We can extend this to a no-pooling model with a different mean for each county. Let \\(j[i] \\in 1, \\dots, m\\) be the county of observation \\(i\\). \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]}, \\sigma) &amp; \\text{for } i \\in 1, \\dots, n \\\\ \\alpha_j &amp;\\sim \\dnorm(0, 10) &amp; \\text{for } j \\in 1, \\dots, m \\end{aligned} \\] The \\(\\alpha_j\\) are all drawn from weakly informative prior distributions. And although the \\(\\alpha_j\\) are drawn from the same prior distribution, it has fixed parameters and thus no information is shared between observations in different counties. fit_radon_2 &lt;- stan_glm(log_radon ~ -1 + county, data = radon, refresh = -1) Finally, consider a partially pooled model. Like the previous model, each county has its own mean value. However, now these county-means share a prior which has its own parameters. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]}, \\sigma) &amp; \\text{for } i \\in 1, \\dots, n \\\\ \\alpha_j &amp;\\sim \\dnorm(\\mu, \\tau) &amp; \\text{for } j \\in 1, \\dots, m \\end{aligned} \\] We could also write the model with the country-level average in the mean equation for \\(y\\), and the \\(\\alpha_j\\) values distributed around the county level average, \\(\\gamma\\). \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]}, \\sigma) &amp; \\text{for } i \\in 1, \\dots, n \\\\ \\alpha_j &amp;\\sim \\dnorm(\\gamma, \\tau) &amp; \\text{for } j \\in 1, \\dots, m \\\\ \\tau &amp;\\sim \\dexp(1) \\end{aligned} \\] Hierarchical/multi-level generalized linear models can be estimated with stan_glmer. fit_radon_3 &lt;- stan_glmer(log_radon ~ (1 + floor | county), data = radon, refresh = -1) For each of these models extract the county means. alpha_1 &lt;- tidyMCMC(fit_radon_1, conf.int = TRUE) %&gt;% filter(term == &quot;(Intercept)&quot;) %&gt;% # add county mutate(county = list(unique(as.character(radon[[&quot;county&quot;]])))) %&gt;% unnest(county) %&gt;% select(-term) %&gt;% mutate(model = &quot;Complete&quot;) alpha_2 &lt;- tidyMCMC(fit_radon_2, conf.int = TRUE) %&gt;% filter(str_detect(term, &quot;^county&quot;)) %&gt;% mutate(county = str_replace(term, &quot;^county&quot;, &quot;&quot;)) %&gt;% select(-term) %&gt;% mutate(model = &quot;No&quot;) See this vignette for extracting the random intercepts. alphas &lt;- as.matrix(fit_radon_3, regex_pars = &quot;^b\\\\[&quot;) alpha_mean &lt;- as.matrix(fit_radon_3, pars = &quot;(Intercept)&quot;) alpha_3 &lt;- sweep(alphas, 1, alpha_mean, FUN = &quot;+&quot;) %&gt;% as_tibble() %&gt;% gather(term, value) %&gt;% group_by(term) %&gt;% summarise(estimate = mean(value), conf.low = quantile(value, 0.025), conf.high = quantile(value, 0.975)) %&gt;% ungroup() %&gt;% mutate(county = str_match(term, &quot;county:(.*)\\\\]&quot;)[ , 2]) %&gt;% select(-term) %&gt;% mutate(model = &quot;Partial&quot;) all_models &lt;- bind_rows(alpha_1, alpha_2, alpha_3) %&gt;% # reorder county by size mutate(county = fct_reorder(county, estimate, mean)) ggplot(all_models, aes(x = county, y = estimate, ymin = conf.low, ymax = conf.high, color = model)) + geom_pointrange(position = position_dodge(width = 1)) + coord_flip() 20.5 With Individual Covariates Individual covariates can also be added. \\[ \\begin{aligned} y_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= \\alpha_{j[i]} + \\beta~\\mathtt{floor}_i \\\\ \\alpha_j &amp;\\sim \\dnorm(\\gamma, \\tau) &amp; \\text{for } j \\in 1, \\dots, m \\\\ \\beta &amp;\\sim \\dnorm(0, 2.5)\\\\ \\tau &amp;\\sim \\dexp(1) \\\\ \\gamma &amp;\\sim \\dnorm(0, 10) \\end{aligned} \\] This is often called a varying intercept model or the random effects model. Each county has a different intercept, but a common value of \\(\\beta\\). Note that the prior on \\(\\beta\\) assumes that \\(y\\) and \\(\\mathtt{floor}\\) are centered and scaled. We can estimate this with stan_glmer as follows: fit_radon_4 &lt;- stan_glmer(log_radon ~ (1 | county) + floor, data = radon, refresh = -1) We could also allow the parameter of \\(\\beta\\) to vary between counties and give it a prior distribution. \\[ \\begin{aligned} y_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= \\alpha_{j[i]} + \\beta_{j[i]}~\\mathtt{floor}_i \\end{aligned} \\] Both \\(\\alpha_j\\) and \\(\\beta_j\\) need to be given hierarchical priors. Since there are features common to each group, it is common to specify a prior that allows these parameters to be correlated, such as a multivariate normal distribution with mean \\(\\gamma\\) and covariance \\(\\Sigma\\), \\[ \\begin{aligned}[t] \\begin{bmatrix} \\alpha_j \\\\ \\beta_j \\end{bmatrix} &amp;\\sim \\dnorm\\left(\\begin{bmatrix}\\gamma_{\\alpha} \\\\ \\gamma_{\\beta} \\end{bmatrix}, \\Sigma\\right) \\\\ \\end{aligned} \\] The vector of locations of \\(\\alpha\\) and \\(\\beta\\) can be given weakly informative priors, which can be the same as the pooled parameters would be given, \\[ \\begin{aligned} \\gamma_{\\alpha} &amp;\\sim \\dnorm(0, 10) \\\\ \\gamma_{\\beta} &amp;\\sim \\dnorm(0, 2.5) \\\\ \\end{aligned} \\] The prior distribution for the covariance matrix is more complicated. See the section Priors for Covariances for a discussion of appropriate prior distirbutions. If instead, \\(\\alpha_j\\) and \\(\\beta_j\\) were given inproper priors, or alternatively, \\(\\Sigma \\to \\tau I\\) where \\(\\tau \\to \\infty\\), then this model would be equivalent to an MLE model in with county fixed effects, and with county interacted with floor, e.g. log_radon ~ county * floor. This model is often called a (varying-intercept) varying-slope model, or a random coefficients model. It can be estimated as: fit_radon_5 &lt;- stan_glmer(log_radon ~ (1 + floor | county), data = radon, refresh = -1) plot(fit_radon_5, regex_pars = c(&quot;^b\\\\[floor&quot;)) 20.6 With Group-Level Covariates Group-level covariates could also be added as predictors. \\[ \\begin{aligned} y_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= \\alpha_{j[i]} + \\beta~\\mathtt{log\\_uranium}_{j[i]} \\\\ \\alpha_j &amp;\\sim \\dnorm(\\gamma, \\tau) &amp; \\text{for } j \\in 1, \\dots, m \\\\ \\beta &amp;\\sim \\dnorm(0, 2.5)\\\\ \\tau &amp;\\sim \\dexp(1) \\\\ \\gamma &amp;\\sim \\dnorm(0, 10) \\end{aligned} \\] We could also write that model with group-level predictors included in the prior fthe group level intercepts as \\[ \\begin{aligned} y_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= \\alpha_{j[i]} \\\\ \\alpha_j &amp;\\sim \\dnorm(\\gamma + \\beta~\\mathtt{log\\_uranium}_j, \\tau) &amp; \\text{for } j \\in 1, \\dots, m \\\\ \\end{aligned} \\] These two models are equivalent. However, they may have different sampling efficiencies. Generally, in estimation, the first form in which the group-level predictors are included in the top level is used. To estimate this model with stan_glmer run the following. fit_radon_6 &lt;- stan_glmer(log_radon ~ (1 | county) + log_uranium, data = radon, refresh = -1) 20.7 Pooling of Hierarchical Parameters What does partial pooling do? This is easiest to understand in a simple mean-model with normal errors. \\[ \\begin{aligned}[t] y &amp;\\sim \\dnorm(\\mu_{j[i]}, \\sigma) \\\\ \\mu_{j} &amp;\\sim \\dnorm(\\gamma, \\tau) . \\end{aligned} \\] If the hyperparameters were known, the posterior of \\(\\mu_j\\) is \\[ \\mu_j | y, \\gamma, \\sigma, \\tau \\sim \\dnorm(\\hat{\\mu}_j, V_j) \\] where \\[ \\begin{aligned}[t] \\hat{\\mu}_j &amp;= \\frac{\\frac{n_j}{\\sigma^2} \\bar{y}_j + \\frac{1}{\\tau^2} \\gamma}{\\frac{n_j}{\\sigma^2} + \\frac{1}{\\tau^2}} \\\\ V_j &amp;= \\frac{1}{\\frac{n_j}{\\sigma^2} + \\frac{1}{\\tau^2}} \\end{aligned} \\] How does this vary depending on the size of the group, \\(n_j\\)? Sample size, \\(n_j\\) Estimate of \\(\\hat{\\mu}_j\\) \\(n_j = 0\\) \\(\\hat{\\mu}_j = \\gamma\\) (complete pooling) \\(n_j &lt; \\frac{\\sigma^2}{\\tau^2}\\) \\(\\hat{\\mu}_j\\) closer to \\(\\gamma\\) \\(n_j = \\frac{\\sigma^2}{\\tau^2}\\) \\(\\hat{\\mu}_j = \\frac{1}{2} \\bar{y}_j + \\frac{1}{2} \\gamma\\) \\(n_j &gt; \\frac{\\sigma^2}{\\tau^2}\\) \\(\\hat{\\mu}_j\\) closer to \\(\\bar{y}_j\\) \\(n_j = \\infty\\) \\(\\hat{\\mu}_j = \\bar{y}_j\\) (no pooling) When the sample size of the group is large, the prior data from other groups provides little additional informiation and the posterior is dominated by the observations in that group. However, when the sample size of the group is small, there is little information coming from the groups own observations and prior data from other groups can have a big influence on the posterior. We even have posterior estimates of groups and observations from groups we have not seen before due to the estimated distribution of group means. This is a good reason to use partial pooling. If there is enough data it will converge to the no-pooling case, but if there is not it will degrade to the full-pooling case. If instead the group means \\(\\mu_j\\) were known, we can calculate some crude estimates. The data variance, \\(\\sigma^2\\), is the residual variance, \\[ \\E(\\sigma^2 | y, \\mu) = \\frac{1}{n} \\sum_{i = 1}^n (y - \\mu_{j[i]})^2 . \\] The global mean is approximately the average of the group-level means, \\[ \\begin{aligned}[t] \\E(\\gamma | y, \\mu) &amp;= \\frac{1}{J} \\sum_{i = 1}^n \\mu_j \\\\ \\Var(\\gamma | y, \\mu) &amp;= \\frac{1}{J} \\tau^2 \\end{aligned} \\] The group level variance is \\(\\tau^2\\) is, \\[ \\E(\\tau^2 | y, \\mu) = \\frac{1}{J} \\sum_{j = 1}^J (\\mu_j - \\gamma)^2 \\] 20.8 lme4 In R, the most widely used package to estimate mixed-effects models is lme4. This estimates models using maximum likelihood or restricted maximum likelihood methods (REML). This will be faster than using full-Bayesian methods but also underestimate the uncertainty, as well as being a worse approximation of the posterior. Additionally, in frequentist inference, the meaning of the random effects is different; they are nuisance parameters and not given standard errors. See Bates (2010) and Bates et al. (2014) for introductions to mixed-effects models with lme4. These are also good introductions to classical approaches to mixed effects models. library(&quot;lme4&quot;) Complete pooling fit_pooled &lt;- lm(log_radon ~ county + floor, data = radon) County-varying intercepts with no-pooling fit_intercept_nopool &lt;- lm(log_radon ~ floor, data = radon) County-varying intercepts with partial-pooling fit_intercept_partial &lt;- lmer(log_radon ~ (1 | county) + floor, data = radon) Varying slopes with no pooling: fit_slope_nopool &lt;- lm(log_radon ~ county * floor, data = radon) Varying slopes with partial pooling: fit_slope_partial &lt;- lmer(log_radon ~ (1 + floor | county), data = radon) We can also include a county-level variable (log_uranium) in various models: With no-pooling, fit_slope_partial &lt;- lm(log_radon ~ floor + log_uranium, data = radon) With varying-intercepts fit_slope_partial &lt;- lmer(log_radon ~ (1 | county) + floor + log_uranium, data = radon) With varying-intercepts and slopes, fit_slope_partial &lt;- lmer(log_radon ~ (1 + floor | county) + log_uranium, data = radon) 20.9 Priors for Covariances Traditinally the Wishart and inverse Wishart distributions have been used for modeling covariance distributions. This was largely because they were in some cases conjugate distributions. However, they have several poor properties. See https://github.com/pymc-devs/pymc3/issues/538#issuecomment-94153586 A preferred approach is to first decompose the covariance matrix (\\(\\Sigma\\)) into a vector of standard deviations (\\(\\omega\\)) and a correlation matrix (\\(R\\)), \\[ \\Sigma = \\diag(\\omega) R \\diag(\\omega) , \\] and then place priors on each of those. The preferred distribution for a correlation distribution is the LKJ distribution. This distribution is proportional to a product of the determinant of the correlation matrix. The LKJ distribution takes a single parameter \\(\\eta &gt; 0\\). It can be interpreted similarly to the the shape parameter of a symmetric Beta distribution. When \\(\\eta = 1\\), then there is a uniform distribution over all correlation matrices. As \\(\\eta \\to 1\\), the correlation matrix approaches the identity matrix. As \\(\\eta \\to 0\\), the density has a trough at the identity matrix. \\[ \\mathsf{LKJ}(R | \\eta) \\propto |R|^{\\eta - 1} \\] There are a few ways to assign prior distributions to the standard deviation vector, \\(\\omega\\). The lkj() prior used by stan_mvmer() and stan_jm() assigns independent Half Student-t priors, with degrees of freedom \\(d\\), and scale, \\(s_j\\), \\[ \\omega_j \\sim \\HalfStudentT(d, 0, s_j) . \\] The deconv() prior used by stan_glmer decomposes the standard deviation vector further. It notes that the trace of a covariance matrix is equal to the sum of the variances. This suggests decomposing the variance vector (\\(\\omega^2\\)) into the product of the trace (\\(\\psi^2\\)) and a simplex (\\(\\pi\\)) which allocates how much of the total variance is associated with each element. \\[ \\begin{aligned} \\omega &amp;= \\psi \\sqrt{\\pi} \\end{aligned} \\] The simplex is given a symmetric Dirichlet prior with concentration parameter \\(k\\), \\[ \\pi &amp;\\sim \\ddirchlet(k, 1 / p). \\] The default for deconv() is 1, for a uniform distribution over the space of simplex vectors of that size. The square root of the trace (\\(\\psi\\)) is given a gamma prior with shape parameter \\(a\\) and scale parameter \\(b\\), \\[ \\psi &amp;\\sim \\dgamma(a, b) . \\] The default for deconv() is \\(a = 1\\) and \\(b = 1\\), which is equal to \\(\\dexp(\\psi | 1)\\). 20.10 Cetered and Non-centered Parameterizations The natural way to write a hiearchical model is with a centered parameterization: \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]}, \\sigma) \\\\ \\alpha_{j} &amp;\\sim \\dnorm(\\mu_\\alpha, \\omega_{\\alpha}) \\end{aligned} \\] However, this can be difficult to sample from. In particular, by construction, the values of \\(\\mu_{\\alpha}\\), \\(\\omega_{\\alpha}\\), and \\(\\alpha_j\\) are going to be highly correlated. This results in a posterior pattern called a “funnel” which is difficult for HMC to sample due to the changes in the posterior curvature. The centered paramerization centers and scales the distribution of the intercepts. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]}, \\sigma) \\\\ \\alpha_{j} &amp;\\sim \\mu_{\\alpha} + \\omega_{\\alpha} \\alpha^* \\\\ \\alpha^*_{j} &amp;\\sim \\dnorm(0, 1) \\end{aligned} \\] These are two ways of writing the same model. However, they change the parameters that the HMC algorithm is actively sampling and thus can have different sampling performance. However, neither is universally better. If much data, the non-centered parameterization works better If less data, the centered parameterization works better And there is currently no ex-ante way to know which will work better, and at what amount of “data” that the performance of one or the other is better. However, one other reason to use the centered parameterization (if it is also scaled), is that the Stan HMC implementation tends to be more efficient if all parameters are on the scale. See also Stan Ref Ch 9 “Regression” has sections on hierarchical/multi-level models Stan Ref Ch 22 “Reparameterizations &amp; Change of Variables” http://twiecki.github.io/blog/2017/02/08/bayesian-hierchical-non-centered/ https://arxiv.org/pdf/1312.0906.pdf &lt;https://www.youtube.com/watch?v=pHsuIaPbNbY&amp;t=8s 20.11 Extensions Including group-level covariates Prior distributions for hierarchical scale Prediction. Hierarchical models can be use new obs in existing groups new group new obs in new group Modeling correlation between intercept and slopes Non-nested models 20.12 Miscellaneous 20.12.1 How many groups? In classical discussions of multi-level or hierarchical models, a common question is how many groups are required to be able to use random effects vs. fixed effects. As noted earlier, random effects estimates the variance between group means. If there are few groups, there is not much information available to estimate this variance. As such, random effects is not much different than fixed effects. This literature provides many different rules of thumb for the number of groups necessary to be able to use random effects: 8, 10, 30, 50, or 100 (Stegmueller 2013, 749). Stegmueller (2013) finds that Bayesian method produces better multi-level-models than maximum likelihood methods for all numbers of groups. ML methods do not suffer severe bias above 10-15 groups. Bayesian point estimates are biased for smaller numbers of groups, but less than the ML. Additionally, the Bayesian methods have better frequentist coverage than ML methods. Beck and Katz (2007) show that ML random coefficient models are superior in terms of efficiency to many types of pooled and un-pooled estimators in small samples. 20.12.2 Correlation between Predictors and Errors Bafumi and Gelman (2006) analyze this case. The standard suggestion in frequentist literature is to use a Hausman test where the null hypothesis is that random effects are consistent. However, Clark and Linzer (2014) note that in small samples this is likely to fail to reject random effects; and in large samples, random effects behave like fixed effects anyways. 20.13 References Texts and chapters on multi-level analysis: Bayesian A. Gelman and Hill (2007 Ch. 11-17). A. Gelman, Carlin, et al. (2013 Ch 5) “Hierarchical Models” A. Gelman, Carlin, et al. (2013 Ch 15) “Hierarchical Linear Models” Jackman (2009 CHh. 7) Draper (2008) Frequentist Goldstein (2011) Snijders and Bosker (2011) Rabe-Hesketh and Skrondal (2012) Jiang (2007) Stan model examples: Stan models for ARM http://mc-stan.org/documentation/case-studies/radon.html https://biologyforfun.wordpress.com/2016/12/08/crossed-and-nested-hierarchical-models-with-stan-and-r/ Examples of multilevel models Western (1998): economic growth for OECD countries Gelman and King (1993): US election polling Park, Gelman, and Bafumi (2004): multi-level models of opinion polls combined with post-stratification to extrapolate national opinion surveys to regions. Steenbergen and Jones (2002): mostly an intro/review of MLM, but uses the cross-country Eurobarometer to model support for the EU A. Gelman, Shor, et al. (2007): state-level opinion polls Raudenbush and Bryk (2001): student performance with student and school-level indicators Gilardi (2010): policy diffusion O’Rourke and Sinnott (2006): attitudes toward immigration Andersen and Fetner (2008): ethnic and social tolerance Weldon (2006): ethnic and social tolerance Arzheimer (2009): right-wing voting Hooghe et al. (2009): social and political trust Anderson and Singer (2008): satisfaction with democracy Meer, Deth, and Scheepers (2009): political participation Iversen and Rosenbluth (2006): political economy of the gender wage gap Hooghe and Marks (2004): support for European integration Lax and Phillips (2009): American politics using states and neighborhoods Voeten (2008): judicial decision making Franchino and Høyland (2009): legislative politics Denisova et al. (2009): politics of economic reforms Aitkin and Longford (1986), Goldstein et al. (2000), Goldstein et al. (1993): education Goldstein et al. (2000): medicine https://en.wikipedia.org/wiki/Multilevel_model↩ "],
["appendix.html", "Appendix Prerequisites 20.14 Parameters 20.15 Miscellaneous Mathematical Background 20.16 Scaled and Unscaled Variables", " Appendix Prerequisites library(&quot;tidyverse&quot;) library(&quot;stringr&quot;) library(&quot;bayz&quot;) 20.14 Parameters Category Description modeled data Data, assigned distribution unmodeled data Data not given a distribution modeled parameters Parameters with an informative prior distribution unmodeled parameters Parameters with non-informative prior distribution derived quantities Variables defined deterministicically See A. Gelman and Hill (2007, 366) 20.15 Miscellaneous Mathematical Background 20.15.1 Location-Scale Families In a location-scale family of distributions, if the random variable \\(X\\) is distributed with mean 0 and standard deviation 1, then the random variable \\(Y\\), \\[ Y = \\mu + \\sigma X , \\] has mean \\(\\mu\\) and standard deviation \\(\\sigma\\). Normal distribution: Suppose \\(X \\sim \\dnorm(0, 1)\\), then \\[ Y = \\mu + \\sigma X, \\] is equivalent to \\(Y \\sim \\dnorm(\\mu, \\sigma)\\) (normal with mean \\(\\mu\\) and standard deviation \\(\\sigma\\)). ** Student-t distribution** (including Cauchy): \\[ \\begin{aligned}[t] X &amp;\\sim \\dt{\\nu}(0, 1) \\\\ Y &amp;= \\mu + \\sigma X \\end{aligned} \\] implies \\[ Y \\sim \\dt{\\nu}(\\mu, \\sigma), \\] i.e. \\(Y\\) is distributed Student-\\(t\\) with location \\(\\mu\\) and scale \\(\\sigma\\). In Stan, it can be useful parameterize distributions in terms of a mean 0, scale 1 parameters, and separate parameters for the locations and scales. E.g. with normal distributions, parameters { real mu; real&lt;lower = 0.0&gt; sigma; vector[n] eps; } transformed parameters { vector[n] y; y = mu + sigma * eps; } model { eps ~ normal(0.0, 1.0); } 20.15.2 Scale Mixtures of Normal Distributions Some commonly used distributions can be represented as scale mixtures of normal distributions. For formal details of scale mixtures of normal distributions see West (1987). Distributions that are scale-mixtures of normal distributions can be written as, \\[ Y \\sim \\dnorm(\\mu, \\sigma_i^2) \\\\ \\sigma_i \\sim \\pi(\\sigma_i) \\] As its name suggests, the individual variances (scales) themselves, have a distribution. Some examples: Student-t Double Exponential Horseshoe or Hierarchical Shrinkage (HS) Horseshoe Plus or Hierarchical Shrinkage Plus (HS+) Even when analytic forms of the distribution are available, representing them as scale mixtures of normal distributions may be convenient in modeling. In particular, it may allow for drawing samples from the distribution easily. And in HMC, it may induce a more tractable posterior density. 20.15.3 Covariance-Correlation Matrix Decomposition The suggested method for modeling covariance matrices in Stan is the separation strategy which decomposes a covariance matrix \\(\\Sigma\\) can be decomposed into a standard deviation vector \\(\\sigma\\), and a correlation matrix \\(R\\) (Barnard, McCulloch, and Meng 2000), \\[ \\Sigma = \\diag(\\sigma) R \\diag(\\sigma) . \\] This is useful for setting priors on covariance because separate priors can be set for the scales of the variables via \\(\\sigma\\), and the correlation between them, via \\(R\\). The rstanarm decov prior goes further and decomposes the covariance matrix into a correlation matrix, \\(\\mat{R}\\), a diagonal variance matrix \\(\\mat{\\Omega}\\) with trace \\(n \\sigma^2\\), a scalar global variance \\(\\sigma^2\\), and a simplex \\(\\vec{\\pi}\\) (proportion of total variance for each variable): \\[ \\begin{aligned}[t] \\mat{\\Sigma} &amp;= \\mat{\\Omega} \\mat{R} \\\\ \\diag(\\mat{\\Omega}) &amp;= n \\vec{\\pi} \\sigma^2 \\end{aligned} \\] Separate and interpretable priors can be put on \\(\\mat{R}\\), \\(\\vec{\\pi}\\), and \\(\\sigma^2\\). The LKJ (Lewandowski, ) distribution is a distribution over correlation coefficients, \\[ R \\sim \\dlkjcorr(\\eta) , \\] where \\[ \\dlkjcorr(\\Sigma | \\eta) \\propto \\det(\\Sigma)^{(\\eta - 1)} . \\] This distribution has the following properties: \\(\\eta = 1\\): uniform correlations \\(\\eta \\to \\infty\\): approaches the identity matrix \\(0 &lt; \\eta &lt; 1\\): there is a trough at the identity matrix with higher probabilities placed on non-zero correlations. For all positive \\(\\eta\\) (\\(\\eta &gt; 0\\)), \\(\\E(R) = \\mat{I}\\). lkjcorr_df &lt;- function(eta, n = 2) { out &lt;- as.data.frame(rlkjcorr(n, eta)) out$.row &lt;- seq_len(nrow(out)) out &lt;- gather(out, .col, value, -.row) out$.col &lt;- as.integer(str_replace(out$.col, &quot;^V&quot;, &quot;&quot;)) out$eta &lt;- eta out } lkjsims &lt;- purrr::map_df(c(0.01, 0.1, 1, 2, 50, 1000), lkjcorr_df, n = 50) This simulates a single matrix from the LKJ distribution with different values of \\(\\eta\\). As \\(\\eta \\to \\infty\\), the off-diagonal correlations tend towards 0, and the correlation matrix to the identity matrix. ggplot(lkjsims, aes(x = .row, y = .col, fill = value)) + facet_wrap(~ eta, ncol = 2) + scale_fill_distiller(limits = c(-1, 1), type = &quot;div&quot;, palette = &quot;RdYlBu&quot;) + geom_raster() + theme_minimal() + theme(panel.grid = element_blank(), axis.text = element_blank()) + labs(x = &quot;&quot;, y = &quot;&quot;) The density of the off-diagonal correlations. lkjsims %&gt;% filter(.row &lt; .col) %&gt;% ggplot(aes(x = value, colour = factor(eta))) + geom_density() For other discussions of the LKJ correlation distribution, see these: https://stats.stackexchange.com/questions/2746/how-to-efficiently-generate-random-positive-semidefinite-correlation-matrices/125017#125017 http://www.zinkov.com/posts/2015-06-09-where-priors-come-from/ http://www.psychstatistics.com/2014/12/27/d-lkj-priors/ 20.15.4 QR Factorization For a full-rank \\(N \\times K\\) matrix, the QR factorization is \\[ \\mat{X} = \\mat{Q} \\mat{R} \\] where \\(\\mat{Q}\\) is an orthonormal matrix such that \\(\\mat{Q}\\T \\mat{Q}\\) and \\(\\mat{R}\\) is an upper triangular matrix. Stan function Stan Development Team (2016) suggest writing it is \\[ \\begin{aligned}[t] \\mat{Q}^* = \\mat{Q} \\times \\sqrt{N - 1} \\\\ \\mat{R}^* = \\frac{1}{\\sqrt{N - 1}} \\mat{R} \\end{aligned} \\] This is used for solving linear model. Suppose \\(\\vec{\\beta}\\) is a \\(K \\times 1\\) vector, then \\[ \\vec{eta} = \\mat{x} \\vec{\\beta} = \\mat{Q} \\mat{R} \\vec{\\beta} = \\mat{Q}^* \\mat{R}^* \\vec{\\beta} . \\] Suppose \\(\\mat{theta} = \\mat{R}^* \\vec{\\beta}\\), then \\(\\vec{eta} = \\mat{Q}^* \\mat{\\theta}\\) and \\(\\vec{beta} = {\\mat{R}^*}^{-1} \\mat{\\theta}\\). rstanarm provides a prior for a normal linear model which uses the QR decomposition to parameterize a prior in terms of \\(R^2\\). Stan functions: qr_Q(matrix A) qr_R(matrix A) See Stan Development Team (2016 Sec 8.2) 20.15.5 Cholesky Decomposition The Cholesky decomposition of a positive definite matrix \\(A\\) is, \\[ \\mat{A} = \\mat{L} \\mat{L}\\T , \\] where \\(\\mat{L}\\) is a lower-triangular matrix. It is similar to a square root for a matrix. It often more numerically stable or efficient to work with the Cholesky decomposition, than with a covariance matrix. When working with the covariance matrix, numerical precision can result in a non positive definite matrix. However, working with \\(\\mat{L}\\) will ensure that \\(\\mat{A} = \\mat{L} \\mat{L}\\T\\) will be positive definite. In Stan Types types cholesky_factor_cov, and cholesky_factor_corr represent the Cholesky factor of covariance and correlation matrices, respectively. Cholesky decomposition function is cholesky_decompose(matrix A) Multiple functions in Stan are parameterized with Cholesky decompositions instead of or in addition to covariance matrices. Use them if possible; they are more numerically stable. lkj_corr_chol_lpdf multi_normal_cholesky_lpdf The Cholesky factor is used for sampling from a multivariate normal distribution using i.i.d. standard normal distributions. Suppose \\(X_1, \\dots, X_N\\) are \\(N\\) i.i.d. standard normal distributions, \\(\\mat{\\Omega}\\) is an \\(N \\times N\\) lower-triangular matrix such that \\(\\mat{\\Omega} \\mat{Omega}\\T = \\mat{\\Sigma}\\), and \\(\\mu\\) is an \\(N \\times 1\\) vector, then \\[ \\vec{\\mu} + \\mat{\\Omega} X \\sim \\dnorm(\\vec{\\mu}, \\mat{\\Sigma}) \\] See Stan Development Team (2016, 40, 147, 241, 246) 20.16 Scaled and Unscaled Variables Though priors shouldn’t depend on the data itself, many priors depends Suppose \\(\\tilde{Y}\\), \\(\\tilde{X}\\), \\(\\tilde{\\alpha}\\), \\(\\tilde{\\beta}\\), and \\(\\epsilon\\) are random variables, such that \\[ \\tilde{Y} = \\tilde{\\alpha} + \\tilde{\\beta} \\tilde{X} + \\epsilon . \\] These random variables have the following properties, \\[ \\begin{aligned}[t] \\tilde{Y} &amp;= \\frac{Y - \\bar{Y}}{\\sigma_Y}, &amp; \\E[\\tilde{Y}] &amp;= 0, &amp; \\sigma_Y^2 &amp;= \\Var[\\tilde{Y}] = 1 \\\\ \\tilde{X} &amp;= \\frac{X - \\bar{X}}{\\sigma_X}, &amp; \\E[\\tilde{X}] &amp;= 0, &amp; \\sigma_X^2 &amp;= \\Var[\\tilde{X}] = 1 , \\\\ &amp;&amp; \\E[\\epsilon] &amp;= 0 &amp; \\sigma_{\\tilde{\\epsilon}}^2 &amp;= \\Var[\\tilde{\\epsilon}] \\end{aligned} \\] where \\[ \\begin{aligned}[t] \\bar{X} &amp;= \\E[X] , &amp; s_X^2 &amp;= \\Var[X] , \\\\ \\bar{Y} &amp;= \\E[Y] , &amp; s_Y^2 &amp;= \\Var[Y] . \\end{aligned} \\] Then via some algebra, \\[ \\begin{aligned} Y &amp;= \\underbrace{\\sigma_{Y} \\tilde{\\alpha} + \\bar{Y} - \\frac{\\sigma_Y }{\\sigma_X} \\tilde{\\beta} \\bar{X}}_{\\alpha} + \\underbrace{\\frac{\\sigma_Y}{\\sigma_X} \\tilde{\\beta}}_{\\beta} X + \\underbrace{\\sigma_Y \\tilde{\\epsilon}}_{\\epsilon} \\\\ &amp;= \\alpha + \\beta X + \\epsilon . \\end{aligned} \\] The primary relationships of interest are those between \\(\\alpha\\) and \\(\\tilde{\\alpha}\\), \\(\\beta\\) and \\(\\tilde{\\beta}\\), and \\(\\epsilon\\) and \\(\\tilde{\\epsilon}\\). These can be used to convert between coefficients estimated with standardized data to the coefficients on the data scale, or to adjust scale-free weakly informative priors to the data scale. \\[ \\begin{aligned}[t] \\tilde{\\alpha} &amp;= \\sigma_Y^{-1}\\left(\\alpha - \\bar{Y} + \\beta \\bar{X} \\right) \\\\ &amp;= \\sigma_Y^{-1}\\left(\\alpha - \\bar{Y} + \\frac{\\sigma_Y}{\\sigma_X} \\tilde{\\beta} \\bar{X} \\right), \\\\ \\alpha &amp;= \\sigma_Y \\tilde{\\alpha} + \\bar{Y} - \\frac{\\sigma_Y}{\\sigma_X} \\tilde{\\beta} \\bar{X} \\\\ &amp;= \\sigma_Y \\tilde{\\alpha} + \\bar{Y} - \\beta \\bar{X} , \\\\ \\tilde{\\beta} &amp;= \\frac{\\sigma_X}{\\sigma_Y} \\beta , \\\\ \\beta &amp;= \\frac{\\sigma_Y}{\\sigma_X} \\tilde{\\beta} , \\\\ \\tilde{\\epsilon} &amp;= \\epsilon / \\sigma_Y , \\\\ \\epsilon &amp;= \\sigma_Y \\tilde{\\epsilon} . \\end{aligned} \\] This implies the following relationships between their means and variances, \\[ \\begin{aligned}[t] E(\\alpha) &amp;= \\sigma_{Y} E(\\tilde{\\alpha}) + \\bar{Y} - \\frac{\\sigma_Y}{\\sigma_X} E(\\tilde{\\beta}) \\bar{X} , &amp; V(\\alpha) &amp;= \\sigma_{Y}^2 V(\\tilde{\\alpha}) + \\frac{\\sigma_Y^2}{\\sigma_X^2} V(\\tilde{\\beta}) \\bar{X}^2 , \\\\ &amp;= \\sigma_{Y} E(\\tilde{\\alpha}) + \\bar{Y} - \\bar{X} E(\\beta) , &amp; &amp;= \\sigma_{Y}^2 V(\\tilde{\\alpha}) + \\bar{X}^2 V(\\beta) , \\\\ E(\\tilde{\\alpha}) &amp;= \\frac{E(\\alpha) - \\bar{Y} + E(\\beta) \\bar{X} }{\\sigma_Y} , &amp; V(\\tilde{\\alpha}) &amp;= \\sigma_Y^{-2} \\left[ V(\\alpha) + \\bar{X}^2 V(\\beta) \\right] \\end{aligned} \\] For example, a weakly informative prior on \\(\\tilde{\\alpha}\\) implies a prior on \\(\\alpha\\), \\[ \\tilde{\\alpha} \\sim N(0, 10^2) \\to \\alpha \\sim N \\left( \\frac{\\beta \\bar{X} - \\bar{Y}}{\\sigma_Y}, \\sigma_Y^2 10^2 \\right) . \\] \\[ \\begin{aligned}[t] E(\\beta) &amp;= \\frac{\\sigma_Y}{\\sigma_X} E(\\tilde{\\beta}) , &amp; V(\\beta) &amp;= \\frac{\\sigma_Y^2}{\\sigma_X^2} V(\\tilde{\\beta}) , \\\\ E(\\tilde{\\beta}) &amp;= \\frac{\\sigma_X}{\\sigma_Y} E(\\beta) , &amp; V(\\tilde{\\beta}) &amp;= \\frac{\\sigma_X^2}{\\sigma_Y^2} V(\\beta) . \\end{aligned} \\] For example, a weakly informative prior on \\(\\tilde{\\beta}\\) implies the following prior on \\(\\beta\\), \\[ \\tilde{\\beta} \\sim N(0, 2.5^2) \\to \\beta \\sim N\\left(0, \\frac{\\sigma_Y^2}{\\sigma_X^2} 2.5^2 \\right) . \\] \\[ \\begin{aligned}[t] E(\\epsilon) &amp;= 0 , &amp; V(\\epsilon) &amp;= \\sigma_Y^2 V(\\tilde{\\epsilon}), \\\\ E(\\tilde{\\epsilon}) &amp;= 0 , &amp; V(\\tilde{\\epsilon}) &amp;= \\sigma_Y^{-2} V(\\epsilon) . \\end{aligned} \\] For example, a weakly informative prior on the variance of \\(\\tilde{\\epsilon}\\) implies a weakly informative prior on the variance of \\(\\epsilon\\), \\[ \\sigma_{\\tilde{\\epsilon}} \\sim C^{+}\\left(0, 5 \\right) \\to \\sigma_{\\epsilon} \\sim C^{+}\\left(0, 5 \\sigma_Y \\right) . \\] "],
["distributions.html", "21 Distributions", " 21 Distributions The parameterizations and notations for distributions largely follow A. Gelman, Carlin, et al. (2013) and Stan Development Team (2016). The Wikipedia List of Probability Distributions is a fairly complete reference. Standard references of probability distributions are (Johnson, Kotz, and Balakrishnan 1994, 1995, 1997; Kotz, Balakrishnan, and Johnson 2000; Wimmer and Altmann 1999; Forbes et al. 2010; Asquith 2011). The Probability Distributions CRAN task view contains both links and descriptions of probability distributions and as such serves as a useful list of probability distributions. “The Chart of Univariate Distribution Relationships” (Leemis and McQueston 2008) is the classic chart of the relationships between univariate distributions. There are a few variations of this chart online: Univariate Distribution Relationships Diagram of distribution relationships ProbOnto "],
["annotated-bibliography.html", "22 Annotated Bibliography 22.1 Textbooks 22.2 Syllabi 22.3 Topics 22.4 Bayes’ Theorem 22.5 Article Length Introductions to Bayesian Statistics 22.6 Software 22.7 Bayesian Model Averaging 22.8 Multilevel Modeling 22.9 Mixture Models 22.10 Inference 22.11 Model Checking 22.12 Hierarchical Modeling 22.13 Shrinkage/Regularization 22.14 Empirical Bayes 22.15 History of Bayesian Statistics 22.16 Sampling Difficulties 22.17 Complicated Estimation and Testing 22.18 Pooling Polls 22.19 Visualizing MCMC Methods 22.20 Bayesian point estimation / Decision 22.21 Stan Modeling Language 22.22 Bayes Factors", " 22 Annotated Bibliography This is less an annotated and more of a citation and link dump while I move the references into the main text. 22.1 Textbooks Kruschke (2015) Doing Bayesian data analysis (Kruschke 2015) Another accessible introduction aimed at psychology. Website with additional material. McElreath (2016) Statistical rethinking (McElreath 2016) An accessible introduction to Bayesian stats; effectively an intro-stats/linear models course taught from a Bayesian perspective. GitHub page Course page Lee (2012) Bayesian Statistics : An Introduction (Lee 2012) Marin and Robert (2015) Bayesian Essentials with R (Marin and Robert 2014) and solutions manual Robert and Casella. 2009. Introducing Monte Carlo Methods with R (Robert and Casella 2009) Robert and Casella. 2004. Monte Carlo statistical methods (Robert and Casella 2004) Albert (2009) Bayesian Computation with R (Albert 2009) Jackman (2009) Bayesian Analysis for the Social Sciences (Jackman 2009) Covers commonly used models in the social sciences. Largely covers Gibbs sampling methods and Hoff (2009) A First Course in Bayesian Statistical Methods (Hoff 2009) Gelman, Carlin, Stern, Dunson, and Vehtari (2013) Bayesian data analysis (3rd Edition) (A. Gelman, Carlin, et al. 2013) Gelman, and Hill (2007) Data analysis using regression and multilevel/hierarchical models (A. Gelman and Hill 2007) An accessible introduction to to linear models and multilevel models. Efron and Hastie (2016) Computer Age Statistical Inference: Algorithms, Evidence, and Data Science This is a unique work that blends an overview of statistical methods with a history of statistics. (Efron and Hastie 2016) Robert (2007) The Bayesian Choice A statistics graduate-level book on Bayesian statistics. Berger (1993) Statistical Decision Theory and Bayesian Analysis (Berger 1993) The classic book on Bayesian inference and decision theory. The underlying statistical theory is still relevant even if its date makes the computational aspects less so. Murphy (2012) Machine Learning: A Probabilistic Perspective (Murphy 2012) A machine learning book with a heavy Bayesian influence. MacKay (2003) Information Theory, Inference, and Learning Algorithms URL. (MacKay 2003) On information theory, but combines it with Bayesian statistics, and is ultimately about learning and evidence. Lectures from the course are available here. Gelman and Hill (2007) Data Analysis Using Regression and Multilevel/Hierarchical Models (A. Gelman and Hill 2007) Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin (2013) Bayesian Data Analysis 3rd ed. Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences (Jackman 2009) Lynch, Scott M. 2007. Introduction to Applied Bayesian Statistics and Estimation for Social Scientists Lunn, Jackson, Best, Thomas, and Spiegelhalter (2012) The BUGS Book: A Practical Introduction to Bayesian Analysis (Lunn et al. 2012) Peter Hoff. 2009. A First Course in Bayesian Statistical Methods (Hoff 2009) Congdon. 2014. Applied Bayesian Modeling. Marin and Roberts. 2014. Bayesian Essentials with R. Robert and Casella. Introducing Monte Carlo Methods with R (Robert and Casella 2009) 22.2 Syllabi Ryan Bakker and Johannes Karreth, “Introduction to Applied Bayesian Modeling” ICPSR. Summer 2016. Syllabus; code Justin Esarey. “Advanced Topics in Political Methodology: Bayesian Statistics” Winter 2015. Syllabus; Lectures. Kruschke. Doing Bayesian Data Analysis site. Nick Beauchamp. “Bayesian Methods.” NYU. syllabus. Alex Tanhk. “Bayesian Methods for the Social Sciences” U of Wisconsin. Spring 2017. syllabus. MTH225 Statistics for Science Spring 2016. github website. Ben Goodrich, “Bayesian Statistics for Social Sciences” Columbia University. Spring 2016. Bakker. “Introduction to Applied Bayesian Analysis” University of Georgia. syllabus; site Myimoto. “Advances in Quantitative Psychology: Bayesian Statistics, Modeling &amp; Reasoning” U of Washington. Winter 2017. site Neil Frazer. Bayesian Data Analysis. Hawaii. Spring 2017. syllabus Lopes. 2016. Bayesian Statistical Learning: Readings in Statistics and Econometrics. syllabus. Lopes. 2012 Simulation-based approaches to modern Bayesian econometrics. Short course. Lopes. 2015. Bayesian Econometrics. syllabus. 22.3 Topics 22.4 Bayes’ Theorem Puga, Kryzwinski, and Altman (2015) “Points of significance: Bayes’ theorem” Nature Methods 22.5 Article Length Introductions to Bayesian Statistics Stan Modeling 2.17. Ch. 29. “Bayesian Inference” Michael Clarke Bayesian Basics. Eddy (2004) “What is Bayesian Statistics” Nature Biotechnology Jackman. 2004. Bayesian Analysis for Political Research. Annual Review of Political Science DOI:10.1146/annurev.polisci.7.012003.104706. Kruschke, J.K. &amp; Liddell, T.M. Psychon Bull Rev (2017). doi:10.3758/s13423-016-1221-4 - Kruschke and Liddell (2017) “Bayesian new statistics: hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective” 22.5.1 Why Bayesian Jim Savage. Why learn Bayesian Modeling? April 10, 2017. 22.5.2 Modern Statistical Workflow Savage, Jaim. 2017. A Brief Introduction to Econometrics in Stan Betancourt, Michael. Robust Statistical Workflow with RStan Stan Modeling Guide “Model Building as Software Development” Gabry, J., Simpson, D., Vehtari, A., Betancourt, M., Gelman, A. (2018). Visualization in Bayesian workflow 22.5.3 Bayesian Philosophy Gelman (2008) “Objections to Bayesian Statistics” Bayesian Analysis Gelman and Shalizi (2012) “Philosophy and the practice of Bayesian statistics” British Journal of Mathematical and Statistical Psychology Borsboom and Haig (2012) “How to practice Bayesian statistics outside the Bayesian church: What philosophy for Bayesian statistical modelling?” British Journal of Mathematical and Statistical Psychology Berger and Berry (1988) “Statistical Analysis and the Illusion of Objectivity” American Scientist American Scientist 1988 Efron (2010) “The Future of Indirect Evidence” Efron (1986) “Why Isn’t Everyone a Bayesian?” American Statistician (B. Efron 1986b). See comments Chernoff (1986), Lindley (1986), Morris (1986), Smith (1986), Press (1986), B. Efron (1986a). Philosophy and the practice of Bayesian statistics in the social sciences Rubin (1984) Rubin, Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician Andrew Gelman Induction and Deduction in Bayesian Data Analysis Berger (2013) \"Could Fisher, Jeffreys and Neyman Have Agreed on Testing? Statistical Science 22.5.4 Bayesian Hypothesis Testing Gross, J. H. (2015) “Testing What Matters (If You Must Test at All): A Context-Driven Approach to Substantive and Statistical Significance” American Journal of Political Science (Gross 2014) 22.5.5 Bayesian Frequentist Debates Bayesians and Frequentists : Models, Assumptions, and Inference (slides) Kass Statistical Inference: The Big Picture Noah Smith Bayesian vs. Frequentist: Is there any “there” there? Kass Kinds of Bayesians Anthony O’Hagan. Science, Subjectivity and Software (Comments on the articles by Berger and Goldstein) VanderPlas (2014) Frequentism and Bayesianism: A Python-driven Primer. posts 22.5.6 Categorical Agresti. Bayesian Inference for Categorical Data Analysis Gelman. 2008. “A weakly informative default prior distribution for logistic and other regression models” Rainey. 2016. “Dealing with Separation in Logistic Regression Models” Political Analysis Wechsler, Izbicki, and Esteves (2013) “A Bayesian look at nonidentifiability: a simple example”\" 22.5.7 Variable Selection J. Ghosh and Ghattas (2015) Ghosh and Ghattas (2015) “Bayesian Variable Selection Under Collinearity” American Statistician Scott and Berger (2011) “Bayes and empirical-Bayes multiplicity adjustment in the variable-selection problem” Annals of Statistics (Scott and Berger 2010) Ishwaran and Rao (2005) “Spike and slab variable selection: Frequentist and Bayesian strategies” Annals of Statistics Ishwaran, Kogalur, and Rao (2010) “spikeslab: prediction and variable selection using spike and slab regression” R Journal Polson and Scott. “Shrink globally, act locally: sparse Bayesian regularization and prediction” Bayesian Statistics Projection predictive variable selection using Stan + R Lasso Meets Horseshoe Piironen and Vehtari, Sparsity information and regularization in the horseshoe and other shrinkage priors Hahn and Carvalho. Decoupling Shrinkage And Selection In Bayesian Linear Models: A Posterior Summary Perspective Michael Betancourt Bayes Sparse Regression 22.5.8 Multiple Testing Gelman, Hill, and Yajima (2012) “Why we (Usually) don’t have to worry about multiple comparisons” Journal of Research on Educational Effectiveness 22.5.9 Rare Events King and Zheng. 2001. \"Explaining Rare Events in International Relations King, Gary, and Langche Zeng. 2001. “Logistic Regression in Rare Events Data” 22.5.10 Identifiability Weschler et al. 2013. A Bayesian Look at Nonidentifiability: A Simple Example 22.5.11 Shrinkage Efron and Morris (1975) “Data Analysis Using Stein’s Estimator and its Generalizations” JASA (Efron and Morris 1975) 22.6 Software Software for general purpose Bayesian computation are called probabilistic programming languages. Stan Joseph Rickert. 2016. R Stan and Statistics BUGS modeling language. Models are specified in a different language. NIMBLE A very new BUGS-like language that works with R. JAGS Gibbs/MCMC based WinBUGS Gibbs and MCMC based software. It was one of the first but is now obsolete and unmaintained. Use JAGS or Stan instead. OpenBUGS The continuation of the WinBUGS project. Also no longer well maintained. Use JAGS or Stan instead. R has multiple packages that implement some Bayesian methods. See the Bayesian Task View LearnBayes TeachBayes Python PyMC Very complete general-purpose Python package for Bayesian Analysis The various Machine learning packages like scikit-learn. Edward. By David Blei. Deep generative models, variational inference. Runs on TensorFlow. Implements variational and HMC methods, as well as optimization. Church and Anglican are Lisp-based inference programs. Stata: Since version 14 it can estimate some Bayesian models. It uses Metropolis-Hastings and Gibbs methods. Julia Mamba MCMC supporting multiple methods including Gibbs, MH, HMC, slice 22.6.1 Stan Official Stan-dev R packages: rstan rstanarm bayesplot ShinyStan loo Others: brms Bayesian generalized non-linear multilevel models using Stan ggmcmc 22.6.2 Diagrams 22.6.2.1 DAGs and Plate Notation See Plate notation tikz-bayesnet A TikZ library for drawing Bayesian networks Daf A python package to draw DAGs Relevant Stack Overflow questions: Software for drawing Bayesian networks Stack Overflow. TikZ Example how to draw plate indices in graphical model in TikZ Can I have automatically adjusted plates in a graphical model? 22.6.2.2 Kruschke Diagrams Diagrams in the style of Kruschke’s Doing Bayesian Analysis: LibreOffice Draw Templates Blog posts http://doingbayesiandataanalysis.blogspot.se/2012/05/graphical-model-diagrams-in-doing.html http://doingbayesiandataanalysis.blogspot.se/2012/05/hierarchical-diagrams-read-bottom-to.html http://doingbayesiandataanalysis.blogspot.se/2013/10/diagrams-for-hierarchical-models-we.html R scripts TikZ scripts 22.6.2.3 Venn Diagrams/Eikosograms Oldford and W.H. Cherry. 2006. “Picturing Probability: the poverty of Venn diagrams, the richness of Eikosograms” 22.6.3 Priors Betancourt (2017) “How the shape of a weakly informative prior affects inferences” Stan Case Studies Stan, Prior Choice Recommendations 22.7 Bayesian Model Averaging Montgomery, Hollenbach and Ward (2012) “Improving Predictions Using Ensemble Bayesian Model Averaging” Political Analysis Montgomery and Nyhan (2011) Bayesian Model Averaging: Theoretical Developments and Practical Applications BMA Package BMS Package BAS Package Amini and Parmeter (2011) “Bayesian Model Averaging in R” Journal of Economic and Social Measurement Fragoso and Neto (2015) Bayesian model averaging: A systematic review and conceptual classification (Fragoso and Neto 2015) Ley and Steel (2012) “Mixtures of g-priors for Bayesian model averaging with economic applications” Journal of Econometrics Ley and Steel (2009) “On the effect of prior assumptions in Bayesian model averaging with applications to growth regression” Journal of Applied Econometrics Volinsky, Raftery, Madigan, and Hoeting (1999) “Bayesian model averaging: A Tutorial” Statistical Science 22.8 Multilevel Modeling Stegmueller (2013), “How Many Countries for Multilevel Modeling? A Comparison of Frequentist and Bayesian Approaches” American Journal of Political Science (Stegmueller 2013) Shor, Bafumi, Keele, and Park (2007) “A Bayesian multilevel modeling approach to time-series cross-sectional data” Political Analysis Beck and Katz (2007) “Random coefficient models for time-series—cross-section data: Monte Carlo experiments” Political Analysis (Beck and Katz 2007) Western and Jackman (1994). “Bayesian Inference for Comparative Research” American Political Science Review (Western and Jackman 1994) Anderson and Fetner. 2008. “Economic inequality and intolerance: attitudes toward homosexuality in 35 democracies” American Journal of Political Science 22.9 Mixture Models Imai, K. and Tingley, D. (2012) “A Statistical Method for Empirical Testing of Competing Theories” AJPS 22.10 Inference 22.10.1 Discussion of Bayesian Inference Lindley. The Analysis of Experimental Data: The Appreciation of Tea and Wine 22.11 Model Checking 22.11.1 Posterior Predictive Checks Gelman, Andrew (2007) “A Bayesian Formulation of Exploratory Data Analysis and Goodness-of-fit Testing” International Statistical Review Gelman, Meng, Stern (1996) “Posterior Predictive Fitness Via Realized Discrepencies” Kruschke. Posterior predictive checks can and should be Bayesian: Comment on Gelman and Shalizi, ‘Philosophy and the practice of Bayesian statistics Confusions about posterior predictive checks Gabry, Jonah. Graphical posterior predictive checks using the bayesplot package 22.11.2 Prediction Criteria Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. “Understanding Predictive Information Criteria for Bayesian Models.” Statistics and Computing Vehtari, Gelman, and Gabry. 2016 Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC Vehtari and Lampinen (2002) Bayesian model assessment and comparison using cross-validation predictive densities Vehtari and Ojanen (2012) “A survey of Bayesian predictive methods for model assessment, selection and comparison” 22.11.3 Software Validation Cook, Gelman, and Rubin (2006) “Validation of Software for Bayesian Models Using Posterior Quantiles” and Correction Savage, Jim. An easy way to simulate fake data from your Stan model Stan Best Practices 22.12 Hierarchical Modeling Kruschke and Vanpaeml “Bayesian Estimation in Hierarchical Models” Park, Gelman, and Bafumi (2004) “Bayesian Multilevel Estimation with Poststratification: State-Level Estimates from National Polls” Political Analysis Lax and Phillips. 2009. “How Should We Estimate Public Opinion in the States?” AJPS 22.13 Shrinkage/Regularization Piironen and Vehtari. 2016. On the Hyperprior Choice for the Global Shrinkage Parameter in the Horseshoe Prior Lopes. 2015. Bayesian Regularization slides. 22.14 Empirical Bayes Berger (2006) “The case for objective Bayesian analysis” Bayesian Analysis Efron (2014) “Frequentist accuracy of Bayesian estimates” JRSS B Efron (2010) “The Future of Indirect Evidence” Statistical Science 22.15 History of Bayesian Statistics Robert and Casella (2011) “A Short History of Markov Chain Monte Carlo: Subjective Recollections from Incomplete Data” Statistical Science Stigler (2018) “Richard Price, the first Bayesian” Statistical Science (Stigler 2018) Stigler (1983) “Who discovered Bayes’s theorem?” American Statistician (Stigler 1983) Fienberg (2006) “When did Bayesian Inference Become \"Bayesian\"?” Bayesian Analysis (Fienberg 2006) 22.16 Sampling Difficulties Carpenter (2017) “Typical sets and the curse of dimensionality” Stan Case Studies Betancourt (2017) “Diagnosing biased inference with divergences” Stan Case Studies Betancourt (2016) “Diagnosing suboptimal cotangent disintegrations in Hamiltonian Monte Carlo” Betancourt and Girolami (2013) “Hamiltonian Monte Carlo for Hierarchical Models” 22.17 Complicated Estimation and Testing King, Tomz, and Wittenberg (2000) “Making the most of statistical analyses: improving interpretation and presentation” Propose a pseudo-Bayesian method. Golder “Interactions”. See referenced papers. Hanmer and Kalkan (2012) “Behind the curve: clarifying the best approach to calculating predicted probabilities and marginal effects from limited dependent variable models” American Journal of Political Science 22.18 Pooling Polls Jackman (2000) “Pooling the Polls over an Election Campaign” Australian Journal of Political Science Linzer (2013) “Dynamic Bayesian forecasting of presidential elections in the States” JASA 22.19 Visualizing MCMC Methods https://chi-feng.github.io/mcmc-demo/ https://mimno.infosci.cornell.edu/hmc/ and http://www.mimno.org/articles/hmc/ http://twiecki.github.io/blog/2014/01/02/visualizing-mcmc/ https://ridlow.wordpress.com/category/animation/ http://people.math.aau.dk/~kkb/Undervisning/Bayes14/sorenh/docs/sampling-notes.pdf https://rpubs.com/mv2521/mcmc-animation http://blog.revolutionanalytics.com/2013/09/an-animated-peek-into-the-workings-of-bayesian-statistics.html https://people.duke.edu/~ccc14/sta-663/Animation.html https://artax.karlin.mff.cuni.cz/r-help/library/asbio/html/anm.mc.bvn.html https://groups.google.com/forum/#!topic/stan-users/nOk80xTlSyE https://www.youtube.com/watch?v=Vv3f0QNWvWQ https://theclevermachine.wordpress.com/2012/11/18/mcmc-hamiltnonian-monte-carlo-a-k-a-hybrid-monte-carlo/ https://www.youtube.com/watch?v=pHsuIaPbNbY&amp;list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF&amp;index=11 http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html 22.20 Bayesian point estimation / Decision Stan Modeling Language. Ch 32. Bayesian Point Estimation. Modes, Medians and Means: A Unifying Perspective. Not explicitly motivated with Bayesian decision theory; nevertheless, it is a good intuitive explanation of these estimators. The Impact of Reparameterization on Point Estimates Rainey 22.21 Stan Modeling Language Ch 1–8 Introduction. pay attention to Ch 1, 8. skim the rest. know where to look for help. Ch 28. Optimizing Stan Code for Efficiency (Neal’s funnel, reparameterization, vectorization) Ch 22. Reparameterization and change of variables Ch 23. Customized Ch 24. User-defined functions Ch 25. problematic posteriors Ch 29. Bayesian Data Analysis Ch 30. Markov Chain Monte Carlo Sampling (R hat, ESS, convergence, thinning) Ch 31. Penalized MLE Ch 32. Bayesian Point Estimation Ch 34. Hamiltonian Monte Carlo Sampling Ch 35. Transformations of Constrained Variables - changes of variables. 22.22 Bayes Factors Lindley’s Paradox Bayes’ Factors Robert (2016) The expected demise of the Bayes factor (Robert 2016). Kass and Raftery (1995) “Bayes factors” (Kass and Raftery 1995) "],
["references-12.html", "References", " References "]
]
