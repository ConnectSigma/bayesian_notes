[
["index.html", "Updating: A Set of Bayesian Notes Preface", " Updating: A Set of Bayesian Notes Jeffrey B. Arnold Preface Notes on Bayesian methods - written to supplement CS&amp;SS/STAT 564: Bayesian Statistics for the Social Sciences. These notes largely focus on the application and theory necessary for quantitative social scientists to successfully apply Bayesian statistical methods. I also don’t hesitate to link to those who have already explained things well, and focus my efforts on places where I haven’t found good explanations (or explanations I understand), or places where I need to write notes to deepen my own understanding. "],
["priors.html", "1 Priors 1.1 Conjugate Priors 1.2 Improper Priors 1.3 References", " 1 Priors Priors for coefficients and scales Improper uniform priors \\((-\\infty, +\\infty)\\) or \\((0, +\\infty)\\). Uninformative Proper Priors such as \\(\\sigma^2 \\sim \\dinvgamma(0.001, 0.001)\\). Weakly Informative Priors Bounded Priors Informative Priors Conjugate priors Hyperparameters - “priors on priors” These are usually specified in models. They should be specified to ensure that the posterior is proper and not sensitive statistically or computationally to wide tails in the priors. Boundary avoiding priors - In MAP, priors can be specified to keep parameters away from boundaries, e.g. 0 in a scale model. 1.1 Conjugate Priors In a few cases, the posterior distribution, \\[ p(\\theta | y) = \\frac{p(y | \\theta) p(\\theta)}{\\int p(y | \\theta&#39;) p(\\theta&#39;) d\\theta&#39;}, \\] has a closed-form solution and can be calculated exactly. In those cases, the posterior distribution is calculated exactly, and more costly numerical approximation methods do not need to be used. Unfortunately, these cases are few. Most of those cases involve conjugate priors. In the case of a conjugate prior, the posterior distribution is in the same family as the prior distribution. Here is a diagram of a few common conjugate priors.1 The table in the Wikipedia page for Conjugate priors is as complete as any out there. Fink (1997) for a compendium of references. Also see Distributions for more information about probability distributions. 1.1.1 Binomial-Beta Binomial distribution: If \\(N \\in \\Nats\\) (number of trials), \\(\\theta \\in (0, 1)\\) (success probability in each trial), then for \\(n \\in \\{0, \\dots, N\\}\\), \\[ \\dBinom(n | N, \\theta) = \\binom{N}{n} \\theta^{n} (1 - \\theta)^{N - n} . \\] Beta distribution: If \\(\\alpha \\in \\RealPos\\) (shape) and \\(\\beta \\in \\RealPos\\) (shape), then for \\(\\theta \\in (0, 1)\\), \\[ \\dbeta(\\theta | \\alpha, \\beta) = \\frac{1}{\\mathrm{B}(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\] where \\(\\mathrm{B}\\) is the beta function, \\[ \\mathrm{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)} . \\] Then, \\[ \\begin{aligned}[t] p(\\theta | \\alpha, \\beta) &amp;= \\dbeta(\\theta | \\alpha, \\beta) &amp;&amp; \\text{Beta prior} \\\\ p(y | \\theta) &amp;= \\dBinom(y | n, \\theta) &amp;&amp; \\text{Binomial likelihood} \\\\ p \\theta | y, \\alpha, \\beta) &amp;= \\dbeta(\\theta | \\alpha + y, \\beta + n - y) &amp;&amp; \\text{Beta posterior} \\end{aligned} \\] 1.1.2 Categorical-Dirichlet The Dirichlet distribution is a multivariate generalization of the Beta, If \\(K \\in \\N\\) and \\(\\alpha \\in (\\R^{+})^{K}\\), then for the \\(\\theta \\in K-\\text{simplex}\\) and \\(\\theta_k &gt; 0\\) for all \\(k\\), \\[ \\ddirichlet(\\theta | \\alpha) = \\frac{\\Gamma(\\sum_{k = 1}^K \\alpha_k)}{\\prod_{k = 1}^K \\Gamma(\\alpha_k)} \\prod_{k = 1}^K \\theta_{k}^{\\alpha_k - 1} \\] The multinomial distribution is a generalization of the binomial distribution with \\(K\\) categories instead of 2. If \\(K \\in \\n\\), \\(N \\in \\N\\), and \\(\\theta \\in K-\\text{simplex}\\), then for \\(y \\in \\N^{K}\\) such that \\(\\sum_{k = 1}^K y_k = N\\), \\[ \\dmultinom(y | \\theta) = \\binom{N}{y_1, \\dots, y_K} \\prod_{k = 1}^{K} \\theta_k^{y_k}, \\] where the multinomial coefficient is defined as, \\[ \\binom{N}{y_1, \\dots, y_K} = \\frac{N!}{\\prod_{k = 1}^K y_k!} \\] \\[ \\begin{aligned}[t] p(\\theta | \\alpha) &amp;= \\ddirichlet(\\theta | \\alpha) &amp;&amp; \\text{Dirichlet prior} \\\\ p(y | \\theta) &amp;= \\dmultinom(y | n, \\theta) &amp;&amp; \\text{Multinomial likelihood} \\\\ p(\\theta | y, \\alpha) &amp;= \\ddirichlet(\\theta | \\alpha + y) &amp;&amp; \\text{Dirichlet posterior} \\end{aligned} \\] 1.1.3 Poisson-Gamma Let \\(\\lamba\\) be the rate parameter of the Poisson distribution. If \\(\\lambda \\in \\R^+\\) (rate parameter), then for \\(n \\in \\N\\), \\[ \\dpois(n|\\lambda) = \\frac{1}{n!} \\lambda^n \\exp(-\\lambda) \\] If \\(\\alpha \\in \\R^{+}\\) (shape parameter), \\(\\beta \\in \\R^{+}\\) (inverse scale parameter), then for \\(y \\in \\R^{+}\\), \\[ \\dgamma(y | \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} y^{\\alpha - 1} \\exp(- \\beta y) \\] Then, \\[ \\begin{aligned}[t] p(\\lambda) &amp;= \\dgamma(\\lambda | \\alpha, \\beta) \\\\ p(n | \\lambda) &amp;= \\dpois(n | \\lambda) \\\\ p(\\lambda | n, \\alpha, \\beta) &amp;= \\dgamma(\\lambda | \\alpha + n, \\beta + 1) \\end{aligned} \\] 1.1.4 Normal with known variance \\[ \\begin{aligned}[t] p(\\mu | \\mu_0, \\sigma_0) &amp;= \\dnorm(\\mu | \\mu, \\sigma_0^2) &amp;&amp; \\text{Normal prior} \\\\ p(y | \\mu) &amp;= \\dnorm(y | \\mu, \\sigma^2) &amp;&amp; \\text{Normal likelihood} \\\\ p(\\mu | y, \\mu, \\sigma^2, \\mu_0, \\sigma_0^2) &amp;= \\dbeta(\\mu | \\tilde{\\mu}, \\tilde{\\sigma}^2) &amp;&amp; \\text{Normal posterior} \\\\ \\tilde{\\mu} &amp;= \\tilde{\\sigma}^{2} \\left(\\frac{\\mu_0}{\\sigma_0^2} + \\frac{y}{\\sigma^2} \\right) \\\\ \\tilde{\\sigma}^2 &amp;= \\left(\\frac{1}{\\sigma_0^2} +\\frac{1}{\\sigma^2}\\right)^{-1} \\\\ \\end{aligned} \\] 1.1.5 Exponential Family Likelihood functions in the exponential family have conjugate priors, often also in the exponential family.2 1.2 Improper Priors If prior distributions are given an improper uniform prior, \\(p(\\theta) \\propto 1\\), then the posterior distribution is proportional to the likelihood, \\[ p(\\theta | y) \\propto p(y | \\theta) p(\\theta) \\propto p(y | \\theta) \\] 1.3 References Stan Wiki and the rstanarm vignette includes comprehensive advice for prior choice recommendations. Betancourt (2017) provides numerical simulation of how the shapes of weakly informative priors affects inferences. Stan Development Team (2016) for discussion of some types of priors in regression models Chung et al. (2013) discuss scale priors in penalized MLE models Gelman et al. (2008) discusses using Cauchy(0, 2.5) for prior distributions Gelman (2006) provides a prior distribution on variance parameters in hierarchical models. Polson and Scott (2012) on using Half-Cauchy priors for scale parameters Based on John Cook’s a Diagram of Conjugate Prior distributions.↩ https://en.wikipedia.org/wiki/Exponential_family#Bayesian_estimation:_conjugate_distributions↩ "],
["mcmc-diagnostics.html", "2 MCMC Diagnostics Prerequisites 2.1 Reparameterize Models 2.2 Convergence Diagnostics 2.3 Autocorrelation, Effective Sample Size, and MCSE 2.4 Thinning 2.5 HMC-NUT Specific Diagnostics", " 2 MCMC Diagnostics There are two parts of checking a Bayesian model: diagnostics: Is the sampler working? Is it adequately approximating the specified posterior distribution: \\(p(\\theta | D)\\). model fit: Does the model adequately represent the data? This chapter covers the former. Also see the bayesplot vignette Visual MCMC diagnostics using the bayesplot package, which though specific to the provides, provides a good overview of these diagnostics. Prerequisites library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) 2.1 Reparameterize Models Reduce correlation between parameters (e.g. see mcmc_pairs) Put parameters on the same scale. The samplers work best when all parameters are roughly on the same scale, e.g. \\(\\approx 1\\). Try to avoid situations where parameters are orders of magnitude different, e.g. 1e-5 and 1e+10. Increase the informativeness of priors. If parameters are too uninformative, the posterior distribution may have wide tails that hamper sampling. One way of thinking about it is that the model is only “weakly identified” and requires either more data or more informative priors to estimate. 2.2 Convergence Diagnostics Under certain conditions, MCMC algorithms will draw a sample from the target posterior distribution after it has converged to equilibrium. However, since in practice, any sample is finite, there is no guarantee about whether its converged, or is close enough to the posterior distribution. In general there is no way to prove that the sampler has converged.3 However, there are several statistics that indicate that a sampler has not converged. 2.2.1 Potential Scale Reduction (\\(\\hat{R}\\)) In equilibrium, the distribution of samples from chains should be the same regardless of the initial starting values of the chains (Stan Development Team 2016, Sec 28.2). One way to check this is to compare the distributions of multiple chains—in equilibrium they should all have the same mean. Additionally, the split \\(\\hat{R}\\) tests for convergence by splitting the chain in half, and testing the hypothesis that the means are the same in each half. This tests for non-stationarity within a chain. See Stan Development Team (2016 Sec 28.2) for the equations to calculate these. TODO: Examples of passing and non-passing \\(\\hat{R}\\) chains using fake data generated from known functions with a given autocorrelation. Rule of Thumb: The rule of thumb is that R-hat values for all less than 1.1 source. Note that all parameters must show convergence. This is a necessary but not sufficient condition for convergence. 2.2.2 References Gelman et al. (2013, 267) Stan Development Team (2016 Ch 28.) for how Stan calculates Hat, autocorrelations, and ESS. Gelman and Rubin (1992) introduce the R-hat statistic 2.3 Autocorrelation, Effective Sample Size, and MCSE MCMC samples are dependent. This does not effect the validity of inference on the posterior if the samplers has time to explore the posterior distribution, but it does affect the efficiency of the sampler. In other words, highly correlated MCMC samplers requires more samples to produce the same level of Monte Carlo error for an estimate. 2.3.1 Effective Sample Size The effective sample size (ESS) measures the amount by which autocorrelation in samples increases uncertainty (standard errors) relative to an independent sample. Suppose that the \\(\\rho^2_t\\) is the ACF function of a sample of size \\(N\\), the effective sample size, \\(N_eff\\), is \\[ N_{eff} = \\frac{N}{\\sum_{t = -\\infty}^\\infty \\rho_t} = \\frac{N}{1 + 2 \\sum_{t = -\\infty}^\\infty \\rho_t}. \\] TODO show that if \\(\\rho_t = 1\\) for all \\(t\\) then \\(N_eff = 1\\), and if \\(\\rho_t = 0\\) for all \\(t\\) then \\(N_eff = N\\) Computing the effective sample size requires calculating an autocorrelation. A multi-chain estimate of the autocorrelation is found by computing the variogram with the correlations for all lags, \\[ V_t = \\frac{1}{m(n - t)} \\sum_{j = 1}^m \\sum_{i = t + 1}^n (\\psi_{i,j} - \\psi_{i - t,j})^2 \\] The estimate of the autocorrelations \\(\\hat{\\rho}_t\\) is \\[ \\hat{\\rho}_t = 1 - \\frac{V_t}{2 \\widehat{\\mathrm{var}}^+} \\] The estimates of the autocorrelations can be noisy, so \\(\\hat{\\rho}_t\\) are summed from 0, to the last \\(t\\) such that \\(\\rho\\) is positive (\\(T\\)), \\[ \\hat{n}_{eff} = \\frac{mn}{1 + 2 \\sum_{t = 1}^T \\hat{\\rho}_t} \\] See also Stan Development Team (2016 Sec 28.4), Geyer (2011), and Gelman et al. (2013 Sec 11.5). This isn’t the only way to calculate the effective sample size. The coda package function coda uses a different method. The differences are due to how the autocorrelation is calculated. Example: Comparison of the effective sample sizes for data generated with various levels of autocorrelation. The package rstan does not directly expose the function it uses to calculate ESS, so this ess function does so (for a single chain). ess &lt;- function(x) { N &lt;- length(x) V &lt;- map_dbl(seq_len(N - 1), function(t) { mean(diff(x, lag = t) ^ 2, na.rm = TRUE) }) rho &lt;- head_while(1 - V / var(x), ~ . &gt; 0) N / (1 + sum(rho)) } n &lt;- 1024 sims &lt;- map_df(c(0, 0.5, 0.75, 0.99), function(ar) { tibble(ar = ar, y = if (ar == 0) { rnorm(n) } else { as.numeric(arima.sim(list(ar = ar), n)) }, x = seq_along(y), n_eff = ess(y), label = sprintf(&quot;AR = %.2f (n_eff = %.0f)&quot;, ar, n_eff)) } ) ggplot(sims, aes(x = x, y = y)) + geom_line() + facet_wrap(~ label, scales = &quot;free_y&quot;) + labs(x = &quot;&quot;, y = &quot;&quot;) 2.4 Thinning Since the autocorrelation tends to decrease as the lag increases, thinning samples will reduce the final autocorrelation in the sample while also reducing the total number of samples saved. Due to the autocorrelation, the reduction in the number of effective samples will often be less than number of samples removed in thinning. Both of these will produce 1,000 samples from the posterior, but effective sample size of \\(B\\) will be greater than the effective sample size of \\(A\\), since after thinning g the autocorrelation in \\(B\\) will be lower. A Generating 1,000 samples after convergence and save all of them B Generating 10,000 samples after convergence and save every 10th sample In this case, A produces 10,000 samples, and B produces 1,000. The effective sample size of A will be higher than B. However, due to autocorrelation, the proportional reduction in the effective sample size in B will be less than the thinning: \\(N_{eff}(A) / N_{eff}(B) &lt; 10\\). A Generating 10,000 samples after convergence and save all of them B Generating 10,000 samples after convergence and save every 10th sample Thinning trades off sample size for memory, and due to autocorrelation in samples, loss in effective sample size is less than the loss in sample size. Thinning has become less of an issue as memory has become less of a computational constraint, and samplers have become more efficient. The following example simulates random values from an autocorrelated series, and applies different levels of thinning. Thinning is always decreasing the effective sample size. However, the number of effective samples per sample (n_eff / n) increases until the thinning is large enough that the thinned samples are uncorrelated. thin_ess &lt;- function(thin, x) { if (thin &gt; 1) { # keep only thinned rows x_thinned &lt;- x[(seq_len(length(x)) %% thin) == 1] } else { x_thinned &lt;- x } tibble(thin = thin, n = length(x_thinned), n_eff = ess(x_thinned), `n_eff / n` = n_eff / n) } map_df(c(1, 2, 4, 8, 16, 32), thin_ess, x = arima.sim(list(ar = .9), 4096)) #&gt; # A tibble: 6 x 4 #&gt; thin n n_eff `n_eff / n` #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1. 4096 1266. 0.309 #&gt; 2 2. 2048 1087. 0.531 #&gt; 3 4. 1024 791. 0.773 #&gt; 4 8. 512 512. 1.00 #&gt; 5 16. 256 256. 1.00 #&gt; 6 32. 128 128. 1.00 Gelman et al. (2013, 282–83) Stan Development Team (2016, 354–55) 2.4.1 Traceplots Trace plots are a time series of sampler iterations, e.g. as produced by bayesplot. These can, but should not, be used to assess convergence, such visual inspection is ‘notoriously unreliable’ (Gelman et al. 2013, 285) it cannot scale to many parameters Trace plots may be useful for diagnosing convergence problems after \\(\\hat{R}\\) or or \\(n_eff\\) indicates problems. Some possible issues to check in these plots are multimodality (the traceplot jumps between different distributions) wide posterior tails (the traceplot shows regions where the sampler will reach and have difficulty returning to the main distribution) 2.4.2 Monte Carlo Standard Error (MCSE) The Monte Carlo standard error is the uncertainty about a statistic in the sample due to sampling error. With a independent sample of size \\(N\\), the MCSE for the sample mean is \\[ MCSE(\\bar{\\theta}) = \\frac{s}{\\sqrt{N}} \\] where \\(s\\) is the sample standard deviation. However, MCMC are generally not independent, and the MCSE will be higher than that of an independent sample. One way to calculate the MCSE with autocorrelated samples is to use the effective sample size instead of the sample size, \\[ MCSE(\\bar{\\theta}) = \\frac{s}{\\sqrt{N_{eff}}} \\] An MCSE estimator for the mean is \\[ \\mathrm{MCSE}(\\hat{\\theta}) = \\frac{\\sd(\\theta)}{\\sqrt{n_{neff}}} \\] An MCSE estimator for any posterior probability, where \\(\\hat{p} = \\Pr(f(\\theta))\\), follows from the standard error of a proportion, but using the effective sample size, \\[ MCSE(\\hat{p}) = \\sqrt{\\hat{p} (1 - \\hat{p}) / n_{eff}} \\] See Flegal, Haran, and Jones (2008) and the mcmcse for methods to calculate MCMC standard errors for means and quantiles using sub-sampling methods. Flegal, Haran, and Jones (2008) argues for using ESS as a stopping rule and convergence diagnostic for Bayesian inference. The estimation of standard errors for quantiles, as would be used in is more complicated. See the package mcmcse for Monte Carlo standard errors of quantiles (though calculated in a different method than rstan). Gelman et al. (2013 Sec. 10.5) Flegal, Haran, and Jones (2008) Talk by Geyer on MCSE 2.5 HMC-NUT Specific Diagnostics Hamiltonian Monte Carlo (HMC), and the No-U-Turn Sampler (HMC-NUTS) in particular, produce several diagnostics that indicate that the sampler is breaking and, thus, not sampling from the posterior distribution. This is unusual, as most Bayesian sampling methods do not give indication of whether they are working well, and all that can be checked are the properties of the samples themselves with methods such \\(\\hat{R}\\). Three specific HMC-NUTS diagnostics are divergent transitions maximum tree-depth Bayesian fraction of missing information The general way to fix these issues is the manually adjust the HMC-NUTS sampler parameters.n Stepsize: Length of the steps to take Tree-fdepth: Number of steps to take During the warmup period, Stan tunes these values, however these auto-tuned parameters may not always be optimal. The other alternative is to reparameterize the models. 2.5.1 Divergent transitions The problem: The details of the HMC are technical and can be found TODO. The gist of the problem is that Stan is using a discrete approximation of a continuous function when integrating. If the step sizes are too large, the discrete approximation does not work. Helpfully, when the approximation is poor it does not fail without any indication but will produce “divergent transitions”. If there are too many divergent transitions, then the sampler is not drawing samples from the entire posterior and inferences will be biased The solution: Reduce the step size. This can be done by increasing the the adapt_delta parameter. This is the target average proposal acceptance probability in the adaptation, which is used to determine the step size during warmup. A higher desired acceptance probability (closer to 1) reduces the the step size. A smaller step size means that it will require more steps to explore the posterior distribution. See Stan Development Team (2016, 380) 2.5.2 Maximum Tree-depth The problem: NUTS is an intelligent method to select the number of steps to take in each iteration. However, there is still a maximum number of steps that NUTS will try. If the sampler is often hitting the maximum number of steps, it means that the optimal number of steps to take in each iteration is higher than the maximum. While divergent transitions bias inference, a too-small maximum tree-depth only affects efficiency. The sampler is still exploring the posterior distribution, but the exploration will be slower and the autocorrelation higher (effective sample size lower) than if the maximum tree-depth were set higher. The solution: Increase the maximum tree-depth. 2.5.3 Bayesian Fraction of Missing Information This is rather technical. See Betancourt (2016). This is also the case in optimization with non-convex objective functions.↩ "],
["model-checking.html", "3 Model Checking 3.1 Why check models? 3.2 Posterior Predictive Checks 3.3 References", " 3 Model Checking 3.1 Why check models? In theory—Bayesian model should include all relevant substantive knowledge and subsume all possible theories. In practice—it won’t. We need to check how the model fits data. The question is not whether a model is “true”; it isn’t (Box 1976). The question is whether it is good enough for the purposes of the analysis. The problem is how we can specify “good enough” criteria, and how we can check those criteria. See Gelman, Meng, and Stern (1996), Gelman (2007), Gelman (2009), Gelman et al. (2013 Ch. 6), Gelman and Shalizi (2012b), Kruschke (2013), Gelman and Shalizi (2012a), Gelman (2014) for more discussion of the motivation and use of posterior predictive checks. 3.2 Posterior Predictive Checks One method evaluate the fit of a model is to use posterior predictive checks Fit the model to the data to get the posterior distribution of the parameters: \\(p(\\theta | D)\\) Simulate data from the fitted model: \\(p(\\tilde{D} | \\theta, D)\\) Compare the simulated data (or a statistic thereof) to the observed data and a statistic thereof. The comparison between data simulated from the model can be formal or visual. Within a Stan function, this is done in the generated quantities block using a _rng distribution functions. The package bayesplot includes multiple functions for posterior predictive checks; see the help for PPC-overview for a summary of these functions. 3.2.1 Bayesian p-values A posterior predictive p-value is a the tail posterior probability for a statistic generated from the model compared to the statistic observed in the data. Let \\(y = (y_1, \\dots, y_n)\\) be the observed data. Suppose the model has been fit and there is a set of simulation \\(\\theta^(s)\\), \\(s = 1, \\dots, n_sims\\). In replicated dataset, \\(y^{rep(s)\\), has been generated from the predictive distribution of the data, \\(p(y^{(rep)} | \\theta = \\theta^{(s)}\\). Then the ensemble of simulated datasets, \\((y^{rep(s)}, \\dots, y^{rep(nsims)})\\), is a sample from the posterior predictive distribution, \\(p(y^{(rep)} | y)\\) The model can be tested by means of discrepancy statistics, which are some function of the data and parameters, \\(T(y, \\theta)\\). If \\(\\theta\\) was known, then compare discrepancy by \\(T(y^{(rep)}, \\theta)\\). The statistical significance is \\(p = \\Pr(T(y^{(rep)}, \\theta) &gt; T(y, \\theta) | y, \\theta)\\). If \\(\\theta\\) is unknown, then average over the posterior distribution of \\(\\theta\\), \\[ \\begin{aligned}[t] p &amp;= \\Pr(T(y^{(rep)}, \\theta) &gt; T(y, \\theta) | y) \\\\ &amp;= \\int Pr(T(y^{(rep)}, \\theta) &gt; T(y, \\theta) | y, \\theta) p(\\theta | y) d\\,\\theta , \\end{aligned} \\] which is easily estimated from the MCMC samples as, \\[ p = \\frac{1}{n_{sims}}\\sum_{s = 1}^{n_{sims}} 1( T(y^{rep(s)}, \\theta(s)) &gt; T(y, \\theta(s))) \\] 3.2.2 Test quantities The definition of a posterior p-value does not specify a particular test-statistic, \\(T\\), to use. The best advice is that \\(T\\) depends on the application. Gelman et al. (2013, 146) Speed of light example uses the 90% interval (61st and 6th order statistics). Gelman et al. (2013, 147) binomial trial example uses the number of switches (0 to 1, or 1 to 0) in order to test independence. Gelman et al. (2013, 148) hierarchical model for adolescent smoking uses. percent of adolescents in the sample who never smoked percentage in the sample who smoked in all waves percentage of “incident smoker”: adolescents who began the study and non-smokers and ended as smokers. 3.2.3 p-values vs. u-values A posterior predictive p-value is different than a classical p-value. Posterior predictive p-value distributed uniform if the model is true Classical p-value distributed uniform if the null hypothesis (\\(H_0\\)) is true A u-value is any function of the data that has a \\(U(0, 1)\\) sampling distribution (Gelman et al. 2013, 151) a u-value can be averaged over \\(\\theta\\), but it is not Bayesian, and is not a probability distribution posterior p-value: probability statement, conditional on model and data, about future observations 3.2.4 Marginal predictive checks Compare statistics for each observation. Conditional Predictive Ordinate (CPO): The CPO (Gelfand 1995) is the leave-one-out cross-validation predictive density: \\[ p(y_i | y_{-i}) = \\int p(y_i | \\theta) p(\\theta | y_{-i}) d\\,\\theta \\] The pointwise predicted LOO probabilities can be calculated using PSIS-LOO or WAIC in the loo package. Predictive Concordance and Predictive Quantiles Gelfand (1995) classifies any \\(y_i\\) that is outside the central 95% predictive posterior of \\(y^{rep}_i\\) is an outlier. Let the predictive quantile (\\(PQ_i\\)) be \\[ PQ_i = p(y_i^{(rep)} &gt; y_i) . \\] Then the predictive concordance be the proportion of \\(y_i\\) that are not outliers. Gelfand (1995) argues that the predictive concordance should match 95% - in other words that the posterior predictive distribution should have the correct coverage. 3.2.5 Outliers Can be identified by the inverse-CPO. larger than 40 are possible outliers, and those higher than 70 are extreme values (Ntzoufras 2009, 376). Congdon (2014) scales CPO by dividing each by its individual max and considers observations with scaled CPO under 0.01 as outliers. 3.2.6 Graphical Posterior Predictive Checks Visualization can surprise you, but it doesn’t scale well. Modeling scales well, but it can’t surprise you. – paraphrase of Hadley Wickham Instead of calculating posterior probabilities, plot simulated data and observed data and visually compare them. See Gelman et al. (2013, 154). plot simulated data and real data (Gelman et al. 2013, 154). This is similar to ideas in Wickham et al. (2010). plot summary statistics or inferences residual plots Bayesian residuals have a distribution \\(r_i^{(s)} = y_i - \\E(y_i | \\theta^{s})\\) Bayesian residual graph plots single realization of the residuals, or a summary of their posterior distributions binned plots are best for discrete data (Gelman et al. 2013, 157) 3.3 References See Gelman and Shalizi (2012b), Gelman and Shalizi (2012a), Kruschke (2013). "],
["introduction-to-stan-and-linear-regression.html", "4 Introduction to Stan and Linear Regression Prerequisites 4.1 OLS and MLE Linear Regression 4.2 Stan Model 4.3 Sampling Model with Stan", " 4 Introduction to Stan and Linear Regression This chapter is an introduction to writing and running a Stan model in R. Also see the rstan vignette for similar content. Prerequisites library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) For this section we will use the duncan dataset included in the carData package. Duncan’s occupational prestige data is an example dataset used throughout the popular Fox regression text, Applied Regression Analysis and Generalized Linear Models (Fox 2016). It is originally from Duncan (1961) consists of survey data on the prestige of occupations in the US in 1950, and several predictors: type of occupation, income, and education of that data(&quot;Duncan&quot;, package = &quot;carData&quot;) 4.1 OLS and MLE Linear Regression The first step in running a Stan model is defining the Bayesian statistical model that will be used for inference. We will model prestige of each occupation as a function of its education, occupation, and type. A standard way to do this is with the OLS estimator: \\[ \\begin{multline} y_i = \\beta_0 + \\beta_1 I(\\mathtt{type} = \\mathtt{&quot;prof&quot;}) + \\beta_2 I(\\mathtt{type} = \\mathtt{&quot;wc&quot;}) \\\\ + \\beta_3 \\mathtt{income} + \\beta_4 \\mathtt{education} + \\epsilon_i \\end{multline} \\] duncan_lm &lt;- lm(prestige ~ type + income + education, data = Duncan) \\[ y_i = x_i&#39; \\beta + \\epsilon_i \\] OLS finds \\(\\hat{\\beta}_{OLS}\\) by minimizing the squared errors, \\[ \\hat{\\beta}_{\\text{OLS}} = \\arg \\min_{b} \\sum_{i = 1}^n (y_i - x_i&#39; b)^2 . \\] OLS is an estimator of the (linear approximation of) the conditional expectation function, \\[ \\mathrm{CEF}(y_i | x_i) = E(y_i, x_i&#39; \\beta) . \\] For valid inference we need to make assumptions about \\(\\epsilon_i\\), namely that they are uncorrelated with \\(X\\), \\(\\Cov(\\epsilon, X) = 0\\), and that they are i.i.d, \\(\\Cov(\\epsilon_i, \\epsilon_j) = 0\\), \\(\\Var(\\epsilon_i) = \\sigma^2\\) for all \\(i\\). However, no specific distributional form is or needs to be assumed for \\(\\epsilon\\) since CLT results show that, asymptotically the sampling distribution of \\(\\beta\\) approaches the normal. Additionally, although \\(\\hat\\sigma^2 = \\sum_{i = 1}^n \\epsilon_i / (n - k - 1)\\) is a estimator of \\(\\sigma^2\\), standard errors of the standard error of the regression are not directly provided. However, the OLS estimator is also the same as the MLE estimator for \\(\\beta\\) (but not \\(\\sigma\\)): \\[ \\begin{aligned}[t] p(y_1, \\dots, y_n | \\beta, \\sigma, x_1, \\dots, x_n) &amp;= \\prod_{i = 1}^n p(y_i | \\beta, x_i) \\\\ &amp;= \\prod_{i = 1}^n N(y_i | x_i&#39; \\beta) \\\\ &amp;= \\prod_{i = 1}^n \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\left( \\frac{-(y_i - x_i&#39; \\beta)}{2 \\sigma^2} \\right) \\end{aligned} \\] so, \\[ \\hat{\\beta}_{MLE}, \\hat{\\sigma}_{MLE} = \\arg\\max_{b,s} \\prod_{i = 1}^n N(y_i | x_i&#39; b, s^2) . \\] And \\(\\hat{\\beta}_{MLE} = \\hat{\\beta}_{OLS}\\). Note that the OLS estimator is equivalent to the MLE estimator of \\(\\beta\\), \\[ \\begin{aligned}[t] \\hat{\\beta}_{MLE} &amp;= \\arg \\max_{b} \\prod_{i = 1}^n N(y_i | x_i&#39; b, \\sigma^2) \\\\ &amp;= \\arg \\max_{b} \\prod_{i = 1}^n \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left( \\frac{-(y_i - x_i&#39; \\beta)^2}{2 \\sigma^2} \\right) \\\\ &amp;= \\arg \\max_{b} \\log \\left( \\prod_{i = 1}^n \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left( \\frac{-(y_i - x_i&#39; \\beta)}{2 \\sigma^2} \\right) \\right) \\\\ &amp;= \\arg \\max_{b} \\sum_{i = 1}^n - \\log \\sigma - \\frac{1}{2} \\log 2 \\pi + \\frac{-(y_i - x_i&#39; \\beta)^2}{2 \\sigma^2} \\\\ &amp;= \\arg \\max_{b} \\sum_{i = 1}^n -(y_i - x_i&#39; \\beta)^2 \\\\ &amp;= \\arg \\min_{b} \\sum_{i = 1}^n (y_i - x_i&#39; \\beta)^2 \\\\ &amp;= \\hat{\\beta}_{OLS} \\end{aligned} \\] However, the estimator of \\(\\sigma^2_{MLE} \\neq \\sigma^2_{OLS}\\). 4.1.1 Bayesian Model with Improper priors In Bayesian inference, our target is the posterior distribution of the parameters, \\(\\beta\\) and \\(\\sigma\\): \\(p(\\beta, \\sigma^2 | y, X)\\). \\[ p(\\beta, \\sigma | y, X) \\propto p(y | \\beta, \\sigma) p(\\beta, \\sigma) \\] For a Bayesian linear regression model, we’ll need to specify distributions for \\(p(y | \\beta, \\sigma)\\) and \\(p(\\beta, \\sigma)\\). Likelihood: \\(p(y_i | x_i, \\beta, \\sigma)\\) suppose that the observations are distributed independent normal: \\[ y_i \\sim \\dnorm(\\beta&#39;x_i, \\sigma^2) \\] Priors: The model needs to specify a prior distribution for the parameters \\((\\beta, \\sigma)\\). Rather than specify a single distribution for \\(\\beta\\) and \\(\\sigma\\), it will be easier to specify independent (separate) distributions for \\(\\beta\\) and \\(\\sigma\\). We will use what are called an improper uniform priors. An improper prior is, \\[ p(\\theta) \\propto C \\] where \\(C\\) is some constants. This function puts an equal density on all values of the support of \\(\\theta\\). This function is not a proper probability density function since \\(\\int_{\\theta \\in \\Theta} C d \\theta = \\infty\\). However, for some Bayesian models, the prior does not need to be a proper probability function for the posterior to be a probability function. In this example we will put improper prior distributions on \\(\\beta\\) and \\(\\sigma\\). \\[ p(\\beta, \\sigma) = C \\] \\[ \\begin{aligned} p(\\beta, \\sigma | x, y) &amp;\\propto p(y| \\beta, \\sigma, x) p(\\beta, \\sigma, x) \\\\ &amp;= \\prod_{i = 1}^n N(y_i | x_i&#39; \\beta, \\sigma^2) \\cdot C \\\\ &amp;\\propto \\prod_{i = 1}^n N(y_i | x_i&#39; \\beta, \\sigma^2) \\end{aligned} \\] Note that under the improper priors, the posterior is proportional to the likelihood, \\[ p(\\beta, \\sigma | x, y) \\propto p(y | x, \\beta, \\sigma) \\] Thus the MAP (maximum a posterior) estimator is the same as the MLE, \\[ \\hat{\\beta}_{MAP}, \\hat{\\sigma}_{MAP} = \\arg\\max_{\\beta, \\sigma} p(\\beta, \\sigma | x, y) = \\arg \\max_{\\beta, \\sigma} p(y | x, \\beta, \\sigma) = \\hat{\\beta}_{MLE}, \\hat{\\sigma}_{MLE} \\] 4.2 Stan Model Let’s write and estimate our model in Stan. Stan models are written in its own domain-specific language that focuses on declaring the statistical model (parameters, variables, distributions) while leaving the details of the sampling algorithm to Stan. A Stan model consists of blocks which contain declarations of variables and/or statements. Each block has a specific purpose in the model. 4.3 Sampling Model with Stan functions { // OPTIONAL: user-defined functions } data { // read in data ... } transformed data { // Create new variables/auxiliary variables from the data } parameters { // Declare parameters that will be estimated } transformed parameters { // Create new variables/auxiliary variables from the parameters } model { // Declare your probability model: priors, hyperpriors &amp; likelihood } generated quantities { // Declare any quantities other than simulated parameters to be generated } The file lm0.stan is a Stan model for the linear regression model previously defined. data { // number of observations int n; // response vector vector[n] y; // number of columns in the design matrix X int k; // design matrix X matrix [n, k] X; // // beta prior // real b_loc; // real&lt;lower = 0.0&gt; b_scale; // // sigma prior // real sigma_scale; } parameters { // regression coefficient vector vector[k] b; // scale of the regression errors real&lt;lower = 0.0&gt; sigma; } transformed parameters { // mu is the observation fitted/predicted value // also called yhat vector[n] mu; mu = X * b; } model { // priors // b ~ normal(b_loc, b_scale); // sigma ~ cauchy(0, sigma_scale); // likelihood y ~ normal(mu, sigma); // the ~ is a shortcut // target += normal_lpdf(y | mu, sigma); // for (i in 1:n) { // y[i] ~ normal(mu[i], sigma) // } } generated quantities { // // simulate data from the posterior // vector[n] y_rep; // // log-likelihood posterior // vector[n] log_lik; // for (i in 1:n) { // y_rep[i] = normal_rng(mu[i], sigma); // log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); // } } library(&quot;rstan&quot;) mod1 &lt;- stan_model(&quot;stan/lm.stan&quot;) mod1 prelist(class = “stan”)list(list(name = “code”, attribs = list(), children = list(“data {// number of observationsint n;// response vectorvector[n] y;// number of columns in the design matrix Xint k;// design matrix Xmatrix [n, k] X;// // beta prior// real b_loc;// real&lt;lower = 0.0&gt; b_scale;// // sigma prior// real sigma_scale;}parameters {// mu is the observation fitted/predicted value// also called yhatvector[n] mu;mu = X * b;}quantities {// // simulate data from the posterior// vector[n] y_rep;// // log-likelihood posterior// vector[n] log_lik;// for (i in 1:n) {// y_rep[i] = normal_rng(mu[i], sigma);// log_lik[i] = normal_lpdf(y[i] | mu[i], sigma);// }}”))) See the Stan Modeling Language User’s Guide and Reference Manual for details of the Stan Language. NoteSince a Stan model compiles to C++ code, you may receive some warning messages such as /Library/Frameworks/R.framework/Versions/3.3/Resources/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function] static void set_zero_all_adjoints() { ^ In file included from file1d4a4d50faa.cpp:8: In file included from /Library/Frameworks/R.framework/Versions/3.3/Resources/library/StanHeaders/include/src/stan/model/model_header.hpp:4: As long as your model compiles, you can ignore these compiler warnings (On the other hard, warnings that occur during sampling should not be ignored). If the Stan model does not give you a syntax error when parsing the model, it should compile to valid C++.[^bugs][^c-warnings] See [bugs]: In the rare case that the Stan parser transpiles the Stan model to C++ but cannot compile the C++ code, it is a bug in Stan. Follow the instructions on how to inform the Stan developers about bugs. [c-warnings]: The extended installation instructions for MacOS/Linux and Windows have instructions for adding compiler options to the R Makevars file. 4.3.1 Sampling In order to sample from the model, we need to at least give it the values for the data to use: n, k, y, X, and the data associated with the priors. mod1_data &lt;- list( y = Duncan$prestige, n = nrow(Duncan) ) The data types in Stan are all numeric (either integers or reals), but they include matrices and vectors. However, there is nothing like a data frame in Stan. Whereas in the R function lm we can provide a formula and a data set for where to look for objects, and the function will create the appropriate \\(X\\) matrix for the regression, we will need to create that matrix ourselves—expanding categorical variables to indicator variables, and expanding interactions and other functions of the predictors. However, we need to do that all manually. The function stats is the workhorse function used in lm and many other R functions to convert a formula into the matrix used in estimation. X &lt;- model.matrix(prestige ~ type + income + education, data = Duncan) mod1_data$X &lt;- X mod1_data$k &lt;- ncol(X) We still need to provide the values for the prior distributions. For specific values of the prior distributions, assume uninformative priors for beta by setting the mean to zero and the variances to large numbers. \\[ \\beta_k \\sim \\dnorm(0, 1000) \\] # mod1_data$b_loc &lt;- 0 # mod1_data$b_scale &lt;- 1000 For prior of the regression scale parameter \\(\\sigma\\), use a half-Cauchy distribution with a large scale parameter, which is a good choice for the priors of scale parameters. \\[ \\sigma \\sim \\dhalfcauchy(0, 50) \\] # mod1_data$sigma_scale &lt;- 50 Now, sample from the posterior, using the function sampling: mod1_fit &lt;- sampling(mod1, data = mod1_data) 4.3.2 Convergence Diagnostics and Model Fit Convergence Diagnostics: Is this the posterior distribution that you were looking for? These don’t directly say anything about how “good” the model is in terms representing the data, they are only evaluating how well the sampler is doing at sampling the posterior distribution of the given model. If there are problems with these, then the sample results do not represent the posterior distribution, and your inferences will be biased. mcse: n_eff: Rhat divergences Model fit: Is this statistical model appropriate for the data? Or better than other models? Posterior predictive checks Information criteria: WAIC Leave-one-out Cross-Validation "],
["heteroskedasticity-and-robust-regression.html", "5 Heteroskedasticity and Robust Regression Prerequisites 5.1 Linear Regression with Student t distributed errors 5.2 Heteroskedasticity 5.3 References", " 5 Heteroskedasticity and Robust Regression Prerequisites library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) library(&quot;rubbish&quot;) 5.1 Linear Regression with Student t distributed errors Like OLS, Bayesian linear regression with normally distributed errors is sensitive to outliers. The normal distribution has narrow tail probabilities. This plots the normal, Double Exponential (Laplace), and Student-t (df = 4) distributions all with mean 0 and scale 1, and the surprise (\\(- log(p)\\)) at each point. Higher surprise is a lower log-likelihood. Both the Student-t and Double Exponential distributions have surprise values well below the normal in the ranges (-6, 6).4 This means that outliers impose less of a penalty on the log-posterior models using these distributions, and the regression line would need to move less to incorporate those observations since the error distribution will not consider them as unusual. z &lt;- seq(-6, 6, length.out = 100) bind_rows( tibble(z = z, p = dnorm(z, 0, 1), distr = &quot;Normal&quot;), tibble(z = z, p = dt(z, 4), distr = &quot;Student-t (df = 4)&quot;), tibble(z = z, p = VGAM::dlaplace(z, 0, 1), distr = &quot;Double Exponential&quot;)) %&gt;% mutate(`-log(p)` = -log(p)) %&gt;% ggplot(aes(x = z, y = `-log(p)`, colour = distr)) + geom_line() z &lt;- seq(-6, 6, length.out = 100) bind_rows( tibble(z = z, p = dnorm(z, 0, 1), distr = &quot;Normal&quot;), tibble(z = z, p = dt(z, 4), distr = &quot;Student-t (df = 4)&quot;), tibble(z = z, p = VGAM::dlaplace(z, 0, 1), distr = &quot;Double Exponential&quot;)) %&gt;% mutate(`-log(p)` = -log(p)) %&gt;% ggplot(aes(x = z, y = p, colour = distr)) + geom_line() mod_t prelist(class = “stan”)list(list(name = “code”, attribs = list(), children = list(“data {// number of observationsint n;// response vectorvector[n] y;// number of columns in the design matrix Xint k;// design matrix Xmatrix [n, k] X;// beta priorreal b_loc;real&lt;lower = 0.0&gt; b_scale;// sigma priorreal sigma_scale;}parameters {// mu is the observation fitted/predicted value// also called yhatvector[n] mu;mu = X * b;}quantities {// simulate data from the posteriorvector[n] y_rep;// log-likelihood valuesvector[n] log_lik;for (i in 1:n) {y_rep[i] = student_t_rng(nu, mu[i], sigma);log_lik[i] = student_t_lpdf(y[i] | nu, mu[i], sigma);}}”))) unionization &lt;- read_tsv(&quot;data/western1995/unionization.tsv&quot;, col_types = cols( country = col_character(), union_density = col_double(), left_government = col_double(), labor_force_size = col_number(), econ_conc = col_double() )) mod_data &lt;- lm_preprocess(union_density ~ left_government + log(labor_force_size) + econ_conc, data = unionization) mod_data &lt;- within(mod_data, { b_loc &lt;- 0 b_scale &lt;- 1000 sigma_scale &lt;- sd(y) }) The max_treedepth parameter needed to be increased because in some runs it was hitting the maximum tree depth. This is likely due to the wide tails of the Student t distribution. mod_t_fit &lt;- sampling(mod_t, data = mod_data, control = list(max_treedepth = 11)) summary(mod_t_fit, pars = c(&quot;b&quot;))$summary #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff #&gt; b[1] 89.656 1.96521 67.2067 -41.182 46.908 89.599 134.636 217.195 1170 #&gt; b[2] 0.276 0.00164 0.0819 0.118 0.222 0.275 0.328 0.445 2488 #&gt; b[3] -5.991 0.12507 4.3510 -14.187 -8.863 -5.928 -3.186 2.628 1210 #&gt; b[4] 3.080 0.66199 22.7704 -40.144 -12.161 3.213 17.466 48.781 1183 #&gt; Rhat #&gt; b[1] 1 #&gt; b[2] 1 #&gt; b[3] 1 #&gt; b[4] 1 Compare those results when using a model with mod_normal prelist(class = “stan”)list(list(name = “code”, attribs = list(), children = list(“data {// number of observationsint n;// response vectorvector[n] y;// number of columns in the design matrix Xint k;// design matrix Xmatrix [n, k] X;// // beta prior// real b_loc;// real&lt;lower = 0.0&gt; b_scale;// // sigma prior// real sigma_scale;}parameters {// mu is the observation fitted/predicted value// also called yhatvector[n] mu;mu = X * b;}quantities {// // simulate data from the posterior// vector[n] y_rep;// // log-likelihood posterior// vector[n] log_lik;// for (i in 1:n) {// y_rep[i] = normal_rng(mu[i], sigma);// log_lik[i] = normal_lpdf(y[i] | mu[i], sigma);// }}”))) mod_normal_fit &lt;- sampling(mod_normal, data = mod_data) summary(mod_normal_fit, pars = c(&quot;b&quot;))$summary #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff #&gt; b[1] 96.906 2.06260 63.1921 -25.1126 55.553 95.214 137.380 228.769 939 #&gt; b[2] 0.270 0.00209 0.0848 0.0986 0.214 0.269 0.327 0.435 1643 #&gt; b[3] -6.412 0.13431 4.1895 -14.9459 -9.154 -6.350 -3.588 1.752 973 #&gt; b[4] 0.582 0.68171 21.1558 -42.5470 -12.443 0.907 14.464 40.923 963 #&gt; Rhat #&gt; b[1] 1.01 #&gt; b[2] 1.00 #&gt; b[3] 1.01 #&gt; b[4] 1.01 5.2 Heteroskedasticity In applied regression, heteroskedasticity consistent or robust standard errors are often used. However, there is straightforwardly direct translation of HC standard error to regression model this in a Bayesian setting. The sandwich method of estimating HC errors uses the same point estimates for the regression coefficients as OLS, but estimates the standard errors of those coefficients in a second stage from the OLS residuals. Disregarding differences in frequentist vs. Bayesian inference, it is clear that a direct translation of that method could not be fully Bayesian since the coefficients and errors are not estimated jointly. In a linear normal regression model with heteroskedasticity, each observation has its own scale parameter, \\(\\sigma_i\\), \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(X \\beta, \\sigma_i) . \\end{aligned} \\] It should be clear that without proper priors this model is not identified, meaning that the posterior distribution is improper. To estimate this model we have to apply some model to the scale terms, \\(\\sigma_i\\). In fact, you can think of homoskedasticity as the simplest such model; assuming that all \\(\\sigma_i = \\sigma\\). A more general model of \\(\\sigma_i\\) should encode any information the analyst has about the scale terms. This can be a distribution or functions of covariates for how we think observations may have different values. 5.2.1 Covariates A simple model of heteroskedasticity is if the observations can be split into groups. Suppose the observations are partitioned into \\(k = 1, \\dots, K\\) groups, and \\(k[i]\\) is the group of observation \\(i\\), \\[ \\sigma_i = \\sigma_{k[i]} \\] Another choice would be to model the scale term with a regression model, for example, \\[ \\log(\\sigma_i) \\sim \\dnorm(X \\gamma, \\tau) \\] 5.2.2 Student-t Error The Student-t distribution of error terms from the Robust Regression chapter is also model of heteroskedasticity. A reparameterization that will be used quite often is to rewrite a normal distributions with unequal scale parameters as the product of a common global scale parameter (\\(\\sigma\\)), and observation specific local scale parameters, \\(\\lambda_i\\),5 \\[ y_i \\sim \\dnorm(X\\beta, \\lambda_i \\sigma) . \\] If the local variance parameters are distributed inverse-gamma, \\[ \\lambda^2 \\sim \\dinvgamma(\\nu / 2, \\nu / 2) \\] then the above is equivalent to a regression with errors distributed Student-t errors with \\(\\nu\\) degrees of freedom, \\[ y_i \\sim \\dt{\\nu}(X \\beta, \\sigma) . \\] Example: Simulate Student-t distribution with \\(\\nu\\) degrees of freedom as a scale mixture of normal. For *s in 1:S$, Simulate \\(z_s \\sim \\dgamma(\\nu / 2, \\nu / 2)\\) \\(x_s = 1 / \\sqrt{z_s}2\\) is draw from \\(\\dt{\\nu}(0, 1)\\). When using R, ensure that you are using the correct parameterization of the gamma distribution. Left to reader 5.3 References 5.3.1 Robust regression See Gelman and Hill (2007 sec 6.6), Gelman et al. (2013 ch 17) Stan Development Team (2016 Sec 8.4) for the Stan example using a Student-t distribution 5.3.2 Heteroskedasticity Gelman et al. (2013 Sec. 14.7) for models with unequal variances and correlations. Stan Development Team (2016) reparameterizes the Student t distribution as a mixture of gamma distributions in Stan. 5.3.3 Quantile regression Benoit and Poel (2017) Yu and Zhang (2005) for the three-parameter asymmetric Laplace distribution The Double Exponential distribution still has a thinner tail than the Student-t at higher values.↩ See this for a visualization of a Student-t distribution a mixture of Normal distributions, and this for a derivation of the Student t distribution as a mixture of normal distributions. This scale mixture of normal representation will also be used with shrinkage priors on the regression coefficients.↩ "],
["generalized-linear-models.html", "6 Generalized Linear Models 6.1 Generalized Linear Models 6.2 Count Models 6.3 Example 6.4 Negative Binomial 6.5 Multinomial / Categorical Models 6.6 Gamma Regression 6.7 Beta Regression 6.8 References", " 6 Generalized Linear Models 6.1 Generalized Linear Models Generalized linear models (GLMs) are a class of commonly used models. In GLMs, the mean is specified as a function of a linear model of predictors, \\[ E(Y) = \\mu = g^{-1}(\\mat{X} \\vec{\\beta}) . \\] GLMs are a generalization of linear regression from an unbounded continuous outcome variable to other types of data: binary, count, categorical, bounded continuous. A GLM consists of three components: A probability distribution (family) specifying the conditional distribution of the response variable. In GLMs, the distribution is in the exponential family: Normal, Binomial, Poisson, Categorical, Multinomial, Poisson, Beta. A linear predictor, which is a linear function of the predictors, \\[ \\eta = \\mat{X} \\vec{\\beta} . \\] A link function (\\(g(.)\\)) which maps the expected value to the the linear predictor, \\[ g(\\mu) = \\eta . \\] The link function is smooth and invertible, and the inverse link function or mean function maps the linear predictor to the mean, \\[ \\mu = g^{-1}(\\eta) . \\] The link function (\\(g\\)) and its inverse ($g^{-1}) translate \\(\\eta\\) from \\((\\-infty, +\\infty)\\) to the proper range for the probability distribution and back again. These models are often estimated with MLE, as with the function stats. These are also easily estimated in a Bayesian setting. See the help for stats for common probability distributions, stats for common links, and the Wikipedia page for a table of common GLMs. See the function VGAM for even more examples of link functions and probability distributions. Common Link Functions and their inverses. Table derived from Fox (2016, 419). Link Range of \\(\\mu_i\\) \\(\\eta_i = g(\\mu_i)\\) \\(\\mu_i = g^{-1}(\\eta)_i\\) Identity \\((-\\infty, \\infty)\\) \\(\\mu_i\\) \\(\\eta_i\\) Inverse \\((-\\infty, \\infty) \\setminus \\{0\\}\\) \\(\\mu_i^{-1}\\) \\(\\eta_i^{-1}\\) Log \\((0, \\infty)\\) \\(\\log(\\mu_i)\\) \\(\\exp(\\eta_i)\\) Inverse-square \\((0, \\infty)\\) \\(\\mu_i^{-2}\\) \\(\\eta_i^{-1/2}\\) Square-root \\((0, \\infty)\\) \\(\\sqrt{\\mu_i}\\) \\(\\eta_{i}^2\\) Logit \\((0, 1)\\) \\(\\log(\\mu / (1 - \\mu_i)\\) \\(1 / (1 + \\exp(-\\eta_i))\\) Probit \\((0, 1)\\) \\(\\Phi^{-1}(\\mu_i)\\) \\(\\Phi(\\eta_i)\\) Cauchit \\((0, 1)\\) \\(\\tan(\\pi (\\mu_i - 1 / 2))\\) \\(\\frac{1}{\\pi} \\arctan(\\eta_i) + \\frac{1}{2}\\) Log-log \\((0, 1)\\) \\(-\\log(-log(\\mu_i))\\) \\(\\exp(-\\exp(-\\eta_i))\\) Complementary Log-log \\((0, 1)\\) \\(\\log(-log(1 - \\mu_i))\\) \\(1 - \\exp(-\\exp(\\eta_i))\\) Common distributions and link functions. Table derived from Fox (2016, 421), Wikipedia, and stats. Distribution Canonical Link Range of \\(Y_i\\) Other link functions Normal Identity real: \\((-\\infty, +\\infty)\\) log, inverse Exponential Inverse real: \\((0, +\\infty)\\) identity, log Gamma Inverse real: \\((0, +\\infty)\\) identity, log Inverse-Gaussian Inverse-squared real: \\((0, +\\infty)\\) inverse, identity, log Bernoulli Logit integer: \\(\\{0, 1\\}\\) probit, cauchit, log, cloglog Binomial Logit integer: \\(0, 1, \\dots, n_i\\) probit, cauchit, log, cloglog Poisson Log integer: \\(0, 1, 2, \\dots\\) identity, sqrt Categorical Logit \\(0, 1, \\dots, K\\) Multinomial Logit K-vector of integers, \\(\\{x_1, \\dots, x_K\\}\\) s.t. \\(\\sum_k x_k = N\\). 6.2 Count Models 6.2.1 Poisson The Poisson model is used for unbounded count data, \\[ Y = 0, 1, \\dots, \\infty \\] The outcome is modeled as a Poisson distribution \\[ y_i \\sim \\dpois(\\lambda_i) \\] with positive mean parameter \\(\\lambda_i \\in (0, \\infty)\\). Since \\(\\lambda_i\\) has to be positive, the most common link function is the log, \\[ \\log(\\lambda_i) = \\exp(\\vec{x}_i&#39; \\vec{\\beta}) \\] which has the inverse, \\[ \\lambda_i = \\log(\\vec{x}_i \\vec{\\beta}) \\] In Stan, the Poisson distribution has two implementations: poisson_lpdf poisson_log_lpdf: Poisson with a log link. This is for numeric stability. Also, rstanarm supports the Poisson. 6.3 Example A regression model of bilateral sanctions for the period 1939 to 1983. The outcome variable is the number of countries imposing sanctions. data(&quot;sanction&quot;, package = &quot;Zelig&quot;) library(&quot;rstan&quot;) #&gt; Loading required package: ggplot2 #&gt; Loading required package: StanHeaders #&gt; rstan (Version 2.17.3, GitRev: 2e1f913d3ca3) #&gt; For execution on a local, multicore CPU with excess RAM we recommend calling #&gt; options(mc.cores = parallel::detectCores()). #&gt; To avoid recompilation of unchanged Stan programs, we recommend calling #&gt; rstan_options(auto_write = TRUE) library(&quot;tidyverse&quot;) #&gt; ── Attaching packages ───────── tidyverse 1.2.1 ── #&gt; ✔ tibble 1.4.2 ✔ purrr 0.2.4 #&gt; ✔ tidyr 0.8.0 ✔ dplyr 0.7.4 #&gt; ✔ readr 1.1.1 ✔ stringr 1.3.0 #&gt; ✔ tibble 1.4.2 ✔ forcats 0.3.0 #&gt; ── Conflicts ──────────── tidyverse_conflicts() ── #&gt; ✖ tidyr::extract() masks rstan::extract() #&gt; ✖ dplyr::filter() masks stats::filter() #&gt; ✖ dplyr::lag() masks stats::lag() library(&quot;magrittr&quot;) #&gt; #&gt; Attaching package: &#39;magrittr&#39; #&gt; The following object is masked from &#39;package:purrr&#39;: #&gt; #&gt; set_names #&gt; The following object is masked from &#39;package:tidyr&#39;: #&gt; #&gt; extract #&gt; The following object is masked from &#39;package:rstan&#39;: #&gt; #&gt; extract URL &lt;- &quot;https://raw.githubusercontent.com/carlislerainey/priors-for-separation/master/br-replication/data/need.csv&quot; # nolint autoscale &lt;- function(x, center = TRUE, scale = TRUE) { nvals &lt;- length(unique(x)) if (nvals &lt;= 1) { out &lt;- x } else if (nvals == 2) { out &lt;- if (scale) { (x - min(x, na.rm = TRUE)) / diff(range(x, finite = TRUE)) } else x if (center) { out &lt;- x - mean(x) } } else { out &lt;- if (center) { x - mean(x, na.rm = TRUE) } else x out &lt;- if (scale) out / sd(out, na.rm = TRUE) } out } f &lt;- (oppose_expansion ~ dem_governor + obama_win + gop_leg + percent_uninsured + income + percent_nonwhite + percent_metro) br &lt;- read_csv(URL) %&gt;% mutate(oppose_expansion = 1 - support_expansion, dem_governor = -1 * gop_governor, obama_win = as.integer(obama_share &gt;= 0.5), percent_nonwhite = percent_black + percent_hispanic) %&gt;% rename(gop_leg = legGOP) %&gt;% # keep only variables in the formula model.frame(f, data = .) %&gt;% # drop missing values (if any?) drop_na() #&gt; Parsed with column specification: #&gt; cols( #&gt; .default = col_integer(), #&gt; state = col_character(), #&gt; state_abbr = col_character(), #&gt; house12 = col_double(), #&gt; sen12 = col_double(), #&gt; support_expansion_new = col_character(), #&gt; percent_uninsured = col_double(), #&gt; ideology = col_double(), #&gt; income = col_double(), #&gt; percent_black = col_double(), #&gt; percent_hispanic = col_double(), #&gt; percent_metro = col_double(), #&gt; dsh = col_double(), #&gt; obama_share = col_double() #&gt; ) #&gt; See spec(...) for full column specifications. br_scaled &lt;- br %&gt;% # Autoscale all vars but response mutate_at(vars(-oppose_expansion), autoscale) glm(f, data = br, family = &quot;binomial&quot;) %&gt;% summary() #&gt; #&gt; Call: #&gt; glm(formula = f, family = &quot;binomial&quot;, data = br) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.374 -0.461 -0.131 0.630 2.207 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 4.5103 4.5986 0.98 0.327 #&gt; dem_governor -4.1556 1.4794 -2.81 0.005 ** #&gt; obama_win -2.1470 1.3429 -1.60 0.110 #&gt; gop_leg -0.1865 1.2974 -0.14 0.886 #&gt; percent_uninsured -0.3072 0.1651 -1.86 0.063 . #&gt; income -0.0421 0.0776 -0.54 0.587 #&gt; percent_nonwhite 17.8505 48.3030 0.37 0.712 #&gt; percent_metro -12.4390 32.4446 -0.38 0.701 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 68.593 on 49 degrees of freedom #&gt; Residual deviance: 37.948 on 42 degrees of freedom #&gt; AIC: 53.95 #&gt; #&gt; Number of Fisher Scoring iterations: 5 library(&quot;rstanarm&quot;) #&gt; Loading required package: Rcpp #&gt; Loading required package: methods #&gt; rstanarm (Version 2.17.3, packaged: 2018-02-17 05:11:16 UTC) #&gt; - Do not expect the default priors to remain the same in future rstanarm versions. #&gt; Thus, R scripts should specify priors explicitly, even if they are just the defaults. #&gt; - For execution on a local, multicore CPU with excess RAM we recommend calling #&gt; options(mc.cores = parallel::detectCores()) #&gt; - Plotting theme set to bayesplot::theme_default(). fit1 &lt;- stan_glm(f, data = br, family = &quot;binomial&quot;) fit2 &lt;- stan_glm(f, data = br, prior = NULL, family = &quot;binomial&quot;) 6.4 Negative Binomial The Negative Binomial model is also used for unbounded count data, \\[ Y = 0, 1, \\dots, \\infty \\] The Poisson distribution has the restriction that the mean is equal to the variance, \\(\\E(X) = \\Var(X) = \\lambda\\). The Negative Binomial distribution has an additional parameter that allows the variance to vary (though it is always larger than the mean). The outcome is modeled as a negative binomial distribution, \\[ y_i \\sim \\dbinom(\\alpha_i, \\beta) \\] with shape \\(\\alpha \\in \\R^{+}\\) and inverse scale \\(\\beta \\in \\R^{+}\\), and \\(\\E(y) = \\alpha_i / \\beta\\) and \\(\\Var(Y) = \\frac{\\alpha_i}{\\beta^2}(\\beta + 1)\\). Then the mean can be modeled and transformed to the \\[ \\begin{aligned}[t] \\mu_i &amp;= \\log( \\vec{x}_i \\vec{\\gamma} ) \\\\ \\alpha_i &amp;= \\mu_i / \\beta \\end{aligned} \\] Important The negative binomial distribution has many different parameterizations. An alternative parameterization of the negative binomial uses the mean and a over-dispersion parameter. \\[ y_i \\sim \\dnbinomalt(\\mu_i, \\phi) \\] with location parameter \\(\\mu \\in \\R^{+}\\) and over-dispersion parameter \\(\\phi \\in \\R^{+}\\), and \\(\\E(y) = \\mu_i\\) and \\(\\Var(Y) = \\mu_i + \\frac{\\mu_i^2}{\\phi}\\). Then the mean can be modeled and transformed to the \\[ \\begin{aligned}[t] \\mu_i &amp;= \\log( \\vec{x}_i \\vec{\\gamma} ) \\\\ \\end{aligned} \\] In Stan, there are multiple parameterizations of the neg_binomial_lpdf(y | alpha, beta)with shape parameter alpha and inverse scale parameter beta. neg_binomial_2_lpdf(y | mu, phi) with mean mu and over-dispersion parameter phi. neg_binomial_2_log_lpdf(y | eta, phi) with log-mean eta and over-dispersion parameter phi Also, rstanarm supports Poisson and negative binomial models. Gelman et al. (2013 Ch 16) 6.4.1 References For general references on count models see Gelman and Hill (2007, 109–16) McElreath (2016 Ch 10) Fox (2016 Ch. 14) Gelman et al. (2013 Ch. 16) 6.5 Multinomial / Categorical Models 6.6 Gamma Regression The response variable is continuous and positive. In gamma regression, the coefficient of variation is constant rather than the variance. \\[ y_i \\sim \\dgamma(\\alpha_i, \\beta) \\] and \\[ \\begin{aligned}[t] \\alpha_i &amp;= \\mu_i / \\beta \\\\ \\mu_i &amp;= \\vec{x}_i \\vec{\\gamma} \\end{aligned} \\] In Stan, gamma(y | alpha, beta) with shape parameter \\(\\alpha &gt; 0\\) and inverse scale parameter \\(\\beta &gt; 0\\). Then \\(\\E(Y) = \\alpha / \\beta\\) and \\(\\Var(Y) = \\alpha / \\beta^2\\). 6.7 Beta Regression This is for a response variable that is a proportion, \\(y_i \\in (0, 1)\\), \\[ y_i \\sim \\dbeta(\\alpha_i, \\beta_i) \\] and \\[ \\begin{aligned}[t] \\mu_i &amp;= g^{-1}(\\vec{x}_i&#39; \\vec{\\gamma}) \\\\ \\alpha_i &amp;= \\mu_i \\phi \\\\ \\beta_i &amp;= (1 - \\mu_i) \\phi \\end{aligned} \\] Additionally, the \\(\\phi\\) parameter could also be modeled. In Stan: beta(y | alpha, beta) with positive prior successes plus one, \\(\\alpha &gt; 0\\), and negative prior failures plus one, \\(\\beta &gt; 0\\). Then \\(\\E(Y) = \\alpha / (\\alpha + \\beta)\\) and \\(\\Var(Y) = \\alpha\\beta / ((\\alpha + \\beta)^2 (\\alpha + \\beta + 1))\\). rstanarm function rstasnarm See: Ferrari and Cribari-Neto (2004), Cribari-Neto and Zeileis (2010), and Grün, Kosmidis, and Zeileis (2012) on beta regression. rstanarm documentation Modeling Rates/Proportions using Beta Regression with rstanarm 6.8 References Gelman et al. (2013 Ch 16), Gelman and Hill (2007 Ch. 5-6), McElreath (2016 Ch. 9). King (1998) discusses MLE estimation of many common GLM models. Many econometrics/statistics textbooks, e.g. Fox (2016), discuss GLMs. Though they are not derived from a Bayesian context, they can easily transferred. "],
["binomial-models.html", "7 Binomial Models 7.1 Rare Events Logit 7.2 Case Control", " 7 Binomial Models library(&quot;rstan&quot;) library(&quot;rstanarm&quot;) library(&quot;tidyverse&quot;) library(&quot;rubbish&quot;) library(&quot;bayz&quot;) Binomial models are used to an outcome that is a bounded integer, \\[ y_i \\in 0, 1, 2, \\dots, n . \\] The outcome is distributed Binomial, \\[ \\begin{aligned}[t] y_i \\sim \\dbin \\left(n_i, \\pi \\right) \\end{aligned} \\] A binary outcome is a common special case, \\[ y_i \\in \\{0, 1\\}, \\] and \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dbin \\left(1, \\pi \\right) &amp; \\text{for all $i$} \\\\ \\end{aligned} \\] Depending on the link function, these are logit and probit models that appear in the literature. 7.0.1 Link Functions {link-function} The parameter \\(\\pi \\in (0, 1)\\) is often modeled with a link function is and a linear predictor. \\[ \\pi_i = g^{-1}(\\vec{x}_i \\vec{\\beta}) \\] There are several common link functions, but they all have to map \\(R \\to (0, 1)\\).6 Logit: The logistic function, \\[ \\pi_i = \\logistic(x_i\\T \\beta) = \\frac{1}{1 + \\exp(- x_i\\T\\beta)} . \\] Stan function softmax. Probit: The CDF of the normal distribution. \\[ \\pi_i = \\Phi(x_i\\T \\beta) \\] Stan function normal_cdf. cauchit: The CDF of the Cauchy distribution. Stan function cauchy_cdf. cloglog: The inverse of the conditional log-log function (cloglog) is \\[ \\pi_i = 1 - \\exp(-\\exp(x_i\\T \\beta)) . \\] Stan function inv_cloglog. Of these link functions, the probit has the narrowest tails (sensitivity to outliers), followed by the logit, and cauchit. The cloglog function is different in that it is asymmetric.7 At zero its value is above 0.5, whereas the cauchit, logit, and probit links all equal 0.5 at 0, make.link(&quot;cloglog&quot;)$linkinv(0) #&gt; [1] 0.632 map(c(&quot;logit&quot;, &quot;probit&quot;, &quot;cauchit&quot;, &quot;cloglog&quot;), make.link) %&gt;% map_df( function(link) { tibble(x = seq(-4, 4, length.out = 101), y = link$linkinv(x), link_name = link$name) } ) %&gt;% ggplot(aes(x = x, y = y, colour = link_name)) + geom_line() 7.0.2 Stan In Stan, the Binomial distribution has two implementations: binomial_lpdf binomial_logit_lpdf. The later implementation is for numeric stability. Taking an exponential of a value can be numerically unstable, and binomial_logit_lpdf input is on the logit scale: Whereas, \\[ y_i \\sim \\mathsf{binomial}(1 / (1 + \\exp(x_i \\beta))) \\] the following is true, \\[ y_i \\sim \\mathsf{binomial\\_logit}(x_i \\beta) \\] 7.0.3 Example: Vote Turnout A general Stan model for estimating logit models is: mod1 prelist(class = “stan”)list(list(name = “code”, attribs = list(), children = list(“// Logit Model//// y ~ Bernoulli(p)// p = a + X B// b0 \\sim cauchy(0, 10)// b \\sim cauchy(0, 2.5)data {# default scales same as rstanarm# assume data is centered and scaledreal&lt;lower = 0.0&gt; a_scale;vector&lt;lower = 0.0&gt;[K] b_scale;a_scale = 10.0;b_scale = rep_vector(2.5, K);}parameters {vector&lt;lower = 0.0, upper = 1.0&gt;[N] p;p = inv_logit(a + X * b);}quantities {// simulate data from the posteriorvector[N] y_rep;// log-likelihood posteriorvector[N] log_lik;for (i in 1:N) {y_rep[i] = binomial_rng(1, p[i]);log_lik[i] = binomial_lpmf(y[i] | 1, p[i]);}}”))) Estimate a model of vote turnout in the 1992 from the American National Election Survey (ANES). The data is from Zelig.8 data(&quot;turnout&quot;, package = &quot;Zelig&quot;) Vote choice (vote) is modeled as a function of age, income, and race. mod_formula &lt;- vote ~ poly(age, 2) + income + educate + race - 1 mod1_data &lt;- lm_preprocess(mod_formula, data = turnout) 7.0.4 Separation Separation is when a predictor perfectly predicts a binary response variable (Rainey 2016, @Zorn2005a). complete separation: the predictor perfectly predicts both 0’s and 1’s. quasi-complete separation: the predictor perfectly predicts either 0’s or 1’s. This is related and similar to identification in MLE and multicollinearity in OLS. The general solution is to penalize the likelihood, which in a Bayesian context is equivalent to placing a proper prior on the coefficient of the separating variable. Using a weakly informative prior such as those suggested by is sufficient to solve separation, \\[ \\beta_k \\sim \\dnorm(0, 2.5) \\] where all the columns of \\(\\code{x}\\) are assumed to mean zero, unit variance (or otherwise standardized). The half-Cauchy prior, \\(\\dhalfcauchy(0, 2.5)\\), suggested in Gelman et al. (2008) is insufficiently informative to to deal with separation (Ghosh, Li, and Mitra 2015), but finite-variance weakly informative Student-t or Normal distributions will work. These are the priors suggested by Stan and used by default in rstanarm rstanarm. Rainey (2016) provides a mixed MLE/Bayesian simulation based approach to apply a prior to the variable with separation, while keeping the other coefficients at their MLE values. Since the results are highly sensitive to the prior, multiple priors should be tried (informative, skeptical, and enthusiastic). Firth (1993) suggests the Jeffreys invariant prior, \\[ p(\\beta_k) \\propto |I(\\beta)|^{\\frac{1}{2}} \\] where \\(|I(\\beta)|\\) is the information matrix, \\[ \\begin{aligned}[t] I(\\beta) &amp;= \\mat{X}\\T \\mat{W} \\mat{X} \\\\ \\mat{W} &amp;= \\diag(\\pi_i (1 - \\pi_i)) \\end{aligned} \\] This is the Jeffreys invariant prior. This was also recommended Zorn (2005). Greenland and Mansournia (2015) suggest a log-F prior distribution which has an intuitive interpretation related to the number of observations. 7.0.4.1 Example: Support of ACA Medicaid Expansion This example is from Rainey (2016) from the original paper Barrilleaux and Rainey (2014) with replication code here. library(&quot;rstan&quot;) library(&quot;tidyverse&quot;) library(&quot;magrittr&quot;) #&gt; #&gt; Attaching package: &#39;magrittr&#39; #&gt; The following object is masked from &#39;package:purrr&#39;: #&gt; #&gt; set_names #&gt; The following object is masked from &#39;package:tidyr&#39;: #&gt; #&gt; extract #&gt; The following object is masked from &#39;package:rstan&#39;: #&gt; #&gt; extract URL &lt;- &quot;https://raw.githubusercontent.com/carlislerainey/priors-for-separation/master/br-replication/data/need.csv&quot; f &lt;- (oppose_expansion ~ dem_governor + obama_win + gop_leg + percent_uninsured + income + percent_nonwhite + percent_metro) br &lt;- read_csv(URL) %&gt;% mutate(oppose_expansion = 1 - support_expansion, dem_governor = -1 * gop_governor, obama_win = as.integer(obama_share &gt;= 0.5), percent_nonwhite = percent_black + percent_hispanic) %&gt;% rename(gop_leg = legGOP) %&gt;% # keep only variables in the formula model.frame(f, data = .) %&gt;% # drop missing values (if any?) drop_na() #&gt; Parsed with column specification: #&gt; cols( #&gt; .default = col_integer(), #&gt; state = col_character(), #&gt; state_abbr = col_character(), #&gt; house12 = col_double(), #&gt; sen12 = col_double(), #&gt; support_expansion_new = col_character(), #&gt; percent_uninsured = col_double(), #&gt; ideology = col_double(), #&gt; income = col_double(), #&gt; percent_black = col_double(), #&gt; percent_hispanic = col_double(), #&gt; percent_metro = col_double(), #&gt; dsh = col_double(), #&gt; obama_share = col_double() #&gt; ) #&gt; See spec(...) for full column specifications. br_scaled &lt;- br %&gt;% # Autoscale all vars but response mutate_at(vars(-oppose_expansion), autoscale) glm(f, data = br, family = &quot;binomial&quot;) %&gt;% summary() #&gt; #&gt; Call: #&gt; glm(formula = f, family = &quot;binomial&quot;, data = br) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.374 -0.461 -0.131 0.630 2.207 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 4.5103 4.5986 0.98 0.327 #&gt; dem_governor -4.1556 1.4794 -2.81 0.005 ** #&gt; obama_win -2.1470 1.3429 -1.60 0.110 #&gt; gop_leg -0.1865 1.2974 -0.14 0.886 #&gt; percent_uninsured -0.3072 0.1651 -1.86 0.063 . #&gt; income -0.0421 0.0776 -0.54 0.587 #&gt; percent_nonwhite 17.8505 48.3030 0.37 0.712 #&gt; percent_metro -12.4390 32.4446 -0.38 0.701 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 68.593 on 49 degrees of freedom #&gt; Residual deviance: 37.948 on 42 degrees of freedom #&gt; AIC: 53.95 #&gt; #&gt; Number of Fisher Scoring iterations: 5 fit1 &lt;- stan_glm(f, data = br, family = &quot;binomial&quot;) fit2 &lt;- stan_glm(f, data = br, prior = NULL, family = &quot;binomial&quot;) 7.1 Rare Events Logit 7.2 Case Control In binary outcome variables, sometimes it is useful to sample on the dependent variable. For example, King and Zeng (2001b) and King and Zeng (2001a) discuss applications with respect to conflicts in international relations. For most country-pairs, for most years, there is no conflict. If some data are costly to gather, it may be cost efficient to get data for conflicts and then randomly select a smaller number of non-conflicts on which to gather data. The sample will no longer be representative, but the estimates can be corrected. The reason this works well, is that if there are very few 1’s, additional 0’s have little influence on the estimation (King and Zeng (2001b)). This should hold more generally will unbalanced classes; in some sense, the amount of effective observations is not much more than the number in the lowest category. King and Zeng (2001b) propose two corrections: Correcting the intercept (prior correction) Weighting observations The prior correction notes that \\[ \\pi_i = \\frac{1}{1 + \\exp(-\\mat{X} \\vec{beta})} \\] The unbalanced sample only affects the intercept. If \\(\\hat\\beta_0\\) is the intercept from the MLE, the case-control corrected intercept \\(\\tilde{\\beta}\\) is, \\[ \\tilde{\\vec{\\beta}}_0^* = \\hat{\\vec{\\beta}}_0 - \\ln \\left(\\frac{1 - \\tau}{\\tau} \\frac{\\bar{y}}{1 - \\bar{y}} \\right) \\] In an MLE setting, this can be applied after estimation, but used in any predicted values. In a Bayesian setting, this correct should be applied within the model by adding the offset to the estimation. In a Stan model, this could be implemented by directly incrementing these values data { int N; int y[N]; real tau; } transformed data { real offset; real y_mean; y_mean = mean(y); offset = log((1 - tau) / tau * (y_mean) / (1 - y_mean)); } parameters { real alpha0; } transformed parameters { real alpha; alpha &lt;- alpha0 - offset; } If there was uncertainty about \\(\\tau\\), then \\(\\tau\\) could be modeled as a parameter. It may also be okay to only correct the intercept in a generated quantities block? (not sure). An alternative approach is to use a weighted likelihood: ones are weighted by \\(\\tau / \\bar{y}\\) zeros are weighted by \\((1 - \\tau) / \\bar{1 - \\bar{y}}\\) The log likelihood would then be \\[ \\ln L_w(\\beta | y) = w_1 \\sum_{Y_i = 1} \\ln (\\pi_i) + w_0 \\sum_{Y_i = 0} \\ln (1 - \\pi_i) \\] In Stan, this can be implemented by directly weighting the log-posterior contributions of each observation. For example, something like this, if (y[i]) { target += w * binomial_lpdf(1, pi[i]) } else { target += (1 - w) * binomial_lpdf(1, pi[i]) } See the example for Zelig-relogit 7.2.0.1 References Firth (1993) proposes a penalized likelihood approach using the Jeffreys invariant prior King and Zeng (2001a) and King and Zeng (2001b) apply an approach similar to the penalized likelihood approach for the similar problem of rare events Zorn (2005) also suggests using the Firth logistic regression to avoid perfect separation Rainey (2016) shows that Cauchy(0, 2.5) priors can be used Greenland and Mansournia (2015) provide another default prior to for binomial models: log F(1,1) and log F(2, 2) priors. These have the nice property that they are interpretable as additional observations. 7.2.1 References For general references on binomial models see Stan Development Team (2016 Sec. 8.5), McElreath (2016 Ch 10), Gelman and Hill (2007) [Ch. 5; Sec 6.4-6.5], Fox (2016 Ch. 14), and Gelman et al. (2013 Ch. 16). Since the cumulative distribution function of a distribution maps reals to \\((0, 1)\\), any CDF can be used as a link function.↩ Beck, Katz, and Tucker (1998) show that the cloglog link function can be derived from a grouped duration model with binary response variables.↩ Example from Zelig-logit.↩ "],
["hierarchical-models.html", "8 Hierarchical Models Prerequisites 8.1 Example: Baseball Hits", " 8 Hierarchical Models Hierarchical models: often groups of parameters, \\(\\{\\theta_1, \\dots, \\theta_J\\}\\), are related. E.g. countries, states, counties, years, etc. Even the regression coefficients, \\(\\beta_1, \\dots, \\beta_k\\) seen the in the [Shrinkage and Regularization] chapter. We can treat those \\(\\theta_j\\) as drawn from a population distribution, \\(\\theta_j \\sim p(\\theta)\\). The prior distribution \\(p(\\theta)\\) is called a hyperprior and its parameters are hyperparameters Exchangeability: parameters \\((\\theta_1, \\dots, \\theta_J)\\) are exchangeable if \\(p(\\theta_1, \\dots, \\theta_J)\\) don’t depend on the indexes. i.i.d. models are a special case of exchangeability. Prerequisites library(&quot;tidyverse&quot;) library(&quot;rstan&quot;) library(&quot;loo&quot;) 8.1 Example: Baseball Hits Efron and Morris (1975) analyzed data from 18 players in the 1970 season. The goal was to predict the batting average of these 18 players from their first 45 at-bats for the remainder of the 1970 season. The following example is based on Carpenter, Gabry, and Goodrich (2017) and the rstanarm vignette Hierarchical Partial Pooling for Repeated Binary Trials. The hitting data used in Efron and Morris (1975) is included in rstanarm as rstanarm: data(&quot;bball1970&quot;, package = &quot;rstanarm&quot;) bball1970 &lt;- mutate(bball1970, BatAvg1 = Hits / AB, BatAvg2 = RemainingHits / RemainingAB) bball1970 #&gt; Player AB Hits RemainingAB RemainingHits BatAvg1 BatAvg2 #&gt; 1 Clemente 45 18 367 127 0.400 0.346 #&gt; 2 Robinson 45 17 426 127 0.378 0.298 #&gt; 3 Howard 45 16 521 144 0.356 0.276 #&gt; 4 Johnstone 45 15 275 61 0.333 0.222 #&gt; 5 Berry 45 14 418 114 0.311 0.273 #&gt; 6 Spencer 45 14 466 126 0.311 0.270 #&gt; 7 Kessinger 45 13 586 155 0.289 0.265 #&gt; 8 Alvarado 45 12 138 29 0.267 0.210 #&gt; 9 Santo 45 11 510 137 0.244 0.269 #&gt; 10 Swaboda 45 11 200 46 0.244 0.230 #&gt; 11 Petrocelli 45 10 538 142 0.222 0.264 #&gt; 12 Rodriguez 45 10 186 42 0.222 0.226 #&gt; 13 Scott 45 10 435 132 0.222 0.303 #&gt; 14 Unser 45 10 277 73 0.222 0.264 #&gt; 15 Williams 45 10 591 195 0.222 0.330 #&gt; 16 Campaneris 45 9 558 159 0.200 0.285 #&gt; 17 Munson 45 8 408 129 0.178 0.316 #&gt; 18 Alvis 45 7 70 14 0.156 0.200 Let \\(y_i\\) be the number of hits in the first 45 at bats for player \\(i\\), \\[ \\begin{aligned}[t] y_i &amp; \\sim \\dbin(45, \\mu_i), \\end{aligned} \\] where \\(\\mu_i \\in (0, 1)\\) is the player-specific batting average. Priors will be placed on the log-odds parameter, \\(\\eta \\in \\R\\), \\[ \\begin{aligned}[t] \\mu_i &amp;\\sim \\frac{1}{1 + \\exp(-\\eta_i)} . \\\\ \\end{aligned} \\] This example considers three ways of modeling \\(\\mu_i\\): Complete Pooling: All players have the same batting average parameter. \\[ \\eta_i = \\eta . \\] The common (log-odds) batting average is given a weakly informative prior, \\[ \\eta \\sim \\dnorm(0, 2.5) \\] On the log odds scale, this places 95% of the probability mass between 0.7 and 99.3 on the proportion scale. Non-pooled: Each players (log-odds) batting average is independent, with each assigned a separate weak prior. \\[ \\begin{aligned}[t] \\eta_i &amp;\\sim \\dnorm(0, 2.5) \\end{aligned} \\] Partial-pooling: Each player has a separate (log-odds) batting average, but these batting average parameters are drawn from a common normal distribution. \\[ \\begin{aligned}[t] \\eta_i &amp;\\sim \\dnorm(0, \\tau) \\\\ \\tau &amp;\\sim \\dnorm(0, 1) \\end{aligned} \\] bball1970_data &lt;- list( N = nrow(bball1970), k = bball1970$AB, y = bball1970$Hits, k_new = bball1970$RemainingAB, y_new = bball1970$RemainingHits ) Create a list to store models: models &lt;- list() models[[&quot;nopool&quot;]] &lt;- stan_model(&quot;stan/binomial-no-pooling.stan&quot;) models[[&quot;nopool&quot;]] prelist(class = “stan”)list(list(name = “code”, attribs = list(), children = list(“/* Binomial Model (No pooling)A binomial model for \\(i = 1, \\\\dots, N\\), no pooling:\\[\\n p(y_i | n_i, \\\\mu_i) &amp;\\\\sim \\\\mathsf{Binomial}(y_i | n_i, \\\\mu_i) \\\\\\\\\\n \\\\mu_i &amp;= \\\\logit^{-1}(\\\\eta_i) \\\\\\\\\\n p(\\\\eta_i) &amp;\\\\sim \\\\mathsf{Normal}^+(0, 10)\\n \\]/quantities {int y_rep[N];vector[N] log_lik;vector[N] log_lik_new;vector&lt;lower = 0., upper = 1.&gt;[N] mu;mu = inv_logit(eta);for (n in 1:N) {y_rep[n] = binomial_rng(k[n], mu[n]);log_lik[n] = binomial_logit_lpmf(y[n] | k[n], eta[n]);log_lik_new[n] = binomial_logit_lpmf(y_new[n] | k_new[n], eta[n]);}}”))) models[[&quot;pool&quot;]] &lt;- stan_model(&quot;stan/binomial-complete-pooling.stan&quot;) models[[&quot;pool&quot;]] prelist(class = “stan”)list(list(name = “code”, attribs = list(), children = list(“/* Binomial ModelA binomial model for \\(i = 1, \\\\dots, N\\), with complete pooling\\[\\n \\\\begin{aligned}[t]\\n p(y_i | n_i, \\\\mu) &amp;\\\\sim \\\\mathsf{Binomial}(n_i, \\\\mu) \\\\\\\\\\n \\\\mu &amp;= \\\\logit^{-1}(\\\\eta) \\\\\\\\\\n p(\\\\eta) &amp;\\\\sim \\\\mathsf{Normal}^+(0, 10)\\n \\\\end{aligned}\\n \\]/quantities {int y_rep[N];vector[N] log_lik;vector[N] log_lik_new;real&lt;lower = 0., upper = 1.&gt; mu;mu = inv_logit(eta);for (n in 1:N) { //y_rep[n] = binomial_rng(k[n], mu);log_lik[n] = binomial_logit_lpmf(y[n] | k[n], eta);log_lik_new[n] = binomial_logit_lpmf(y_new[n] | k_new[n], eta);}}”))) models[[&quot;partial&quot;]] &lt;- stan_model(&quot;stan/binomial-partial-pooling-t.stan&quot;) models[[&quot;partial&quot;]] prelist(class = “stan”)list(list(name = “code”, attribs = list(), children = list(“/* Binomial ModelA binomial model for \\(i = 1, \\\\dots, N\\), with partial pooling\\[\\n \\\\begin{aligned}[t]\\n p(y_i | n_i, \\\\mu_i) &amp;\\\\sim \\\\mathsf{Binomial}(y_i | n_i, \\\\mu_i) \\\\\\\\\\n \\\\mu_i &amp;= \\\\logit^{-1}(\\\\eta_i) \\\\\\\\\\n p(\\\\eta_i | \\\\tau) &amp;\\\\sim \\\\mathsf{Normal}(alpha, \\\\tau) \\\\\\\\\\n p(\\\\tau) &amp;\\\\sim \\\\mathsf{Normal}^+(0, 1) \\\\\\\\\\n p(alpha) &amp; \\\\sim \\\\mathsf{Normal}(0, 2.5) \\\\\\\\\\n \\\\end{aligned}\\n \\]/quantities {int y_rep[N];vector[N] log_lik;vector[N] log_lik_new;vector&lt;lower = 0., upper = 1.&gt;[N] mu;mu = inv_logit(eta);for (n in 1:N) { //y_rep[n] = binomial_rng(k[n], mu[n]);log_lik[n] = binomial_logit_lpmf(y[n] | k[n], eta[n]);log_lik_new[n] = binomial_logit_lpmf(y_new[n] | k_new[n], eta[n]);}}”))) Sample from all three models a fits &lt;- map(models, sampling, data = bball1970_data, refresh = -1) %&gt;% set_names(names(models)) #&gt; Warning: There were 6 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See #&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #&gt; Warning: There were 4 chains where the estimated Bayesian Fraction of Missing Information was low. See #&gt; http://mc-stan.org/misc/warnings.html#bfmi-low #&gt; Warning: Examine the pairs() plot to diagnose sampling problems For each model calculate the posterior mean of \\(\\mu\\) for each player: bball1970 &lt;- map2_df(names(fits), fits, function(nm, fit) { mu &lt;- broom::tidy(fit) %&gt;% filter(str_detect(term, &quot;^mu&quot;)) if (nrow(mu) == 1) { out &lt;- tibble(estimate = rep(mu$estimate, 18L)) } else { out &lt;- select(mu, estimate) } out$model &lt;- nm out$.id &lt;- seq_len(nrow(out)) out }) %&gt;% spread(model, estimate) %&gt;% bind_cols(bball1970) The partially pooled estimates are shrunk towards the overall average, and are between the no-pooling and pooled estimates. select(bball1970, Player, nopool, partial, pool) %&gt;% mutate(Player = factor(Player, levels = Player)) %&gt;% gather(variable, value, -Player) %&gt;% ggplot(aes(y = value, x = factor(variable), group = Player)) + geom_point() + geom_line() + labs(x = &quot;&quot;, y = expression(mu)) We can plot the actual batting averages (BatAvg1 and BatAvg2) and the model estimates: select(bball1970, Player, nopool, partial, pool, BatAvg1, BatAvg2) %&gt;% mutate(Player = factor(Player, levels = Player)) %&gt;% gather(variable, value, -Player) %&gt;% ggplot(aes(y = Player, x = value, colour = variable)) + geom_point() + labs(x = expression(mu), y = &quot;&quot;) The estimates of the no-pooling model is almost exactly the same as BatAvg1. The out-of-sample batting averages BatAvg2 show regression to the mean. For these models, compare the overall out-of-sample performance by calculating the actual average out-of-sample log-pointwise predictive density (lppd), and the expected lppd using LOO-PSIS. The LOO-PSIS estimates of the out-of-sample lppd are optimistic. However, they still show the pooling and partial estimates as superior to the no-pooling estimates. The actual out-of-sample average lppd for the partial pooled model is the best fitting. map2_df(names(fits), fits, function(nm, fit) { loo &lt;- loo(extract_log_lik(fit, &quot;log_lik&quot;)) ll_new &lt;- rstan::extract(fit)[[&quot;log_lik_new&quot;]] tibble(model = nm, loo = loo$elpd_loo / bball1970_data$N, ll_out = mean(log(colMeans(exp(ll_new))))) }) #&gt; # A tibble: 3 x 3 #&gt; model loo ll_out #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 nopool -3.20 -4.62 #&gt; 2 pool -2.58 -4.06 #&gt; 3 partial -2.59 -4.01 To see why this is the case, plot the average errors for each observation in- and out-of-sample. In-sample for the no-pooling model is zero, but it over-estimates (under-estimates) the players with the highest (lowest) batting averages in their first 45 at bats—this is regression to the mean. In sample, the partially pooling model shrinks the estimates towards the mean and reducing error. Out of sample, the errors of the partially pooled model are not much different than the no-pooling model, except that the extreme observations have lower errors. select(bball1970, Player, nopool, partial, pool, BatAvg1, BatAvg2) %&gt;% mutate(Player = as.integer(factor(Player, levels = Player))) %&gt;% gather(variable, value, -Player, -matches(&quot;BatAvg&quot;)) %&gt;% mutate(`In-sample Errors` = value - BatAvg1, `Out-of-sample Errors` = value - BatAvg2) %&gt;% select(-matches(&quot;BatAvg&quot;), -value) %&gt;% gather(sample, error, -variable, -Player) %&gt;% ggplot(aes(y = error, x = Player, colour = variable)) + geom_hline(yintercept = 0, colour = &quot;white&quot;, size = 2) + geom_point() + geom_line() + facet_wrap(~ sample, ncol = 1) + theme(legend.position = &quot;bottom&quot;) Extensions: Redo this analysis with the rstanarm dataset with hits and at-bats for the entire 2006 AL season of MLB. Use a beta distribution for the prior of \\(\\mu_i\\). How would you specify the prior beta distribution so that it is uninformative? If you used the beta distribution, how would you specify the beta distribution as a function of the mean? The lowest batting average of the modern era is approximately 0.16 and the highest is approximately 0.4. Use this information for an informative prior distribution. There may be some truly exceptional players. Model this by replacing the normal prior for \\(\\eta\\) with a wide tailed distribution. The distribution of batting averages may be asymmetric - since there may be a few great players, but a player can only be so bad before they are relegated to the minor league. Find a skewed distribution to use as a prior. 8.1.1 References Albert, Jim. Revisiting Efron and Morris’s Baseball Study Feb 15, 2016 Bob Carpenter. Hierarchical Bayesian Batting Ability, with Multiple Comparisons. November 4, 2009. John Kruschke. Shrinkage in multi-level hierarchical models. November 27, 2012. See Jensen, McShane, and Wyner (2009) for an updated hierarchical model of baseball hitting "],
["multilevel-models.html", "9 Multilevel Models 9.1 Example: Radon 9.2 Pooling of Hierarchical Parameters 9.3 ANOVA 9.4 Time-Series Cross Section 9.5 Extensions 9.6 Miscellaneous 9.7 References", " 9 Multilevel Models library(&quot;rstan&quot;) library(&quot;rstanarm&quot;) library(&quot;tidyverse&quot;) Multilevel models are commonly used hierarchical model. They extend (generalized) linear models to include coefficients that vary by discrete groups. Suppose that there are \\(i = 1, dots, n\\) observations, and each observation is in one of \\(j = 1, \\dots, J\\) groups. Let \\(j[i]\\) be the group for \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]} + \\beta_{j[i]} x_i, \\sigma^2) \\\\ \\begin{bmatrix} \\alpha_j \\\\ \\beta_j \\end{bmatrix} &amp; \\sim \\dnorm \\left( \\begin{bmatrix} \\mu_\\alpha \\\\ \\mu_\\beta \\end{bmatrix}, \\Omega \\right) \\end{aligned} . \\] Pooled model: All coefficients are common between groups. This is equivalent to a linear model. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha + \\beta x_i, \\sigma^2) \\\\ \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix} &amp;\\sim \\dnorm \\left( \\begin{bmatrix} \\mu_{\\alpha} \\\\ \\mu_{\\beta} \\end{bmatrix}, \\Omega \\right) \\end{aligned} \\] Pooled model: All coefficients are common between groups. This is equivalent to a linear model. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha + \\beta x_i, \\sigma^2) \\\\ \\end{aligned} \\] Varying-intercept: The slope coefficients (\\(\\beta\\)) are common between groups, but the intercepts (\\(\\alpha_j\\)) vary by group. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha_{j[i]} + \\beta x_i, \\sigma^2) \\\\ \\end{aligned} \\] Varying-slope model: The groups share a common intercept, \\(\\alpha\\), but the slope coefficient (\\(\\beta\\)), varies between groups. This is less common since it is hard to think of cases when it is appropriate. \\[ \\begin{aligned}[t] y_i &amp;\\sim \\dnorm(\\alpha + \\beta_{j[i]} x_i, \\sigma^2) \\\\ \\end{aligned} \\] These models go by different names in different literatures: hierarchical (generalized) linear models, nested data models, mixed models, random coefficients, random-effects, random parameter models, split-plot designs.9 The model can be extended to other cases: generalized linear models multiple parameters One of the difficulties in these models is the prior to the covariance matrix, \\(\\Omega\\). Figure 9.1: Visual representation of hierarchical models 9.1 Example: Radon This example models the presence of radon in houses in Minnesota which appears in Gelman and Hill (2007) and Gelman et al. (2013). This is partly derived from a Stan Case Study, which uses PyStan instead of rstan. 9.1.1 Data The radon data is included in the rstanarm package. data(&quot;radon&quot;, package = &quot;rstanarm&quot;) glimpse(radon) #&gt; Observations: 919 #&gt; Variables: 4 #&gt; $ floor &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... #&gt; $ county &lt;fct&gt; AITKIN, AITKIN, AITKIN, AITKIN, ANOKA, ANOKA, ANOK... #&gt; $ log_radon &lt;dbl&gt; 0.8329, 0.8329, 1.0986, 0.0953, 1.1632, 0.9555, 0.... #&gt; $ log_uranium &lt;dbl&gt; -0.689, -0.689, -0.689, -0.689, -0.847, -0.847, -0... The data consist of 919 observations of radon levels of houses from 85 counties. radon_county &lt;- radon %&gt;% group_by(county) %&gt;% summarise(log_radon_mean = mean(log_radon), log_radon_sd = sd(log_radon), log_uranium = mean(log_uranium), n = length(county)) ggplot() + geom_point(data = radon, mapping = aes(y = log_radon, x = fct_reorder(county, log_radon, mean))) + geom_point(data = radon_county, mapping = aes(x = fct_reorder(county, log_radon_mean), y = log_radon_mean), colour = &quot;red&quot;) + coord_flip() + labs(y = &quot;log(radon)&quot;, x = &quot;&quot;) Relationship between mean and sample size ggplot(radon_county, aes(y = log_radon_mean, x = log2(n))) + geom_point() 9.1.2 Varying Intercepts Models Consider the general model with an intercept for each county representing the baseline average of the county: \\[ \\begin{aligned} y_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= \\alpha_{j[i]} + \\beta x_i \\end{aligned} \\] where \\(j[i]\\) means that observation \\(i\\) is in county \\(j \\in (1, \\dots, 85)\\). In this particular example, \\(y = \\mathtt{log_radon}\\) and \\(x = \\mathtt{basement}\\). \\[ \\begin{aligned} \\mathtt{log\\_radon}_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= \\alpha_{j[i]} + \\beta~\\mathtt{basement}_i \\end{aligned} \\] We can put a prior distribution on \\(\\alpha_{j[i]}\\), \\[ \\begin{aligned}[t] \\alpha_{j} &amp;\\sim N(\\gamma, \\tau) &amp; \\text{for $i \\in (1, \\dots, 85)} \\end{aligned} \\] This parameterization nests common cases, Complete pooling: When \\(\\tau \\to 0\\), the intercepts are the same, \\[ \\begin{aligned}[t] \\alpha_j &amp;= \\gamma &amp; \\text{for all $j$.} \\end{aligned} \\] No pooling: When \\(\\tau \\to \\infty\\), prior distribution on the intercepts is equivalent to an improper normal distribution, and there is no shrinkage, \\[ p(\\alpha_j) \\propto 1, \\] for all \\(j\\). Partial pooling: When \\(\\tau\\) is a parameter, the amount of shrinkage can be estimated from the data. 9.1.3 Varying Intercept Model 9.1.4 Varying Slope Model \\[ \\begin{aligned} \\mathtt{log\\_radon}_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= \\alpha_{j[i]} + \\beta_{j[i]}~\\mathtt{basement}_i \\end{aligned} \\] 9.1.5 Group Level Predictors The radon dataset also contains the county-level measurements of uranium. One way to include county level measurements is to model the county-level intercepts. The values of each county intercept is a function of the county-level uranium. \\[ \\begin{aligned} \\mathtt{log\\_radon}_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= \\alpha_{j[i]} + \\beta_{j[i]}~\\mathtt{basement}_i \\alpha_{j} \\sim N(\\gamma_0 + \\gamma_1~\\mathtt{log\\_uranium}_j, \\tau) \\end{aligned} \\] Alternatively, we can model model the county-level intercepts. The values of each county intercept is a function of the county-level uranium. \\[ \\begin{aligned} \\mathtt{log\\_radon}_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= \\alpha_{j[i]} + \\beta_{j[i]}~\\mathtt{basement}_i \\\\ \\alpha_{j} &amp;\\sim N(\\gamma_0 + \\gamma_1~\\mathtt{log\\_uranium}_j, \\tau) \\end{aligned} \\] 9.1.6 lme4 In R, the most widely used package to estimate mixed-effects models is lme4. This estimates models using maximum likelihood or restricted maximum likelihood methods (REML). This will be faster than using full-Bayesian methods but also underestimate the uncertainty, as well as being a worse approximation of the posterior. Additionally, in frequentist inference, the meaning of the random effects is different; they are nuisance parameters and not given standard errors. See Bates (2010) and Bates et al. (2014) for introductions to mixed-effects models with lme4. These are also good introductions to classical approaches to mixed effects models. library(&quot;lme4&quot;) Complete pooling fit_pooled &lt;- lm(log_radon ~ county + floor, data = radon) County-varying intercepts with no-pooling fit_intercept_nopool &lt;- lm(log_radon ~ floor, data = radon) County-varying intercepts with partial-pooling fit_intercept_partial &lt;- lmer(log_radon ~ (1 | county) + floor, data = radon) Varying slopes with no pooling: fit_slope_nopool &lt;- lm(log_radon ~ county * floor, data = radon) Varying slopes with partial pooling: fit_slope_partial &lt;- lmer(log_radon ~ (1 + floor | county), data = radon) Including a county-level variable (log_uranium) in various models: With no-pooling, fit_slope_partial &lt;- lm(log_radon ~ floor + log_uranium, data = radon) With varying-intercepts fit_slope_partial &lt;- lmer(log_radon ~ (1 | county) + floor + log_uranium, data = radon) With varying-intercepts and slopes, fit_slope_partial &lt;- lmer(log_radon ~ (1 + floor | county) + log_uranium, data = radon) 9.1.7 rstanarm Some multilevel models can also be estimated using the rstanarm functions stan_glmer and stan_lmer. These functions have syntax similar to lme4 functions, but estimate the mixed models using Bayesian methods with Stan. Complete pooling fit_pooled &lt;- stan_glm(log_radon ~ county + floor, data = radon) County-varying intercepts with no-pooling fit_intercept_nopool &lt;- stan_glm(log_radon ~ floor, data = radon) County-varying intercepts with partial-pooling fit_intercept_partial &lt;- stan_glmer(log_radon ~ (1 | county) + floor, data = radon) Varying slopes with no pooling. There is an error estimating this fit_slope_nopool &lt;- stan_glm(log_radon ~ -1 + county + county:floor, data = radon, prior = normal(scale = 1)) Varying slopes with partial pooling: fit_slope_partial &lt;- stan_glmer(log_radon ~ (1 + floor | county), data = radon) Including a county-level variable (log_uranium) in various models: With no-pooling, fit_slope_partial &lt;- stan_glm(log_radon ~ floor + log_uranium, data = radon) With varying-intercepts fit_slope_partial &lt;- stan_glmer(log_radon ~ (1 | county) + floor + log_uranium, data = radon) With varying-intercepts and slopes, fit_slope_partial &lt;- stan_glmer(log_radon ~ (1 + floor | county) + log_uranium, data = radon) 9.2 Pooling of Hierarchical Parameters This is easiest understood in the case of a model of group means, \\[ \\begin{aligned}[t] y &amp;\\sim \\dnorm(\\mu_{j[i]}, \\sigma^2) \\\\ \\mu_{j} &amp;\\sim \\dnorm(\\gamma, \\tau^2) . \\end{aligned} \\] Each group has size \\(n_j\\). Sample size, \\(n_j\\) Estimate of \\(\\hat{\\mu}_j\\) \\(n_j = 0\\) \\(\\hat{\\mu}_j = \\gamma\\) (complete pooling) \\(n_j &lt; \\frac{\\sigma^2}{\\tau^2}\\) \\(\\hat{\\mu}_j\\) closer to \\(\\gamma\\) \\(n_j = \\frac{\\sigma^2}{\\tau^2}\\) \\(\\hat{\\mu}_j = \\frac{1}{2} \\bar{y}_j + \\frac{1}{2} \\gamma\\) \\(n_j &gt; \\frac{\\sigma^2}{\\tau^2}\\) \\(\\hat{\\mu}_j\\) closer to \\(\\bar{y}_j\\) \\(n_j = \\infty\\) \\(\\hat{\\mu}_j = \\bar{y}_j\\) (no pooling) If the hyperparameters were known, the posterior of \\(\\mu_j\\) is \\[ \\mu_j | y, \\gamma, \\sigma, \\tau \\sim \\dnorm(\\hat{\\mu}_j, V_j) \\] where \\[ \\begin{aligned}[t] \\hat{\\mu}_j &amp;= \\frac{\\frac{n_j}{\\sigma^2} \\bar{y}_j + \\frac{1}{\\tau^2} \\gamma}{\\frac{n_j}{\\sigma^2} + \\frac{1}{\\tau^2}} \\\\ V_j &amp;= \\frac{1}{\\frac{n_j}{\\sigma^2} + \\frac{1}{\\tau^2}} \\end{aligned} \\] Some crude estimates given \\(\\mu_j\\). The data variance, \\(\\sigma^2\\), is the residual variance, \\[ \\E(\\sigma^2 | y, \\mu) = \\frac{1}{n} \\sum_{i = 1}^n (y - \\mu_{j[i]})^2 . \\] The global mean is approximately the average of the group-level means, \\[ \\begin{aligned}[t] \\E(\\gamma | y, \\mu) &amp;= \\frac{1}{J} \\sum_{i = 1}^n \\mu_j \\\\ \\Var(\\gamma | y, \\mu) &amp;= \\frac{1}{J} \\tau^2 \\end{aligned} \\] The group level variance is \\(\\tau^2\\) is, \\[ \\E(\\tau^ | y, \\mu) = \\frac{1}{J} \\sum_{j = 1}^J (\\mu_j - \\gamma)^2 \\] 9.3 ANOVA TODO 9.4 Time-Series Cross Section TODO A common application for these models are Time-Series Cross-Section (TSCS) or panel models. In this case, both the time and units can be modeled. 9.5 Extensions Including group-level covariates Prior distributions Prediction new obs in existing groups new group new obs in new group Modeling correlation between intercept and slopes Non-nested models 9.6 Miscellaneous 9.6.1 How many groups? In classical discussions of multi-level or hierarchical models, a common question is how many groups are required to be able to use random effects vs. fixed effects. As noted earlier, random effects estimates the variance between group means. If there are few groups, there is not much information available to estimate this variance. As such, random effects is not much different than fixed effects. This literature provides many different rules of thumb for the number of groups necessary to be able to use random effects: 8, 10, 30, 50, or 100 (Stegmueller 2013, 749). Stegmueller (2013) finds that Bayesian method produces better multi-level-models than maximum likelihood methods for all numbers of groups. ML methods do not suffer severe bias above 10-15 groups. Bayesian point estimates are biased for smaller numbers of groups, but less than the ML. Additionally, the Bayesian methods have better frequentist coverage than ML methods. Beck and Katz (2007) show that ML random coefficient models are superior in terms of efficiency to many types of pooled and un-pooled estimators in small samples. 9.6.2 Correlation between Predictors and Errors Bafumi and Gelman (2006) analyze this case. The standard suggestion in frequentist literature is to use a Hausman test where the null hypothesis is that random effects are consistent. However, Clark and Linzer (2014) note that in small samples this is likely to fail to reject random effects; and in large samples, random effects behave like fixed effects anyways. 9.7 References Texts and chapters on multi-level analysis: Bayesian Gelman and Hill (2007 Ch. 11-17). Gelman et al. (2013 Ch 5) “Hierarchical Models” Gelman et al. (2013 Ch 15) “Hierarchical Linear Models” Jackman (2009 CHh. 7) Draper (2008) Frequentist Goldstein (2011) Snijders and Bosker (2011) Rabe-Hesketh and Skrondal (2012) Jiang (2007) Stan model examples: Stan models for ARM http://mc-stan.org/documentation/case-studies/radon.html https://biologyforfun.wordpress.com/2016/12/08/crossed-and-nested-hierarchical-models-with-stan-and-r/ Examples of multilevel models Western (1998): economic growth for OECD countries Gelman and King (1993): US election polling Park, Gelman, and Bafumi (2004): multi-level models of opinion polls combined with post-stratification to extrapolate national opinion surveys to regions. Steenbergen and Jones (2002): mostly an intro/review of MLM, but uses the cross-country Eurobarometer to model support for the EU Gelman et al. (2007): state-level opinion polls Raudenbush and Bryk (2001): student performance with student and school-level indicators Gilardi (2010): policy diffusion O’Rourke and Sinnott (2006): attitudes toward immigration Andersen and Fetner (2008): ethnic and social tolerance Weldon (2006): ethnic and social tolerance Arzheimer (2009): right-wing voting Hooghe et al. (2009): social and political trust Anderson and Singer (2008): satisfaction with democracy Meer, Deth, and Scheepers (2009): political participation Iversen and Rosenbluth (2006): political economy of the gender wage gap Hooghe and Marks (2004): support for European integration Lax and Phillips (2009): American politics using states and neighborhoods Voeten (2008): judicial decision making Franchino and Høyland (2009): legislative politics Denisova et al. (2009): politics of economic reforms Aitkin and Longford (1986), Goldstein et al. (2000), Goldstein et al. (1993): education Goldstein et al. (2000): medicine https://en.wikipedia.org/wiki/Multilevel_model↩ "],
["distributions.html", "10 Distributions", " 10 Distributions The parameterizations and notations for distributions largely follow Gelman et al. (2013) and Stan Development Team (2016). The Wikipedia List of Probability Distributions is a fairly complete reference. Standard references of probability distributions are (Johnson, Kotz, and Balakrishnan 1994, 1995, 1997; Kotz, Balakrishnan, and Johnson 2000; Wimmer and Altmann 1999; Forbes et al. 2010; Asquith 2011). The Probability Distributions CRAN task view contains both links and descriptions of probability distributions and as such serves as a useful list of probability distributions. “The Chart of Univariate Distribution Relationships” (Leemis and McQueston 2008) is the classic chart of the relationships between univariate distributions. There are a few variations of this chart online: Univariate Distribution Relationships Diagram of distribution relationships "],
["annotated-bibliography.html", "11 Annotated Bibliography 11.1 Textbooks 11.2 Syllabi 11.3 Topics 11.4 Bayes’ Theorem 11.5 Article Length Introductions to Bayesian Statistics 11.6 Software 11.7 Bayesian Model Averaging 11.8 Multilevel Modeling 11.9 Mixture Models 11.10 Inference 11.11 Model Checking 11.12 Hierarchical Modeling 11.13 Shrinkage/Regularization 11.14 Empirical Bayes 11.15 History of Bayesian Statistics 11.16 Sampling Difficulties 11.17 Complicated Estimation and Testing 11.18 Pooling Polls 11.19 Visualizing MCMC Methods 11.20 Bayesian point estimation / Decision 11.21 Stan Modeling Language 11.22 Bayes Factors", " 11 Annotated Bibliography This is less an annotated and more of a citation and link dump while I move the references into the main text. 11.1 Textbooks Kruschke (2015) Doing Bayesian data analysis (Kruschke 2015) Another accessible introduction aimed at psych. Website with additional material. McElreath (2016) Statistical rethinking (McElreath 2016) An accessible introduction to Bayesian stats; effectively an intro-stats/linear models course taught from a Bayesian perspective. Website with lectures and slides. Lee (2012) Bayesian Statistics : An Introduction (Lee, n.d.) Marin and Robert (2015) Bayesian Essentials with R (Marin and Robert 2014) Marin and Robert (2015) Bayesian Essentials with R: The complete solution manual URL Robert and Casella. 2009. Introducing Monte Carlo Methods with R (Robert and Casella 2009) Robert and Casella. 2004. Monte Carlo statistical methods (Robert and Casella 2004) Albert (2009) Bayesian Computation with R (Albert, n.d.) Jackman (2009) Bayesian Analysis for the Social Sciences (Jackman 2009) Covers commonly used models in the social sciences. Largely covers Gibbs sampling methods and Hoff (2009) A First Course in Bayesian Statistical Methods (Hoff 2009) Gelman, Carlin, Stern, Dunson, and Vehtari (2013) Bayesian data analysis (3rd Edition) (Gelman et al. 2013) Gelman, and Hill (2007) Data analysis using regression and multilevel/hierarchical models (Gelman and Hill 2007) An accessible introduction to to linear models and multilevel models. Efron and Hastie (2016) Computer Age Statistical Inference: Algorithms, Evidence, and Data Science This is a unique work that blends an overview of statistical methods with a history of statistics. (Efron and Hastie 2016) Robert (2007) The Bayesian Choice A statistics grad level book on Bayesian statistics. Berger (1993) Statistical Decision Theory and Bayesian Analysis (Berger 1993) The classic book on Bayesian inference and decision theory. The underlying statistical theory is still relevant even if its date makes the computational aspects less so. Murphy (2012) Machine Learning: A Probabilistic Perspective (Murphy 2012) A machine learning book with a heavy Bayesian influence. MacKay (2003) Information Theory, Inference, and Learning Algorithms URL. (MacKay 2003) On information theory, but combines it with Bayesian statistics, and is ultimately about learning and evidence. Lectures from the course are available here. Gelman and Hill (2007) Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill 2007) Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin (2013) Bayesian Data Analysis 3rd ed. Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences (Jackman 2009) Lynch, Scott M. 2007. Introduction to Applied Bayesian Statistics and Estimation for Social Scientists McElreath, Richard. 2016. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. GitHub page Course page Lunn, Jackson, Best, Thomas, and Spiegelhalter (2012) The BUGS Book: A Practical Introduction to Bayesian Analysis (Lunn et al. 2012) Peter Hoff. 2009. A First Course in Bayesian Statistical Methods (Hoff 2009) Congdon. 2014. Applied Bayesian Modeling. Marin and Roberts. 2014. Bayesian Essentials with R. Robert and Casella. Introducing Monte Carlo Methods with R (Robert and Casella 2009) 11.2 Syllabi Ryan Bakker and Johannes Karreth, “Introduction to Applied Bayesian Modeling” ICPSR. Summer 2016. Syllabus; code Justin Esarey. “Advanced Topics in Political Methodology: Bayesian Statistics” Winter 2015. Syllabus; Lectures. Kruschke. Doing Bayesian Data Analysis site. Nick Beauchamp. “Bayesian Methods.” NYU. syllabus. Alex Tanhk. “Bayesian Methods for the Social Sciences” U of Wisconsin. Spring 2017. syllabus. MTH225 Statistics for Science Spring 2016. github website. Ben Goodrich, “Bayesian Statistics for Social Sciences” Columbia University. Spring 2016. Bakker. “Introduction to Applied Bayesian Analysis” University of Georgia. syllabus; site Myimoto. “Advances in Quantitative Psychology: Bayesian Statistics, Modeling &amp; Reasoning” U of Washington. Winter 2017. site Neil Frazer. Bayesian Data Analysis. Hawaii. Spring 2017. syllabus Lopes. 2016. Bayesian Statistical Learning: Readings in Statistics and Econometrics. syllabus. Lopes. 2012 Simulation-based approaches to modern Bayesian econometrics. Short course. Lopes. 2015. Bayesian Econometrics. syllabus. 11.3 Topics 11.4 Bayes’ Theorem Puga, Kryzwinski, and Altman (2015) “Points of significance: Bayes’ theorem” Nature Methods 11.5 Article Length Introductions to Bayesian Statistics Stan Modeling 2.17. Ch. 29. “Bayesian Inference” Michael Clarke Bayesian Basics. Eddy (2004) “What is Bayesian Statistics” Nature Biotechnology Jackman. 2004. Bayesian Analysis for Political Research. Annual Review of Political Science DOI:10.1146/annurev.polisci.7.012003.104706. Kruschke, J.K. &amp; Liddell, T.M. Psychon Bull Rev (2017). doi:10.3758/s13423-016-1221-4 - Kruschke and Liddell (2017) “Bayesian new statistics: hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective” 11.5.1 Why Bayesian Jim Savage. Why learn Bayesian Modeling? April 10, 2017. 11.5.2 Modern Statistical Workflow Savage, Jaim. 2017. A Brief Introduction to Econometrics in Stan Betancourt, Michael. Robust Statistical Workflow with RStan Stan Modeling Guide “Model Building as Software Development” Gabry, J., Simpson, D., Vehtari, A., Betancourt, M., Gelman, A. (2018). Visualization in Bayesian workflow 11.5.3 Bayesian Philosophy Gelman (2008) “Objections to Bayesian Statistics” Bayesian Analysis Gelman and Shalizi (2012) “Philosophy and the practice of Bayesian statistics” British Journal of Mathematical and Statistical Psychology Borsboom and Haig (2012) “How to practice Bayesian statistics outside the Bayesian church: What philosophy for Bayesian statistical modelling?” British Journal of Mathematical and Statistical Psychology Berger and Berry (1988) “Statistical Analysis and the Illusion of Objectivity” American Scientist American Scientist 1988 Efron (2010) “The Future of Indirect Evidence” Efron (1986) “Why Isn’t Everyone a Bayesian?” American Statistician (B. Efron 1986b). See comments Chernoff (1986), Lindley (1986), Morris (1986), Smith (1986), Press (1986), B. Efron (1986a). Philosophy and the practice of Bayesian statistics in the social sciences. http://www.stat.columbia.edu/~gelman/research/published/philosophy_chapter.pdf Rubin (1984) Rubin, Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician Andrew Gelman Induction and Deduction in Bayesian Data Analysis Berger (2013) “Could Fisher, Jeffreys and Neyman Have Agreed on Testing? Statistical Science 11.5.4 Bayesian Hypothesis Testing Gross, J. H. (2015) “Testing What Matters (If You Must Test at All): A Context-Driven Approach to Substantive and Statistical Significance” American Journal of Political Science (Gross 2014) 11.5.5 Bayesian Frequentist Debates Bayesians and Frequentists : Models, Assumptions, and Inference (slides) Kass Statistical Inference: The Big Picture Noah Smith Bayesian vs. Frequentist: Is there any “there” there? Kass Kinds of Bayesians Anthony O’Hagan. Science, Subjectivity and Software (Comments on the articles by Berger and Goldstein) VanderPlas (2014) Frequentism and Bayesianism: A Python-driven Primer. posts 11.5.6 Categorical Agresti. Bayesian Inference for Categorical Data Analysis. http://www.stat.ufl.edu/~aa/cda2/bayes.pdf Perfect Separation Gelman. 2008. “A weakly informative default prior distribution for logistic and other regression models” Annal Applied Statistics Rainey. 2016. “Dealing with Separation in Logistic Regression Models” Political Analysis Wechsler, Izbicki, and Esteves (2013) “A Bayesian look at nonidentifiability: a simple example”&quot; 11.5.7 Variable Selection Ghosh and Ghattas (2015) Ghosh and Ghattas (2015) “Bayesian Variable Selection Under Collinearity” American Statistician Scott and Berger (2011) “Bayes and empirical-Bayes multiplicity adjustment in the variable-selection problem” Annals of Statistics (Scott and Berger 2010) Ishwaran and Rao (2005) “Spike and slab variable selection: Frequentist and Bayesian strategies” Annals of Statistics Ishwaran, Kogalur, and Rao (2010) “spikeslab: prediction and variable selection using spike and slab regression” R Journal Polson and Scott. “Shrink globally, act locally: sparse Bayesian regularization and prediction” Bayesian Statistics Projection predictive variable selection using Stan + R Lasso Meets Horseshoe Piironen and Vehtari, Sparsity information and regularization in the horseshoe and other shrinkage priors P. Richard Hahn and Carlos M. Carvalho. Decoupling Shrinkage And Selection In Bayesian Linear Models: A Posterior Summary Perspective Michael Betancourt Bayes Sparse Regression 11.5.8 Multiple Testing Gelman, Hill, and Yajima (2012) “Why we (Usually) don’t have to worry about multiple comparisons” Journal of Research on Educational Effectiveness 11.5.9 Rare Events King and Zheng. 2001. “Explaining Rare Events in International Relations” Int Org https://doi.org/10.1162/00208180152507597 King, Gary, and Langche Zeng. 2001. “Logistic Regression in Rare Events Data.” Political Analysis http://www.jstor.org/stable/25791637. 11.5.10 Identifiability Weschler et al. 2013. A. Bayesian Look at Nonidentifiability: A Simple Example. Am stat http://dx.doi.org/10.1080/00031305.2013.778787 11.5.11 Shrinkage Efron and Morris (1975) “Data Analysis Using Stein’s Estimator and its Generalizations” JASA (Efron and Morris 1975) 11.6 Software Software for general purpose Bayesian computation are called probabilistic programming languages. Stan Joseph Rickert. 2016. R Stan and Statistics BUGS modeling language. Models are specified in a different language. NIMBLE A very new BUGS-like language that works with R. JAGS Gibbs/MCMC based WinBUGS Gibbs and MCMC based software. It was one of the first but is now obsolete and unmaintained. Use JAGS or Stan instead. OpenBUGS The continuation of the WinBUGS project. Also no longer well maintained. Use JAGS or Stan instead. R has multiple packages that implement some Bayesian methods. See the Bayesian Task View LearnBayes TeachBayes Python PyMC Very complete general-purpose Python package for Bayesian Analysis The various Machine learning packages like scikit-learn. Edward. By David Blei. Deep generative models, variational inference. Runs on TensorFlow. Implements variational and HMC methods, as well as optimization. Church and Anglican are Lisp-based inference programs. Stata: Since version 14 it can estimate some Bayesian models. It uses Metropolis-Hastings and Gibbs methods. Julia Mamba MCMC supporting multiple methods including Gibbs, MH, HMC, slice 11.6.1 Stan Official Stan-dev R packages: rstan rstanarm bayesplot ShinyStan loo Others: brms Bayesian generalized non-linear multilevel models using Stan ggmcmc 11.6.2 Diagrams 11.6.2.1 DAGs and Plate Notation See Plate notation tikz-bayesnet A TikZ library for drawing Bayesian networks Daf A python package to draw DAGs Relevant Stack Overflow questions: - [Software for drawing Bayesian networks](http://stats.stackexchange.com/questions/16750/software-for-drawing-bayesian-networks-graphical-models) Stack Overflow. - [TikZ Example](http://www.texample.net/tikz/examples/bayes/) - [how to draw plate indices in graphical model by tikz](http://tex.stackexchange.com/questions/199734/how-to-draw-plate-indices-in-graphical-model-by-tikz) Stackexchange - [Can I have automatically adjusted plates in a graphical model?](http://tex.stackexchange.com/questions/11751/can-i-have-automatically-adjusted-plates-in-a-graphical-model?rq=1) 11.6.2.2 Kruschke Diagrams Diagrams in the style of Kruschke’s Doing Bayesian Analysis: LibreOffice Draw Templates Blog posts http://doingbayesiandataanalysis.blogspot.se/2012/05/graphical-model-diagrams-in-doing.html http://doingbayesiandataanalysis.blogspot.se/2012/05/hierarchical-diagrams-read-bottom-to.html http://doingbayesiandataanalysis.blogspot.se/2013/10/diagrams-for-hierarchical-models-we.html R scripts TikZ scripts 11.6.2.3 Venn Diagrams/Eikosograms Oldford and W.H. Cherry. 2006. “Picturing Probability: the poverty of Venn diagrams, the richness of Eikosograms” 11.6.3 Priors Betancourt (2017) “How the shape of a weakly informative prior affects inferences” Stan Case Studies Stan, Prior Choice Recommendations 11.7 Bayesian Model Averaging Montgomery, Hollenbach and Ward (2012) “Improving Predictions Using Ensemble Bayesian Model Averaging” Political Analysis Montgomery and Nyhan (2011) Bayesian Model Averaging: Theoretical Developments and Practical Applications BMA Package BMS Package BAS Package Amini and Parmeter (2011) “Bayesian Model Averaging in R” Journal of Economic and Social Measurement Fragoso and Neto (2015) Bayesian model averaging: A systematic review and conceptual classification (Fragoso and Neto 2015) Ley and Steel (2012) “Mixtures of g-priors for Bayesian model averaging with economic applications” Journal of Econometrics Ley and Steel (2009) “On the effect of prior assumptions in Bayesian model averaging with applications to growth regression” Journal of Applied Econometrics Volinsky, Raftery, Madigan, and Hoeting (1999) “Bayesian model averaging: A Tutorial” Statistical Science 11.8 Multilevel Modeling Stegmueller (2013), “How Many Countries for Multilevel Modeling? A Comparison of Frequentist and Bayesian Approaches” American Journal of Political Science (Stegmueller 2013) Shor, Bafumi, Keele, and Park (2007) “A Bayesian multilevel modeling approach to time-series cross-sectional data” Political Analysis Beck and Katz (2007) “Random coefficient models for time-series—cross-section data: Monte Carlo experiments” Political Analysis (Beck and Katz 2007) Western and Jackman (1994). “Bayesian Inference for Comparative Research” American Political Science Review (Western and Jackman 1994) Anderson and Fetner. 2008. “Economic inequality and intolerance: attitudes toward homosexuality in 35 democracies” American Journal of Political Science 11.9 Mixture Models Imai, K. and Tingley, D. (2012) “A Statistical Method for Empirical Testing of Competing Theories” AJPS 11.10 Inference 11.10.1 Discussion of Bayesian Inference Lindley. The Analysis of Experimental Data: The Appreciation of Tea and Wine 11.11 Model Checking 11.11.1 Posterior Predictive Checks Gelman, Andrew (2007) “A Bayesian Formulation of Exploratory Data Analysis and Goodness-of-fit Testing” International Statistical Review Gelman, Meng, Stern (1996) “Posterior Predictive Fitness Via Realized Discrepencies” Kruschke. Posterior predictive checks can and should be Bayesian: Comment on Gelman and Shalizi, ‘Philosophy and the practice of Bayesian statistics Confusions about posterior predictive checks Gabry, Jonah. Graphical posterior predictive checks using the bayesplot package 11.11.2 Prediction Criteria Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. “Understanding Predictive Information Criteria for Bayesian Models.” Statistics and Computing Vehtari, Gelman, and Gabry. 2016 Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC Vehtari and Lampinen (2002) Bayesian model assessment and comparison using cross-validation predictive densities Vehtari and Ojanen (2012) “A survey of Bayesian predictive methods for model assessment, selection and comparison” 11.11.3 Software Validation Cook, Gelman, and Rubin (2006) “Validation of Software for Bayesian Models Using Posterior Quantiles” J of Comp. and Graphical Stat Gelman. Correction https://doi.org/10.1080/10618600.2017.1377082 Savage, Jim. An easy way to simulate fake data from your Stan model Stan Best Practices 11.12 Hierarchical Modeling Kruschke and Vanpaeml “Bayesian Estimation in Hierarchical Models” http://www.indiana.edu/~kruschke/articles/KruschkeVanpaemel2015.pdf Park, Gelman, and Bafumi (2004) “Bayesian Multilevel Estimation with Poststratification: State-Level Estimates from National Polls” Political Analysis Lax and Phillips. 2009. “How Should We Estimate Public Opinion in the States?” AJPS 11.13 Shrinkage/Regularization Piironen and Vehtari. 2016. On the Hyperprior Choice for the Global Shrinkage Parameter in the Horseshoe Prior Lopes. 2015. Bayesian Regularization slides. 11.14 Empirical Bayes Berger (2006) “The case for objective Bayesian analysis” Bayesian Analysis Efron (2014) “Frequentist accuracy of Bayesian estimates” JRSS B Efron (2010) “The Future of Indirect Evidence” Statistical Science 11.15 History of Bayesian Statistics Robert and Casella (2011) “A Short History of Markov Chain Monte Carlo: Subjective Recollections from Incomplete Data” Statistical Science Stigler (2018) “Richard Price, the first Bayesian” Statistical Science (Stigler 2018) Stigler (1983) “Who discovered Bayes’s theorem?” American Statistician (Stigler 1983) Fienberg (2006) “When did Bayesian Inference Become “Bayesian”?” Bayesian Analysis (Fienberg 2006) 11.16 Sampling Difficulties Carpenter (2017) “Typical sets and the curse of dimensionality” Stan Case Studies Betancourt (2017) “Diagnosing biased inference with divergences” Stan Case Studies Betancourt (2016) “Diagnosing suboptimal cotangent disintegrations in Hamiltonian Monte Carlo” Betancourt and Girolami (2013) “Hamiltonian Monte Carlo for Hierarchical Models” 11.17 Complicated Estimation and Testing King, Tomz, and Wittenberg (2000) “Making the most of statistical analyses: improving interpretation and presentation” Propose a pseudo-Bayesian method. Golder “Interactions”. See referenced papers. Hanmer and Kalkan (2012) “Behind the curve: clarifying the best approach to calculating predicted probabilities and marginal effects from limited dependent variable models” American Journal of Political Science 11.18 Pooling Polls Jackman (2000) “Pooling the Polls over an Election Campaign” Australian Journal of Political Science Linzer (2013) “Dynamic Bayesian forecasting of presidential elections in the States” JASA 11.19 Visualizing MCMC Methods https://chi-feng.github.io/mcmc-demo/ https://mimno.infosci.cornell.edu/hmc/ and http://www.mimno.org/articles/hmc/ http://twiecki.github.io/blog/2014/01/02/visualizing-mcmc/ https://ridlow.wordpress.com/category/animation/ http://people.math.aau.dk/~kkb/Undervisning/Bayes14/sorenh/docs/sampling-notes.pdf https://rpubs.com/mv2521/mcmc-animation http://blog.revolutionanalytics.com/2013/09/an-animated-peek-into-the-workings-of-bayesian-statistics.html https://people.duke.edu/~ccc14/sta-663/Animation.html https://artax.karlin.mff.cuni.cz/r-help/library/asbio/html/anm.mc.bvn.html https://groups.google.com/forum/#!topic/stan-users/nOk80xTlSyE https://www.youtube.com/watch?v=Vv3f0QNWvWQ https://theclevermachine.wordpress.com/2012/11/18/mcmc-hamiltnonian-monte-carlo-a-k-a-hybrid-monte-carlo/ https://www.youtube.com/watch?v=pHsuIaPbNbY&amp;list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF&amp;index=11 http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html 11.20 Bayesian point estimation / Decision Stan Modeling Language. Ch 32. Bayesian Point Estimation. Modes, Medians and Means: A Unifying Perspective. Not explicitly motivated with Bayesian decision theory; nevertheless, it is a good intuitive explanation of these estimators. The Impact of Reparameterization on Point Estimates. http://mc-stan.org/users/documentation/case-studies/mle-params.html Rainey. https://github.com/carlislerainey/transformation-induced-bias 11.21 Stan Modeling Language Ch 1–8 Introduction. pay attention to Ch 1, 8. skim the rest. know where to look for help. Ch 28. Optimizing Stan Code for Efficiency (Neal’s funnel, reparameterization, vectorization) Ch 22. Reparameterization and change of variables Ch 23. Customized Ch 24. User-defined functions Ch 25. problematic posteriors Ch 29. Bayesian Data Analysis Ch 30. Markov Chain Monte Carlo Sampling (R hat, ESS, convergence, thinning) Ch 31. Penalized MLE Ch 32. Bayesian Point Estimation Ch 34. Hamiltonian Monte Carlo Sampling Ch 35. Transformations of Constrained Variables - changes of variables. 11.22 Bayes Factors Lindley’s Paradox Bayes’ Factors Robert (2016) The expected demise of the Bayes factor (Robert 2016). Kass and Raftery (1995) “Bayes factors” (Kass and Raftery 1995) "],
["references-10.html", "References", " References "]
]
