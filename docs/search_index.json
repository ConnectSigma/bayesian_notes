[
["index.html", "Updating: A Set of Bayesian Notes Preface", " Updating: A Set of Bayesian Notes Jeffrey B. Arnold Preface Notes on Bayesian methods - written to supplement CS&amp;SS/STAT 564: Bayesian Statistics for the Social Sciences. These notes largely focus on the application and theory necessary for quantitative social scientists to successfully apply Bayesian statistical methods. I also don’t hesitate to link to those who have already explained things well, and focus my efforts on places where I haven’t found good explanations (or explanations I understand), or places where I need to write notes to deepen my own understanding. All these chapters will use the rstan package: library(&quot;rstan&quot;) "],
["introduction-to-stan-and-linear-regression.html", "1 Introduction to Stan and Linear Regression 1.1 Prerequites 1.2 The Statistical Model 1.3 Maximum A Posteriori estimation", " 1 Introduction to Stan and Linear Regression This chapter is an introduction to writing and running a Stan model in R. Also see the rstan vignette for similar content. 1.1 Prerequites For this section we will use the duncan dataset included in the car package. Duncan’s occupational prestige data is an example dataset used throughout the popular Fox regression text, Applied Regression Analysis and Generalized Linear Models [@Fox2016a]. It is originally from @Duncan1961a consists of survey data on the prestige of occupations in the US in 1950, and several predictors: type of occupation, income, and education of that data(&quot;Duncan&quot;, package = &quot;car&quot;) 1.2 The Statistical Model The first step in running a Stan model is defining the Bayesian statistical model that will be used for inference. Let’s run the regression of occupational prestige on the type of occupation, income, and education: \\[ \\begin{multline} y_i = \\beta_0 + \\beta_1 I(\\mathtt{type} = \\mathtt{&quot;prof&quot;}) + \\beta_2 I(\\mathtt{type} = \\mathtt{&quot;wc&quot;}) \\\\ + \\beta_3 \\mathtt{income} + \\beta_4 \\mathtt{education} + \\epsilon_i \\end{multline} \\] duncan_lm &lt;- lm(prestige ~ type + income + education, data = Duncan) duncan_lm #&gt; #&gt; Call: #&gt; lm(formula = prestige ~ type + income + education, data = Duncan) #&gt; #&gt; Coefficients: #&gt; (Intercept) typeprof typewc income education #&gt; -0.185 16.658 -14.661 0.598 0.345 There are \\(n = 45\\) observations in the dataset. Let \\(y\\) be a \\(n \\times 1\\) vector of the values of prestige. Let \\(X\\) be the \\(n \\times k\\) design matrix of the regression. In this case, \\(k = 5\\), \\[ X = \\begin{bmatrix} 1 &amp; \\mathtt{typeprof} &amp; \\mathtt{typewc} &amp; \\mathtt{income} &amp; \\mathtt{education} \\end{bmatrix} \\] In OLS, we get the frequentist estimates of \\(\\hat{\\beta}\\) by minimizing the squared errors, \\[ \\hat{\\beta}_{OLS} = \\argmin_{\\beta} \\sum_{i = 1}^n (y_i - \\beta&#39; x_i)^2 = \\argmin \\sum_{i = 1}^n \\hat{\\epsilon}_i \\] For valid inference we need to make assumptions about \\(\\epsilon_i\\), namely that they are uncorrelated with \\(X\\), \\(\\Cov(\\epsilon, X) = 0\\), and that they are i.i.d, \\(\\Cov(\\epsilon_i, \\epsilon_j) = 0\\), \\(\\Var(\\epsilon_i) = \\sigma^2\\) for all \\(i\\). However, no specific distributional form is or needs to be assumed for \\(\\epsilon\\) since CLT results show that, asymptotically, the sampling distribution of \\(\\beta\\) is distributed normal. Additionally, although \\(\\hat\\sigma^2 = \\sum_{i = 1}^n \\epsilon_i / (n - k - 1)\\) is a estimator of \\(\\sigma^2\\), standard errors of the standard error of the regression are not directly provided. In Bayesian inference, our target is the posterior distribution of the parameters, \\(\\beta\\) and \\(\\sigma\\): \\(p(\\beta, \\sigma^2 | y, X)\\). Since all uncertainty in Bayesian inference is provided via probability, we will need to explicitly provide parametric distributions for the likelihood and parameters. \\[ p(\\beta, \\sigma | y, X) \\propto p(y | \\beta, \\sigma) p(\\beta, \\sigma) \\] For a Bayesian linear regression model, we’ll need to specify distributions for \\(p(y | \\beta, \\sigma)\\) and \\(p(\\beta, \\sigma)\\). Likelihood: \\(p(y_i | x_i, \\beta, \\sigma)\\) suppose that the observations are distributed independent normal: \\[ y_i \\sim N(\\beta&#39;x_i, \\sigma^2) \\] Priors: The model needs to specify a prior distribution for the parameters \\((\\beta, \\sigma)\\). Rather than specify a single distribution for \\(\\beta\\) and \\(\\sigma\\), it will be easier to specify independent (separate) distributions for \\(\\beta\\) and \\(\\sigma\\). The Stan manual and … provide For the normal distribution, assume i.i.d. normal distributions for each element of \\(\\beta\\): \\[ \\beta_k \\sim N(b, s) \\] For the scale parameter of the normal distribution, \\(\\sigma\\), we will use a half-Cauchy. The Cauchy distribution is a special case of the Student t distribution when the degrees of freedom is 1. In Bayesian stats, it has the property that it concentrates probability mass around its median (zero), but has very wide tails, so if the prior distribution guess is wrong, the parameter can still adapt to data. A half-Cauchy distribution is a Cauchy distribution but with support of \\((0, \\infty)\\) instead of the entire real line. \\[ \\sigma \\sim C^{+}(0, w) \\] Combining all the previous equations, our statistical model for linear regression is, \\[ \\begin{aligned}[t] y &amp;\\sim N(\\mu, \\sigma) \\\\ \\mu &amp;= X \\beta \\\\ \\beta &amp;\\sim N(b, s) \\\\ \\sigma &amp;\\sim C^{+}(0, w) \\end{aligned} \\] This defines a Bayesian model gives us \\[ p(\\beta, \\sigma | y, X, b, s, w) \\propto p(y | X, \\beta) p(\\beta | b, s) p(\\sigma | w) \\] The targets of inference in this model are the two parameters: \\(\\beta\\) (regression coefficients), and \\(\\sigma\\) (standard deviation of the regression). This is conditional on the observed or assumed quantities, which including both the data \\(y\\) (response) and \\(X\\) (predictors), as well the values defining the prior distributions: \\(b\\), \\(s\\), and \\(w\\). Now that we’ve defined a statistical model, we can write it as a Stan model. Stan models are written in its own domain-specific language that focuses on declaring the statistical model (parameters, variables, distributions) while leaving the details of the sampling algorithm to Stan. A Stan model consists of blocks which contain declarations of variables and/or statements. Each block has a specific purpose in the model. functions { // OPTIONAL: user-defined functions } data { // read in data ... } transformed data { // Create new variables/auxiliary variables from the data } parameters { // Declare parameters that will be estimated } transformed parameters { // Create new variables/auxiliary variables from the parameters } model { // Declare your probability model: priors, hyperpriors &amp; likelihood } generated quantities { // Declare any quantities other than simulated parameters to be generated } The file lm.stan is a Stan model for the linear regression model previously defined. data { // number of observations int n; // response vector vector[n] y; // number of columns in the design matrix X int k; // design matrix X matrix [n, k] X; // beta prior real b_loc; real&lt;lower = 0.0&gt; b_scale; // sigma prior real sigma_scale; } parameters { // regression coefficient vector vector[k] b; // scale of the regression errors real&lt;lower = 0.0&gt; sigma; } transformed parameters { // mu is the observation fitted/predicted value // also called yhat vector[n] mu; mu = a + X * b; } model { // priors b ~ normal(b_loc, b_scale); sigma ~ cauchy(0, sigma_scale); // likelihood y ~ normal(mu, sigma); } generated quantities { // simulate data from the posterior vector[n] y_rep; for (i in 1:n) { y_rep[i] = normal_rng(mu[i], sigma); } } mod1 &lt;- stan_model(&quot;stan/lm.stan&quot;) See the Stan Modeling Language User’s Guide and Reference Manual for details of the Stan Language. NoteSince a Stan model compiles to C++ code, you may receive some warning messages such as /Library/Frameworks/R.framework/Versions/3.3/Resources/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function] static void set_zero_all_adjoints() { ^ In file included from file1d4a4d50faa.cpp:8: In file included from /Library/Frameworks/R.framework/Versions/3.3/Resources/library/StanHeaders/include/src/stan/model/model_header.hpp:4: As long as your model compiles, you can ignore these compiler warnings (On the other hard, warnings that occur during sampling should not be ignored). If the Stan model does not give you a syntax error when parsing the model, it should compile to valid C++.[^bugs][^c-warnings] See [bugs]: In the rare case that the Stan parser transpiles the Stan model to C++ but cannot compile the C++ code, it is a bug in Stan. Follow the instructions on how to inform the Stan developers about bugs. [c-warnings]: The extended installation instructions for MacOS/Linux and Windows have instructions for adding compiler options to the R Makevars file. 1.2.1 Sampling In order to sample from the model, we need to at least give it the values for the data to use: n, k, y, X, and the data associated with the priors. mod1_data &lt;- list( y = Duncan$prestige, n = nrow(Duncan) ) The data types in Stan are all numeric (either integers or reals), but they include matrices and vectors. However, there is nothing like a data frame in Stan. Whereas in the R function lm we can provide a formula and a data set for where to look for objects, and the function will create the appropriate \\(X\\) matrix for the regression, we will need to create that matrix ourselves—expanding categorical variables to indicator variables, and expanding interactions and other functions of the predictors. However, we need to do that all manually. The function stats is the workhorse function used in lm and many other R functions to convert a formula into the matrix used in estimation. X &lt;- model.matrix(prestige ~ type + income + education, data = Duncan) mod1_data$X &lt;- X mod1_data$k &lt;- ncol(X) We still need to provide the values for the prior distributions. For specific values of the prior distributions, assume uninformative priors for beta by setting the mean to zero and the variances to large numbers. \\[ \\beta_k \\sim N(0, 1000) \\] mod1_data$b_loc &lt;- 0 mod1_data$b_scale &lt;- 1000 For prior of the regression scale parameter \\(\\sigma\\), use a half-Cauchy distribution with a large scale parameter, which is a good choice for the priors of scale parameters. \\[ \\sigma \\sim C^{+}(0, 50) \\] mod1_data$sigma_scale &lt;- 50 Now, sample from the posterior, using the function sampling: mod1_fit &lt;- sampling(mod1, data = mod1_data) 1.2.2 Convergence Diagnostics and Model Fit Convergence Diagnostics: Is this the posterior distribution that you were looking for? These don’t directly say anything about how “good” the model is in terms representing the data, they are only evaluating how well the sampler is doing at sampling the posterior distribution of the given model. If there are problems with these, then the sample results do not represent the posterior distribution, and your inferences will be biased. mcse: n_eff: Rhat divergences Model fit: Is this statistical model appropriate for the data? Or better than other models? Posterior predictive checks Information criteria: WAIC Leave-one-out Cross-Validation 1.3 Maximum A Posteriori estimation The Statistical Rethinking text focuses on maximum a posteriori (MAP) estimation. In addition to sampling from the posterior distribution using HMC, the same Stan model can be used to estimate the MAP estimate of the parameters. Use the optimizing function to find the MAP estimates of the model: mod1_fit_opt &lt;- optimizing(mod1, data = mod1_data) #&gt; STAN OPTIMIZATION COMMAND (LBFGS) #&gt; init = random #&gt; save_iterations = 1 #&gt; init_alpha = 0.001 #&gt; tol_obj = 1e-12 #&gt; tol_grad = 1e-08 #&gt; tol_param = 1e-08 #&gt; tol_rel_obj = 10000 #&gt; tol_rel_grad = 1e+07 #&gt; history_size = 5 #&gt; seed = 1425311915 #&gt; initial log joint probability = -546666 #&gt; Error evaluating model log probability: Non-finite gradient. #&gt; Error evaluating model log probability: Non-finite function evaluation. #&gt; Error evaluating model log probability: Non-finite gradient. #&gt; Optimization terminated normally: #&gt; Convergence detected: relative gradient magnitude is below tolerance mod1_fit_opt #&gt; $par #&gt; b[1] b[2] b[3] b[4] b[5] sigma mu[1] #&gt; -0.181 16.480 -14.841 0.597 0.345 9.180 83.218 #&gt; mu[2] mu[3] mu[4] mu[5] mu[6] mu[7] mu[8] #&gt; 85.740 93.057 80.416 84.413 58.030 86.830 98.806 #&gt; mu[9] mu[10] mu[11] mu[12] mu[13] mu[14] mu[15] #&gt; 55.230 89.193 67.125 95.726 95.381 69.980 76.579 #&gt; mu[16] mu[17] mu[18] mu[19] mu[20] mu[21] mu[22] #&gt; 42.308 63.684 71.665 56.767 91.397 27.346 32.829 #&gt; mu[23] mu[24] mu[25] mu[26] mu[27] mu[28] mu[29] #&gt; 42.535 19.750 20.307 41.367 57.883 32.377 20.560 #&gt; mu[30] mu[31] mu[32] mu[33] mu[34] mu[35] mu[36] #&gt; 34.740 18.794 6.418 33.891 11.756 17.545 19.272 #&gt; mu[37] mu[38] mu[39] mu[40] mu[41] mu[42] mu[43] #&gt; 18.356 19.046 11.066 15.780 17.347 18.608 10.907 #&gt; mu[44] mu[45] y_rep[1] y_rep[2] y_rep[3] y_rep[4] y_rep[5] #&gt; 36.361 15.647 94.076 89.496 95.805 82.105 74.688 #&gt; y_rep[6] y_rep[7] y_rep[8] y_rep[9] y_rep[10] y_rep[11] y_rep[12] #&gt; 52.630 77.017 115.110 46.107 91.437 70.361 103.725 #&gt; y_rep[13] y_rep[14] y_rep[15] y_rep[16] y_rep[17] y_rep[18] y_rep[19] #&gt; 95.808 56.171 73.826 49.434 63.228 58.018 36.331 #&gt; y_rep[20] y_rep[21] y_rep[22] y_rep[23] y_rep[24] y_rep[25] y_rep[26] #&gt; 82.678 32.345 47.514 46.091 20.639 14.317 32.379 #&gt; y_rep[27] y_rep[28] y_rep[29] y_rep[30] y_rep[31] y_rep[32] y_rep[33] #&gt; 47.882 28.828 41.644 31.181 14.286 -6.776 37.436 #&gt; y_rep[34] y_rep[35] y_rep[36] y_rep[37] y_rep[38] y_rep[39] y_rep[40] #&gt; 8.027 7.335 21.752 15.772 9.419 4.057 21.350 #&gt; y_rep[41] y_rep[42] y_rep[43] y_rep[44] y_rep[45] #&gt; 29.336 15.381 4.734 45.092 20.127 #&gt; #&gt; $value #&gt; [1] -122 It can also return samples from the multivariate normal (Laplace) approximation to the posterior distribution. Adding the option hessian = TRUE returns the hessian, which is defined on the unconstrained parameter space (all parameters are defined over \\((-\\infty, \\infty)\\)). To get a sample of values from that multivariate normal distribution set draws = TRUE. These draws will be from the unconstrained parameter space, unless constrained = TRUE, in which case they will be on the scales of the original parameters. mod1_fit_opt &lt;- optimizing(mod1, data = mod1_data, hessian = TRUE, constrained = TRUE) #&gt; STAN OPTIMIZATION COMMAND (LBFGS) #&gt; init = random #&gt; save_iterations = 1 #&gt; init_alpha = 0.001 #&gt; tol_obj = 1e-12 #&gt; tol_grad = 1e-08 #&gt; tol_param = 1e-08 #&gt; tol_rel_obj = 10000 #&gt; tol_rel_grad = 1e+07 #&gt; history_size = 5 #&gt; seed = 764155989 #&gt; initial log joint probability = -41463.6 #&gt; Optimization terminated normally: #&gt; Convergence detected: relative gradient magnitude is below tolerance "],
["posterior-inference.html", "2 Posterior Inference 2.1 Prerequisites", " 2 Posterior Inference 2.1 Prerequisites The haven package is used to read Stata .dta files. library(&quot;rubbish&quot;) library(&quot;haven&quot;) 2.1.1 Introduction The posterior distribution is the probability distribution \\(\\Pr(\\theta | y)\\). One we have the posterior distribution, or more often a sample from the posterior distribution, it is relatively easy to perform inference on any function of the posterior. Common means to summarize the post mean: \\(\\E(p(\\theta | y)) \\approx \\frac{1}{S} \\sum_{i = 1}^S \\theta^{(s)}\\) median: \\(\\median(p(\\theta | y)) \\approx \\median \\theta^{(s)}\\) quantiles: 2.5%, 5%, 25%, 50%, 75%, 95%, 97.5% credible interval: central credible interval: the interval between the p/2% and 1 - p/2% quantiles highest posterior density interval: the narrowest interval containing p% of distribution 2.1.2 Functions of the Posterior Distribution It is also easy to conduct inference on functions of the posterior distribution. Suppose \\(\\theta^{(1)}, \\dots, \\theta^{(S)}\\) are a sample from \\(p(\\theta | y)\\), the \\(f(\\theta^{(1)}), \\dots, f(\\theta^{(S)})\\) are a sample from \\(p(f(\\theta) | y)\\). This is not easy for methods like MLE that produce point estimates. Even with MLE Even in OLS, non-linear functions coefficients generally require either the Delta method or bootstrapping to calculate confidence intervals. @BerryGolderMilton2012a, @Goldera,@BramborClarkGolder2006a discuss calculating confidence intervals See @Rainey2016b on “transformation induced bias” See @Carpenter2016a on how reparameterization affects point estimates; this is a Stan Case study with working code 2.1.3 Marginal Effects 2.1.3.1 Exmample: Marginal Effect Plot for X This example from Matt Golder’s Interactions page constructs a marginal effect plot for \\(X\\), where there is an interaction between \\(X\\) and \\(Z\\). \\[ Y = \\beta_0 + \\beta_x + \\beta_z + \\beta_{xz} X Z + \\epsilon \\] alexseev &lt;- read_dta(&quot;data/alexseev.dta&quot;) The regression that is run mod_f &lt;- xenovote ~ slavicshare * changenonslav + inc9903 + eduhi02 + unemp02 + apt9200 + vsall03 + brdcont lm(mod_f, data = alexseev) #&gt; #&gt; Call: #&gt; lm(formula = mod_f, data = alexseev) #&gt; #&gt; Coefficients: #&gt; (Intercept) slavicshare #&gt; 8.942878 0.031486 #&gt; changenonslav inc9903 #&gt; -0.851108 0.000234 #&gt; eduhi02 unemp02 #&gt; -0.039512 1.432013 #&gt; apt9200 vsall03 #&gt; 0.030125 0.661163 #&gt; brdcont slavicshare:changenonslav #&gt; 2.103688 0.008226 Use the lm_preprocess function in the rubbish package to turn the model formula into a list with relevant data. mod_data &lt;- lm_preprocess(mod_f, data = alexseev)[c(&quot;X&quot;, &quot;y&quot;)] mod_data &lt;- within(mod_data, { n &lt;- nrow(X) k &lt;- ncol(X) # indices of relevant coefficients M &lt;- 100 changenonslav &lt;- seq(min(X[ , &quot;changenonslav&quot;]), max(X[ , &quot;changenonslav&quot;]), length.out = M) idx_b_slavicshare &lt;- which(colnames(X) == &quot;slavicshare&quot;) idx_b_slavicshare_changenonslav &lt;- which(colnames(X) == &quot;slavicshare:changenonslav&quot;) b_loc &lt;- 0 # data appropriate prior b_scale &lt;- max(apply(X, 2, sd)) * 3 sigma_scale &lt;- sd(y) }) Get the mean of dydx dydx &lt;- get_posterior_mean(mod_fit, pars = &quot;dydx&quot;) ggplot(tibble(changenonslav = mod_data$changenonslav, dydx = dydx[ , &quot;mean-all chains&quot;]), aes(x = changenonslav, y = dydx)) + geom_line() + ylab(&quot;Marginal effect of slavic share&quot;) + xlab(paste(expression(Delta, &quot;non-Slavic Share&quot;))) Plotting each iteration as a line: dydx_all &lt;- rstan::extract(mod_fit, pars = &quot;dydx&quot;)$dydx %&gt;% as.tibble() %&gt;% mutate(.iter = row_number()) %&gt;% # keep only a few iter gather(param, value, -.iter) %&gt;% left_join(tibble(param = paste0(&quot;V&quot;, seq_along(mod_data$changenonslav)), changenonslav = mod_data$changenonslav), by = &quot;param&quot;) dydx_all %&gt;% filter(.iter %in% sample(unique(.iter), 2 ^ 8)) %&gt;% ggplot(aes(x = changenonslav, y = value, group = .iter)) + geom_line(alpha = 0.3) + ylab(&quot;Marginal effect of slavic share&quot;) + xlab(paste(expression(Delta, &quot;non-Slavic Share&quot;))) Summarize the marginal effects with mean, 50% central credible interval, and 90% central credible intervals: dydx_all %&gt;% group_by(changenonslav) %&gt;% summarise(mean = mean(value), q5 = quantile(value, 0.05), q25 = quantile(value, 0.25), q75 = quantile(value, 0.75), q95 = quantile(value, 0.95)) %&gt;% ggplot(aes(x = changenonslav, y = mean)) + geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.2) + geom_ribbon(aes(ymin = q25, ymax = q75), alpha = 0.2) + geom_line(colour = &quot;blue&quot;) + ylab(&quot;Marginal effect of slavic share&quot;) + xlab(expression(paste(Delta, &quot;non-Slavic Share&quot;))) "],
["model-checking.html", "3 Model Checking 3.1 Why check models? 3.2 Posterior Predictive Checks 3.3 Sources", " 3 Model Checking 3.1 Why check models? In theory—Bayesian model should include all relevant substantive knowledge and subsume all possible theories. In practice—It won’t. Need to check how the model fits data. The question is not whether a model is “true”; it isn’t [@Box1976a]. But is it good enough for the purposes of the analysis. See @GelmanMengStern1996a, @Gelman2007a, @Gelman2009a, @GelmanCarlinSternEtAl2013a [Ch. 6], @GelmanShalizi2012a, @Kruschke2013b, @GelmanShalizi2012b, @Gelman2014 for more discussion of the motivation and use of posterior predictive checks. 3.2 Posterior Predictive Checks One way to evaluate the fit of a model is posterior predictive checks Fit the model to the data to get the posterior distribution of the parameters: \\(p(\\theta | D)\\) Simulate data from the fitted model: \\(p(\\tilde{D} | \\theta, D)\\) Compare the simulated data (or a statistic thereof) to the observed data and a statistic thereof. The comparison between data simulated from the model can be formal or visual. Within a Stan function, this is done in the generated quantities block using a _rng distribution functions: generated quantities { vector[n] yrep; for (i in 1:n) { yrep[i] ~ } } The package bayesplot includes multiple functions for posterior predictive checks; see the help for PPC-overview for a summary of these functions. 3.2.1 Bayesian p-values A posterior predictive p-value is a the tail posterior probability for a statistic generated from the model compared to the statistic observed in the data. Let \\(y = (y_1, \\dots, y_n)\\) be the observed data. Suppose the model has been fit and there is a set of simulation \\(\\theta^(s)\\), \\(s = 1, \\dots, n_sims\\). In replicated dataset, \\(y^{rep(s)\\), has been generated from the predictive distribution of the data, \\(p(y^{(rep)} | \\theta = \\theta^{(s)}\\). Then the ensemble of simulated datasets, \\((y^{rep(s)}, \\dots, y^{rep(nsims)})\\), is a sample from the posterior predictive distribution, \\(p(y^{(rep)} | y)\\) The model can be tested by means of discrepancy statistics, which are some function of the data and parameters, \\(T(y, \\theta)\\). If \\(\\theta\\) was known, then compare discrepancy by \\(T(y^{(rep)}, \\theta)\\). The statistical significance is \\(p = \\Pr(T(y^{(rep)}, \\theta) &gt; T(y, \\theta) | y, \\theta)\\). If \\(\\theta\\) is unknown, then average over the posterior distribution of \\(\\theta\\), \\[ \\begin{aligned}[t] p &amp;= \\Pr(T(y^{(rep)}, \\theta) &gt; T(y, \\theta) | y) \\\\ &amp;= \\int Pr(T(y^{(rep)}, \\theta) &gt; T(y, \\theta) | y, \\theta) p(\\theta | y) d\\,\\theta , \\end{aligned} \\] which is easily estimated from the MCMC samples as, \\[ p = \\frac{1}{n_{sims}}\\sum_{s = 1}^{n_{sims}} 1( T(y^{rep(s)}, \\theta(s)) &gt; T(y, \\theta(s))) \\] 3.2.2 Test quantities The definition of a posterior p-value does not specify a particular test-statistic, \\(T\\), to use. The best advice is that \\(T\\) depends on the application. @BDA3 [p. 146] Speed of light example uses the 90% interval (61st and 6th order statistics). @BDA3 [p. 147] binomial trial example uses the number of swicthes (0 to 1, or 1 to 0) in order to test independence. @BDA3 [p. 148] hierarchical model for adolesce smoking uses percent of adolescents in the sample who never smoked percentage in the sample who smoked in all waves precentage of “incident smoker”: adolescents who began the study and non-smokers and ended as smokers. 3.2.3 p-values vs. u-values A posterior predictive p-value is different than a classical p-value. Posterior predictive p-value distributed uniform if the model is true Classical p-value distributed uniform if the null hypothesis (\\(H_0\\)) is true A u-value is any function of the data that has a \\(U(0, 1)\\) sampling distribution [@BDA3, p. 151] a u-value can be averaged over \\(\\theta\\), but it is not Bayesian, and is not a probability distribution posterior p-value: probability statement, conditional on model and data, about future observations 3.2.4 Marginal predictive checks Compare statistics for each observation. Conditional Predictive Ordinate (CPO): The CPO (Gelfand 1996) is the leave-on-out cross-validation predictive density: \\[ p(y_i | y_{-i}) = \\int p(y_i | \\theta) p(\\theta | y_{-i}) d\\,\\theta \\] The pointwise predicted LOO probabilities can be calculated using PSIS-LOO or WAIC in the loo package. Predictive Concordance and Predictive QuantilesP Gelfand (1996) classifies any \\(y_i\\) that is outside the central 95% predictive posterior of \\(y^{rep}_i\\) is an outlier. Let the predictive quantile (\\(PQ_i\\)) be \\[ PQ_i = p(y_i^{(rep)} &gt; y_i) . \\] Then the predictive concordance be the proportion of \\(y_i\\) that are not outliers. Gelfand (1996) argues that the predictive concordance should match 95% - in other words that the posterior predictive distribution should have the correct coverage. (Laplace Demon p. 20) 3.2.5 Outliers Can be identified by the inverse-CPO. larger than 40 are possible outliers, and those higher than 70 are extreme values (Ntzoufras 2009, p. 376). Congdon (2005) scales CPO by dividing each by its individual max and considers observations with scaled CPO under 0.01 as outliers. 3.2.6 Grapical Posterior Predictive Checks Visualization can surprise you, but it doesn’t scale well. Modeling scales well, but it can’t surprise you. – paraphrase of Hadley Hickham Instead of calculating posterior probabilities, plot simulated data and observed data and visually compare them. See @BDA3 [p. 154]. plot simulated data and real data [@BDA3, p. 154]. This is similar to ideas in @WickhamCookHofmannEtAl2010a. plot summary statistics or inferences residual plots Bayesian residuals have a distribution \\(r_i^{(s)} = y_i - \\E(y_i | \\theta^{s})\\) Bayesian resdiual graph plots single realization of the residuals, or a summary of their posterior distributions binned plots are best for discrete data [@BDA3, p. 157] 3.3 Sources See @GelmanShalizi2012a, @GelmanShalizi2012b, @Kruschke2013b "]
]
