<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Updating: A Set of Bayesian Notes</title>
  <meta name="description" content="Updating: A Set of Bayesian Notes">
  <meta name="generator" content="bookdown 0.7.7 and GitBook 2.6.7">

  <meta property="og:title" content="Updating: A Set of Bayesian Notes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jrnold.github.io/bayesian_notes" />
  
  
  <meta name="github-repo" content="jrnold/bayesian_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Updating: A Set of Bayesian Notes" />
  <meta name="twitter:site" content="@jrnld" />
  
  

<meta name="author" content="Jeffrey B. Arnold">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="binomial-models.html">
<link rel="next" href="multilevel-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.0/htmlwidgets.js"></script>
<script src="libs/d3-3.3.8/d3.min.js"></script>
<script src="libs/dagre-0.4.0/dagre-d3.min.js"></script>
<link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet" />
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/chromatography-0.1/chromatography.js"></script>
<script src="libs/DiagrammeR-binding-1.0.0/DiagrammeR.js"></script>
<script src="libs/viz-0.3/viz.js"></script>
<script src="libs/grViz-binding-1.0.0/grViz.js"></script>



<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Bayesian Notes</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>1</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="1.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#bayesian-analysis"><i class="fa fa-check"></i><b>1.1</b> Bayesian Analysis</a></li>
<li class="chapter" data-level="1.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>1.2</b> Posterior Predictive Distribution</a></li>
</ul></li>
<li class="part"><span><b>I Theory</b></span></li>
<li class="chapter" data-level="2" data-path="priors.html"><a href="priors.html"><i class="fa fa-check"></i><b>2</b> Priors</a><ul>
<li class="chapter" data-level="2.1" data-path="priors.html"><a href="priors.html#levels-of-priors"><i class="fa fa-check"></i><b>2.1</b> Levels of Priors</a></li>
<li class="chapter" data-level="2.2" data-path="priors.html"><a href="priors.html#conjugate-priors"><i class="fa fa-check"></i><b>2.2</b> Conjugate Priors</a><ul>
<li class="chapter" data-level="2.2.1" data-path="priors.html"><a href="priors.html#binomial-beta"><i class="fa fa-check"></i><b>2.2.1</b> Binomial-Beta</a></li>
<li class="chapter" data-level="2.2.2" data-path="priors.html"><a href="priors.html#categorical-dirichlet"><i class="fa fa-check"></i><b>2.2.2</b> Categorical-Dirichlet</a></li>
<li class="chapter" data-level="2.2.3" data-path="priors.html"><a href="priors.html#poisson-gamma"><i class="fa fa-check"></i><b>2.2.3</b> Poisson-Gamma</a></li>
<li class="chapter" data-level="2.2.4" data-path="priors.html"><a href="priors.html#normal-with-known-variance"><i class="fa fa-check"></i><b>2.2.4</b> Normal with known variance</a></li>
<li class="chapter" data-level="2.2.5" data-path="priors.html"><a href="priors.html#exponential-family"><i class="fa fa-check"></i><b>2.2.5</b> Exponential Family</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="priors.html"><a href="priors.html#improper-priors"><i class="fa fa-check"></i><b>2.3</b> Improper Priors</a></li>
<li class="chapter" data-level="2.4" data-path="priors.html"><a href="priors.html#cromwells-rule"><i class="fa fa-check"></i><b>2.4</b> Cromwellâ€™s Rule</a></li>
<li class="chapter" data-level="2.5" data-path="priors.html"><a href="priors.html#asymptotics"><i class="fa fa-check"></i><b>2.5</b> Asymptotics</a></li>
<li class="chapter" data-level="2.6" data-path="priors.html"><a href="priors.html#proper-and-improper-priors"><i class="fa fa-check"></i><b>2.6</b> Proper and Improper Priors</a></li>
<li class="chapter" data-level="2.7" data-path="priors.html"><a href="priors.html#hyperpriors-and-hyperparameters"><i class="fa fa-check"></i><b>2.7</b> Hyperpriors and Hyperparameters</a></li>
<li class="chapter" data-level="2.8" data-path="priors.html"><a href="priors.html#references"><i class="fa fa-check"></i><b>2.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>3</b> Estimation</a><ul>
<li class="chapter" data-level="3.1" data-path="estimation.html"><a href="estimation.html#point-estimates"><i class="fa fa-check"></i><b>3.1</b> Point Estimates</a></li>
<li class="chapter" data-level="3.2" data-path="estimation.html"><a href="estimation.html#credible-intervals"><i class="fa fa-check"></i><b>3.2</b> Credible Intervals</a><ul>
<li class="chapter" data-level="3.2.1" data-path="estimation.html"><a href="estimation.html#compared-to-confidence-intervals"><i class="fa fa-check"></i><b>3.2.1</b> Compared to confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="estimation.html"><a href="estimation.html#bayesian-decision-theory"><i class="fa fa-check"></i><b>3.3</b> Bayesian Decision Theory</a></li>
</ul></li>
<li class="part"><span><b>II Computation</b></span></li>
<li class="chapter" data-level="4" data-path="bayesian-computation.html"><a href="bayesian-computation.html"><i class="fa fa-check"></i><b>4</b> Bayesian Computation</a><ul>
<li class="chapter" data-level="4.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#how-to-calculate-a-posterior"><i class="fa fa-check"></i><b>4.1</b> How to calculate a posterior?</a></li>
<li class="chapter" data-level="4.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#example-globe-tossing-model"><i class="fa fa-check"></i><b>4.2</b> Example: Globe-tossing model</a></li>
<li class="chapter" data-level="4.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#quadrature"><i class="fa fa-check"></i><b>4.3</b> Quadrature</a><ul>
<li class="chapter" data-level="4.3.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#grid-approximation"><i class="fa fa-check"></i><b>4.3.1</b> Grid approximation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="bayesian-computation.html"><a href="bayesian-computation.html#functional-approximations"><i class="fa fa-check"></i><b>4.4</b> Functional Approximations</a><ul>
<li class="chapter" data-level="4.4.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#maximum-a-posteriori"><i class="fa fa-check"></i><b>4.4.1</b> Maximum A Posteriori</a></li>
<li class="chapter" data-level="4.4.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#laplace-approximation"><i class="fa fa-check"></i><b>4.4.2</b> Laplace Approximation</a></li>
<li class="chapter" data-level="4.4.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#example"><i class="fa fa-check"></i><b>4.4.3</b> Example</a></li>
<li class="chapter" data-level="4.4.4" data-path="bayesian-computation.html"><a href="bayesian-computation.html#variational-inference"><i class="fa fa-check"></i><b>4.4.4</b> Variational Inference</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="bayesian-computation.html"><a href="bayesian-computation.html#sampling-methods"><i class="fa fa-check"></i><b>4.5</b> Sampling Methods</a><ul>
<li class="chapter" data-level="4.5.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#numerical-integration"><i class="fa fa-check"></i><b>4.5.1</b> Numerical Integration</a></li>
<li class="chapter" data-level="4.5.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#inverse-transform-sampling"><i class="fa fa-check"></i><b>4.5.2</b> Inverse transform sampling</a></li>
<li class="chapter" data-level="4.5.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#direct-approximation"><i class="fa fa-check"></i><b>4.5.3</b> Direct approximation</a></li>
<li class="chapter" data-level="4.5.4" data-path="bayesian-computation.html"><a href="bayesian-computation.html#rejection-sampling"><i class="fa fa-check"></i><b>4.5.4</b> Rejection sampling</a></li>
<li class="chapter" data-level="4.5.5" data-path="bayesian-computation.html"><a href="bayesian-computation.html#importance-sampling"><i class="fa fa-check"></i><b>4.5.5</b> Importance Sampling</a></li>
<li class="chapter" data-level="4.5.6" data-path="bayesian-computation.html"><a href="bayesian-computation.html#example-2"><i class="fa fa-check"></i><b>4.5.6</b> Example</a></li>
<li class="chapter" data-level="4.5.7" data-path="bayesian-computation.html"><a href="bayesian-computation.html#mcmc-methods"><i class="fa fa-check"></i><b>4.5.7</b> MCMC Methods</a></li>
<li class="chapter" data-level="4.5.8" data-path="bayesian-computation.html"><a href="bayesian-computation.html#discarding-early-iterations"><i class="fa fa-check"></i><b>4.5.8</b> Discarding early iterations</a></li>
<li class="chapter" data-level="4.5.9" data-path="bayesian-computation.html"><a href="bayesian-computation.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>4.5.9</b> Monte Carlo Sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>5</b> MCMC Diagnostics</a><ul>
<li class="chapter" data-level="" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="5.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#reparameterize-models"><i class="fa fa-check"></i><b>5.1</b> Reparameterize Models</a></li>
<li class="chapter" data-level="5.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#convergence-diagnostics"><i class="fa fa-check"></i><b>5.2</b> Convergence Diagnostics</a><ul>
<li class="chapter" data-level="5.2.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#potential-scale-reduction-hatr"><i class="fa fa-check"></i><b>5.2.1</b> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</a></li>
<li class="chapter" data-level="5.2.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#references-1"><i class="fa fa-check"></i><b>5.2.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation-effective-sample-size-and-mcse"><i class="fa fa-check"></i><b>5.3</b> Autocorrelation, Effective Sample Size, and MCSE</a><ul>
<li class="chapter" data-level="5.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#effective-sample-size"><i class="fa fa-check"></i><b>5.3.1</b> Effective Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#thinning"><i class="fa fa-check"></i><b>5.4</b> Thinning</a><ul>
<li class="chapter" data-level="5.4.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#traceplots"><i class="fa fa-check"></i><b>5.4.1</b> Traceplots</a></li>
<li class="chapter" data-level="5.4.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#monte-carlo-standard-error-mcse"><i class="fa fa-check"></i><b>5.4.2</b> Monte Carlo Standard Error (MCSE)</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#hmc-nut-specific-diagnostics"><i class="fa fa-check"></i><b>5.5</b> HMC-NUT Specific Diagnostics</a><ul>
<li class="chapter" data-level="5.5.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#divergent-transitions"><i class="fa fa-check"></i><b>5.5.1</b> Divergent transitions</a></li>
<li class="chapter" data-level="5.5.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#maximum-tree-depth"><i class="fa fa-check"></i><b>5.5.2</b> Maximum Tree-depth</a></li>
<li class="chapter" data-level="5.5.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#bayesian-fraction-of-missing-information"><i class="fa fa-check"></i><b>5.5.3</b> Bayesian Fraction of Missing Information</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#debugging-bayesian-computing"><i class="fa fa-check"></i><b>5.6</b> Debugging Bayesian Computing</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>6</b> Model Checking</a><ul>
<li class="chapter" data-level="6.1" data-path="model-checking.html"><a href="model-checking.html#why-check-models"><i class="fa fa-check"></i><b>6.1</b> Why check models?</a></li>
<li class="chapter" data-level="6.2" data-path="model-checking.html"><a href="model-checking.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>6.2</b> Posterior Predictive Checks</a><ul>
<li class="chapter" data-level="6.2.1" data-path="model-checking.html"><a href="model-checking.html#bayesian-p-values"><i class="fa fa-check"></i><b>6.2.1</b> Bayesian p-values</a></li>
<li class="chapter" data-level="6.2.2" data-path="model-checking.html"><a href="model-checking.html#test-quantities"><i class="fa fa-check"></i><b>6.2.2</b> Test quantities</a></li>
<li class="chapter" data-level="6.2.3" data-path="model-checking.html"><a href="model-checking.html#p-values-vs.u-values"><i class="fa fa-check"></i><b>6.2.3</b> p-values vs.Â u-values</a></li>
<li class="chapter" data-level="6.2.4" data-path="model-checking.html"><a href="model-checking.html#marginal-predictive-checks"><i class="fa fa-check"></i><b>6.2.4</b> Marginal predictive checks</a></li>
<li class="chapter" data-level="6.2.5" data-path="model-checking.html"><a href="model-checking.html#outliers"><i class="fa fa-check"></i><b>6.2.5</b> Outliers</a></li>
<li class="chapter" data-level="6.2.6" data-path="model-checking.html"><a href="model-checking.html#graphical-posterior-predictive-checks"><i class="fa fa-check"></i><b>6.2.6</b> Graphical Posterior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="model-checking.html"><a href="model-checking.html#average-predictive-comparisons"><i class="fa fa-check"></i><b>6.3</b> Average Predictive Comparisons</a></li>
<li class="chapter" data-level="6.4" data-path="model-checking.html"><a href="model-checking.html#references-2"><i class="fa fa-check"></i><b>6.4</b> References</a></li>
</ul></li>
<li class="part"><span><b>III Models</b></span></li>
<li class="chapter" data-level="7" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html"><i class="fa fa-check"></i><b>7</b> Introduction to Stan and Linear Regression</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#prerequisites-1"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="7.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#ols-and-mle-linear-regression"><i class="fa fa-check"></i><b>7.1</b> OLS and MLE Linear Regression</a><ul>
<li class="chapter" data-level="7.1.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#bayesian-model-with-improper-priors"><i class="fa fa-check"></i><b>7.1.1</b> Bayesian Model with Improper priors</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#stan-model"><i class="fa fa-check"></i><b>7.2</b> Stan Model</a></li>
<li class="chapter" data-level="7.3" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling-model-with-stan"><i class="fa fa-check"></i><b>7.3</b> Sampling Model with Stan</a><ul>
<li class="chapter" data-level="7.3.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling"><i class="fa fa-check"></i><b>7.3.1</b> Sampling</a></li>
<li class="chapter" data-level="7.3.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#convergence-diagnostics-and-model-fit"><i class="fa fa-check"></i><b>7.3.2</b> Convergence Diagnostics and Model Fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html"><i class="fa fa-check"></i><b>8</b> Heteroskedasticity and Robust Regression</a><ul>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#prerequisites-2"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="8.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#linear-regression-with-student-t-distributed-errors"><i class="fa fa-check"></i><b>8.1</b> Linear Regression with Student t distributed errors</a></li>
<li class="chapter" data-level="8.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity"><i class="fa fa-check"></i><b>8.2</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="8.2.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#covariates"><i class="fa fa-check"></i><b>8.2.1</b> Covariates</a></li>
<li class="chapter" data-level="8.2.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#student-t-error"><i class="fa fa-check"></i><b>8.2.2</b> Student-t Error</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#references-3"><i class="fa fa-check"></i><b>8.3</b> References</a><ul>
<li class="chapter" data-level="8.3.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#quantile-regression"><i class="fa fa-check"></i><b>8.3.1</b> Quantile regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>9</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="9.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#count-models"><i class="fa fa-check"></i><b>9.1</b> Count Models</a><ul>
<li class="chapter" data-level="9.1.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson"><i class="fa fa-check"></i><b>9.1.1</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example-3"><i class="fa fa-check"></i><b>9.2</b> Example</a></li>
<li class="chapter" data-level="9.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#negative-binomial"><i class="fa fa-check"></i><b>9.3</b> Negative Binomial</a></li>
<li class="chapter" data-level="9.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial-categorical-models"><i class="fa fa-check"></i><b>9.4</b> Multinomial / Categorical Models</a></li>
<li class="chapter" data-level="9.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#gamma-regression"><i class="fa fa-check"></i><b>9.5</b> Gamma Regression</a></li>
<li class="chapter" data-level="9.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#beta-regression"><i class="fa fa-check"></i><b>9.6</b> Beta Regression</a></li>
<li class="chapter" data-level="9.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-4"><i class="fa fa-check"></i><b>9.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="binomial-models.html"><a href="binomial-models.html"><i class="fa fa-check"></i><b>10</b> Binomial Models</a><ul>
<li class="chapter" data-level="10.1" data-path="binomial-models.html"><a href="binomial-models.html#link-functions-link-function"><i class="fa fa-check"></i><b>10.1</b> Link Functions {link-function}</a><ul>
<li class="chapter" data-level="10.1.1" data-path="binomial-models.html"><a href="binomial-models.html#stan"><i class="fa fa-check"></i><b>10.1.1</b> Stan</a></li>
<li class="chapter" data-level="10.1.2" data-path="binomial-models.html"><a href="binomial-models.html#example-vote-turnout"><i class="fa fa-check"></i><b>10.1.2</b> Example: Vote Turnout</a></li>
<li class="chapter" data-level="10.1.3" data-path="binomial-models.html"><a href="binomial-models.html#separation"><i class="fa fa-check"></i><b>10.1.3</b> Separation</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="binomial-models.html"><a href="binomial-models.html#rare-events-logit"><i class="fa fa-check"></i><b>10.2</b> Rare Events Logit</a></li>
<li class="chapter" data-level="10.3" data-path="binomial-models.html"><a href="binomial-models.html#case-control"><i class="fa fa-check"></i><b>10.3</b> Case Control</a><ul>
<li class="chapter" data-level="10.3.1" data-path="binomial-models.html"><a href="binomial-models.html#references-5"><i class="fa fa-check"></i><b>10.3.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>11</b> Hierarchical Models</a><ul>
<li class="chapter" data-level="" data-path="hierarchical-models.html"><a href="hierarchical-models.html#prerequisites-3"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="11.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-baseball-hits"><i class="fa fa-check"></i><b>11.1</b> Example: Baseball Hits</a><ul>
<li class="chapter" data-level="11.1.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#references-6"><i class="fa fa-check"></i><b>11.1.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>12</b> Multilevel Models</a><ul>
<li class="chapter" data-level="12.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-radon"><i class="fa fa-check"></i><b>12.1</b> Example: Radon</a><ul>
<li class="chapter" data-level="12.1.1" data-path="multilevel-models.html"><a href="multilevel-models.html#data"><i class="fa fa-check"></i><b>12.1.1</b> Data</a></li>
<li class="chapter" data-level="12.1.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercepts-models"><i class="fa fa-check"></i><b>12.1.2</b> Varying Intercepts Models</a></li>
<li class="chapter" data-level="12.1.3" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercept-model"><i class="fa fa-check"></i><b>12.1.3</b> Varying Intercept Model</a></li>
<li class="chapter" data-level="12.1.4" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-slope-model"><i class="fa fa-check"></i><b>12.1.4</b> Varying Slope Model</a></li>
<li class="chapter" data-level="12.1.5" data-path="multilevel-models.html"><a href="multilevel-models.html#group-level-predictors"><i class="fa fa-check"></i><b>12.1.5</b> Group Level Predictors</a></li>
<li class="chapter" data-level="12.1.6" data-path="multilevel-models.html"><a href="multilevel-models.html#lme4"><i class="fa fa-check"></i><b>12.1.6</b> lme4</a></li>
<li class="chapter" data-level="12.1.7" data-path="multilevel-models.html"><a href="multilevel-models.html#rstanarm"><i class="fa fa-check"></i><b>12.1.7</b> rstanarm</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="multilevel-models.html"><a href="multilevel-models.html#pooling-of-hierarchical-parameters"><i class="fa fa-check"></i><b>12.2</b> Pooling of Hierarchical Parameters</a></li>
<li class="chapter" data-level="12.3" data-path="multilevel-models.html"><a href="multilevel-models.html#anova"><i class="fa fa-check"></i><b>12.3</b> ANOVA</a></li>
<li class="chapter" data-level="12.4" data-path="multilevel-models.html"><a href="multilevel-models.html#time-series-cross-section"><i class="fa fa-check"></i><b>12.4</b> Time-Series Cross Section</a></li>
<li class="chapter" data-level="12.5" data-path="multilevel-models.html"><a href="multilevel-models.html#miscellaneous"><i class="fa fa-check"></i><b>12.5</b> Miscellaneous</a><ul>
<li class="chapter" data-level="12.5.1" data-path="multilevel-models.html"><a href="multilevel-models.html#how-many-groups"><i class="fa fa-check"></i><b>12.5.1</b> How many groups?</a></li>
<li class="chapter" data-level="12.5.2" data-path="multilevel-models.html"><a href="multilevel-models.html#correlation-between-predictors-and-errors"><i class="fa fa-check"></i><b>12.5.2</b> Correlation between Predictors and Errors</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span></li>
<li class="chapter" data-level="13" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>13</b> Distributions</a><ul>
<li class="chapter" data-level="13.0.1" data-path="distributions.html"><a href="distributions.html#beta-distribution"><i class="fa fa-check"></i><b>13.0.1</b> Beta Distribution</a></li>
<li class="chapter" data-level="13.0.2" data-path="distributions.html"><a href="distributions.html#gamma-distribution"><i class="fa fa-check"></i><b>13.0.2</b> Gamma Distribution</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html"><i class="fa fa-check"></i><b>14</b> Annotated Bibliography</a><ul>
<li class="chapter" data-level="14.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#textbooks"><i class="fa fa-check"></i><b>14.1</b> Textbooks</a></li>
<li class="chapter" data-level="14.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#syllabi"><i class="fa fa-check"></i><b>14.2</b> Syllabi</a></li>
<li class="chapter" data-level="14.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#topics"><i class="fa fa-check"></i><b>14.3</b> Topics</a></li>
<li class="chapter" data-level="14.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayes-theorem"><i class="fa fa-check"></i><b>14.4</b> Bayesâ€™ Theorem</a></li>
<li class="chapter" data-level="14.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#article-length-introductions-to-bayesian-statistics"><i class="fa fa-check"></i><b>14.5</b> Article Length Introductions to Bayesian Statistics</a><ul>
<li class="chapter" data-level="14.5.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#why-bayesian"><i class="fa fa-check"></i><b>14.5.1</b> Why Bayesian</a></li>
<li class="chapter" data-level="14.5.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#modern-statistical-workflow"><i class="fa fa-check"></i><b>14.5.2</b> Modern Statistical Workflow</a></li>
<li class="chapter" data-level="14.5.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-philosophy"><i class="fa fa-check"></i><b>14.5.3</b> Bayesian Philosophy</a></li>
<li class="chapter" data-level="14.5.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>14.5.4</b> Bayesian Hypothesis Testing</a></li>
<li class="chapter" data-level="14.5.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-frequentist-debates"><i class="fa fa-check"></i><b>14.5.5</b> Bayesian Frequentist Debates</a></li>
<li class="chapter" data-level="14.5.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#categorical"><i class="fa fa-check"></i><b>14.5.6</b> Categorical</a></li>
<li class="chapter" data-level="14.5.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#variable-selection"><i class="fa fa-check"></i><b>14.5.7</b> Variable Selection</a></li>
<li class="chapter" data-level="14.5.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multiple-testing"><i class="fa fa-check"></i><b>14.5.8</b> Multiple Testing</a></li>
<li class="chapter" data-level="14.5.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#rare-events"><i class="fa fa-check"></i><b>14.5.9</b> Rare Events</a></li>
<li class="chapter" data-level="14.5.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#identifiability"><i class="fa fa-check"></i><b>14.5.10</b> Identifiability</a></li>
<li class="chapter" data-level="14.5.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkage"><i class="fa fa-check"></i><b>14.5.11</b> Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software"><i class="fa fa-check"></i><b>14.6</b> Software</a><ul>
<li class="chapter" data-level="14.6.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#stan-1"><i class="fa fa-check"></i><b>14.6.1</b> Stan</a></li>
<li class="chapter" data-level="14.6.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#diagrams"><i class="fa fa-check"></i><b>14.6.2</b> Diagrams</a></li>
<li class="chapter" data-level="14.6.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#priors-1"><i class="fa fa-check"></i><b>14.6.3</b> Priors</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-model-averaging"><i class="fa fa-check"></i><b>14.7</b> Bayesian Model Averaging</a></li>
<li class="chapter" data-level="14.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multilevel-modeling"><i class="fa fa-check"></i><b>14.8</b> Multilevel Modeling</a></li>
<li class="chapter" data-level="14.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#mixture-models"><i class="fa fa-check"></i><b>14.9</b> Mixture Models</a></li>
<li class="chapter" data-level="14.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#inference"><i class="fa fa-check"></i><b>14.10</b> Inference</a><ul>
<li class="chapter" data-level="14.10.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#discussion-of-bayesian-inference"><i class="fa fa-check"></i><b>14.10.1</b> Discussion of Bayesian Inference</a></li>
</ul></li>
<li class="chapter" data-level="14.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#model-checking-1"><i class="fa fa-check"></i><b>14.11</b> Model Checking</a><ul>
<li class="chapter" data-level="14.11.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#posterior-predictive-checks-1"><i class="fa fa-check"></i><b>14.11.1</b> Posterior Predictive Checks</a></li>
<li class="chapter" data-level="14.11.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#prediction-criteria"><i class="fa fa-check"></i><b>14.11.2</b> Prediction Criteria</a></li>
<li class="chapter" data-level="14.11.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software-validation"><i class="fa fa-check"></i><b>14.11.3</b> Software Validation</a></li>
</ul></li>
<li class="chapter" data-level="14.12" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#hierarchical-modeling"><i class="fa fa-check"></i><b>14.12</b> Hierarchical Modeling</a></li>
<li class="chapter" data-level="14.13" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkageregularization"><i class="fa fa-check"></i><b>14.13</b> Shrinkage/Regularization</a></li>
<li class="chapter" data-level="14.14" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#empirical-bayes"><i class="fa fa-check"></i><b>14.14</b> Empirical Bayes</a></li>
<li class="chapter" data-level="14.15" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#history-of-bayesian-statistics"><i class="fa fa-check"></i><b>14.15</b> History of Bayesian Statistics</a></li>
<li class="chapter" data-level="14.16" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#sampling-difficulties"><i class="fa fa-check"></i><b>14.16</b> Sampling Difficulties</a></li>
<li class="chapter" data-level="14.17" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#complicated-estimation-and-testing"><i class="fa fa-check"></i><b>14.17</b> Complicated Estimation and Testing</a></li>
<li class="chapter" data-level="14.18" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#pooling-polls"><i class="fa fa-check"></i><b>14.18</b> Pooling Polls</a></li>
<li class="chapter" data-level="14.19" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#visualizing-mcmc-methods"><i class="fa fa-check"></i><b>14.19</b> Visualizing MCMC Methods</a></li>
<li class="chapter" data-level="14.20" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-point-estimation-decision"><i class="fa fa-check"></i><b>14.20</b> Bayesian point estimation / Decision</a></li>
<li class="chapter" data-level="14.21" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#stan-modeling-language"><i class="fa fa-check"></i><b>14.21</b> Stan Modeling Language</a></li>
<li class="chapter" data-level="14.22" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayes-factors"><i class="fa fa-check"></i><b>14.22</b> Bayes Factors</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-7.html"><a href="references-7.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Updating: A Set of Bayesian Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\median}{median}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\logistic}{Logistic}
\DeclareMathOperator{\logit}{Logit}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

% This follows BDA
\newcommand{\dunif}{\mathrm{U}}
\newcommand{\dnorm}{\mathrm{N}}
\newcommand{\dlnorm}{\mathrm{lognormal}}
\newcommand{\dmvnorm}{\mathrm{N}}
\newcommand{\dgamma}{\mathrm{Gamma}}
\newcommand{\dinvgamma}{\mathrm{Inv-Gamma}}
\newcommand{\dchisq}[1]{\chi^2_{#1}}
\newcommand{\dinvchisq}[1]{\mathrm{Inv-}\chi^2_{#1}}
\newcommand{\dexp}{\mathrm{Expon}}
\newcommand{\dlaplace}{\mathrm{Laplace}}
\newcommand{\dweibull}{\mathrm{Weibull}}
\newcommand{\dwishart}[1]{\mathrm{Wishart}_{#1}}
\newcommand{\dinvwishart}[1]{\mathrm{Inv-Wishart}_{#1}}
\newcommand{\dlkj}{\mathrm{LkjCorr}}
\newcommand{\dt}[1]{t_{#1}}
\newcommand{\dbeta}{\mathrm{Beta}}
\newcommand{\ddirichlet}{\mathrm{Dirichlet}}
\newcommand{\dlogistic}{\mathrm{Logistic}}
\newcommand{\dllogistic}{\mathrm{Log-logistic}}
\newcommand{\dpois}{\mathrm{Poisson}}
\newcommand{\dBinom}{\mathrm{Bin}}
\newcommand{\dmultinom}{\mathrm{Multinom}}
\newcommand{\dnbinom}{\mathrm{Neg-bin}}
\newcommand{\dnbinomalt}{\mathrm{Neg-bin2}}
\newcommand{\dbetabinom}{\mathrm{Beta-bin}}
\newcommand{\dcauchy}{\mathrm{Cauchy}}
\newcommand{\dhalfcauchy}{\mathrm{Cauchy}^{+}}
\newcommand{\dlkjcorr}{\mathrm{LKJ}^{+}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Reals}{\R}
\newcommand{\RealPos}{\R^{+}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Nats}{\N}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]
<div id="hierarchical-models" class="section level1">
<h1><span class="header-section-number">11</span> Hierarchical Models</h1>
<ul>
<li><em>Hierarchical models:</em> often groups of parameters, <span class="math inline">\(\{\theta_1, \dots, \theta_J\}\)</span>, are related.</li>
<li>E.g. countries, states, counties, years, etc. Even the regression coefficients, <span class="math inline">\(\beta_1, \dots, \beta_k\)</span> seen the in the [Shrinkage and Regularization] chapter.</li>
<li>We can treat those <span class="math inline">\(\theta_j\)</span> as drawn from a <em>population distribution</em>, <span class="math inline">\(\theta_j \sim p(\theta)\)</span>.</li>
<li>The prior distribution <span class="math inline">\(p(\theta)\)</span> is called a <em>hyperprior</em> and its parameters are <em>hyperparameters</em></li>
</ul>
<p><em>Exchangeability:</em></p>
<ul>
<li>parameters <span class="math inline">\((\theta_1, \dots, \theta_J)\)</span> are <em>exchangeable</em> if <span class="math inline">\(p(\theta_1, \dots, \theta_J)\)</span> donâ€™t depend on the indexes.</li>
<li>i.i.d. models are a special case of exchangeability.</li>
</ul>
<div id="prerequisites-3" class="section level2 unnumbered">
<h2>Prerequisites</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;loo&quot;</span>)</code></pre>
</div>
<div id="example-baseball-hits" class="section level2">
<h2><span class="header-section-number">11.1</span> Example: Baseball Hits</h2>
<p><span class="citation">Efron and Morris (1975)</span> analyzed data from 18 players in the 1970 season.
The goal was to predict the batting average of these 18 players from their first 45 at-bats for the remainder of the 1970 season.</p>
<p>The following example is based on <span class="citation">Carpenter, Gabry, and Goodrich (2017)</span> and the <strong><a href="https://cran.r-project.org/package=rstanarm">rstanarm</a></strong> vignette <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/pooling.html">Hierarchical Partial Pooling for Repeated Binary Trials</a>.</p>
<p>The hitting data used in <span class="citation">Efron and Morris (1975)</span> is included in <strong><a href="https://cran.r-project.org/package=rstanarm">rstanarm</a></strong> as <a href="https://www.rdocumentation.org/packages/rstanarm/topics/bball1970">rstanarm</a>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;bball1970&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;rstanarm&quot;</span>)
bball1970 &lt;-
<span class="st">  </span><span class="kw">mutate</span>(bball1970,
         <span class="dt">BatAvg1 =</span> Hits <span class="op">/</span><span class="st"> </span>AB,
         <span class="dt">BatAvg2 =</span> RemainingHits <span class="op">/</span><span class="st"> </span>RemainingAB)
bball1970
<span class="co">#&gt;        Player AB Hits RemainingAB RemainingHits BatAvg1 BatAvg2</span>
<span class="co">#&gt; 1    Clemente 45   18         367           127   0.400   0.346</span>
<span class="co">#&gt; 2    Robinson 45   17         426           127   0.378   0.298</span>
<span class="co">#&gt; 3      Howard 45   16         521           144   0.356   0.276</span>
<span class="co">#&gt; 4   Johnstone 45   15         275            61   0.333   0.222</span>
<span class="co">#&gt; 5       Berry 45   14         418           114   0.311   0.273</span>
<span class="co">#&gt; 6     Spencer 45   14         466           126   0.311   0.270</span>
<span class="co">#&gt; 7   Kessinger 45   13         586           155   0.289   0.265</span>
<span class="co">#&gt; 8    Alvarado 45   12         138            29   0.267   0.210</span>
<span class="co">#&gt; 9       Santo 45   11         510           137   0.244   0.269</span>
<span class="co">#&gt; 10    Swaboda 45   11         200            46   0.244   0.230</span>
<span class="co">#&gt; 11 Petrocelli 45   10         538           142   0.222   0.264</span>
<span class="co">#&gt; 12  Rodriguez 45   10         186            42   0.222   0.226</span>
<span class="co">#&gt; 13      Scott 45   10         435           132   0.222   0.303</span>
<span class="co">#&gt; 14      Unser 45   10         277            73   0.222   0.264</span>
<span class="co">#&gt; 15   Williams 45   10         591           195   0.222   0.330</span>
<span class="co">#&gt; 16 Campaneris 45    9         558           159   0.200   0.285</span>
<span class="co">#&gt; 17     Munson 45    8         408           129   0.178   0.316</span>
<span class="co">#&gt; 18      Alvis 45    7          70            14   0.156   0.200</span></code></pre>
<p>Let <span class="math inline">\(y_i\)</span> be the number of hits in the first 45 at bats for player <span class="math inline">\(i\)</span>,
<span class="math display">\[
\begin{aligned}[t]
y_i &amp; \sim \dbin(45, \mu_i),
\end{aligned}
\]</span>
where <span class="math inline">\(\mu_i \in (0, 1)\)</span> is the player-specific batting average.
Priors will be placed on the log-odds parameter, <span class="math inline">\(\eta \in \R\)</span>,
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;\sim \frac{1}{1 + \exp(-\eta_i)} . \\
\end{aligned}
\]</span></p>
<p>This example considers three ways of modeling <span class="math inline">\(\mu_i\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Complete Pooling:</strong> All players have the same batting average parameter.
<span class="math display">\[
\eta_i = \eta .
\]</span>
The common (log-odds) batting average is given a weakly informative prior,
<span class="math display">\[
\eta \sim \dnorm(0, 2.5)
\]</span>
On the log odds scale, this places 95% of the probability mass between 0.7 and 99.3 on the proportion scale.</p></li>
<li><p><strong>Non-pooled:</strong> Each players (log-odds) batting average is independent, with each assigned a separate weak prior.
<span class="math display">\[
\begin{aligned}[t]
\eta_i &amp;\sim \dnorm(0, 2.5)
\end{aligned}
\]</span></p></li>
<li><p><strong>Partial-pooling:</strong> Each player has a separate (log-odds) batting average, but these batting average parameters are drawn from a common normal distribution.
<span class="math display">\[
\begin{aligned}[t]
\eta_i &amp;\sim \dnorm(0, \tau) \\
\tau &amp;\sim \dnorm(0, 1)
\end{aligned}
\]</span></p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">bball1970_data &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">N =</span> <span class="kw">nrow</span>(bball1970),
  <span class="dt">k =</span> bball1970<span class="op">$</span>AB,
  <span class="dt">y =</span> bball1970<span class="op">$</span>Hits,
  <span class="dt">k_new =</span> bball1970<span class="op">$</span>RemainingAB,
  <span class="dt">y_new =</span> bball1970<span class="op">$</span>RemainingHits
)</code></pre>
<p>Create a list to store models:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># models &lt;- list()</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">models[[<span class="st">&quot;nopool&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/binomial-no-pooling.stan&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># models[[&quot;nopool&quot;]]</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">models[[<span class="st">&quot;pool&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/binomial-complete-pooling.stan&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># models[[&quot;pool&quot;]]</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">models[[<span class="st">&quot;partial&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/binomial-partial-pooling-t.stan&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># models[[&quot;partial&quot;]]</span></code></pre>
<p>Sample from all three models a</p>
<pre class="sourceCode r"><code class="sourceCode r">fits &lt;-<span class="st"> </span><span class="kw">map</span>(models, sampling, <span class="dt">data =</span> bball1970_data,
            <span class="dt">refresh =</span> <span class="dv">-1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_names</span>(<span class="kw">names</span>(models))</code></pre>
<p>For each model calculate the posterior mean of <span class="math inline">\(\mu\)</span> for each player:</p>
<pre class="sourceCode r"><code class="sourceCode r">bball1970 &lt;-
<span class="st">  </span><span class="kw">map2_df</span>(<span class="kw">names</span>(fits), fits,
     <span class="cf">function</span>(nm, fit) {
      mu &lt;-<span class="st"> </span>broom<span class="op">::</span><span class="kw">tidy</span>(fit) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(term, <span class="st">&quot;^mu&quot;</span>))
      <span class="cf">if</span> (<span class="kw">nrow</span>(mu) <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
        out &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">estimate =</span> <span class="kw">rep</span>(mu<span class="op">$</span>estimate, 18L))
      } <span class="cf">else</span> {
        out &lt;-<span class="st"> </span><span class="kw">select</span>(mu, estimate)
      }
      out<span class="op">$</span>model &lt;-<span class="st"> </span>nm
      out<span class="op">$</span>.id &lt;-<span class="st"> </span><span class="kw">seq_len</span>(<span class="kw">nrow</span>(out))
      out
     }) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spread</span>(model, estimate) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(bball1970)</code></pre>
<p>The partially pooled estimates are shrunk towards the overall average, and are between the no-pooling and pooled estimates.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">select</span>(bball1970,
       Player, nopool, partial, pool) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Player =</span> <span class="kw">factor</span>(Player, <span class="dt">levels =</span> Player)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(variable, value, <span class="op">-</span>Player) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> value, <span class="dt">x =</span> <span class="kw">factor</span>(variable), <span class="dt">group =</span> Player)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">y =</span> <span class="kw">expression</span>(mu))</code></pre>
<p><img src="hierarchical_files/figure-html/unnamed-chunk-13-1.png" width="70%" style="display: block; margin: auto;" />
We can plot the actual batting averages (<code>BatAvg1</code> and <code>BatAvg2</code>) and the model estimates:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">select</span>(bball1970,
       Player, nopool, partial, pool, BatAvg1, BatAvg2) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Player =</span> <span class="kw">factor</span>(Player, <span class="dt">levels =</span> Player)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(variable, value, <span class="op">-</span>Player) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> Player, <span class="dt">x =</span> value, <span class="dt">colour =</span> variable)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(mu), <span class="dt">y =</span> <span class="st">&quot;&quot;</span>)</code></pre>
<p><img src="hierarchical_files/figure-html/unnamed-chunk-14-1.png" width="70%" style="display: block; margin: auto;" />
The estimates of the no-pooling model is almost exactly the same as <code>BatAvg1</code>.
The out-of-sample batting averages <code>BatAvg2</code> show regression to the mean.</p>
<p>For these models, compare the overall out-of-sample performance by calculating the actual average out-of-sample log-pointwise predictive density (lppd), and the expected lppd using LOO-PSIS.
The LOO-PSIS estimates of the out-of-sample lppd are optimistic.
However, they still show the pooling and partial estimates as superior to the no-pooling estimates.
The actual out-of-sample average lppd for the partial pooled model is the best fitting.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">map2_df</span>(<span class="kw">names</span>(fits), fits,
     <span class="cf">function</span>(nm, fit) {
      loo &lt;-<span class="st"> </span><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(fit, <span class="st">&quot;log_lik&quot;</span>))
      ll_new &lt;-<span class="st"> </span>rstan<span class="op">::</span><span class="kw">extract</span>(fit)[[<span class="st">&quot;log_lik_new&quot;</span>]]
      <span class="kw">tibble</span>(<span class="dt">model =</span> nm,
             <span class="dt">loo =</span> loo<span class="op">$</span>elpd_loo <span class="op">/</span><span class="st"> </span>bball1970_data<span class="op">$</span>N,
             <span class="dt">ll_out =</span> <span class="kw">mean</span>(<span class="kw">log</span>(<span class="kw">colMeans</span>(<span class="kw">exp</span>(ll_new)))))
     })
<span class="co">#&gt; # A tibble: 3 x 3</span>
<span class="co">#&gt;   model     loo ll_out</span>
<span class="co">#&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="co">#&gt; 1 nopool  -3.20  -4.62</span>
<span class="co">#&gt; 2 pool    -2.58  -4.06</span>
<span class="co">#&gt; 3 partial -2.59  -4.01</span></code></pre>
<p>To see why this is the case, plot the average errors for each observation in- and out-of-sample.
In-sample for the no-pooling model is zero, but it over-estimates (under-estimates) the players with the highest (lowest) batting averages in their first 45 at batsâ€”this is regression to the mean.
In sample, the partially pooling model shrinks the estimates towards the mean and
reducing error.
Out of sample, the errors of the partially pooled model are not much different than the no-pooling model, except that the extreme observations have lower errors.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">select</span>(bball1970,
       Player, nopool, partial, pool, BatAvg1, BatAvg2) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Player =</span> <span class="kw">as.integer</span>(<span class="kw">factor</span>(Player, <span class="dt">levels =</span> Player))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(variable, value, <span class="op">-</span>Player, <span class="op">-</span><span class="kw">matches</span>(<span class="st">&quot;BatAvg&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="st">`</span><span class="dt">In-sample Errors</span><span class="st">`</span> =<span class="st"> </span>value <span class="op">-</span><span class="st"> </span>BatAvg1,
         <span class="st">`</span><span class="dt">Out-of-sample Errors</span><span class="st">`</span> =<span class="st"> </span>value <span class="op">-</span><span class="st"> </span>BatAvg2) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span><span class="kw">matches</span>(<span class="st">&quot;BatAvg&quot;</span>), <span class="op">-</span>value) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(sample, error, <span class="op">-</span>variable, <span class="op">-</span>Player) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> error, <span class="dt">x =</span> Player, <span class="dt">colour =</span> variable)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">colour =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>sample, <span class="dt">ncol =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</code></pre>
<p><img src="hierarchical_files/figure-html/unnamed-chunk-16-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Extensions:</p>
<ul>
<li>Redo this analysis with the <a href="https://www.rdocumentation.org/packages/rstanarm/topics/bball2006">rstanarm</a> dataset with hits and at-bats for the entire 2006 AL season of MLB.</li>
<li>Use a beta distribution for the prior of <span class="math inline">\(\mu_i\)</span>. How would you specify the prior beta distribution so that it is uninformative?</li>
<li>If you used the beta distribution, how would you specify the beta distribution as a function of the mean?</li>
<li>The lowest batting average of the modern era is approximately 0.16 and the highest is approximately 0.4. Use this information for an informative prior distribution.</li>
<li>There may be some truly exceptional players. Model this by replacing the normal prior for <span class="math inline">\(\eta\)</span> with a wide tailed distribution.</li>
<li>The distribution of batting averages may be asymmetric - since there may be a few great players, but a player can only be so bad before they are relegated to the minor league. Find a skewed distribution to use as a prior.</li>
</ul>
<div id="references-6" class="section level3">
<h3><span class="header-section-number">11.1.1</span> References</h3>
<ul>
<li>Albert, Jim. <a href="https://baseballwithr.wordpress.com/2016/02/15/revisiting-efron-and-morriss-baseball-study/">Revisiting Efron and Morrisâ€™s Baseball Study</a> Feb 15, 2016</li>
<li>Bob Carpenter. <a href="https://lingpipe-blog.com/2009/11/04/hierarchicalbayesian-batting-ability-with-multiple-comparisons/">Hierarchical Bayesian Batting Ability, with Multiple Comparisons</a>. November 4, 2009.</li>
<li>John Kruschke. <a href="http://doingbayesiandataanalysis.blogspot.com/2012/11/shrinkage-in-multi-level-hierarchical.html">Shrinkage in multi-level hierarchical models</a>. November 27, 2012.</li>
<li>See <span class="citation">Jensen, McShane, and Wyner (2009)</span> for an updated hierarchical model of baseball hitting</li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="binomial-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multilevel-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/bayesian_notes/edit/master/hierarchical.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
