<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>15 Robust Regression | Updating: A Set of Bayesian Notes</title>
  <meta name="description" content="15 Robust Regression | Updating: A Set of Bayesian Notes">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="15 Robust Regression | Updating: A Set of Bayesian Notes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jrnold.github.io/bayesian_notes" />
  
  
  <meta name="github-repo" content="jrnold/bayesian_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="15 Robust Regression | Updating: A Set of Bayesian Notes" />
  <meta name="twitter:site" content="@jrnld" />
  
  

<meta name="author" content="Jeffrey B. Arnold">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="separtion.html">
<link rel="next" href="heteroskedasticity.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/d3-3.3.8/d3.min.js"></script>
<script src="libs/dagre-0.4.0/dagre-d3.min.js"></script>
<link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet" />
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/chromatography-0.1/chromatography.js"></script>
<script src="libs/DiagrammeR-binding-1.0.0/DiagrammeR.js"></script>
<script src="libs/viz-0.3/viz.js"></script>
<script src="libs/grViz-binding-1.0.0/grViz.js"></script>



<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Bayesian Notes</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>1</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="1.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#bayesian-analysis"><i class="fa fa-check"></i><b>1.1</b> Bayesian Analysis</a></li>
<li class="chapter" data-level="1.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>1.2</b> Posterior Predictive Distribution</a></li>
</ul></li>
<li class="part"><span><b>I Theory</b></span></li>
<li class="chapter" data-level="2" data-path="bayes-theorem.html"><a href="bayes-theorem.html"><i class="fa fa-check"></i><b>2</b> Bayes Theorem</a><ul>
<li class="chapter" data-level="" data-path="bayes-theorem.html"><a href="bayes-theorem.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="2.1" data-path="bayes-theorem.html"><a href="bayes-theorem.html#introduction-to-bayes-theorem"><i class="fa fa-check"></i><b>2.1</b> Introduction to Bayes’ Theorem</a></li>
<li class="chapter" data-level="2.2" data-path="bayes-theorem.html"><a href="bayes-theorem.html#examples"><i class="fa fa-check"></i><b>2.2</b> Examples</a><ul>
<li class="chapter" data-level="2.2.1" data-path="bayes-theorem.html"><a href="bayes-theorem.html#taxi-cab-problem"><i class="fa fa-check"></i><b>2.2.1</b> Taxi-Cab Problem</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="bayes-theorem.html"><a href="bayes-theorem.html#why-most-research-findings-are-false"><i class="fa fa-check"></i><b>2.3</b> Why most research findings are false</a><ul>
<li class="chapter" data-level="2.3.1" data-path="bayes-theorem.html"><a href="bayes-theorem.html#questions"><i class="fa fa-check"></i><b>2.3.1</b> Questions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="bayes-theorem.html"><a href="bayes-theorem.html#measurement-error-and-rare-events-in-surveys"><i class="fa fa-check"></i><b>2.4</b> Measurement Error and Rare Events in Surveys</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html"><i class="fa fa-check"></i><b>3</b> Example: Predicting Names from Ages</a><ul>
<li class="chapter" data-level="" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#prerequisites-1"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="3.1" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#statement-of-the-problem"><i class="fa fa-check"></i><b>3.1</b> Statement of the problem</a></li>
<li class="chapter" data-level="3.2" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#data-wrangling"><i class="fa fa-check"></i><b>3.2</b> Data Wrangling</a></li>
<li class="chapter" data-level="3.3" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#probability-of-age-given-name-and-sex"><i class="fa fa-check"></i><b>3.3</b> Probability of age given name and sex</a><ul>
<li class="chapter" data-level="3.3.1" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#questions-1"><i class="fa fa-check"></i><b>3.3.1</b> Questions</a></li>
<li class="chapter" data-level="3.3.2" data-path="example-predicting-names-from-ages.html"><a href="example-predicting-names-from-ages.html#references"><i class="fa fa-check"></i><b>3.3.2</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>4</b> Naive Bayes</a><ul>
<li class="chapter" data-level="" data-path="naive-bayes.html"><a href="naive-bayes.html#prerequisites-2"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="4.1" data-path="naive-bayes.html"><a href="naive-bayes.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="naive-bayes.html"><a href="naive-bayes.html#examples-1"><i class="fa fa-check"></i><b>4.2</b> Examples</a><ul>
<li class="chapter" data-level="4.2.1" data-path="naive-bayes.html"><a href="naive-bayes.html#federalist-papers"><i class="fa fa-check"></i><b>4.2.1</b> Federalist Papers</a></li>
<li class="chapter" data-level="4.2.2" data-path="naive-bayes.html"><a href="naive-bayes.html#extensions"><i class="fa fa-check"></i><b>4.2.2</b> Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="naive-bayes.html"><a href="naive-bayes.html#details"><i class="fa fa-check"></i><b>4.3</b> Details</a><ul>
<li class="chapter" data-level="4.3.1" data-path="naive-bayes.html"><a href="naive-bayes.html#generative-vs.-discriminative-models"><i class="fa fa-check"></i><b>4.3.1</b> Generative vs. Discriminative Models</a></li>
<li class="chapter" data-level="4.3.2" data-path="naive-bayes.html"><a href="naive-bayes.html#estimation"><i class="fa fa-check"></i><b>4.3.2</b> Estimation</a></li>
<li class="chapter" data-level="4.3.3" data-path="naive-bayes.html"><a href="naive-bayes.html#prediction"><i class="fa fa-check"></i><b>4.3.3</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="naive-bayes.html"><a href="naive-bayes.html#references-1"><i class="fa fa-check"></i><b>4.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="priors.html"><a href="priors.html"><i class="fa fa-check"></i><b>5</b> Priors</a><ul>
<li class="chapter" data-level="5.1" data-path="priors.html"><a href="priors.html#levels-of-priors"><i class="fa fa-check"></i><b>5.1</b> Levels of Priors</a></li>
<li class="chapter" data-level="5.2" data-path="priors.html"><a href="priors.html#conjugate-priors"><i class="fa fa-check"></i><b>5.2</b> Conjugate Priors</a><ul>
<li class="chapter" data-level="5.2.1" data-path="priors.html"><a href="priors.html#binomial-beta"><i class="fa fa-check"></i><b>5.2.1</b> Binomial-Beta</a></li>
<li class="chapter" data-level="5.2.2" data-path="priors.html"><a href="priors.html#categorical-dirichlet"><i class="fa fa-check"></i><b>5.2.2</b> Categorical-Dirichlet</a></li>
<li class="chapter" data-level="5.2.3" data-path="priors.html"><a href="priors.html#poisson-gamma"><i class="fa fa-check"></i><b>5.2.3</b> Poisson-Gamma</a></li>
<li class="chapter" data-level="5.2.4" data-path="priors.html"><a href="priors.html#normal-with-known-variance"><i class="fa fa-check"></i><b>5.2.4</b> Normal with known variance</a></li>
<li class="chapter" data-level="5.2.5" data-path="priors.html"><a href="priors.html#exponential-family"><i class="fa fa-check"></i><b>5.2.5</b> Exponential Family</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="priors.html"><a href="priors.html#improper-priors"><i class="fa fa-check"></i><b>5.3</b> Improper Priors</a></li>
<li class="chapter" data-level="5.4" data-path="priors.html"><a href="priors.html#cromwells-rule"><i class="fa fa-check"></i><b>5.4</b> Cromwell’s Rule</a></li>
<li class="chapter" data-level="5.5" data-path="priors.html"><a href="priors.html#asymptotics"><i class="fa fa-check"></i><b>5.5</b> Asymptotics</a></li>
<li class="chapter" data-level="5.6" data-path="priors.html"><a href="priors.html#proper-and-improper-priors"><i class="fa fa-check"></i><b>5.6</b> Proper and Improper Priors</a></li>
<li class="chapter" data-level="5.7" data-path="priors.html"><a href="priors.html#hyperpriors-and-hyperparameters"><i class="fa fa-check"></i><b>5.7</b> Hyperpriors and Hyperparameters</a></li>
<li class="chapter" data-level="5.8" data-path="priors.html"><a href="priors.html#references-2"><i class="fa fa-check"></i><b>5.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimation-1.html"><a href="estimation-1.html"><i class="fa fa-check"></i><b>6</b> Estimation</a><ul>
<li class="chapter" data-level="6.1" data-path="estimation-1.html"><a href="estimation-1.html#point-estimates"><i class="fa fa-check"></i><b>6.1</b> Point Estimates</a></li>
<li class="chapter" data-level="6.2" data-path="estimation-1.html"><a href="estimation-1.html#credible-intervals"><i class="fa fa-check"></i><b>6.2</b> Credible Intervals</a><ul>
<li class="chapter" data-level="6.2.1" data-path="estimation-1.html"><a href="estimation-1.html#compared-to-confidence-intervals"><i class="fa fa-check"></i><b>6.2.1</b> Compared to confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="estimation-1.html"><a href="estimation-1.html#bayesian-decision-theory"><i class="fa fa-check"></i><b>6.3</b> Bayesian Decision Theory</a></li>
</ul></li>
<li class="part"><span><b>II Computation</b></span></li>
<li class="chapter" data-level="7" data-path="bayesian-computation.html"><a href="bayesian-computation.html"><i class="fa fa-check"></i><b>7</b> Bayesian Computation</a><ul>
<li class="chapter" data-level="7.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#how-to-calculate-a-posterior"><i class="fa fa-check"></i><b>7.1</b> How to calculate a posterior?</a></li>
<li class="chapter" data-level="7.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#example-globe-tossing-model"><i class="fa fa-check"></i><b>7.2</b> Example: Globe-tossing model</a></li>
<li class="chapter" data-level="7.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#quadrature"><i class="fa fa-check"></i><b>7.3</b> Quadrature</a><ul>
<li class="chapter" data-level="7.3.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#grid-approximation"><i class="fa fa-check"></i><b>7.3.1</b> Grid approximation</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="bayesian-computation.html"><a href="bayesian-computation.html#functional-approximations"><i class="fa fa-check"></i><b>7.4</b> Functional Approximations</a><ul>
<li class="chapter" data-level="7.4.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#maximum-a-posteriori"><i class="fa fa-check"></i><b>7.4.1</b> Maximum A Posteriori</a></li>
<li class="chapter" data-level="7.4.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#laplace-approximation"><i class="fa fa-check"></i><b>7.4.2</b> Laplace Approximation</a></li>
<li class="chapter" data-level="7.4.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#variational-inference"><i class="fa fa-check"></i><b>7.4.3</b> Variational Inference</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="bayesian-computation.html"><a href="bayesian-computation.html#sampling-methods"><i class="fa fa-check"></i><b>7.5</b> Sampling Methods</a><ul>
<li class="chapter" data-level="7.5.1" data-path="bayesian-computation.html"><a href="bayesian-computation.html#numerical-integration"><i class="fa fa-check"></i><b>7.5.1</b> Numerical Integration</a></li>
<li class="chapter" data-level="7.5.2" data-path="bayesian-computation.html"><a href="bayesian-computation.html#inverse-transform-sampling"><i class="fa fa-check"></i><b>7.5.2</b> Inverse transform sampling</a></li>
<li class="chapter" data-level="7.5.3" data-path="bayesian-computation.html"><a href="bayesian-computation.html#direct-approximation"><i class="fa fa-check"></i><b>7.5.3</b> Direct approximation</a></li>
<li class="chapter" data-level="7.5.4" data-path="bayesian-computation.html"><a href="bayesian-computation.html#rejection-sampling"><i class="fa fa-check"></i><b>7.5.4</b> Rejection sampling</a></li>
<li class="chapter" data-level="7.5.5" data-path="bayesian-computation.html"><a href="bayesian-computation.html#importance-sampling"><i class="fa fa-check"></i><b>7.5.5</b> Importance Sampling</a></li>
<li class="chapter" data-level="7.5.6" data-path="bayesian-computation.html"><a href="bayesian-computation.html#mcmc-methods"><i class="fa fa-check"></i><b>7.5.6</b> MCMC Methods</a></li>
<li class="chapter" data-level="7.5.7" data-path="bayesian-computation.html"><a href="bayesian-computation.html#discarding-early-iterations"><i class="fa fa-check"></i><b>7.5.7</b> Discarding early iterations</a></li>
<li class="chapter" data-level="7.5.8" data-path="bayesian-computation.html"><a href="bayesian-computation.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>7.5.8</b> Monte Carlo Sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>8</b> MCMC Diagnostics</a><ul>
<li class="chapter" data-level="" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#prerequisites-3"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="8.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#reparameterize-models"><i class="fa fa-check"></i><b>8.1</b> Reparameterize Models</a></li>
<li class="chapter" data-level="8.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#convergence-diagnostics"><i class="fa fa-check"></i><b>8.2</b> Convergence Diagnostics</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#potential-scale-reduction-hatr"><i class="fa fa-check"></i><b>8.2.1</b> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</a></li>
<li class="chapter" data-level="8.2.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#references-3"><i class="fa fa-check"></i><b>8.2.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation-effective-sample-size-and-mcse"><i class="fa fa-check"></i><b>8.3</b> Autocorrelation, Effective Sample Size, and MCSE</a><ul>
<li class="chapter" data-level="8.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#effective-sample-size"><i class="fa fa-check"></i><b>8.3.1</b> Effective Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#thinning"><i class="fa fa-check"></i><b>8.4</b> Thinning</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#traceplots"><i class="fa fa-check"></i><b>8.4.1</b> Traceplots</a></li>
<li class="chapter" data-level="8.4.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#monte-carlo-standard-error-mcse"><i class="fa fa-check"></i><b>8.4.2</b> Monte Carlo Standard Error (MCSE)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#hmc-nut-specific-diagnostics"><i class="fa fa-check"></i><b>8.5</b> HMC-NUT Specific Diagnostics</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#divergent-transitions"><i class="fa fa-check"></i><b>8.5.1</b> Divergent transitions</a></li>
<li class="chapter" data-level="8.5.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#maximum-tree-depth"><i class="fa fa-check"></i><b>8.5.2</b> Maximum Tree-depth</a></li>
<li class="chapter" data-level="8.5.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#bayesian-fraction-of-missing-information"><i class="fa fa-check"></i><b>8.5.3</b> Bayesian Fraction of Missing Information</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#debugging-bayesian-computing"><i class="fa fa-check"></i><b>8.6</b> Debugging Bayesian Computing</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>9</b> Model Checking</a><ul>
<li class="chapter" data-level="9.1" data-path="model-checking.html"><a href="model-checking.html#why-check-models"><i class="fa fa-check"></i><b>9.1</b> Why check models?</a></li>
<li class="chapter" data-level="9.2" data-path="model-checking.html"><a href="model-checking.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>9.2</b> Posterior Predictive Checks</a><ul>
<li class="chapter" data-level="9.2.1" data-path="model-checking.html"><a href="model-checking.html#bayesian-p-values"><i class="fa fa-check"></i><b>9.2.1</b> Bayesian p-values</a></li>
<li class="chapter" data-level="9.2.2" data-path="model-checking.html"><a href="model-checking.html#test-quantities"><i class="fa fa-check"></i><b>9.2.2</b> Test quantities</a></li>
<li class="chapter" data-level="9.2.3" data-path="model-checking.html"><a href="model-checking.html#p-values-vs.-u-values"><i class="fa fa-check"></i><b>9.2.3</b> p-values vs. u-values</a></li>
<li class="chapter" data-level="9.2.4" data-path="model-checking.html"><a href="model-checking.html#marginal-predictive-checks"><i class="fa fa-check"></i><b>9.2.4</b> Marginal predictive checks</a></li>
<li class="chapter" data-level="9.2.5" data-path="model-checking.html"><a href="model-checking.html#outliers"><i class="fa fa-check"></i><b>9.2.5</b> Outliers</a></li>
<li class="chapter" data-level="9.2.6" data-path="model-checking.html"><a href="model-checking.html#graphical-posterior-predictive-checks"><i class="fa fa-check"></i><b>9.2.6</b> Graphical Posterior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="model-checking.html"><a href="model-checking.html#references-4"><i class="fa fa-check"></i><b>9.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>10</b> Model Comparison</a><ul>
<li class="chapter" data-level="10.1" data-path="model-comparison.html"><a href="model-comparison.html#models"><i class="fa fa-check"></i><b>10.1</b> Models</a></li>
<li class="chapter" data-level="10.2" data-path="model-comparison.html"><a href="model-comparison.html#classes-of-model-spaces"><i class="fa fa-check"></i><b>10.2</b> Classes of Model Spaces</a></li>
<li class="chapter" data-level="10.3" data-path="model-comparison.html"><a href="model-comparison.html#continuous-model-expansion"><i class="fa fa-check"></i><b>10.3</b> Continuous model expansion</a></li>
<li class="chapter" data-level="10.4" data-path="model-comparison.html"><a href="model-comparison.html#discrete-model-expansion"><i class="fa fa-check"></i><b>10.4</b> Discrete Model Expansion</a></li>
<li class="chapter" data-level="10.5" data-path="model-comparison.html"><a href="model-comparison.html#out-of-sample-predictive-accuracy"><i class="fa fa-check"></i><b>10.5</b> Out-of-sample predictive accuracy</a></li>
<li class="chapter" data-level="10.6" data-path="model-comparison.html"><a href="model-comparison.html#stacking"><i class="fa fa-check"></i><b>10.6</b> Stacking</a></li>
<li class="chapter" data-level="10.7" data-path="model-comparison.html"><a href="model-comparison.html#posterior-predictive-criteria"><i class="fa fa-check"></i><b>10.7</b> Posterior Predictive Criteria</a><ul>
<li class="chapter" data-level="10.7.1" data-path="model-comparison.html"><a href="model-comparison.html#summary-and-advice"><i class="fa fa-check"></i><b>10.7.1</b> Summary and Advice</a></li>
<li class="chapter" data-level="10.7.2" data-path="model-comparison.html"><a href="model-comparison.html#expected-log-predictive-density"><i class="fa fa-check"></i><b>10.7.2</b> Expected Log Predictive Density</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="model-comparison.html"><a href="model-comparison.html#bayesian-model-averaging"><i class="fa fa-check"></i><b>10.8</b> Bayesian Model Averaging</a></li>
<li class="chapter" data-level="10.9" data-path="model-comparison.html"><a href="model-comparison.html#pseudo-bma"><i class="fa fa-check"></i><b>10.9</b> Pseudo-BMA</a></li>
<li class="chapter" data-level="10.10" data-path="model-comparison.html"><a href="model-comparison.html#loo-cv-via-importance-sampling"><i class="fa fa-check"></i><b>10.10</b> LOO-CV via importance sampling</a></li>
<li class="chapter" data-level="10.11" data-path="model-comparison.html"><a href="model-comparison.html#selection-induced-bias"><i class="fa fa-check"></i><b>10.11</b> Selection induced Bias</a></li>
</ul></li>
<li class="part"><span><b>III Models</b></span></li>
<li class="chapter" data-level="11" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Introduction to Stan and Linear Regression</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#prerequisites-4"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="11.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#ols-and-mle-linear-regression"><i class="fa fa-check"></i><b>11.1</b> OLS and MLE Linear Regression</a><ul>
<li class="chapter" data-level="11.1.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#bayesian-model-with-improper-priors"><i class="fa fa-check"></i><b>11.1.1</b> Bayesian Model with Improper priors</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#stan-model"><i class="fa fa-check"></i><b>11.2</b> Stan Model</a></li>
<li class="chapter" data-level="11.3" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling-model-with-stan"><i class="fa fa-check"></i><b>11.3</b> Sampling Model with Stan</a><ul>
<li class="chapter" data-level="11.3.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling"><i class="fa fa-check"></i><b>11.3.1</b> Sampling</a></li>
<li class="chapter" data-level="11.3.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#convergence-diagnostics-and-model-fit"><i class="fa fa-check"></i><b>11.3.2</b> Convergence Diagnostics and Model Fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>12</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#prerequisites-5"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="12.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#introduction-1"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#count-models"><i class="fa fa-check"></i><b>12.2</b> Count Models</a><ul>
<li class="chapter" data-level="12.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson"><i class="fa fa-check"></i><b>12.2.1</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example-3"><i class="fa fa-check"></i><b>12.3</b> Example</a></li>
<li class="chapter" data-level="12.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#negative-binomial"><i class="fa fa-check"></i><b>12.4</b> Negative Binomial</a></li>
<li class="chapter" data-level="12.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial-categorical-models"><i class="fa fa-check"></i><b>12.5</b> Multinomial / Categorical Models</a></li>
<li class="chapter" data-level="12.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#gamma-regression"><i class="fa fa-check"></i><b>12.6</b> Gamma Regression</a></li>
<li class="chapter" data-level="12.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#beta-regression"><i class="fa fa-check"></i><b>12.7</b> Beta Regression</a></li>
<li class="chapter" data-level="12.8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-5"><i class="fa fa-check"></i><b>12.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="binomial-models.html"><a href="binomial-models.html"><i class="fa fa-check"></i><b>13</b> Binomial Models</a><ul>
<li class="chapter" data-level="" data-path="binomial-models.html"><a href="binomial-models.html#prerequisites-6"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="13.1" data-path="binomial-models.html"><a href="binomial-models.html#introduction-2"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="binomial-models.html"><a href="binomial-models.html#link-functions-link-function"><i class="fa fa-check"></i><b>13.2</b> Link Functions {link-function}</a><ul>
<li class="chapter" data-level="13.2.1" data-path="binomial-models.html"><a href="binomial-models.html#stan"><i class="fa fa-check"></i><b>13.2.1</b> Stan</a></li>
<li class="chapter" data-level="13.2.2" data-path="binomial-models.html"><a href="binomial-models.html#example-vote-turnout"><i class="fa fa-check"></i><b>13.2.2</b> Example: Vote Turnout</a></li>
<li class="chapter" data-level="13.2.3" data-path="binomial-models.html"><a href="binomial-models.html#stan-1"><i class="fa fa-check"></i><b>13.2.3</b> Stan</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="binomial-models.html"><a href="binomial-models.html#references-6"><i class="fa fa-check"></i><b>13.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="separtion.html"><a href="separtion.html"><i class="fa fa-check"></i><b>14</b> Separation</a><ul>
<li class="chapter" data-level="" data-path="separtion.html"><a href="separtion.html#prerequisites-7"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="14.1" data-path="separtion.html"><a href="separtion.html#introduction-3"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="separtion.html"><a href="separtion.html#complete-separation"><i class="fa fa-check"></i><b>14.2</b> Complete Separation</a></li>
<li class="chapter" data-level="14.3" data-path="separtion.html"><a href="separtion.html#quasi-separation"><i class="fa fa-check"></i><b>14.3</b> Quasi-Separation</a></li>
<li class="chapter" data-level="14.4" data-path="separtion.html"><a href="separtion.html#weak-priors"><i class="fa fa-check"></i><b>14.4</b> Weak Priors</a></li>
<li class="chapter" data-level="14.5" data-path="separtion.html"><a href="separtion.html#example-support-of-aca-medicaid-expansion"><i class="fa fa-check"></i><b>14.5</b> Example: Support of ACA Medicaid Expansion</a></li>
<li class="chapter" data-level="14.6" data-path="separtion.html"><a href="separtion.html#questions-2"><i class="fa fa-check"></i><b>14.6</b> Questions</a></li>
<li class="chapter" data-level="14.7" data-path="separtion.html"><a href="separtion.html#references-7"><i class="fa fa-check"></i><b>14.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="robust-regression.html"><a href="robust-regression.html"><i class="fa fa-check"></i><b>15</b> Robust Regression</a><ul>
<li class="chapter" data-level="" data-path="robust-regression.html"><a href="robust-regression.html#prerequisites-8"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="15.1" data-path="robust-regression.html"><a href="robust-regression.html#wide-tailed-distributions"><i class="fa fa-check"></i><b>15.1</b> Wide Tailed Distributions</a></li>
<li class="chapter" data-level="15.2" data-path="robust-regression.html"><a href="robust-regression.html#student-t-distribution"><i class="fa fa-check"></i><b>15.2</b> Student-t distribution</a><ul>
<li class="chapter" data-level="15.2.1" data-path="robust-regression.html"><a href="robust-regression.html#examples-2"><i class="fa fa-check"></i><b>15.2.1</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="robust-regression.html"><a href="robust-regression.html#robit"><i class="fa fa-check"></i><b>15.3</b> Robit</a></li>
<li class="chapter" data-level="15.4" data-path="robust-regression.html"><a href="robust-regression.html#quantile-regression"><i class="fa fa-check"></i><b>15.4</b> Quantile regression</a><ul>
<li class="chapter" data-level="15.4.1" data-path="robust-regression.html"><a href="robust-regression.html#questions-3"><i class="fa fa-check"></i><b>15.4.1</b> Questions</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="robust-regression.html"><a href="robust-regression.html#references-8"><i class="fa fa-check"></i><b>15.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html"><i class="fa fa-check"></i><b>16</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#prerequisites-9"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="16.1" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#introduction-4"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#weighted-regression"><i class="fa fa-check"></i><b>16.2</b> Weighted Regression</a></li>
<li class="chapter" data-level="16.3" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#modeling-the-scale-with-covariates"><i class="fa fa-check"></i><b>16.3</b> Modeling the Scale with Covariates</a></li>
<li class="chapter" data-level="16.4" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#prior-distributions"><i class="fa fa-check"></i><b>16.4</b> Prior Distributions</a><ul>
<li class="chapter" data-level="16.4.1" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#examples-duncan"><i class="fa fa-check"></i><b>16.4.1</b> Examples: Duncan</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#exercises"><i class="fa fa-check"></i><b>16.5</b> Exercises</a></li>
<li class="chapter" data-level="16.6" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#references-9"><i class="fa fa-check"></i><b>16.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="rare-events.html"><a href="rare-events.html"><i class="fa fa-check"></i><b>17</b> Rare Events</a><ul>
<li class="chapter" data-level="" data-path="rare-events.html"><a href="rare-events.html#prerequisites-10"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="17.1" data-path="rare-events.html"><a href="rare-events.html#introduction-5"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="rare-events.html"><a href="rare-events.html#finite-sample-bias"><i class="fa fa-check"></i><b>17.2</b> Finite-Sample Bias</a></li>
<li class="chapter" data-level="17.3" data-path="rare-events.html"><a href="rare-events.html#case-control"><i class="fa fa-check"></i><b>17.3</b> Case Control</a></li>
<li class="chapter" data-level="17.4" data-path="rare-events.html"><a href="rare-events.html#questions-4"><i class="fa fa-check"></i><b>17.4</b> Questions</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="shrinkage-and-hierarchical-models.html"><a href="shrinkage-and-hierarchical-models.html"><i class="fa fa-check"></i><b>18</b> Shrinkage and Hierarchical Models</a><ul>
<li class="chapter" data-level="18.1" data-path="shrinkage-and-hierarchical-models.html"><a href="shrinkage-and-hierarchical-models.html#hierarchical-models"><i class="fa fa-check"></i><b>18.1</b> Hierarchical Models</a></li>
<li class="chapter" data-level="18.2" data-path="shrinkage-and-hierarchical-models.html"><a href="shrinkage-and-hierarchical-models.html#baseball-hits"><i class="fa fa-check"></i><b>18.2</b> Baseball Hits</a><ul>
<li class="chapter" data-level="18.2.1" data-path="shrinkage-and-hierarchical-models.html"><a href="shrinkage-and-hierarchical-models.html#references-10"><i class="fa fa-check"></i><b>18.2.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html"><i class="fa fa-check"></i><b>19</b> Shrinkage and Regularized Regression</a><ul>
<li class="chapter" data-level="" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#prerequisites-11"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="19.1" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#introduction-6"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#shrinkage-estimators"><i class="fa fa-check"></i><b>19.2</b> Shrinkage Estimators</a><ul>
<li class="chapter" data-level="19.2.1" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#penalized-maximum-likelihood-regression"><i class="fa fa-check"></i><b>19.2.1</b> Penalized Maximum Likelihood Regression</a></li>
<li class="chapter" data-level="19.2.2" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#bayesian-shrinkage"><i class="fa fa-check"></i><b>19.2.2</b> Bayesian Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#sparse-shrinkage"><i class="fa fa-check"></i><b>19.3</b> Sparse Shrinkage</a><ul>
<li class="chapter" data-level="19.3.1" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#penalized-likelihood"><i class="fa fa-check"></i><b>19.3.1</b> Penalized Likelihood</a></li>
<li class="chapter" data-level="19.3.2" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#bayesian-sparse-shrinkage-models"><i class="fa fa-check"></i><b>19.3.2</b> Bayesian Sparse Shrinkage Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#section"><i class="fa fa-check"></i><b>19.4</b> </a><ul>
<li class="chapter" data-level="19.4.1" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#shrinkage-factor"><i class="fa fa-check"></i><b>19.4.1</b> Shrinkage Factor</a></li>
<li class="chapter" data-level="19.4.2" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#prior-on-the-global-scale"><i class="fa fa-check"></i><b>19.4.2</b> Prior on the Global Scale</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#differences-between-bayesian-and-penalized-ml"><i class="fa fa-check"></i><b>19.5</b> Differences between Bayesian and Penalized ML</a></li>
<li class="chapter" data-level="19.6" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#examples-3"><i class="fa fa-check"></i><b>19.6</b> Examples</a><ul>
<li class="chapter" data-level="19.6.1" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#diabetes"><i class="fa fa-check"></i><b>19.6.1</b> Diabetes</a></li>
<li class="chapter" data-level="19.6.2" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#example-4"><i class="fa fa-check"></i><b>19.6.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="19.7" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#shrinkage-with-correlated-variables"><i class="fa fa-check"></i><b>19.7</b> Shrinkage with Correlated Variables</a></li>
<li class="chapter" data-level="19.8" data-path="shrinkage-and-regularized-regression.html"><a href="shrinkage-and-regularized-regression.html#variable-selection"><i class="fa fa-check"></i><b>19.8</b> Variable Selection</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>20</b> Multilevel Models</a><ul>
<li class="chapter" data-level="20.1" data-path="multilevel-models.html"><a href="multilevel-models.html#terminology"><i class="fa fa-check"></i><b>20.1</b> Terminology</a></li>
<li class="chapter" data-level="20.2" data-path="multilevel-models.html"><a href="multilevel-models.html#normal"><i class="fa fa-check"></i><b>20.2</b> Normal</a></li>
<li class="chapter" data-level="20.3" data-path="multilevel-models.html"><a href="multilevel-models.html#example-radon"><i class="fa fa-check"></i><b>20.3</b> Example: Radon</a><ul>
<li class="chapter" data-level="20.3.1" data-path="multilevel-models.html"><a href="multilevel-models.html#data"><i class="fa fa-check"></i><b>20.3.1</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="multilevel-models.html"><a href="multilevel-models.html#radon-example"><i class="fa fa-check"></i><b>20.4</b> Radon Example</a></li>
<li class="chapter" data-level="20.5" data-path="multilevel-models.html"><a href="multilevel-models.html#with-individual-covariates"><i class="fa fa-check"></i><b>20.5</b> With Individual Covariates</a></li>
<li class="chapter" data-level="20.6" data-path="multilevel-models.html"><a href="multilevel-models.html#with-group-level-covariates"><i class="fa fa-check"></i><b>20.6</b> With Group-Level Covariates</a></li>
<li class="chapter" data-level="20.7" data-path="multilevel-models.html"><a href="multilevel-models.html#pooling-of-hierarchical-parameters"><i class="fa fa-check"></i><b>20.7</b> Pooling of Hierarchical Parameters</a></li>
<li class="chapter" data-level="20.8" data-path="multilevel-models.html"><a href="multilevel-models.html#lme4"><i class="fa fa-check"></i><b>20.8</b> lme4</a></li>
<li class="chapter" data-level="20.9" data-path="multilevel-models.html"><a href="multilevel-models.html#covariance-priors"><i class="fa fa-check"></i><b>20.9</b> Priors for Covariances</a></li>
<li class="chapter" data-level="20.10" data-path="multilevel-models.html"><a href="multilevel-models.html#cetered-and-non-centered-parameterizations"><i class="fa fa-check"></i><b>20.10</b> Cetered and Non-centered Parameterizations</a></li>
<li class="chapter" data-level="20.11" data-path="multilevel-models.html"><a href="multilevel-models.html#extensions-1"><i class="fa fa-check"></i><b>20.11</b> Extensions</a></li>
<li class="chapter" data-level="20.12" data-path="multilevel-models.html"><a href="multilevel-models.html#miscellaneous"><i class="fa fa-check"></i><b>20.12</b> Miscellaneous</a><ul>
<li class="chapter" data-level="20.12.1" data-path="multilevel-models.html"><a href="multilevel-models.html#how-many-groups"><i class="fa fa-check"></i><b>20.12.1</b> How many groups?</a></li>
<li class="chapter" data-level="20.12.2" data-path="multilevel-models.html"><a href="multilevel-models.html#correlation-between-predictors-and-errors"><i class="fa fa-check"></i><b>20.12.2</b> Correlation between Predictors and Errors</a></li>
</ul></li>
<li class="chapter" data-level="20.13" data-path="multilevel-models.html"><a href="multilevel-models.html#references-11"><i class="fa fa-check"></i><b>20.13</b> References</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#prerequisites-12"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="20.14" data-path="appendix.html"><a href="appendix.html#parameters"><i class="fa fa-check"></i><b>20.14</b> Parameters</a></li>
<li class="chapter" data-level="20.15" data-path="appendix.html"><a href="appendix.html#miscellaneous-mathematical-background"><i class="fa fa-check"></i><b>20.15</b> Miscellaneous Mathematical Background</a><ul>
<li class="chapter" data-level="20.15.1" data-path="appendix.html"><a href="appendix.html#location-scale-families"><i class="fa fa-check"></i><b>20.15.1</b> Location-Scale Families</a></li>
<li class="chapter" data-level="20.15.2" data-path="appendix.html"><a href="appendix.html#scale-mixtures-of-normal-distributions"><i class="fa fa-check"></i><b>20.15.2</b> Scale Mixtures of Normal Distributions</a></li>
<li class="chapter" data-level="20.15.3" data-path="appendix.html"><a href="appendix.html#covariance-correlation-matrix-decomposition"><i class="fa fa-check"></i><b>20.15.3</b> Covariance-Correlation Matrix Decomposition</a></li>
<li class="chapter" data-level="20.15.4" data-path="appendix.html"><a href="appendix.html#qr-factorization"><i class="fa fa-check"></i><b>20.15.4</b> QR Factorization</a></li>
<li class="chapter" data-level="20.15.5" data-path="appendix.html"><a href="appendix.html#cholesky-decomposition"><i class="fa fa-check"></i><b>20.15.5</b> Cholesky Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="20.16" data-path="appendix.html"><a href="appendix.html#scaled-and-unscaled-variables"><i class="fa fa-check"></i><b>20.16</b> Scaled and Unscaled Variables</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>21</b> Distributions</a></li>
<li class="chapter" data-level="22" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html"><i class="fa fa-check"></i><b>22</b> Annotated Bibliography</a><ul>
<li class="chapter" data-level="22.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#textbooks"><i class="fa fa-check"></i><b>22.1</b> Textbooks</a></li>
<li class="chapter" data-level="22.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#syllabi"><i class="fa fa-check"></i><b>22.2</b> Syllabi</a></li>
<li class="chapter" data-level="22.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#topics"><i class="fa fa-check"></i><b>22.3</b> Topics</a></li>
<li class="chapter" data-level="22.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayes-theorem-1"><i class="fa fa-check"></i><b>22.4</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="22.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#article-length-introductions-to-bayesian-statistics"><i class="fa fa-check"></i><b>22.5</b> Article Length Introductions to Bayesian Statistics</a><ul>
<li class="chapter" data-level="22.5.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#why-bayesian"><i class="fa fa-check"></i><b>22.5.1</b> Why Bayesian</a></li>
<li class="chapter" data-level="22.5.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#modern-statistical-workflow"><i class="fa fa-check"></i><b>22.5.2</b> Modern Statistical Workflow</a></li>
<li class="chapter" data-level="22.5.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-philosophy"><i class="fa fa-check"></i><b>22.5.3</b> Bayesian Philosophy</a></li>
<li class="chapter" data-level="22.5.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>22.5.4</b> Bayesian Hypothesis Testing</a></li>
<li class="chapter" data-level="22.5.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-frequentist-debates"><i class="fa fa-check"></i><b>22.5.5</b> Bayesian Frequentist Debates</a></li>
<li class="chapter" data-level="22.5.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#categorical"><i class="fa fa-check"></i><b>22.5.6</b> Categorical</a></li>
<li class="chapter" data-level="22.5.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#variable-selection-1"><i class="fa fa-check"></i><b>22.5.7</b> Variable Selection</a></li>
<li class="chapter" data-level="22.5.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multiple-testing"><i class="fa fa-check"></i><b>22.5.8</b> Multiple Testing</a></li>
<li class="chapter" data-level="22.5.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#rare-events-1"><i class="fa fa-check"></i><b>22.5.9</b> Rare Events</a></li>
<li class="chapter" data-level="22.5.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#identifiability"><i class="fa fa-check"></i><b>22.5.10</b> Identifiability</a></li>
<li class="chapter" data-level="22.5.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkage"><i class="fa fa-check"></i><b>22.5.11</b> Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="22.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software"><i class="fa fa-check"></i><b>22.6</b> Software</a><ul>
<li class="chapter" data-level="22.6.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#stan-2"><i class="fa fa-check"></i><b>22.6.1</b> Stan</a></li>
<li class="chapter" data-level="22.6.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#diagrams"><i class="fa fa-check"></i><b>22.6.2</b> Diagrams</a></li>
<li class="chapter" data-level="22.6.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#priors-1"><i class="fa fa-check"></i><b>22.6.3</b> Priors</a></li>
</ul></li>
<li class="chapter" data-level="22.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-model-averaging-1"><i class="fa fa-check"></i><b>22.7</b> Bayesian Model Averaging</a></li>
<li class="chapter" data-level="22.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multilevel-modeling"><i class="fa fa-check"></i><b>22.8</b> Multilevel Modeling</a></li>
<li class="chapter" data-level="22.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#mixture-models-1"><i class="fa fa-check"></i><b>22.9</b> Mixture Models</a></li>
<li class="chapter" data-level="22.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#inference"><i class="fa fa-check"></i><b>22.10</b> Inference</a><ul>
<li class="chapter" data-level="22.10.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#discussion-of-bayesian-inference"><i class="fa fa-check"></i><b>22.10.1</b> Discussion of Bayesian Inference</a></li>
</ul></li>
<li class="chapter" data-level="22.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#model-checking-1"><i class="fa fa-check"></i><b>22.11</b> Model Checking</a><ul>
<li class="chapter" data-level="22.11.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#posterior-predictive-checks-1"><i class="fa fa-check"></i><b>22.11.1</b> Posterior Predictive Checks</a></li>
<li class="chapter" data-level="22.11.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#prediction-criteria"><i class="fa fa-check"></i><b>22.11.2</b> Prediction Criteria</a></li>
<li class="chapter" data-level="22.11.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software-validation"><i class="fa fa-check"></i><b>22.11.3</b> Software Validation</a></li>
</ul></li>
<li class="chapter" data-level="22.12" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#hierarchical-modeling"><i class="fa fa-check"></i><b>22.12</b> Hierarchical Modeling</a></li>
<li class="chapter" data-level="22.13" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkageregularization"><i class="fa fa-check"></i><b>22.13</b> Shrinkage/Regularization</a></li>
<li class="chapter" data-level="22.14" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#empirical-bayes"><i class="fa fa-check"></i><b>22.14</b> Empirical Bayes</a></li>
<li class="chapter" data-level="22.15" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#history-of-bayesian-statistics"><i class="fa fa-check"></i><b>22.15</b> History of Bayesian Statistics</a></li>
<li class="chapter" data-level="22.16" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#sampling-difficulties"><i class="fa fa-check"></i><b>22.16</b> Sampling Difficulties</a></li>
<li class="chapter" data-level="22.17" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#complicated-estimation-and-testing"><i class="fa fa-check"></i><b>22.17</b> Complicated Estimation and Testing</a></li>
<li class="chapter" data-level="22.18" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#pooling-polls"><i class="fa fa-check"></i><b>22.18</b> Pooling Polls</a></li>
<li class="chapter" data-level="22.19" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#visualizing-mcmc-methods"><i class="fa fa-check"></i><b>22.19</b> Visualizing MCMC Methods</a></li>
<li class="chapter" data-level="22.20" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-point-estimation-decision"><i class="fa fa-check"></i><b>22.20</b> Bayesian point estimation / Decision</a></li>
<li class="chapter" data-level="22.21" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#stan-modeling-language"><i class="fa fa-check"></i><b>22.21</b> Stan Modeling Language</a></li>
<li class="chapter" data-level="22.22" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayes-factors"><i class="fa fa-check"></i><b>22.22</b> Bayes Factors</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-12.html"><a href="references-12.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Updating: A Set of Bayesian Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\median}{median}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\logistic}{Logistic}
\DeclareMathOperator{\logit}{Logit}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

% This follows BDA
\newcommand{\dunif}{\mathsf{Uniform}}
\newcommand{\dnorm}{\mathsf{Normal}}
\newcommand{\dhalfnorm}{\mathrm{HalfNormal}}
\newcommand{\dlnorm}{\mathsf{LogNormal}}
\newcommand{\dmvnorm}{\mathsf{Normal}}
\newcommand{\dgamma}{\mathsf{Gamma}}
\newcommand{\dinvgamma}{\mathsf{InvGamma}}
\newcommand{\dchisq}{\mathsf{ChiSquared}}
\newcommand{\dinvchisq}{\mathsf{InvChiSquared}}
\newcommand{\dexp}{\mathsf{Exponential}}
\newcommand{\dlaplace}{\mathsf{Laplace}}
\newcommand{\dweibull}{\mathsf{Weibull}}
\newcommand{\dwishart}{\mathsf{Wishart}}
\newcommand{\dinvwishart}{\mathsf{InvWishart}}
\newcommand{\dlkj}{\mathsf{LkjCorr}}
\newcommand{\dt}{\mathsf{StudentT}}
\newcommand{\dhalft}{\mathsf{HalfStudentT}}
\newcommand{\dbeta}{\mathsf{Beta}}
\newcommand{\ddirichlet}{\mathsf{Dirichlet}}
\newcommand{\dlogistic}{\mathsf{Logistic}}
\newcommand{\dllogistic}{\mathsf{LogLogistic}}
\newcommand{\dpois}{\mathsf{Poisson}}
\newcommand{\dBinom}{\mathsf{Binomial}}
\newcommand{\dmultinom}{\mathsf{Multinom}}
\newcommand{\dnbinom}{\mathsf{NegativeBinomial}}
\newcommand{\dnbinomalt}{\mathsf{NegativeBinomial2}}
\newcommand{\dbetabinom}{\mathsf{BetaBinomial}}
\newcommand{\dcauchy}{\mathsf{Cauchy}}
\newcommand{\dhalfcauchy}{\mathsf{HalfCauchy}}
\newcommand{\dbernoulli}{\mathsf{Bernoulli}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Reals}{\R}
\newcommand{\RealPos}{\R^{+}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Nats}{\N}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}

\DeclareMathOperator{\invlogit}{Inv-Logit}
\DeclareMathOperator{\logit}{Logit}
\DeclareMathOperator{\diag}{diag}

\]
<div id="robust-regression" class="section level1">
<h1><span class="header-section-number">15</span> Robust Regression</h1>
<div id="prerequisites-8" class="section level2 unnumbered">
<h2>Prerequisites</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;rstanarm&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;bayz&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;loo&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;jrnold.bayes.notes&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;recipes&quot;</span>)</code></pre>
</div>
<div id="wide-tailed-distributions" class="section level2">
<h2><span class="header-section-number">15.1</span> Wide Tailed Distributions</h2>
<p>Like OLS, Bayesian linear regression with normally distributed errors is
sensitive to outliers.
This is because the normal distribution has narrow tail probabilities,
with approximately 99.8% of the probability within three standard deviations.</p>
<p><a href="https://en.wikipedia.org/wiki/Robust_regression">Robust regression</a> refers to regression methods which are less sensitive to outliers.
Bayesian robust regression uses distributions with wider tails than the normal instead of the normal.
This plots the normal, Double Exponential (Laplace), and Student-t (<span class="math inline">\(df = 4\)</span>)
distributions all with mean 0 and scale 1, and the surprise (<span class="math inline">\(- log(p)\)</span>) at each point.
Both the Student-<span class="math inline">\(t\)</span> and Double Exponential distributions have surprise values well below the normal in the ranges (-6, 6).<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>
This means that outliers will have less of an affect on the log-posterior of models using these distributions.
The regression line would need to move less incorporate those observations since the error distribution will not consider them as unusual.</p>
<p><img src="robust_files/figure-html/unnamed-chunk-2-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p><img src="robust_files/figure-html/unnamed-chunk-3-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="student-t-distribution" class="section level2">
<h2><span class="header-section-number">15.2</span> Student-t distribution</h2>
<p>The most commonly used Bayesian model for robust regression is a linear regression with independent Student-<span class="math inline">\(t\)</span> errors <span class="citation">(Geweke 1993; A. Gelman, Carlin, et al. 2013, Ch. 17)</span>:
<span class="math display">\[
y_i \sim \dt\left(\nu, \mu_i, \sigma \right)
\]</span>
where <span class="math inline">\(\nu \in \R^{+}\)</span> is a degrees of freedom parameter, <span class="math inline">\(\mu_i \in \R\)</span> are observation specific locations often modeled with a regression, and and <span class="math inline">\(\sigma \in R^{+}\)</span> is a
the scale parameter.</p>
<p>Note that as <span class="math inline">\(\nu \to \infty\)</span>, this model approaches an independent normal model, since
the Student-t distribution asymptotically approaches the normal distribution as the degrees of freedom increases.
For the value of <span class="math inline">\(\nu\)</span>, either a low degrees of freedom <span class="math inline">\(\nu \in (4, 6)\)</span> can be used, or
it can be given a prior distribution.
For the Student-t distribution, the existence of various moments depends on the value of <span class="math inline">\(\nu\)</span>: the mean exists for <span class="math inline">\(\nu &gt; 1\)</span>, variance for <span class="math inline">\(\nu &gt; 2\)</span>, and kurtosis for <span class="math inline">\(\nu &gt; 3\)</span>.
As such, it is often useful to restrict the support of <span class="math inline">\(\nu\)</span> to at least 1 or 2 (or even higher) ensure the existence of a mean or variance.</p>
<p>A reasonable prior distribution for the degrees of freedom parameter is a Gamma
distribution with shape parameter 2, and an inverse-scale (rate) parameter of 0.1 <span class="citation">(Juárez and Steel 2010,<span class="citation">@Stan-prior-choices</span>)</span>,
<span class="math display">\[
\nu \sim \dgamma(2, 0.1) .
\]</span>
<img src="robust_files/figure-html/unnamed-chunk-4-1.png" width="70%" style="display: block; margin: auto;" />
This density places the majority of the prior mass for values <span class="math inline">\(\nu &lt; 50\)</span>, in which
the Student-<span class="math inline">\(t\)</span> distribution is substantively different from the Normal distribution,
and also allows for all prior moments to exist.</p>
<p>The Stan model that estimates this is <code>lm_student_t_1.stan</code>:
<pre class="stan">
<code>// lm_student_t_1.stan
// Linear Model with Student-t Errors
data {
  // number of observations
  int<lower=0> N;
  // response
  vector[N] y;
  // number of columns in the design matrix X
  int<lower=0> K;
  // design matrix X
  // should not include an intercept
  matrix [N, K] X;
  // priors on alpha
  real<lower=0.> scale_alpha;
  vector<lower=0.>[K] scale_beta;
  real<lower=0.> loc_sigma;
  // keep responses
  int<lower=0, upper=1> use_y_rep;
  int<lower=0, upper=1> use_log_lik;
}
parameters {
  // regression coefficient vector
  real alpha;
  vector[K] beta;
  real<lower=0.> sigma;
  // degrees of freedom;
  // limit df = 2 so that there is a finite variance
  real<lower=2.> nu;
}
transformed parameters {
  vector[N] mu;

  mu = alpha + X * beta;
}
model {
  // priors
  alpha ~ normal(0.0, scale_alpha);
  beta ~ normal(0.0, scale_beta);
  sigma ~ exponential(loc_sigma);
  // see Stan prior distribution suggestions
  nu ~ gamma(2, 0.1);
  // likelihood
  y ~ student_t(nu, mu, sigma);
}
generated quantities {
  // simulate data from the posterior
  vector[N * use_y_rep] y_rep;
  // log-likelihood posterior
  vector[N * use_log_lik] log_lik;
  for (i in 1:num_elements(y_rep)) {
    y_rep[i] = student_t_rng(nu, mu[i], sigma);
  }
  for (i in 1:num_elements(log_lik)) {
    log_lik[i] = student_t_lpdf(y[i] | nu, mu[i], sigma);
  }
}</code>
</pre></p>
<p>As noted in <a href="heteroskedasticity.html#heteroskedasticity">Heteroskedasticity</a>, the Student-t distribution can be represented as a
scale-mixture of normal distributions, where the inverse-variances (precisions) follow
a Gamma distribution,
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm\left(\mu_i, \omega^2 \lambda_i^2 \right) \\
\lambda^{-2} &amp;\sim \dgamma\left(\nu / 2, \nu / 2\right)
\end{aligned}
\]</span>
The scale mixture distribution of normal parameterization of the Student t distribution is useful for computational reasons.
A Stan model that implements this scale mixture of normal distribution representation of the Student-t distribution is <code>lm_student_t_2.stan</code>:
<pre class="stan">
<code>// lm_student_t_2.stan
// Linear Model with Student-t Errors
data {
  // number of observations
  int<lower=0> N;
  // response
  vector[N] y;
  // number of columns in the design matrix X
  int<lower=0> K;
  // design matrix X
  // should not include an intercept
  matrix [N, K] X;
  // priors on alpha
  real<lower=0.> scale_alpha;
  vector<lower=0.>[K] scale_beta;
  real<lower=0.> loc_sigma;
  // keep responses
  int<lower=0, upper=1> use_y_rep;
  int<lower=0, upper=1> use_log_lik;
}
parameters {
  // regression coefficient vector
  real alpha;
  vector[K] beta;
  // regression scale
  real<lower=0.> sigma;
  // 1 / lambda_i^2
  vector<lower = 0.0>[N] inv_lambda2;
  // degrees of freedom;
  // limit df = 2 so that there is a finite variance
  real<lower=2.> nu;
}
transformed parameters {
  vector[N] mu;
  vector[N] omega;
  // observation variances
  for (n in 1:N) {
    omega[n] = sigma / sqrt(inv_lambda2[n]);
  }
  mu = alpha + X * beta;
}
model {
  real half_nu;

  // priors
  alpha ~ normal(0.0, scale_alpha);
  beta ~ normal(0.0, scale_beta);
  sigma ~ exponential(loc_sigma);
  nu ~ gamma(2, 0.1);
  half_nu = 0.5 * nu;
  inv_lambda2 ~ gamma(half_nu, half_nu);
  // likelihood with obs specific scales
  y ~ normal(mu, sigma);
}
generated quantities {
  // simulate data from the posterior
  vector[N * use_y_rep] y_rep;
  // log-likelihood posterior
  vector[N * use_log_lik] log_lik;
  for (n in 1:num_elements(y_rep)) {
    y_rep[n] = student_t_rng(nu, mu[n], omega[n]);
  }
  for (n in 1:num_elements(log_lik)) {
    log_lik[n] = student_t_lpdf(y[n] | nu, mu[n], omega[n]);
  }
}</code>
</pre></p>
<p>Another reparameterization of these models that is useful computationally is
The variance of the Student-t distribution is a function of the scale and the degree-of-freedom parameters.
Suppose <span class="math inline">\(X \sim \dt(\nu, \mu, \sigma)\)</span>, then
<span class="math display">\[
\Var(X) = \frac{\nu}{\nu - 2} \sigma^2.
\]</span>
So variance of data can be fit better by <em>either</em> increasing <span class="math inline">\(\nu\)</span> or increasing the scale <span class="math inline">\(\sigma\)</span>.
This will create posterior correlations between the parameters, and make it more difficult to sample the posterior distribution.
We can reparameterize the model to make <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(\nu\)</span> less correlated by multiplying the scale by the degrees of freedom.
<span class="math display">\[
\begin{aligned}
y_i \sim \dt\left(\nu, \mu_i, \sigma \sqrt{\frac{\nu - 2}{\nu}} \right)
\end{aligned}
\]</span>
In this model, changing the value of <span class="math inline">\(\nu\)</span> has no effect on the variance of <span class="math inline">\(y\)</span>, since
<span class="math display">\[
\Var(y_i) = \frac{\nu}{\nu - 2} \sigma^2 \frac{\nu - 2}{\nu} = \sigma^2 .
\]</span></p>
<div id="examples-2" class="section level3">
<h3><span class="header-section-number">15.2.1</span> Examples</h3>
<p>Estimate some examples with known outliers and compare to using a normal
See the data examples <code>income_ineq</code>, <code>unionization</code>, and <code>econ_growth</code> in the
associated <strong>jrnold.bayes.notes</strong> package.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;econ_growth&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;jrnold.bayes.notes&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">rec_union &lt;-
<span class="st">  </span><span class="kw">recipe</span>(union_density <span class="op">~</span><span class="st"> </span>left_government <span class="op">+</span><span class="st"> </span>labor_force_size <span class="op">+</span><span class="st"> </span>econ_conc,
       <span class="dt">data =</span> unionization) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">step_center</span>(<span class="kw">everything</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">step_scale</span>(<span class="kw">everything</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">prep</span>(<span class="dt">retain =</span> <span class="ot">TRUE</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">union_data &lt;-<span class="st"> </span><span class="kw">lst</span>(
  <span class="dt">X =</span> <span class="kw">juice</span>(rec_union, <span class="kw">all_predictors</span>(), <span class="dt">composition =</span> <span class="st">&quot;matrix&quot;</span>),
  <span class="dt">y =</span> <span class="kw">drop</span>(<span class="kw">juice</span>(rec_union, <span class="kw">all_outcomes</span>(), <span class="dt">composition =</span> <span class="st">&quot;matrix&quot;</span>)),
  <span class="dt">N =</span> <span class="kw">nrow</span>(X),
  <span class="dt">K =</span> <span class="kw">ncol</span>(X),
  <span class="dt">scale_alpha =</span> <span class="dv">10</span>,
  <span class="dt">scale_beta =</span><span class="kw">rep</span>(<span class="fl">2.5</span>, K),
  <span class="dt">loc_sigma =</span> <span class="dv">1</span>,
  <span class="dt">use_y_rep =</span> <span class="dv">1</span>,
  <span class="dt">use_log_lik =</span> <span class="dv">1</span>,
  <span class="dt">d =</span> <span class="dv">4</span>
)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">rec_econ_growth &lt;-
<span class="st">  </span><span class="kw">recipe</span>(econ_growth <span class="op">~</span><span class="st"> </span>labor_org <span class="op">+</span><span class="st"> </span>social_dem,
       <span class="dt">data =</span> econ_growth) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">step_interact</span>(<span class="op">~</span><span class="st"> </span>labor_org <span class="op">*</span><span class="st"> </span>social_dem, <span class="dt">sep =</span> <span class="st">&quot;:&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">step_center</span>(<span class="kw">everything</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">step_scale</span>(<span class="kw">everything</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">prep</span>(<span class="dt">retain =</span> <span class="ot">TRUE</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">econ_growth_data &lt;-<span class="st"> </span><span class="kw">lst</span>(
  <span class="dt">X =</span> <span class="kw">juice</span>(rec_econ_growth, <span class="kw">all_predictors</span>(), <span class="dt">composition =</span> <span class="st">&quot;matrix&quot;</span>),
  <span class="dt">y =</span> <span class="kw">drop</span>(<span class="kw">juice</span>(rec_econ_growth, <span class="kw">all_outcomes</span>(), <span class="dt">composition =</span> <span class="st">&quot;matrix&quot;</span>)),
  <span class="dt">N =</span> <span class="kw">nrow</span>(X),
  <span class="dt">K =</span> <span class="kw">ncol</span>(X),
  <span class="dt">scale_alpha =</span> <span class="dv">10</span>,
  <span class="dt">scale_beta =</span><span class="kw">rep</span>(<span class="fl">2.5</span>, K),
  <span class="dt">loc_sigma =</span> <span class="dv">1</span>,
  <span class="dt">use_y_rep =</span> <span class="dv">1</span>,
  <span class="dt">use_log_lik =</span> <span class="dv">1</span>,
  <span class="dt">d =</span> <span class="dv">4</span>
)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">models &lt;-<span class="st"> </span><span class="kw">list</span>()
models[[<span class="st">&quot;lm_normal_1&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm_normal_1.stan&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fits &lt;-<span class="st"> </span><span class="kw">list</span>()
fits[[<span class="st">&quot;econ_normal&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">sampling</span>(models[[<span class="st">&quot;lm_normal_1&quot;</span>]], <span class="dt">data =</span> econ_growth_data)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">models[[<span class="st">&quot;lm_student_t_0&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm_student_t_0.stan&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fits[[<span class="st">&quot;econ_t0&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">sampling</span>(models[[<span class="st">&quot;lm_student_t_0&quot;</span>]], <span class="dt">data =</span> econ_growth_data, <span class="dt">refresh =</span> <span class="dv">-1</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">models[[<span class="st">&quot;lm_student_t_1&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm_student_t_1.stan&quot;</span>)
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:1:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Core:531:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:2:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/LU:47:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:12:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Jacobi:29:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:3:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Cholesky:43:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/QR:17:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Householder:27:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:5:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SVD:48:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:6:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Geometry:58:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core.hpp:14:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/core/matrix_vari.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat/fun/Eigen_NumTraits.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Dense:7:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Eigenvalues:58:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:26:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCore:66:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:27:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/OrderingMethods:71:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:29:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseCholesky:43:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:32:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/SparseQR:35:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; In file included from file199a4ffb80c1.cpp:8:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math.hpp:4:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/rev/mat.hpp:12:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat.hpp:83:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/StanHeaders/include/stan/math/prim/mat/fun/csr_extract_u.hpp:6:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/Sparse:33:</span>
<span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/IterativeLinearSolvers:46:</span>
<span class="co">#&gt; /Users/jrnold/Library/R/3.5/library/RcppEigen/include/Eigen/src/Core/util/ReenableStupidWarnings.h:10:30: warning: pragma diagnostic pop could not pop, no matching push [-Wunknown-pragmas]</span>
<span class="co">#&gt;     #pragma clang diagnostic pop</span>
<span class="co">#&gt;                              ^</span>
<span class="co">#&gt; 13 warnings generated.</span>
<span class="co">#&gt; ld: warning: directory not found for option &#39;-L/usr/local/opt/llvm/lib/clang/5.0.0/lib/darwin/&#39;</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fits[[<span class="st">&quot;mod_student_t_1&quot;</span>]]
<span class="co">#&gt; NULL</span>
fit_econ_t1 &lt;-<span class="st"> </span><span class="kw">sampling</span>(models[[<span class="st">&quot;lm_student_t_1&quot;</span>]], <span class="dt">data =</span> econ_growth_data, <span class="dt">refresh =</span> <span class="dv">-1</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">models[[<span class="st">&quot;lm_student_t_2&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm_student_t_2.stan&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fits[[<span class="st">&quot;econ_t2&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">sampling</span>(models[[<span class="st">&quot;lm_student_t_2&quot;</span>]], <span class="dt">data =</span> econ_growth_data, <span class="dt">refresh =</span> <span class="dv">-1</span>)
<span class="co">#&gt; Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See</span>
<span class="co">#&gt; http://mc-stan.org/misc/warnings.html#bfmi-low</span>
<span class="co">#&gt; Warning: Examine the pairs() plot to diagnose sampling problems</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">calc_loo &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
  ll &lt;-<span class="st"> </span><span class="kw">extract_log_lik</span>(x, <span class="st">&quot;log_lik&quot;</span>, 
                        <span class="dt">merge_chains =</span> <span class="ot">FALSE</span>)
  r_eff &lt;-<span class="st"> </span><span class="kw">relative_eff</span>(<span class="kw">exp</span>(ll))
  <span class="kw">loo</span>(ll, <span class="dt">r_eff =</span> r_eff)
}

model_loo &lt;-<span class="st"> </span><span class="kw">map</span>(fits, calc_loo)
<span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-diagnostic&#39;) for details.</span>

<span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-diagnostic&#39;) for details.</span>
<span class="co">#&gt; Warning: Some Pareto k diagnostic values are slightly high. See help(&#39;pareto-k-diagnostic&#39;) for details.</span>

<span class="kw">map</span>(model_loo, <span class="op">~</span><span class="st"> </span>.x[[<span class="st">&quot;estimates&quot;</span>]][<span class="st">&quot;elpd_loo&quot;</span>, <span class="st">&quot;Estimate&quot;</span>])
<span class="co">#&gt; $econ_normal</span>
<span class="co">#&gt; [1] -22.7</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $econ_t0</span>
<span class="co">#&gt; [1] -22.8</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $econ_t2</span>
<span class="co">#&gt; [1] -22.2</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">pars &lt;-<span class="st"> </span><span class="kw">imap_dfr</span>(fits, <span class="op">~</span><span class="st"> </span><span class="kw">mutate</span>(<span class="kw">tidyMCMC</span>(.x, <span class="dt">conf.int =</span> <span class="ot">TRUE</span>), <span class="dt">model =</span> .y))
  </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">data =</span> <span class="kw">filter</span>(pars, <span class="kw">str_detect</span>(term, <span class="st">&quot;^y_rep&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">                    </span><span class="kw">mutate</span>(<span class="dt">id =</span> <span class="kw">as.integer</span>(<span class="kw">str_extract</span>(term, <span class="st">&quot;</span><span class="ch">\\</span><span class="st">d+&quot;</span>))),
                <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> id, <span class="dt">y =</span> estimate, <span class="dt">ymin =</span> conf.low, <span class="dt">ymax =</span> conf.high, <span class="dt">colour =</span> model),
                <span class="dt">position =</span> <span class="kw">position_dodge</span>(<span class="dt">width =</span> <span class="fl">0.2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> <span class="kw">tibble</span>(<span class="dt">y =</span> econ_growth_data<span class="op">$</span>y,
                           <span class="dt">x =</span> <span class="kw">seq_along</span>(y)),
             <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre>
<p><img src="robust_files/figure-html/unnamed-chunk-14-1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">data =</span> <span class="kw">filter</span>(pars, <span class="kw">str_detect</span>(term, <span class="st">&quot;^beta&quot;</span>)),
                <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> term, <span class="dt">y =</span> estimate, <span class="dt">ymin =</span> conf.low, <span class="dt">ymax =</span> conf.high, <span class="dt">colour =</span> model),
                <span class="dt">position =</span> <span class="kw">position_dodge</span>(<span class="dt">width =</span> <span class="fl">0.2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre>
<p><img src="robust_files/figure-html/unnamed-chunk-15-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="robit" class="section level2">
<h2><span class="header-section-number">15.3</span> Robit</h2>
<p>The “robit” is a “robust” bivariate model.<span class="citation">(A. Gelman and Hill 2007, 125; Liu 2005)</span>
For the link-function the robit uses the CDF of the Student-t distribution with <span class="math inline">\(d\)</span> degrees of freedom.
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dBinom \left(n_i, \pi_i \right) \\
\pi_i &amp;= \int_{-\infty}^{\eta_i} \mathsf{StudentT}(x | \nu, 0, (\nu - 2)/ \nu) dx \\
\eta_i &amp;= \alpha + X \beta
\end{aligned}
\]</span>
Since the variance of a random variable distributed Student-<span class="math inline">\(t\)</span> is <span class="math inline">\(d / d - 2\)</span>, the scale fixes the variance of the distribution at 1.
Fixing the variance of the Student-<span class="math inline">\(t\)</span> distribution is not necessary if <span class="math inline">\(d\)</span> is fixed, but is necessary if <span class="math inline">\(d\)</span> were modeled as a parameter.
Where <span class="math inline">\(\nu\)</span> is given a low degrees of freedom <span class="math inline">\(\nu \in [3, 7]\)</span>, or a prior distribution.</p>
</div>
<div id="quantile-regression" class="section level2">
<h2><span class="header-section-number">15.4</span> Quantile regression</h2>
<p>A different form of robust regression and one that often serves a different purpose is quantile regression.</p>
<p><a href="https://en.wikipedia.org/wiki/Least_absolute_deviations">Least absolute deviation</a> (LAD) regression minimizes the following objective function,
<span class="math display">\[
\hat{\beta}_{LAD} = \arg \min_{\beta} \sum | y_i - \alpha - X \beta | .
\]</span>
The Bayesian analog is the <a href="https://en.wikipedia.org/wiki/Laplace_distribution">Laplace distribution</a>,
<span class="math display">\[
\dlaplace(x | \mu, \sigma) = \frac{1}{2 \sigma} \left( - \frac{|x - \mu|}{\sigma} \right) .
\]</span>
The Laplace distribution is analogous to least absolute deviations because the kernel of the distribution is <span class="math inline">\(|x - \mu|\)</span>, so minimizing the likelihood will also minimize the least absolute distances.</p>
<p>Thus, a linear regression with Laplace errors is analogous to a median regression.
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dlaplace\left( \alpha + X \beta, \sigma \right)
\end{aligned}
\]</span>
This can be generalized to other quantiles using the asymmetric Laplace distribution <span class="citation">(Benoit and Poel 2017, @YuZhang2005a)</span>.</p>
<div id="questions-3" class="section level3">
<h3><span class="header-section-number">15.4.1</span> Questions</h3>
<ol style="list-style-type: decimal">
<li><p>OLS is a model of the conditional mean <span class="math inline">\(E(y | x)\)</span>. A linear model with
normal errors is a model of the outcomes <span class="math inline">\(p(y | x)\)</span>. How would you estimate
the conditional mean, median, and quantile functions from the linear-normal
model? What role would quantile regression play? Hint: See <span class="citation">Benoit and Poel (2017 Sec. 3.4)</span>.</p></li>
<li><p>Implement the asymmetric Laplace distribution in Stan in two ways:</p>
<ul>
<li>Write a user function to calculate the log-PDF</li>
<li>Implement it as a scale-mixture of normal distributions</li>
</ul></li>
</ol>
</div>
</div>
<div id="references-8" class="section level2">
<h2><span class="header-section-number">15.5</span> References</h2>
<p>For more on robust regression see <span class="citation">A. Gelman and Hill (2007 sec 6.6)</span>, <span class="citation">A. Gelman, Carlin, et al. (2013 ch 17)</span>, and <span class="citation">Stan Development Team (2016 Sec 8.4)</span>.</p>
<p>For more on heteroskedasticity see <span class="citation">A. Gelman, Carlin, et al. (2013 Sec. 14.7)</span> for models with unequal variances and correlations.
<span class="citation">Stan Development Team (2016)</span> discusses reparameterizing the Student t distribution as a mixture of gamma distributions in Stan.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="11">
<li id="fn11"><p>The Double Exponential distribution still has a thinner tail than the Student-t at higher values.<a href="robust-regression.html#fnref11" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="separtion.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="heteroskedasticity.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/bayesian_notes/edit/master/robust.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
