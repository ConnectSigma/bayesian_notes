<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Updating: A Set of Bayesian Notes</title>
  <meta name="description" content="Updating: A Set of Bayesian Notes">
  <meta name="generator" content="bookdown 0.7.1 and GitBook 2.6.7">

  <meta property="og:title" content="Updating: A Set of Bayesian Notes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jrnold.github.io/bayesian_notes" />
  
  
  <meta name="github-repo" content="jrnold/bayesian_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Updating: A Set of Bayesian Notes" />
  <meta name="twitter:site" content="@jrnld" />
  
  

<meta name="author" content="Jeffrey B. Arnold">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="heteroskedasticity-and-robust-regression.html">
<link rel="next" href="binomial-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Bayesian Notes</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Theory</b></span></li>
<li class="chapter" data-level="1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>1</b> Bayesian Inference</a></li>
<li class="part"><span><b>II Computation</b></span></li>
<li class="chapter" data-level="2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>2</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>2.1</b> Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-sampling"><i class="fa fa-check"></i><b>2.2</b> Markov Chain Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#references"><i class="fa fa-check"></i><b>2.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>3</b> MCMC Diagnostics</a><ul>
<li class="chapter" data-level="3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#reparameterize-models"><i class="fa fa-check"></i><b>3.1</b> Reparameterize Models</a></li>
<li class="chapter" data-level="3.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#convergence-diagnostics"><i class="fa fa-check"></i><b>3.2</b> Convergence Diagnostics</a><ul>
<li class="chapter" data-level="3.2.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#potential-scale-reduction-hatr"><i class="fa fa-check"></i><b>3.2.1</b> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</a></li>
<li class="chapter" data-level="3.2.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#references-1"><i class="fa fa-check"></i><b>3.2.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation-effective-sample-size-and-mcse"><i class="fa fa-check"></i><b>3.3</b> Autocorrelation, Effective Sample Size, and MCSE</a><ul>
<li class="chapter" data-level="3.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#effective-sample-size"><i class="fa fa-check"></i><b>3.3.1</b> Effective Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#thinning"><i class="fa fa-check"></i><b>3.4</b> Thinning</a><ul>
<li class="chapter" data-level="3.4.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#traceplots"><i class="fa fa-check"></i><b>3.4.1</b> Traceplots</a></li>
<li class="chapter" data-level="3.4.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#monte-carlo-standard-error-mcse"><i class="fa fa-check"></i><b>3.4.2</b> Monte Carlo Standard Error (MCSE)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#hmc-nut-specific-diagnostics"><i class="fa fa-check"></i><b>3.5</b> HMC-NUT Specific Diagnostics</a><ul>
<li class="chapter" data-level="3.5.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#divergent-transitions"><i class="fa fa-check"></i><b>3.5.1</b> Divergent transitions</a></li>
<li class="chapter" data-level="3.5.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#maximum-treedepth"><i class="fa fa-check"></i><b>3.5.2</b> Maximum Treedepth</a></li>
<li class="chapter" data-level="3.5.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#bayesian-fraction-of-missing-information"><i class="fa fa-check"></i><b>3.5.3</b> Bayesian Fraction of Missing Information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="posterior-inference.html"><a href="posterior-inference.html"><i class="fa fa-check"></i><b>4</b> Posterior Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#prerequisites"><i class="fa fa-check"></i><b>4.1</b> Prerequisites</a></li>
<li class="chapter" data-level="4.2" data-path="posterior-inference.html"><a href="posterior-inference.html#introduction"><i class="fa fa-check"></i><b>4.2</b> Introduction</a></li>
<li class="chapter" data-level="4.3" data-path="posterior-inference.html"><a href="posterior-inference.html#functions-of-the-posterior-distribution"><i class="fa fa-check"></i><b>4.3</b> Functions of the Posterior Distribution</a></li>
<li class="chapter" data-level="4.4" data-path="posterior-inference.html"><a href="posterior-inference.html#marginal-effects"><i class="fa fa-check"></i><b>4.4</b> Marginal Effects</a><ul>
<li class="chapter" data-level="4.4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#example-marginal-effect-plot-for-x"><i class="fa fa-check"></i><b>4.4.1</b> Example: Marginal Effect Plot for X</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>5</b> Model Checking</a><ul>
<li class="chapter" data-level="5.1" data-path="model-checking.html"><a href="model-checking.html#why-check-models"><i class="fa fa-check"></i><b>5.1</b> Why check models?</a></li>
<li class="chapter" data-level="5.2" data-path="model-checking.html"><a href="model-checking.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2</b> Posterior Predictive Checks</a><ul>
<li class="chapter" data-level="5.2.1" data-path="model-checking.html"><a href="model-checking.html#bayesian-p-values"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian p-values</a></li>
<li class="chapter" data-level="5.2.2" data-path="model-checking.html"><a href="model-checking.html#test-quantities"><i class="fa fa-check"></i><b>5.2.2</b> Test quantities</a></li>
<li class="chapter" data-level="5.2.3" data-path="model-checking.html"><a href="model-checking.html#p-values-vs.u-values"><i class="fa fa-check"></i><b>5.2.3</b> p-values vs. u-values</a></li>
<li class="chapter" data-level="5.2.4" data-path="model-checking.html"><a href="model-checking.html#marginal-predictive-checks"><i class="fa fa-check"></i><b>5.2.4</b> Marginal predictive checks</a></li>
<li class="chapter" data-level="5.2.5" data-path="model-checking.html"><a href="model-checking.html#outliers"><i class="fa fa-check"></i><b>5.2.5</b> Outliers</a></li>
<li class="chapter" data-level="5.2.6" data-path="model-checking.html"><a href="model-checking.html#grapical-posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2.6</b> Grapical Posterior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="model-checking.html"><a href="model-checking.html#sources"><i class="fa fa-check"></i><b>5.3</b> Sources</a></li>
</ul></li>
<li class="part"><span><b>III Models</b></span></li>
<li class="chapter" data-level="6" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Introduction to Stan and Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#prerequites"><i class="fa fa-check"></i><b>6.1</b> Prerequites</a></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#the-statistical-model"><i class="fa fa-check"></i><b>6.2</b> The Statistical Model</a><ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling"><i class="fa fa-check"></i><b>6.2.1</b> Sampling</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#convergence-diagnostics-and-model-fit"><i class="fa fa-check"></i><b>6.2.2</b> Convergence Diagnostics and Model Fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html"><i class="fa fa-check"></i><b>7</b> Heteroskedasticity and Robust Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#prerequisites-1"><i class="fa fa-check"></i><b>7.1</b> Prerequisites</a></li>
<li class="chapter" data-level="7.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#linear-regression-with-student-t-distributed-errors"><i class="fa fa-check"></i><b>7.2</b> Linear Regression with Student t distributed errors</a><ul>
<li class="chapter" data-level="7.2.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#double-exponential-laplace-errors"><i class="fa fa-check"></i><b>7.2.1</b> Double Exponential (Laplace) Errors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity"><i class="fa fa-check"></i><b>7.3</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="7.3.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#covariates"><i class="fa fa-check"></i><b>7.3.1</b> Covariates</a></li>
<li class="chapter" data-level="7.3.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#student-t-error"><i class="fa fa-check"></i><b>7.3.2</b> Student-t Error</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#references-2"><i class="fa fa-check"></i><b>7.4</b> References</a><ul>
<li class="chapter" data-level="7.4.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#robust-regression"><i class="fa fa-check"></i><b>7.4.1</b> Robust regression</a></li>
<li class="chapter" data-level="7.4.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity-1"><i class="fa fa-check"></i><b>7.4.2</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="7.4.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#qunatile-regression"><i class="fa fa-check"></i><b>7.4.3</b> Qunatile regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>8</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="8.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#generalized-linear-models-1"><i class="fa fa-check"></i><b>8.1</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="8.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#count-models"><i class="fa fa-check"></i><b>8.2</b> Count Models</a><ul>
<li class="chapter" data-level="8.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson"><i class="fa fa-check"></i><b>8.2.1</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example"><i class="fa fa-check"></i><b>8.3</b> Example</a></li>
<li class="chapter" data-level="8.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#negative-binomial"><i class="fa fa-check"></i><b>8.4</b> Negative Binomial</a><ul>
<li class="chapter" data-level="8.4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-3"><i class="fa fa-check"></i><b>8.4.1</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial-categorical-models"><i class="fa fa-check"></i><b>8.5</b> Multinomial / Categorical Models</a></li>
<li class="chapter" data-level="8.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#gamma-regression"><i class="fa fa-check"></i><b>8.6</b> Gamma Regression</a></li>
<li class="chapter" data-level="8.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#beta-regression"><i class="fa fa-check"></i><b>8.7</b> Beta Regression</a></li>
<li class="chapter" data-level="8.8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-4"><i class="fa fa-check"></i><b>8.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="binomial-models.html"><a href="binomial-models.html"><i class="fa fa-check"></i><b>9</b> Binomial Models</a><ul>
<li class="chapter" data-level="9.0.1" data-path="binomial-models.html"><a href="binomial-models.html#link-functions-link-function"><i class="fa fa-check"></i><b>9.0.1</b> Link Functions {link-function}</a></li>
<li class="chapter" data-level="9.0.2" data-path="binomial-models.html"><a href="binomial-models.html#stan"><i class="fa fa-check"></i><b>9.0.2</b> Stan</a></li>
<li class="chapter" data-level="9.0.3" data-path="binomial-models.html"><a href="binomial-models.html#example-vote-turnout"><i class="fa fa-check"></i><b>9.0.3</b> Example: Vote Turnout</a></li>
<li class="chapter" data-level="9.0.4" data-path="binomial-models.html"><a href="binomial-models.html#separation"><i class="fa fa-check"></i><b>9.0.4</b> Separation</a></li>
<li class="chapter" data-level="9.1" data-path="binomial-models.html"><a href="binomial-models.html#rare-events-logit"><i class="fa fa-check"></i><b>9.1</b> Rare Events Logit</a></li>
<li class="chapter" data-level="9.2" data-path="binomial-models.html"><a href="binomial-models.html#case-control"><i class="fa fa-check"></i><b>9.2</b> Case Control</a><ul>
<li class="chapter" data-level="9.2.1" data-path="binomial-models.html"><a href="binomial-models.html#references-6"><i class="fa fa-check"></i><b>9.2.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html"><i class="fa fa-check"></i><b>10</b> Unbounded Count Models</a><ul>
<li class="chapter" data-level="10.1" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#poisson-1"><i class="fa fa-check"></i><b>10.1</b> Poisson</a></li>
<li class="chapter" data-level="10.2" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#negative-binomial-1"><i class="fa fa-check"></i><b>10.2</b> Negative Binomial</a><ul>
<li class="chapter" data-level="10.2.1" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#stan-1"><i class="fa fa-check"></i><b>10.2.1</b> Stan</a></li>
<li class="chapter" data-level="10.2.2" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#example-number-of-number-o"><i class="fa fa-check"></i><b>10.2.2</b> Example: Number of Number o</a></li>
<li class="chapter" data-level="10.2.3" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#references-7"><i class="fa fa-check"></i><b>10.2.3</b> References</a></li>
<li class="chapter" data-level="10.2.4" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#link-functions"><i class="fa fa-check"></i><b>10.2.4</b> Link functions</a></li>
<li class="chapter" data-level="10.2.5" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#stan-2"><i class="fa fa-check"></i><b>10.2.5</b> Stan</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#example-bilateral-sanctions"><i class="fa fa-check"></i><b>10.3</b> Example: Bilateral Sanctions</a></li>
<li class="chapter" data-level="10.4" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#negative-binomial-2"><i class="fa fa-check"></i><b>10.4</b> Negative Binomial</a><ul>
<li class="chapter" data-level="10.4.1" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#example-economic-sanctions-ii-ex-econ-sanctions-2"><i class="fa fa-check"></i><b>10.4.1</b> Example: Economic Sanctions II {ex-econ-sanctions-2}</a></li>
<li class="chapter" data-level="10.4.2" data-path="unbounded-count-models.html"><a href="unbounded-count-models.html#references-8"><i class="fa fa-check"></i><b>10.4.2</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="categorical-variables.html"><a href="categorical-variables.html"><i class="fa fa-check"></i><b>11</b> Categorical Variables</a><ul>
<li class="chapter" data-level="11.1" data-path="categorical-variables.html"><a href="categorical-variables.html#example-mexico-vote-choice"><i class="fa fa-check"></i><b>11.1</b> Example: Mexico Vote Choice</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html"><i class="fa fa-check"></i><b>12</b> Shrinkage and Regularization</a><ul>
<li class="chapter" data-level="12.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#normal-linear-regression-model"><i class="fa fa-check"></i><b>12.1</b> Normal Linear Regression Model</a></li>
<li class="chapter" data-level="12.2" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#penalized-regression"><i class="fa fa-check"></i><b>12.2</b> Penalized Regression</a><ul>
<li class="chapter" data-level="12.2.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#ridge-regression"><i class="fa fa-check"></i><b>12.2.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="12.2.2" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#lasso"><i class="fa fa-check"></i><b>12.2.2</b> Lasso</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#bayesian-shrinkage-priors"><i class="fa fa-check"></i><b>12.3</b> Bayesian Shrinkage Priors</a></li>
<li class="chapter" data-level="12.4" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#differences-between-bayesian-shrinkage-and-penalized-likelihood"><i class="fa fa-check"></i><b>12.4</b> Differences between Bayesian Shrinkage and Penalized Likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#hierarchical-shrinkage-priors"><i class="fa fa-check"></i><b>12.5</b> Hierarchical Shrinkage Priors</a></li>
<li class="chapter" data-level="12.6" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#example-1"><i class="fa fa-check"></i><b>12.6</b> Example</a><ul>
<li class="chapter" data-level="12.6.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#double-exponential-laplace-prior"><i class="fa fa-check"></i><b>12.6.1</b> Double Exponential (Laplace) Prior</a></li>
<li class="chapter" data-level="12.6.2" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#hierarchical-prior-hs"><i class="fa fa-check"></i><b>12.6.2</b> Hierarchical Prior (HS)</a></li>
<li class="chapter" data-level="12.6.3" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#comparison"><i class="fa fa-check"></i><b>12.6.3</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#shrinkage-parameters"><i class="fa fa-check"></i><b>12.7</b> Shrinkage Parameters</a></li>
<li class="chapter" data-level="12.8" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#choice-of-hyperparameter-on-tau"><i class="fa fa-check"></i><b>12.8</b> Choice of Hyperparameter on <span class="math inline">\(\tau\)</span></a></li>
<li class="chapter" data-level="12.9" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#r-implementations"><i class="fa fa-check"></i><b>12.9</b> R Implementations</a></li>
<li class="chapter" data-level="12.10" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#bayesian-model-averaging"><i class="fa fa-check"></i><b>12.10</b> Bayesian Model Averaging</a><ul>
<li class="chapter" data-level="12.10.1" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#zellners-g-prior"><i class="fa fa-check"></i><b>12.10.1</b> Zellner’s g-prior</a></li>
</ul></li>
<li class="chapter" data-level="12.11" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#slab-and-spike-priors"><i class="fa fa-check"></i><b>12.11</b> Slab and Spike Priors</a></li>
<li class="chapter" data-level="12.12" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#technical-notes"><i class="fa fa-check"></i><b>12.12</b> Technical Notes</a></li>
<li class="chapter" data-level="12.13" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#multiple-comparisons-and-thresholding-rules"><i class="fa fa-check"></i><b>12.13</b> Multiple Comparisons and Thresholding rules</a></li>
<li class="chapter" data-level="12.14" data-path="shrinkage-regularization.html"><a href="shrinkage-regularization.html#examples-of-applications-of-sensitivity-analysis"><i class="fa fa-check"></i><b>12.14</b> Examples of Applications of Sensitivity Analysis</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>13</b> Hierarchical Models</a><ul>
<li class="chapter" data-level="13.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-baseball-hits"><i class="fa fa-check"></i><b>13.1</b> Example: Baseball Hits</a><ul>
<li class="chapter" data-level="13.1.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#other-examples"><i class="fa fa-check"></i><b>13.1.1</b> Other Examples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>14</b> Multilevel Models</a><ul>
<li class="chapter" data-level="14.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-radon"><i class="fa fa-check"></i><b>14.1</b> Example: Radon</a><ul>
<li class="chapter" data-level="14.1.1" data-path="multilevel-models.html"><a href="multilevel-models.html#data"><i class="fa fa-check"></i><b>14.1.1</b> Data</a></li>
<li class="chapter" data-level="14.1.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercepts-models"><i class="fa fa-check"></i><b>14.1.2</b> Varying Intercepts Models</a></li>
<li class="chapter" data-level="14.1.3" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-intercept-model"><i class="fa fa-check"></i><b>14.1.3</b> Varying Intercept Model</a></li>
<li class="chapter" data-level="14.1.4" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-slope-model"><i class="fa fa-check"></i><b>14.1.4</b> Varying Slope Model</a></li>
<li class="chapter" data-level="14.1.5" data-path="multilevel-models.html"><a href="multilevel-models.html#group-level-predictors"><i class="fa fa-check"></i><b>14.1.5</b> Group Level Predictors</a></li>
<li class="chapter" data-level="14.1.6" data-path="multilevel-models.html"><a href="multilevel-models.html#lme4"><i class="fa fa-check"></i><b>14.1.6</b> lme4</a></li>
<li class="chapter" data-level="14.1.7" data-path="multilevel-models.html"><a href="multilevel-models.html#rstanarm"><i class="fa fa-check"></i><b>14.1.7</b> rstanarm</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="multilevel-models.html"><a href="multilevel-models.html#pooling-of-hierarchical-parameters"><i class="fa fa-check"></i><b>14.2</b> Pooling of Hierarchical Parameters</a></li>
<li class="chapter" data-level="14.3" data-path="multilevel-models.html"><a href="multilevel-models.html#anova"><i class="fa fa-check"></i><b>14.3</b> ANOVA</a></li>
<li class="chapter" data-level="14.4" data-path="multilevel-models.html"><a href="multilevel-models.html#time-series-cross-section"><i class="fa fa-check"></i><b>14.4</b> Time-Series Cross Section</a></li>
<li class="chapter" data-level="14.5" data-path="multilevel-models.html"><a href="multilevel-models.html#extensions"><i class="fa fa-check"></i><b>14.5</b> Extensions</a></li>
<li class="chapter" data-level="14.6" data-path="multilevel-models.html"><a href="multilevel-models.html#miscellaneous"><i class="fa fa-check"></i><b>14.6</b> Miscellaneous</a><ul>
<li class="chapter" data-level="14.6.1" data-path="multilevel-models.html"><a href="multilevel-models.html#how-many-groups"><i class="fa fa-check"></i><b>14.6.1</b> How many groups?</a></li>
<li class="chapter" data-level="14.6.2" data-path="multilevel-models.html"><a href="multilevel-models.html#correlation-between-predictors-and-errors"><i class="fa fa-check"></i><b>14.6.2</b> Correlation between Predictors and Errors</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="multilevel-models.html"><a href="multilevel-models.html#references-9"><i class="fa fa-check"></i><b>14.7</b> References</a></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span><ul>
<li class="chapter" data-level="14.8" data-path="multilevel-models.html"><a href="multilevel-models.html#parameters"><i class="fa fa-check"></i><b>14.8</b> Parameters</a></li>
<li class="chapter" data-level="14.9" data-path="multilevel-models.html"><a href="multilevel-models.html#miscellaneous-mathematical-background"><i class="fa fa-check"></i><b>14.9</b> Miscellaneous Mathematical Background</a><ul>
<li class="chapter" data-level="14.9.1" data-path="multilevel-models.html"><a href="multilevel-models.html#location-scale-families"><i class="fa fa-check"></i><b>14.9.1</b> Location-Scale Families</a></li>
<li class="chapter" data-level="14.9.2" data-path="multilevel-models.html"><a href="multilevel-models.html#scale-mixtures-of-normal-distributions"><i class="fa fa-check"></i><b>14.9.2</b> Scale Mixtures of Normal Distributions</a></li>
<li class="chapter" data-level="14.9.3" data-path="multilevel-models.html"><a href="multilevel-models.html#covariance-correlation-matrix-decomposition"><i class="fa fa-check"></i><b>14.9.3</b> Covariance-Correlation Matrix Decomposition</a></li>
<li class="chapter" data-level="14.9.4" data-path="multilevel-models.html"><a href="multilevel-models.html#qr-factorization"><i class="fa fa-check"></i><b>14.9.4</b> QR Factorization</a></li>
<li class="chapter" data-level="14.9.5" data-path="multilevel-models.html"><a href="multilevel-models.html#cholesky-decomposition"><i class="fa fa-check"></i><b>14.9.5</b> Cholesky Decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="scaled-and-unscaled-variables.html"><a href="scaled-and-unscaled-variables.html"><i class="fa fa-check"></i><b>15</b> Scaled and Unscaled Variables</a></li>
<li class="chapter" data-level="16" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html"><i class="fa fa-check"></i><b>16</b> Annotated Bibliography</a><ul>
<li class="chapter" data-level="16.0.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#textbooks"><i class="fa fa-check"></i><b>16.0.1</b> Textbooks</a></li>
<li class="chapter" data-level="16.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#syllabi"><i class="fa fa-check"></i><b>16.1</b> Syllabi</a></li>
<li class="chapter" data-level="16.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#topics"><i class="fa fa-check"></i><b>16.2</b> Topics</a></li>
<li class="chapter" data-level="16.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayes-theorem"><i class="fa fa-check"></i><b>16.3</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="16.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#article-length-introductions-to-bayesian-statistics"><i class="fa fa-check"></i><b>16.4</b> Article Length Introductions to Bayesian Statistics</a><ul>
<li class="chapter" data-level="16.4.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#why-bayesian"><i class="fa fa-check"></i><b>16.4.1</b> Why Bayesian</a></li>
<li class="chapter" data-level="16.4.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-philosophy"><i class="fa fa-check"></i><b>16.4.2</b> Bayesian Philosophy</a></li>
<li class="chapter" data-level="16.4.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>16.4.3</b> Bayesian Hypothesis Testing</a></li>
<li class="chapter" data-level="16.4.4" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-frequentist-debates"><i class="fa fa-check"></i><b>16.4.4</b> Bayesian Frequentist Debates</a></li>
<li class="chapter" data-level="16.4.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#categorical"><i class="fa fa-check"></i><b>16.4.5</b> Categorical</a></li>
<li class="chapter" data-level="16.4.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#variable-selection"><i class="fa fa-check"></i><b>16.4.6</b> Variable Selection</a></li>
<li class="chapter" data-level="16.4.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multiple-testing"><i class="fa fa-check"></i><b>16.4.7</b> Multiple Testing</a></li>
<li class="chapter" data-level="16.4.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#rare-events"><i class="fa fa-check"></i><b>16.4.8</b> Rare Events</a></li>
<li class="chapter" data-level="16.4.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#identifiability"><i class="fa fa-check"></i><b>16.4.9</b> Identifiability</a></li>
<li class="chapter" data-level="16.4.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkage"><i class="fa fa-check"></i><b>16.4.10</b> Shrinkage</a></li>
<li class="chapter" data-level="16.4.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#convergence"><i class="fa fa-check"></i><b>16.4.11</b> Convergence</a></li>
<li class="chapter" data-level="16.4.12" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software"><i class="fa fa-check"></i><b>16.4.12</b> Software</a></li>
<li class="chapter" data-level="16.4.13" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#stan-3"><i class="fa fa-check"></i><b>16.4.13</b> Stan</a></li>
<li class="chapter" data-level="16.4.14" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#diagrams"><i class="fa fa-check"></i><b>16.4.14</b> Diagrams</a></li>
<li class="chapter" data-level="16.4.15" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#priors"><i class="fa fa-check"></i><b>16.4.15</b> Priors</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#bayesian-model-averaging-1"><i class="fa fa-check"></i><b>16.5</b> Bayesian Model Averaging</a></li>
<li class="chapter" data-level="16.6" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#multilevel-modeling"><i class="fa fa-check"></i><b>16.6</b> Multilevel Modeling</a></li>
<li class="chapter" data-level="16.7" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#mixture-models"><i class="fa fa-check"></i><b>16.7</b> Mixture Models</a></li>
<li class="chapter" data-level="16.8" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#model-checking-1"><i class="fa fa-check"></i><b>16.8</b> Model Checking</a><ul>
<li class="chapter" data-level="16.8.1" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#posterior-predictive-checks-1"><i class="fa fa-check"></i><b>16.8.1</b> Posterior Predictive Checks</a></li>
<li class="chapter" data-level="16.8.2" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#prediction-criteria"><i class="fa fa-check"></i><b>16.8.2</b> Prediction Criteria</a></li>
<li class="chapter" data-level="16.8.3" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#software-validation"><i class="fa fa-check"></i><b>16.8.3</b> Software Validation</a></li>
</ul></li>
<li class="chapter" data-level="16.9" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#hierarchical-modeling"><i class="fa fa-check"></i><b>16.9</b> Hierarchical Modeling</a></li>
<li class="chapter" data-level="16.10" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#shrinkageregularization"><i class="fa fa-check"></i><b>16.10</b> Shrinkage/Regularization</a></li>
<li class="chapter" data-level="16.11" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#empirical-bayes"><i class="fa fa-check"></i><b>16.11</b> Empirical Bayes</a></li>
<li class="chapter" data-level="16.12" data-path="annotated-bibliography.html"><a href="annotated-bibliography.html#history-of-bayesian-statistics"><i class="fa fa-check"></i><b>16.12</b> History of Bayesian Statistics</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html"><i class="fa fa-check"></i><b>17</b> Sampling Difficulties</a><ul>
<li class="chapter" data-level="17.1" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#complicated-estimation-and-testing"><i class="fa fa-check"></i><b>17.1</b> Complicated Estimation and Testing</a></li>
<li class="chapter" data-level="17.2" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#pooling-polls"><i class="fa fa-check"></i><b>17.2</b> Pooling Polls</a></li>
<li class="chapter" data-level="17.3" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#numerical-analysis"><i class="fa fa-check"></i><b>17.3</b> Numerical Analysis</a></li>
<li class="chapter" data-level="17.4" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#visualizing-mcmc-methods"><i class="fa fa-check"></i><b>17.4</b> Visualizing MCMC Methods</a></li>
<li class="chapter" data-level="17.5" data-path="sampling-difficulties.html"><a href="sampling-difficulties.html#bayesian-point-estimation-decision"><i class="fa fa-check"></i><b>17.5</b> Bayesian point estimation / Decision</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="information-theory.html"><a href="information-theory.html"><i class="fa fa-check"></i><b>18</b> Information Theory</a></li>
<li class="chapter" data-level="19" data-path="stan-modeling-language.html"><a href="stan-modeling-language.html"><i class="fa fa-check"></i><b>19</b> Stan Modeling Language</a></li>
<li class="chapter" data-level="" data-path="references-10.html"><a href="references-10.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Updating: A Set of Bayesian Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\median}{median}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\logistic}{Logistic}
\DeclareMathOperator{\logit}{Logit}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

% This follows BDA
\newcommand{\dunif}{\mathrm{U}}
\newcommand{\dnorm}{\mathrm{N}}
\newcommand{\dlnorm}{\mathrm{lognormal}}
\newcommand{\dmvnorm}{\mathrm{N}}
\newcommand{\dgamma}{\mathrm{Gamma}}
\newcommand{\dinvgamma}{\mathrm{Inv-Gamma}}
\newcommand{\dchisq}[1]{\chi^2_{#1}}
\newcommand{\dinvchisq}[1]{\mathrm{Inv-}\chi^2_{#1}}
\newcommand{\dexp}{\mathrm{Expon}}
\newcommand{\dlaplace}{\mathrm{Laplace}}
\newcommand{\dweibull}{\mathrm{Weibull}}
\newcommand{\dwishart}[1]{\mathrm{Wishart}_{#1}}
\newcommand{\dinvwishart}[1]{\mathrm{Inv-Wishart}_{#1}}
\newcommand{\dlkj}{\mathrm{LkjCorr}}
\newcommand{\dt}[1]{t_{#1}}
\newcommand{\dbeta}{\mathrm{Beta}}
\newcommand{\ddirichlet}{\mathrm{Dirichlet}}
\newcommand{\dlogistic}{\mathrm{Logistic}}
\newcommand{\dllogistic}{\mathrm{Log-logistic}}
\newcommand{\dpois}{\mathrm{Poisson}}
\newcommand{\dbin}{\mathrm{Bin}}
\newcommand{\dmultinom}{\mathrm{Multinom}}
\newcommand{\dnbinom}{\mathrm{Neg-bin}}
\newcommand{\dnbinomalt}{\mathrm{Neg-bin2}}
\newcommand{\dbetabinom}{\mathrm{Beta-bin}}
\newcommand{\dcauchy}{\mathrm{Cauchy}}
\newcommand{\dhalfcauchy}{\mathrm{Cauchy}^{+}}
\newcommand{\dlkjcorr}{\mathrm{LKJ}^{+}}



\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]
<div id="generalized-linear-models" class="section level1">
<h1><span class="header-section-number">8</span> Generalized Linear Models</h1>
<div id="generalized-linear-models-1" class="section level2">
<h2><span class="header-section-number">8.1</span> Generalized Linear Models</h2>
<p>Generalized linear models (GLMs) are a class of commonly used models.[^glm-r]
In GLMs, the mean is specified as a function of a linear model of predictors,
<span class="math display">\[
E(Y) = \mu = g^{-1}(\mat{X} \vec{\beta}) .
\]</span>
GLMs are a generalization of linear regression from an unbounded continuous outcome variable to other types of data: binary, count, categorical, bounded continuous.</p>
<p>A GLM consists of three components:</p>
<ol style="list-style-type: decimal">
<li>A <em>probability distribution</em> (<em>family</em>) specifying the conditional distribution of the response variable.
In GLMs, the distribution is in the exponential family: Normal, Binomial, Poisson, Categorical, Multinomial, Poisson, Beta.</li>
<li>A <em>linear predictor</em>, which is a linear function of the predictors,
<span class="math display">\[
 \eta = \mat{X} \vec{\beta} .
 \]</span></li>
<li>A <em>link function</em> (<span class="math inline">\(g(.)\)</span>) which maps the expected value to the the linear predictor,
<span class="math display">\[
 g(\mu) = \eta .
 \]</span>
The link function is smooth and invertible, and the <em>inverse link function</em> or <em>mean function</em> maps the linear predictor to the mean,
<span class="math display">\[
 \mu = g^{-1}(\eta) .
 \]</span>
The link function (<span class="math inline">\(g\)</span>) and its inverse ($g^{-1}) translate <span class="math inline">\(\eta\)</span> from <span class="math inline">\((\-infty, +\infty)\)</span> to the proper range for the probability distribution and back again.</li>
</ol>
<p>These models are often estimated with MLE, as with the function <a href="https://www.rdocumentation.org/packages/stats/topics/glm">stats</a>.
These are also easily estimated in a Bayesian setting.</p>
<p>See the help for <a href="https://www.rdocumentation.org/packages/stats/topics/family">stats</a> for common probability distributions, <a href="https://www.rdocumentation.org/packages/stats/topics/make.link">stats</a> for common links, and the <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">Wikipedia</a> page for a table of common GLMs.
See the function <strong><a href="https://cran.r-project.org/package=VGAM">VGAM</a></strong> for even more examples of link functions and probability distributions.</p>
<table>
<caption>Common Link Functions and their inverses. Table derived from <span class="citation">Fox (2016, 419)</span>.</caption>
<thead>
<tr class="header">
<th align="left">Link</th>
<th align="left">Range of <span class="math inline">\(\mu_i\)</span></th>
<th align="left"><span class="math inline">\(\eta_i = g(\mu_i)\)</span></th>
<th align="left"><span class="math inline">\(\mu_i = g^{-1}(\eta)_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Identity</td>
<td align="left"><span class="math inline">\((-\infty, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\mu_i\)</span></td>
<td align="left"><span class="math inline">\(\eta_i\)</span></td>
</tr>
<tr class="even">
<td align="left">Inverse</td>
<td align="left"><span class="math inline">\((-\infty, \infty) \setminus \{0\}\)</span></td>
<td align="left"><span class="math inline">\(\mu_i^{-1}\)</span></td>
<td align="left"><span class="math inline">\(\eta_i^{-1}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Log</td>
<td align="left"><span class="math inline">\((0, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\log(\mu_i)\)</span></td>
<td align="left"><span class="math inline">\(\exp(\eta_i)\)</span></td>
</tr>
<tr class="even">
<td align="left">Inverse-square</td>
<td align="left"><span class="math inline">\((0, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\mu_i^{-2}\)</span></td>
<td align="left"><span class="math inline">\(\eta_i^{-1/2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Square-root</td>
<td align="left"><span class="math inline">\((0, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\sqrt{\mu_i}\)</span></td>
<td align="left"><span class="math inline">\(\eta_{i}^2\)</span></td>
</tr>
<tr class="even">
<td align="left">Logit</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\log(\mu / (1 - \mu_i)\)</span></td>
<td align="left"><span class="math inline">\(1 / (1 + \exp(-\eta_i))\)</span></td>
</tr>
<tr class="odd">
<td align="left">Probit</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\Phi^{-1}(\mu_i)\)</span></td>
<td align="left"><span class="math inline">\(\Phi(\eta_i)\)</span></td>
</tr>
<tr class="even">
<td align="left">Cauchit</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\tan(\pi (\mu_i - 1 / 2))\)</span></td>
<td align="left"><span class="math inline">\(\frac{1}{\pi} \arctan(\eta_i) + \frac{1}{2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Log-log</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(-\log(-log(\mu_i))\)</span></td>
<td align="left"><span class="math inline">\(\exp(-\exp(-\eta_i))\)</span></td>
</tr>
<tr class="even">
<td align="left">Complementary Log-log</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\log(-log(1 - \mu_i))\)</span></td>
<td align="left"><span class="math inline">\(1 - \exp(-\exp(\eta_i))\)</span></td>
</tr>
</tbody>
</table>
<table>
<caption>Common distributions and link functions. Table derived from <span class="citation">Fox (2016, 421)</span>, <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">Wikipedia</a>, and <a href="https://www.rdocumentation.org/packages/stats/topics/glm">stats</a>.</caption>
<thead>
<tr class="header">
<th align="left">Distribution</th>
<th align="left">Canonical Link</th>
<th align="left">Range of <span class="math inline">\(Y_i\)</span></th>
<th align="left">Other link functions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Normal</td>
<td align="left">Identity</td>
<td align="left">real: <span class="math inline">\((-\infty, +\infty)\)</span></td>
<td align="left">log, inverse</td>
</tr>
<tr class="even">
<td align="left">Exponential</td>
<td align="left">Inverse</td>
<td align="left">real: <span class="math inline">\((0, +\infty)\)</span></td>
<td align="left">identity, log</td>
</tr>
<tr class="odd">
<td align="left">Gamma</td>
<td align="left">Inverse</td>
<td align="left">real: <span class="math inline">\((0, +\infty)\)</span></td>
<td align="left">identity, log</td>
</tr>
<tr class="even">
<td align="left">Inverse-Gaussian</td>
<td align="left">Inverse-squared</td>
<td align="left">real: <span class="math inline">\((0, +\infty)\)</span></td>
<td align="left">inverse, identity, log</td>
</tr>
<tr class="odd">
<td align="left">Bernoulli</td>
<td align="left">Logit</td>
<td align="left">integer: <span class="math inline">\(\{0, 1\}\)</span></td>
<td align="left">probit, cauchit, log, cloglog</td>
</tr>
<tr class="even">
<td align="left">Binomial</td>
<td align="left">Logit</td>
<td align="left">integer: <span class="math inline">\(0, 1, \dots, n_i\)</span></td>
<td align="left">probit, cauchit, log, cloglog</td>
</tr>
<tr class="odd">
<td align="left">Poisson</td>
<td align="left">Log</td>
<td align="left">integer: <span class="math inline">\(0, 1, 2, \dots\)</span></td>
<td align="left">identity, sqrt</td>
</tr>
<tr class="even">
<td align="left">Categorical</td>
<td align="left">Logit</td>
<td align="left"><span class="math inline">\(0, 1, \dots, K\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Multinomial</td>
<td align="left">Logit</td>
<td align="left">K-vector of integers, <span class="math inline">\(\{x_1, \dots, x_K\}\)</span> s.t. <span class="math inline">\(\sum_k x_k = N\)</span>.</td>
<td align="left"></td>
</tr>
</tbody>
</table>
</div>
<div id="count-models" class="section level2">
<h2><span class="header-section-number">8.2</span> Count Models</h2>
<div id="poisson" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Poisson</h3>
<p>The Poisson model is used for unbounded count data,
<span class="math display">\[
Y = 0, 1, \dots, \infty
\]</span>
The outcome is modeled as a Poisson distribution
<span class="math display">\[
y_i \sim \dpois(\lambda_i)
\]</span>
with positive mean parameter <span class="math inline">\(\lambda_i \in (0, \infty)\)</span>.
Since <span class="math inline">\(\lambda_i\)</span> has to be positive, the most common link function is the log,
<span class="math display">\[
\log(\lambda_i) = \exp(\vec{x}_i&#39; \vec{\beta})
\]</span>
which has the inverse,
<span class="math display">\[
\lambda_i = \log(\vec{x}_i \vec{\beta})
\]</span></p>
<p>In Stan, the Poisson distribution has two implementations:</p>
<ul>
<li><code>poisson_lpdf</code></li>
<li><code>poisson_log_lpdf</code>: Poisson with a log link. This is for numeric stability.</li>
</ul>
<p>Also, <code>rstanarm</code> supports the <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html">Poisson</a>.</p>
</div>
</div>
<div id="example" class="section level2">
<h2><span class="header-section-number">8.3</span> Example</h2>
<p>A regression model of bilateral sanctions for the period 1939 to 1983.
The outcome variable is the number of countries imposing sanctions.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;sanction&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;Zelig&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)</a>
<a class="sourceLine" id="cb44-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</a>
<a class="sourceLine" id="cb44-3" data-line-number="3"><span class="kw">library</span>(<span class="st">&quot;magrittr&quot;</span>)</a>
<a class="sourceLine" id="cb44-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-5" data-line-number="5"><span class="co">#&gt; Attaching package: &#39;magrittr&#39;</span></a>
<a class="sourceLine" id="cb44-6" data-line-number="6"><span class="co">#&gt; The following object is masked from &#39;package:purrr&#39;:</span></a>
<a class="sourceLine" id="cb44-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-8" data-line-number="8"><span class="co">#&gt;     set_names</span></a>
<a class="sourceLine" id="cb44-9" data-line-number="9"><span class="co">#&gt; The following object is masked from &#39;package:tidyr&#39;:</span></a>
<a class="sourceLine" id="cb44-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-11" data-line-number="11"><span class="co">#&gt;     extract</span></a>
<a class="sourceLine" id="cb44-12" data-line-number="12"><span class="co">#&gt; The following object is masked from &#39;package:rstan&#39;:</span></a>
<a class="sourceLine" id="cb44-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-14" data-line-number="14"><span class="co">#&gt;     extract</span></a>
<a class="sourceLine" id="cb44-15" data-line-number="15"></a>
<a class="sourceLine" id="cb44-16" data-line-number="16">URL &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/carlislerainey/priors-for-separation/master/br-replication/data/need.csv&quot;</span></a>
<a class="sourceLine" id="cb44-17" data-line-number="17"></a>
<a class="sourceLine" id="cb44-18" data-line-number="18">autoscale &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">scale =</span> <span class="ot">TRUE</span>) {</a>
<a class="sourceLine" id="cb44-19" data-line-number="19">  nvals &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(x))</a>
<a class="sourceLine" id="cb44-20" data-line-number="20">  <span class="cf">if</span> (nvals <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb44-21" data-line-number="21">    out &lt;-<span class="st"> </span>x</a>
<a class="sourceLine" id="cb44-22" data-line-number="22">  } <span class="cf">else</span> <span class="cf">if</span> (nvals <span class="op">==</span><span class="st"> </span><span class="dv">2</span>) {</a>
<a class="sourceLine" id="cb44-23" data-line-number="23">    out &lt;-<span class="st"> </span><span class="cf">if</span> (scale) {</a>
<a class="sourceLine" id="cb44-24" data-line-number="24">      (x <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)) <span class="op">/</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">range</span>(x, <span class="dt">finite =</span> <span class="ot">TRUE</span>))</a>
<a class="sourceLine" id="cb44-25" data-line-number="25">    } <span class="cf">else</span> x</a>
<a class="sourceLine" id="cb44-26" data-line-number="26">    <span class="cf">if</span> (center) {</a>
<a class="sourceLine" id="cb44-27" data-line-number="27">      out &lt;-<span class="st"> </span>x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)</a>
<a class="sourceLine" id="cb44-28" data-line-number="28">    }</a>
<a class="sourceLine" id="cb44-29" data-line-number="29">  } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb44-30" data-line-number="30">    out &lt;-<span class="st"> </span><span class="cf">if</span> (center) {</a>
<a class="sourceLine" id="cb44-31" data-line-number="31">      x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb44-32" data-line-number="32">    } <span class="cf">else</span> x</a>
<a class="sourceLine" id="cb44-33" data-line-number="33">    out &lt;-<span class="st"> </span><span class="cf">if</span> (scale) out <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(out, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb44-34" data-line-number="34">  }</a>
<a class="sourceLine" id="cb44-35" data-line-number="35">  out</a>
<a class="sourceLine" id="cb44-36" data-line-number="36">}</a>
<a class="sourceLine" id="cb44-37" data-line-number="37"></a>
<a class="sourceLine" id="cb44-38" data-line-number="38"></a>
<a class="sourceLine" id="cb44-39" data-line-number="39">f &lt;-<span class="st"> </span>(oppose_expansion <span class="op">~</span><span class="st"> </span>dem_governor <span class="op">+</span><span class="st"> </span>obama_win <span class="op">+</span><span class="st"> </span>gop_leg <span class="op">+</span><span class="st"> </span>percent_uninsured <span class="op">+</span></a>
<a class="sourceLine" id="cb44-40" data-line-number="40"><span class="st">      </span>income <span class="op">+</span><span class="st"> </span>percent_nonwhite <span class="op">+</span><span class="st"> </span>percent_metro)</a>
<a class="sourceLine" id="cb44-41" data-line-number="41"></a>
<a class="sourceLine" id="cb44-42" data-line-number="42">br &lt;-<span class="st"> </span><span class="kw">read_csv</span>(URL) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-43" data-line-number="43"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">oppose_expansion =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>support_expansion,</a>
<a class="sourceLine" id="cb44-44" data-line-number="44">         <span class="dt">dem_governor =</span> <span class="dv">-1</span> <span class="op">*</span><span class="st"> </span>gop_governor,</a>
<a class="sourceLine" id="cb44-45" data-line-number="45">         <span class="dt">obama_win =</span> <span class="kw">as.integer</span>(obama_share <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>),</a>
<a class="sourceLine" id="cb44-46" data-line-number="46">         <span class="dt">percent_nonwhite =</span> percent_black <span class="op">+</span><span class="st"> </span>percent_hispanic) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-47" data-line-number="47"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">gop_leg =</span> legGOP) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-48" data-line-number="48"><span class="st">  </span><span class="co"># keep only variables in the formula</span></a>
<a class="sourceLine" id="cb44-49" data-line-number="49"><span class="st">  </span><span class="kw">model.frame</span>(f, <span class="dt">data =</span> .) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-50" data-line-number="50"><span class="st">  </span><span class="co"># drop missing values (if any?)</span></a>
<a class="sourceLine" id="cb44-51" data-line-number="51"><span class="st">  </span><span class="kw">drop_na</span>()</a>
<a class="sourceLine" id="cb44-52" data-line-number="52"><span class="co">#&gt; Parsed with column specification:</span></a>
<a class="sourceLine" id="cb44-53" data-line-number="53"><span class="co">#&gt; cols(</span></a>
<a class="sourceLine" id="cb44-54" data-line-number="54"><span class="co">#&gt;   .default = col_integer(),</span></a>
<a class="sourceLine" id="cb44-55" data-line-number="55"><span class="co">#&gt;   state = col_character(),</span></a>
<a class="sourceLine" id="cb44-56" data-line-number="56"><span class="co">#&gt;   state_abbr = col_character(),</span></a>
<a class="sourceLine" id="cb44-57" data-line-number="57"><span class="co">#&gt;   house12 = col_double(),</span></a>
<a class="sourceLine" id="cb44-58" data-line-number="58"><span class="co">#&gt;   sen12 = col_double(),</span></a>
<a class="sourceLine" id="cb44-59" data-line-number="59"><span class="co">#&gt;   support_expansion_new = col_character(),</span></a>
<a class="sourceLine" id="cb44-60" data-line-number="60"><span class="co">#&gt;   percent_uninsured = col_double(),</span></a>
<a class="sourceLine" id="cb44-61" data-line-number="61"><span class="co">#&gt;   ideology = col_double(),</span></a>
<a class="sourceLine" id="cb44-62" data-line-number="62"><span class="co">#&gt;   income = col_double(),</span></a>
<a class="sourceLine" id="cb44-63" data-line-number="63"><span class="co">#&gt;   percent_black = col_double(),</span></a>
<a class="sourceLine" id="cb44-64" data-line-number="64"><span class="co">#&gt;   percent_hispanic = col_double(),</span></a>
<a class="sourceLine" id="cb44-65" data-line-number="65"><span class="co">#&gt;   percent_metro = col_double(),</span></a>
<a class="sourceLine" id="cb44-66" data-line-number="66"><span class="co">#&gt;   dsh = col_double(),</span></a>
<a class="sourceLine" id="cb44-67" data-line-number="67"><span class="co">#&gt;   obama_share = col_double()</span></a>
<a class="sourceLine" id="cb44-68" data-line-number="68"><span class="co">#&gt; )</span></a>
<a class="sourceLine" id="cb44-69" data-line-number="69"><span class="co">#&gt; See spec(...) for full column specifications.</span></a>
<a class="sourceLine" id="cb44-70" data-line-number="70"></a>
<a class="sourceLine" id="cb44-71" data-line-number="71">br_scaled &lt;-<span class="st"> </span>br <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-72" data-line-number="72"><span class="st">  </span><span class="co"># Autoscale all vars but response</span></a>
<a class="sourceLine" id="cb44-73" data-line-number="73"><span class="st">  </span><span class="kw">mutate_at</span>(<span class="kw">vars</span>(<span class="op">-</span>oppose_expansion), autoscale)</a>
<a class="sourceLine" id="cb44-74" data-line-number="74"></a>
<a class="sourceLine" id="cb44-75" data-line-number="75"><span class="kw">glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</a>
<a class="sourceLine" id="cb44-76" data-line-number="76"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-77" data-line-number="77"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb44-78" data-line-number="78"><span class="co">#&gt; glm(formula = f, family = &quot;binomial&quot;, data = br)</span></a>
<a class="sourceLine" id="cb44-79" data-line-number="79"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-80" data-line-number="80"><span class="co">#&gt; Deviance Residuals: </span></a>
<a class="sourceLine" id="cb44-81" data-line-number="81"><span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span></a>
<a class="sourceLine" id="cb44-82" data-line-number="82"><span class="co">#&gt; -2.374  -0.461  -0.131   0.630   2.207  </span></a>
<a class="sourceLine" id="cb44-83" data-line-number="83"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-84" data-line-number="84"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb44-85" data-line-number="85"><span class="co">#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)   </span></a>
<a class="sourceLine" id="cb44-86" data-line-number="86"><span class="co">#&gt; (Intercept)         4.5103     4.5986    0.98    0.327   </span></a>
<a class="sourceLine" id="cb44-87" data-line-number="87"><span class="co">#&gt; dem_governor       -4.1556     1.4794   -2.81    0.005 **</span></a>
<a class="sourceLine" id="cb44-88" data-line-number="88"><span class="co">#&gt; obama_win          -2.1470     1.3429   -1.60    0.110   </span></a>
<a class="sourceLine" id="cb44-89" data-line-number="89"><span class="co">#&gt; gop_leg            -0.1865     1.2974   -0.14    0.886   </span></a>
<a class="sourceLine" id="cb44-90" data-line-number="90"><span class="co">#&gt; percent_uninsured  -0.3072     0.1651   -1.86    0.063 . </span></a>
<a class="sourceLine" id="cb44-91" data-line-number="91"><span class="co">#&gt; income             -0.0421     0.0776   -0.54    0.587   </span></a>
<a class="sourceLine" id="cb44-92" data-line-number="92"><span class="co">#&gt; percent_nonwhite   17.8505    48.3030    0.37    0.712   </span></a>
<a class="sourceLine" id="cb44-93" data-line-number="93"><span class="co">#&gt; percent_metro     -12.4390    32.4446   -0.38    0.701   </span></a>
<a class="sourceLine" id="cb44-94" data-line-number="94"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb44-95" data-line-number="95"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a>
<a class="sourceLine" id="cb44-96" data-line-number="96"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-97" data-line-number="97"><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></a>
<a class="sourceLine" id="cb44-98" data-line-number="98"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-99" data-line-number="99"><span class="co">#&gt;     Null deviance: 68.593  on 49  degrees of freedom</span></a>
<a class="sourceLine" id="cb44-100" data-line-number="100"><span class="co">#&gt; Residual deviance: 37.948  on 42  degrees of freedom</span></a>
<a class="sourceLine" id="cb44-101" data-line-number="101"><span class="co">#&gt; AIC: 53.95</span></a>
<a class="sourceLine" id="cb44-102" data-line-number="102"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-103" data-line-number="103"><span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></a>
<a class="sourceLine" id="cb44-104" data-line-number="104"></a>
<a class="sourceLine" id="cb44-105" data-line-number="105"><span class="kw">library</span>(<span class="st">&quot;rstanarm&quot;</span>)</a>
<a class="sourceLine" id="cb44-106" data-line-number="106"></a>
<a class="sourceLine" id="cb44-107" data-line-number="107">fit1 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb44-108" data-line-number="108"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-109" data-line-number="109"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb44-110" data-line-number="110"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-111" data-line-number="111"><span class="co">#&gt; Gradient evaluation took 7.6e-05 seconds</span></a>
<a class="sourceLine" id="cb44-112" data-line-number="112"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.</span></a>
<a class="sourceLine" id="cb44-113" data-line-number="113"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-114" data-line-number="114"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-115" data-line-number="115"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-116" data-line-number="116"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-117" data-line-number="117"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-118" data-line-number="118"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-119" data-line-number="119"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-120" data-line-number="120"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-121" data-line-number="121"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-122" data-line-number="122"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-123" data-line-number="123"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-124" data-line-number="124"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-125" data-line-number="125"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-126" data-line-number="126"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-127" data-line-number="127"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-128" data-line-number="128"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-129" data-line-number="129"><span class="co">#&gt;  Elapsed Time: 0.227826 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-130" data-line-number="130"><span class="co">#&gt;                0.216907 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-131" data-line-number="131"><span class="co">#&gt;                0.444733 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-132" data-line-number="132"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-133" data-line-number="133"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-134" data-line-number="134"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb44-135" data-line-number="135"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-136" data-line-number="136"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb44-137" data-line-number="137"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb44-138" data-line-number="138"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-139" data-line-number="139"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-140" data-line-number="140"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-141" data-line-number="141"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-142" data-line-number="142"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-143" data-line-number="143"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-144" data-line-number="144"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-145" data-line-number="145"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-146" data-line-number="146"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-147" data-line-number="147"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-148" data-line-number="148"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-149" data-line-number="149"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-150" data-line-number="150"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-151" data-line-number="151"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-152" data-line-number="152"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-153" data-line-number="153"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-154" data-line-number="154"><span class="co">#&gt;  Elapsed Time: 0.2258 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-155" data-line-number="155"><span class="co">#&gt;                0.234074 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-156" data-line-number="156"><span class="co">#&gt;                0.459874 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-157" data-line-number="157"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-158" data-line-number="158"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-159" data-line-number="159"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb44-160" data-line-number="160"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-161" data-line-number="161"><span class="co">#&gt; Gradient evaluation took 2.2e-05 seconds</span></a>
<a class="sourceLine" id="cb44-162" data-line-number="162"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.</span></a>
<a class="sourceLine" id="cb44-163" data-line-number="163"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-164" data-line-number="164"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-165" data-line-number="165"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-166" data-line-number="166"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-167" data-line-number="167"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-168" data-line-number="168"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-169" data-line-number="169"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-170" data-line-number="170"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-171" data-line-number="171"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-172" data-line-number="172"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-173" data-line-number="173"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-174" data-line-number="174"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-175" data-line-number="175"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-176" data-line-number="176"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-177" data-line-number="177"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-178" data-line-number="178"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-179" data-line-number="179"><span class="co">#&gt;  Elapsed Time: 0.232678 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-180" data-line-number="180"><span class="co">#&gt;                0.224351 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-181" data-line-number="181"><span class="co">#&gt;                0.457029 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-182" data-line-number="182"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-183" data-line-number="183"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-184" data-line-number="184"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb44-185" data-line-number="185"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-186" data-line-number="186"><span class="co">#&gt; Gradient evaluation took 2.2e-05 seconds</span></a>
<a class="sourceLine" id="cb44-187" data-line-number="187"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.</span></a>
<a class="sourceLine" id="cb44-188" data-line-number="188"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-189" data-line-number="189"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-190" data-line-number="190"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-191" data-line-number="191"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-192" data-line-number="192"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-193" data-line-number="193"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-194" data-line-number="194"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-195" data-line-number="195"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-196" data-line-number="196"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-197" data-line-number="197"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-198" data-line-number="198"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-199" data-line-number="199"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-200" data-line-number="200"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-201" data-line-number="201"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-202" data-line-number="202"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-203" data-line-number="203"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-204" data-line-number="204"><span class="co">#&gt;  Elapsed Time: 0.221657 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-205" data-line-number="205"><span class="co">#&gt;                0.224032 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-206" data-line-number="206"><span class="co">#&gt;                0.445689 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-207" data-line-number="207"></a>
<a class="sourceLine" id="cb44-208" data-line-number="208">fit2 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">prior =</span> <span class="ot">NULL</span>, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb44-209" data-line-number="209"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-210" data-line-number="210"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb44-211" data-line-number="211"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-212" data-line-number="212"><span class="co">#&gt; Gradient evaluation took 2.7e-05 seconds</span></a>
<a class="sourceLine" id="cb44-213" data-line-number="213"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.</span></a>
<a class="sourceLine" id="cb44-214" data-line-number="214"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-215" data-line-number="215"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-216" data-line-number="216"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-217" data-line-number="217"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-218" data-line-number="218"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-219" data-line-number="219"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-220" data-line-number="220"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-221" data-line-number="221"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-222" data-line-number="222"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-223" data-line-number="223"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-224" data-line-number="224"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-225" data-line-number="225"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-226" data-line-number="226"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-227" data-line-number="227"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-228" data-line-number="228"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-229" data-line-number="229"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-230" data-line-number="230"><span class="co">#&gt;  Elapsed Time: 1.56167 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-231" data-line-number="231"><span class="co">#&gt;                0.243438 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-232" data-line-number="232"><span class="co">#&gt;                1.80511 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-233" data-line-number="233"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-234" data-line-number="234"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-235" data-line-number="235"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb44-236" data-line-number="236"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-237" data-line-number="237"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb44-238" data-line-number="238"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb44-239" data-line-number="239"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-240" data-line-number="240"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-241" data-line-number="241"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-242" data-line-number="242"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-243" data-line-number="243"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-244" data-line-number="244"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-245" data-line-number="245"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-246" data-line-number="246"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-247" data-line-number="247"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-248" data-line-number="248"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-249" data-line-number="249"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-250" data-line-number="250"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-251" data-line-number="251"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-252" data-line-number="252"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-253" data-line-number="253"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-254" data-line-number="254"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-255" data-line-number="255"><span class="co">#&gt;  Elapsed Time: 1.37833 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-256" data-line-number="256"><span class="co">#&gt;                0.208435 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-257" data-line-number="257"><span class="co">#&gt;                1.58676 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-258" data-line-number="258"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-259" data-line-number="259"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-260" data-line-number="260"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb44-261" data-line-number="261"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-262" data-line-number="262"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb44-263" data-line-number="263"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb44-264" data-line-number="264"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-265" data-line-number="265"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-266" data-line-number="266"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-267" data-line-number="267"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-268" data-line-number="268"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-269" data-line-number="269"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-270" data-line-number="270"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-271" data-line-number="271"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-272" data-line-number="272"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-273" data-line-number="273"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-274" data-line-number="274"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-275" data-line-number="275"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-276" data-line-number="276"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-277" data-line-number="277"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-278" data-line-number="278"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-279" data-line-number="279"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-280" data-line-number="280"><span class="co">#&gt;  Elapsed Time: 1.06808 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-281" data-line-number="281"><span class="co">#&gt;                0.245541 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-282" data-line-number="282"><span class="co">#&gt;                1.31363 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-283" data-line-number="283"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-284" data-line-number="284"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-285" data-line-number="285"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb44-286" data-line-number="286"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-287" data-line-number="287"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb44-288" data-line-number="288"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb44-289" data-line-number="289"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-290" data-line-number="290"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-291" data-line-number="291"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-292" data-line-number="292"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-293" data-line-number="293"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-294" data-line-number="294"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-295" data-line-number="295"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-296" data-line-number="296"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-297" data-line-number="297"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-298" data-line-number="298"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-299" data-line-number="299"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-300" data-line-number="300"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-301" data-line-number="301"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-302" data-line-number="302"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-303" data-line-number="303"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-304" data-line-number="304"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-305" data-line-number="305"><span class="co">#&gt;  Elapsed Time: 1.21401 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-306" data-line-number="306"><span class="co">#&gt;                0.217275 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-307" data-line-number="307"><span class="co">#&gt;                1.43128 seconds (Total)</span></a></code></pre></div>
</div>
<div id="negative-binomial" class="section level2">
<h2><span class="header-section-number">8.4</span> Negative Binomial</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">Negative Binomial</a> model is also used for unbounded count data,
<span class="math display">\[
Y = 0, 1, \dots, \infty
\]</span>
The Poisson distribution has the restriction that the mean is equal to the variance, <span class="math inline">\(\E(X) = \Var(X) = \lambda\)</span>.
The Negative Binomial distribution has an additional parameter that allows the variance to vary (though it is always larger than the mean).</p>
<p>The outcome is modeled as a negative binomial distribution,
<span class="math display">\[
y_i \sim \dbinom(\alpha_i, \beta)
\]</span>
with shape <span class="math inline">\(\alpha \in \R^{+}\)</span> and inverse scale <span class="math inline">\(\beta \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \alpha_i / \beta\)</span> and <span class="math inline">\(\Var(Y) = \frac{\alpha_i}{\beta^2}(\beta + 1)\)</span>.
Then the mean can be modeled and transformed to the
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\alpha_i &amp;= \mu_i / \beta
\end{aligned}
\]</span></p>
<p><strong>Important</strong> The negative binomial distribution has many different parameterizations.
An alternative parameterization of the negative binomial uses the mean and a over-dispersion parameter.
<span class="math display">\[
y_i \sim \dnbinomalt(\mu_i, \phi)
\]</span>
with location parameter <span class="math inline">\(\mu \in \R^{+}\)</span> and over-dispersion parameter <span class="math inline">\(\phi \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \mu_i\)</span> and <span class="math inline">\(\Var(Y) = \mu_i + \frac{\mu_i^2}{\phi}\)</span>.
Then the mean can be modeled and transformed to the
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\end{aligned}
\]</span></p>
<p>In Stan, there are multiple parameterizations of the</p>
<ul>
<li><code>neg_binomial_lpdf(y | alpha, beta)</code>with shape parameter <code>alpha</code> and inverse scale parameter <code>beta</code>.</li>
<li><code>neg_binomial_2_lpdf(y | mu, phi)</code> with mean <code>mu</code> and over-dispersion parameter <code>phi</code>.</li>
<li><code>neg_binomial_2_log_lpdf(y | eta, phi)</code> with log-mean <code>eta</code> and over-dispersion parameter <code>phi</code></li>
</ul>
<p>Also, <code>rstanarm</code> supports Poisson and <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html">negative binomial models</a>.</p>
<ul>
<li><span class="citation">Gelman et al. (2013 Ch 16)</span></li>
</ul>
<div id="references-3" class="section level3">
<h3><span class="header-section-number">8.4.1</span> References</h3>
<p>For general references on count models see</p>
<ul>
<li><span class="citation">Gelman and Hill (2007, 109–16)</span></li>
<li><span class="citation">McElreath (2016 Ch 10)</span></li>
<li><span class="citation">Fox (2016 Ch. 14)</span></li>
<li><span class="citation">Gelman et al. (2013 Ch. 16)</span></li>
</ul>
</div>
</div>
<div id="multinomial-categorical-models" class="section level2">
<h2><span class="header-section-number">8.5</span> Multinomial / Categorical Models</h2>
</div>
<div id="gamma-regression" class="section level2">
<h2><span class="header-section-number">8.6</span> Gamma Regression</h2>
<p>The response variable is continuous and positive.
In gamma regression, the coefficient of variation is constant rather than the variance.
<span class="math display">\[
y_i \sim \dgamma(\alpha_i, \beta)
\]</span>
and
<span class="math display">\[
\begin{aligned}[t]
\alpha_i &amp;= \mu_i / \beta \\
\mu_i &amp;= \vec{x}_i \vec{\gamma}
\end{aligned}
\]</span></p>
<p>In Stan,</p>
<ul>
<li><code>gamma(y | alpha, beta)</code> with shape parameter <span class="math inline">\(\alpha &gt; 0\)</span> and inverse scale parameter <span class="math inline">\(\beta &gt; 0\)</span>. Then <span class="math inline">\(\E(Y) = \alpha / \beta\)</span> and <span class="math inline">\(\Var(Y) = \alpha / \beta^2\)</span>.</li>
</ul>
</div>
<div id="beta-regression" class="section level2">
<h2><span class="header-section-number">8.7</span> Beta Regression</h2>
<p>This is for a response variable that is a proportion, <span class="math inline">\(y_i \in (0, 1)\)</span>,
<span class="math display">\[
y_i \sim \dbeta(\alpha_i, \beta_i)
\]</span>
and
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= g^{-1}(\vec{x}_i&#39; \vec{\gamma}) \\
\alpha_i &amp;= \mu_i \phi \\
\beta_i &amp;= (1 - \mu_i) \phi 
\end{aligned}
\]</span>
Additionally, the <span class="math inline">\(\phi\)</span> parameter could also be modeled.</p>
<p>In Stan:</p>
<ul>
<li><code>beta(y | alpha, beta)</code> with positive prior successes plus one, <span class="math inline">\(\alpha &gt; 0\)</span>, and negative prior failures plus one, <span class="math inline">\(\beta &gt; 0\)</span>. Then <span class="math inline">\(\E(Y) = \alpha / (\alpha + \beta)\)</span> and <span class="math inline">\(\Var(Y) = \alpha\beta / ((\alpha + \beta)^2 (\alpha + \beta + 1))\)</span>.</li>
</ul>
<p><strong>rstanarm</strong> function <a href="https://www.rdocumentation.org/packages/rstasnarm/topics/stan_betareg">rstasnarm</a></p>
<p>See:</p>
<ul>
<li><span class="citation">Ferrari and Cribari-Neto (2004)</span>, <span class="citation">Cribari-Neto and Zeileis (2010)</span>, and <span class="citation">Grün, Kosmidis, and Zeileis (2012)</span> on beta regression.</li>
<li><strong>rstanarm</strong> documentation <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/betareg.html">Modeling Rates/Proportions using Beta Regression with rstanarm</a></li>
</ul>
</div>
<div id="references-4" class="section level2">
<h2><span class="header-section-number">8.8</span> References</h2>
<p><span class="citation">Gelman et al. (2013 Ch 16)</span>, <span class="citation">Gelman and Hill (2007 Ch. 5-6)</span>, <span class="citation">McElreath (2016 Ch. 9)</span>. <span class="citation">King (1998)</span> discusses MLE estimation of many common GLM models.</p>
<p>Many econometrics/statistics textbooks, e.g. <span class="citation">Fox (2016)</span>, discuss GLMs. Though they are not derived from a Bayesian context, they can easily transferred.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="heteroskedasticity-and-robust-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="binomial-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/bayesian_notes/edit/master/generalized-linear-models.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
