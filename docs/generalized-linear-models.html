<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Updating: A Set of Bayesian Notes</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Updating: A Set of Bayesian Notes">
  <meta name="generator" content="bookdown 0.3.6 and GitBook 2.6.7">

  <meta property="og:title" content="Updating: A Set of Bayesian Notes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jrnold.github.io/bayesian_notes" />
  
  
  <meta name="github-repo" content="jrnold/bayesian_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Updating: A Set of Bayesian Notes" />
  <meta name="twitter:site" content="@jrnld" />
  
  

<meta name="author" content="Jeffrey B. Arnold">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="heteroskedasticity-and-robust-regression.html">
<link rel="next" href="notes.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Bayesian Notes</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Theory</b></span></li>
<li class="chapter" data-level="1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>1</b> Bayesian Inference</a></li>
<li class="part"><span><b>II Computation</b></span></li>
<li class="chapter" data-level="2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>2</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>2.1</b> Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-sampling"><i class="fa fa-check"></i><b>2.2</b> Markov Chain Monte Carlo Sampling</a></li>
<li class="chapter" data-level="2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#references"><i class="fa fa-check"></i><b>2.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>3</b> MCMC Diagnostics</a><ul>
<li class="chapter" data-level="3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#convergence-diagnostics"><i class="fa fa-check"></i><b>3.1</b> Convergence Diagnostics</a><ul>
<li class="chapter" data-level="3.1.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#potential-scale-reduction-hatr"><i class="fa fa-check"></i><b>3.1.1</b> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation-effective-sample-size-and-mcse"><i class="fa fa-check"></i><b>3.2</b> Autocorrelation, Effective Sample Size, and MCSE</a><ul>
<li class="chapter" data-level="3.2.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation"><i class="fa fa-check"></i><b>3.2.1</b> Autocorrelation</a></li>
<li class="chapter" data-level="3.2.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#monte-carlo-standard-error-mcse"><i class="fa fa-check"></i><b>3.2.2</b> Monte Carlo Standard Error (MCSE)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#hmc-specific-diagnostics"><i class="fa fa-check"></i><b>3.3</b> HMC Specific Diagnostics</a><ul>
<li class="chapter" data-level="3.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#divergent-transitions"><i class="fa fa-check"></i><b>3.3.1</b> Divergent transitions</a></li>
<li class="chapter" data-level="3.3.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#maximum-treedepth"><i class="fa fa-check"></i><b>3.3.2</b> Maximum Treedepth</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#references-1"><i class="fa fa-check"></i><b>3.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="posterior-inference.html"><a href="posterior-inference.html"><i class="fa fa-check"></i><b>4</b> Posterior Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#prerequisites"><i class="fa fa-check"></i><b>4.1</b> Prerequisites</a></li>
<li class="chapter" data-level="4.2" data-path="posterior-inference.html"><a href="posterior-inference.html#introduction"><i class="fa fa-check"></i><b>4.2</b> Introduction</a></li>
<li class="chapter" data-level="4.3" data-path="posterior-inference.html"><a href="posterior-inference.html#functions-of-the-posterior-distribution"><i class="fa fa-check"></i><b>4.3</b> Functions of the Posterior Distribution</a></li>
<li class="chapter" data-level="4.4" data-path="posterior-inference.html"><a href="posterior-inference.html#marginal-effects"><i class="fa fa-check"></i><b>4.4</b> Marginal Effects</a><ul>
<li class="chapter" data-level="4.4.1" data-path="posterior-inference.html"><a href="posterior-inference.html#example-marginal-effect-plot-for-x"><i class="fa fa-check"></i><b>4.4.1</b> Example: Marginal Effect Plot for X</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>5</b> Model Checking</a><ul>
<li class="chapter" data-level="5.1" data-path="model-checking.html"><a href="model-checking.html#why-check-models"><i class="fa fa-check"></i><b>5.1</b> Why check models?</a></li>
<li class="chapter" data-level="5.2" data-path="model-checking.html"><a href="model-checking.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2</b> Posterior Predictive Checks</a><ul>
<li class="chapter" data-level="5.2.1" data-path="model-checking.html"><a href="model-checking.html#bayesian-p-values"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian p-values</a></li>
<li class="chapter" data-level="5.2.2" data-path="model-checking.html"><a href="model-checking.html#test-quantities"><i class="fa fa-check"></i><b>5.2.2</b> Test quantities</a></li>
<li class="chapter" data-level="5.2.3" data-path="model-checking.html"><a href="model-checking.html#p-values-vs.u-values"><i class="fa fa-check"></i><b>5.2.3</b> p-values vs.Â u-values</a></li>
<li class="chapter" data-level="5.2.4" data-path="model-checking.html"><a href="model-checking.html#marginal-predictive-checks"><i class="fa fa-check"></i><b>5.2.4</b> Marginal predictive checks</a></li>
<li class="chapter" data-level="5.2.5" data-path="model-checking.html"><a href="model-checking.html#outliers"><i class="fa fa-check"></i><b>5.2.5</b> Outliers</a></li>
<li class="chapter" data-level="5.2.6" data-path="model-checking.html"><a href="model-checking.html#grapical-posterior-predictive-checks"><i class="fa fa-check"></i><b>5.2.6</b> Grapical Posterior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="model-checking.html"><a href="model-checking.html#sources"><i class="fa fa-check"></i><b>5.3</b> Sources</a></li>
</ul></li>
<li class="part"><span><b>III Models</b></span></li>
<li class="chapter" data-level="6" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Introduction to Stan and Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#prerequites"><i class="fa fa-check"></i><b>6.1</b> Prerequites</a></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#the-statistical-model"><i class="fa fa-check"></i><b>6.2</b> The Statistical Model</a><ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#sampling"><i class="fa fa-check"></i><b>6.2.1</b> Sampling</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-to-stan-and-linear-regression.html"><a href="introduction-to-stan-and-linear-regression.html#convergence-diagnostics-and-model-fit"><i class="fa fa-check"></i><b>6.2.2</b> Convergence Diagnostics and Model Fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html"><i class="fa fa-check"></i><b>7</b> Heteroskedasticity and Robust Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#prerequisites-1"><i class="fa fa-check"></i><b>7.1</b> Prerequisites</a></li>
<li class="chapter" data-level="7.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#linear-regression-with-student-t-distributed-errors"><i class="fa fa-check"></i><b>7.2</b> Linear Regression with Student t distributed errors</a><ul>
<li class="chapter" data-level="7.2.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#double-exponential-laplace-errors"><i class="fa fa-check"></i><b>7.2.1</b> Double Exponential (Laplace) Errors</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity"><i class="fa fa-check"></i><b>7.3</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="7.3.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#covariates"><i class="fa fa-check"></i><b>7.3.1</b> Covariates</a></li>
<li class="chapter" data-level="7.3.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#student-t-error"><i class="fa fa-check"></i><b>7.3.2</b> Student-t Error</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#references-2"><i class="fa fa-check"></i><b>7.4</b> References</a><ul>
<li class="chapter" data-level="7.4.1" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#robust-regression"><i class="fa fa-check"></i><b>7.4.1</b> Robust regression</a></li>
<li class="chapter" data-level="7.4.2" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#heteroskedasticity-1"><i class="fa fa-check"></i><b>7.4.2</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="7.4.3" data-path="heteroskedasticity-and-robust-regression.html"><a href="heteroskedasticity-and-robust-regression.html#qunatile-regression"><i class="fa fa-check"></i><b>7.4.3</b> Qunatile regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>8</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="8.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#generalized-linear-models-1"><i class="fa fa-check"></i><b>8.1</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="8.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#binomial"><i class="fa fa-check"></i><b>8.2</b> Binomial</a><ul>
<li class="chapter" data-level="8.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#example-vote-turnout"><i class="fa fa-check"></i><b>8.2.1</b> Example: Vote Turnout</a></li>
<li class="chapter" data-level="8.2.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#extensions"><i class="fa fa-check"></i><b>8.2.2</b> Extensions</a></li>
<li class="chapter" data-level="8.2.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#perfect-separation"><i class="fa fa-check"></i><b>8.2.3</b> Perfect Separation</a></li>
<li class="chapter" data-level="8.2.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-3"><i class="fa fa-check"></i><b>8.2.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#count-models"><i class="fa fa-check"></i><b>8.3</b> Count Models</a><ul>
<li class="chapter" data-level="8.3.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson"><i class="fa fa-check"></i><b>8.3.1</b> Poisson</a></li>
<li class="chapter" data-level="8.3.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-4"><i class="fa fa-check"></i><b>8.3.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#negative-binomial"><i class="fa fa-check"></i><b>8.4</b> Negative Binomial</a><ul>
<li class="chapter" data-level="8.4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial-categorical-models"><i class="fa fa-check"></i><b>8.4.1</b> Multinomial / Categorical Models</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#gamma-regression"><i class="fa fa-check"></i><b>8.5</b> Gamma Regression</a></li>
<li class="chapter" data-level="8.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#beta-regression"><i class="fa fa-check"></i><b>8.6</b> Beta Regression</a></li>
<li class="chapter" data-level="8.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#ordered-logistic"><i class="fa fa-check"></i><b>8.7</b> Ordered Logistic</a></li>
<li class="chapter" data-level="8.8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#references-5"><i class="fa fa-check"></i><b>8.8</b> References</a></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span></li>
<li class="chapter" data-level="9" data-path="notes.html"><a href="notes.html"><i class="fa fa-check"></i><b>9</b> Notes</a><ul>
<li class="chapter" data-level="9.1" data-path="notes.html"><a href="notes.html#syllabi"><i class="fa fa-check"></i><b>9.1</b> Syllabi</a></li>
<li class="chapter" data-level="9.2" data-path="notes.html"><a href="notes.html#textbooks"><i class="fa fa-check"></i><b>9.2</b> Textbooks</a></li>
<li class="chapter" data-level="9.3" data-path="notes.html"><a href="notes.html#topics"><i class="fa fa-check"></i><b>9.3</b> Topics</a><ul>
<li class="chapter" data-level="9.3.1" data-path="notes.html"><a href="notes.html#overviews"><i class="fa fa-check"></i><b>9.3.1</b> Overviews</a></li>
<li class="chapter" data-level="9.3.2" data-path="notes.html"><a href="notes.html#bayesian-philosophy"><i class="fa fa-check"></i><b>9.3.2</b> Bayesian Philosophy</a></li>
<li class="chapter" data-level="9.3.3" data-path="notes.html"><a href="notes.html#bayesian-frequentist-debates"><i class="fa fa-check"></i><b>9.3.3</b> Bayesian Frequentist Debates</a></li>
<li class="chapter" data-level="9.3.4" data-path="notes.html"><a href="notes.html#categorical"><i class="fa fa-check"></i><b>9.3.4</b> Categorical</a></li>
<li class="chapter" data-level="9.3.5" data-path="notes.html"><a href="notes.html#identifiability"><i class="fa fa-check"></i><b>9.3.5</b> Identifiability</a></li>
<li class="chapter" data-level="9.3.6" data-path="notes.html"><a href="notes.html#time-series"><i class="fa fa-check"></i><b>9.3.6</b> Time Series</a></li>
<li class="chapter" data-level="9.3.7" data-path="notes.html"><a href="notes.html#topic-models"><i class="fa fa-check"></i><b>9.3.7</b> Topic Models</a></li>
<li class="chapter" data-level="9.3.8" data-path="notes.html"><a href="notes.html#nonparametric-bayesian-methods"><i class="fa fa-check"></i><b>9.3.8</b> Nonparametric Bayesian Methods</a></li>
<li class="chapter" data-level="9.3.9" data-path="notes.html"><a href="notes.html#prior-elicitation"><i class="fa fa-check"></i><b>9.3.9</b> Prior Elicitation</a></li>
<li class="chapter" data-level="9.3.10" data-path="notes.html"><a href="notes.html#variable-selection"><i class="fa fa-check"></i><b>9.3.10</b> Variable Selection</a></li>
<li class="chapter" data-level="9.3.11" data-path="notes.html"><a href="notes.html#shrinkage"><i class="fa fa-check"></i><b>9.3.11</b> Shrinkage</a></li>
<li class="chapter" data-level="9.3.12" data-path="notes.html"><a href="notes.html#applied-bayes-rule"><i class="fa fa-check"></i><b>9.3.12</b> Applied Bayes Rule</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="notes.html"><a href="notes.html#computation-methods"><i class="fa fa-check"></i><b>9.4</b> Computation Methods</a><ul>
<li class="chapter" data-level="9.4.1" data-path="notes.html"><a href="notes.html#software"><i class="fa fa-check"></i><b>9.4.1</b> Software</a></li>
<li class="chapter" data-level="9.4.2" data-path="notes.html"><a href="notes.html#stan"><i class="fa fa-check"></i><b>9.4.2</b> Stan</a></li>
<li class="chapter" data-level="9.4.3" data-path="notes.html"><a href="notes.html#diagrams"><i class="fa fa-check"></i><b>9.4.3</b> Diagrams</a></li>
<li class="chapter" data-level="9.4.4" data-path="notes.html"><a href="notes.html#political-science-bayesian-works"><i class="fa fa-check"></i><b>9.4.4</b> Political Science Bayesian Works</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="notes.html"><a href="notes.html#model-checking-1"><i class="fa fa-check"></i><b>9.5</b> Model Checking</a></li>
<li class="chapter" data-level="9.6" data-path="notes.html"><a href="notes.html#general-applications-and-models"><i class="fa fa-check"></i><b>9.6</b> General Applications and Models</a><ul>
<li class="chapter" data-level="9.6.1" data-path="notes.html"><a href="notes.html#mixed-methods-and-qualitative-research"><i class="fa fa-check"></i><b>9.6.1</b> Mixed Methods and Qualitative Research</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="notes.html"><a href="notes.html#hierarchical-modeling"><i class="fa fa-check"></i><b>9.7</b> Hierarchical Modeling</a></li>
<li class="chapter" data-level="9.8" data-path="notes.html"><a href="notes.html#shrinkageregularization"><i class="fa fa-check"></i><b>9.8</b> Shrinkage/Regularization</a><ul>
<li class="chapter" data-level="9.8.1" data-path="notes.html"><a href="notes.html#examples"><i class="fa fa-check"></i><b>9.8.1</b> Examples</a></li>
<li class="chapter" data-level="9.8.2" data-path="notes.html"><a href="notes.html#latent-variable-models"><i class="fa fa-check"></i><b>9.8.2</b> Latent Variable Models</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="notes.html"><a href="notes.html#bayes-theorem-examples"><i class="fa fa-check"></i><b>9.9</b> Bayes Theorem Examples</a><ul>
<li class="chapter" data-level="9.9.1" data-path="notes.html"><a href="notes.html#miscallaneous"><i class="fa fa-check"></i><b>9.9.1</b> Miscallaneous</a></li>
<li class="chapter" data-level="9.9.2" data-path="notes.html"><a href="notes.html#german-tank-problem"><i class="fa fa-check"></i><b>9.9.2</b> German Tank Problem</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="notes.html"><a href="notes.html#good-turing-estimator"><i class="fa fa-check"></i><b>9.10</b> Good-Turing Estimator</a></li>
<li class="chapter" data-level="9.11" data-path="notes.html"><a href="notes.html#reproducibility"><i class="fa fa-check"></i><b>9.11</b> Reproducibility</a><ul>
<li class="chapter" data-level="9.11.1" data-path="notes.html"><a href="notes.html#uncategorized"><i class="fa fa-check"></i><b>9.11.1</b> Uncategorized</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="notes.html"><a href="notes.html#empirical-bayes"><i class="fa fa-check"></i><b>9.12</b> Empirical Bayes</a></li>
<li class="chapter" data-level="9.13" data-path="notes.html"><a href="notes.html#things-to-cover"><i class="fa fa-check"></i><b>9.13</b> Things to cover</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-6.html"><a href="references-6.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Updating: A Set of Bayesian Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\median}{median}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

% This follows BDA
\newcommand{\dunif}{\mathrm{U}}
\newcommand{\dnorm}{\mathrm{N}}
\newcommand{\dlnorm}{\mathrm{lognormal}}
\newcommand{\dmvnorm}{\mathrm{N}}
\newcommand{\dgamma}{\mathrm{Gamma}}
\newcommand{\dinvgamma}{\mathrm{Inv-Gamma}}
\newcommand{\dchisq}[1]{\chi^2_{#1}}
\newcommand{\dinvchisq}[1]{\mathrm{Inv-}\chi^2_{#1}}
\newcommand{\dexp}{\mathrm{Expon}}
\newcommand{\dlaplace}{\mathrm{Laplace}}
\newcommand{\dweibull}{\mathrm{Weibull}}
\newcommand{\dwishart}[1]{\mathrm{Wishart}_{#1}}
\newcommand{\dinvwishart}[1]{\mathrm{Inv-Wishart}_{#1}}
\newcommand{\dlkj}{\mathrm{LkjCorr}}
\newcommand{\dt}[1]{t_{#1}}
\newcommand{\dbeta}{\mathrm{Beta}}
\newcommand{\ddirichlet}{\mathrm{Dirichlet}}
\newcommand{\dlogistic}{\mathrm{Logistic}}
\newcommand{\dllogistic}{\mathrm{Log-logistic}}
\newcommand{\dpoisson}{\mathrm{Poisson}}
\newcommand{\dbinom}{\mathrm{Bin}}
\newcommand{\dmultinom}{\mathrm{Multinom}}
\newcommand{\dnegbin}{\mathrm{Neg-bin}}
\newcommand{\dbetabinom}{\mathrm{Beta-bin}}
\newcommand{\dcauchy}{\mathrm{Cauchy}}
\newcommand{\dhalfcauchy}{\mathrm{Cauchy}^{+}}

\DeclareMathOperator{\logistic}{\Logistic}

\newcommand{\R}{\mathfrak{R}}
\newcommand{\N}{\mathfrak{N}}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]
<div id="generalized-linear-models" class="section level1">
<h1><span class="header-section-number">8</span> Generalized Linear Models</h1>
<div id="generalized-linear-models-1" class="section level2">
<h2><span class="header-section-number">8.1</span> Generalized Linear Models</h2>
<p>Generalized linear models (GLMs) are a class of commonly used models.[^glm-r] In GLMs, the mean is specified as a function of a linear model of predictors, <span class="math display">\[
E(Y) = \mu = g^{-1}(\mat{X} \vec{\beta}) .
\]</span> GLMs are a generalization of linear regression from an unbounded continuous outcome variable to other types of data: binary, count, categorical, bounded continuous.</p>
<p>A GLM consists of three components:</p>
<ol style="list-style-type: decimal">
<li>A <em>probability distribution</em> (<em>family</em>) specifying the conditional distribution of the response variable. In GLMs, the distribution is in the exponential family: Normal, Binomial, Poisson, Categorical, Multinomial, Poisson, Beta.</li>
<li>A <em>linear predictor</em>, which is a linear function of the predictors, <span class="math display">\[
\eta = \mat{X} \vec{\beta} .
\]</span></li>
<li>A <em>link function</em> (<span class="math inline">\(g(.)\)</span>) which maps the expected value to the the linear predictor, <span class="math display">\[
g(\mu) = \eta .
\]</span> The link function is smooth and invertible, and the <em>inverse link function</em> or <em>mean function</em> maps the linear predictor to the mean, <span class="math display">\[
\mu = g^{-1}(\eta) .
\]</span> The link function (<span class="math inline">\(g\)</span>) and its inverse ($g^{-1}) translate <span class="math inline">\(\eta\)</span> from <span class="math inline">\((\-infty, +\infty)\)</span> to the proper range for the probability distribution and back again.</li>
</ol>
<p>These models are often estimated with MLE, as with the function <a href="https://www.rdocumentation.org/packages/stats/topics/glm">stats</a>. However, these are also easily estimated in a Bayesian setting.</p>
<p>See the help for <a href="https://www.rdocumentation.org/packages/stats/topics/family">stats</a> for common probability distributions, <a href="https://www.rdocumentation.org/packages/stats/topics/make.link">stats</a> for common links, and the <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">Wikipedia</a> page for a table of common GLMs. See the function <strong><a href="https://cran.r-project.org/package=VGAM">VGAM</a></strong> for even more examples of link functions and probability distributions.</p>
<table>
<caption>Common Link Functions and their inverses. Table derived from <span class="citation">Fox (2016, 419)</span>.</caption>
<thead>
<tr class="header">
<th align="left">Link</th>
<th align="left">Range of <span class="math inline">\(\mu_i\)</span></th>
<th align="left"><span class="math inline">\(\eta_i = g(\mu_i)\)</span></th>
<th align="left"><span class="math inline">\(\mu_i = g^{-1}(\eta)_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Identity</td>
<td align="left"><span class="math inline">\((-\infty, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\mu_i\)</span></td>
<td align="left"><span class="math inline">\(\eta_i\)</span></td>
</tr>
<tr class="even">
<td align="left">Inverse</td>
<td align="left"><span class="math inline">\((-\infty, \infty) \setminus \{0\}\)</span></td>
<td align="left"><span class="math inline">\(\mu_i^{-1}\)</span></td>
<td align="left"><span class="math inline">\(\eta_i^{-1}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Log</td>
<td align="left"><span class="math inline">\((0, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\log(\mu_i)\)</span></td>
<td align="left"><span class="math inline">\(\exp(\eta_i)\)</span></td>
</tr>
<tr class="even">
<td align="left">Inverse-square</td>
<td align="left"><span class="math inline">\((0, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\mu_i^{-2}\)</span></td>
<td align="left"><span class="math inline">\(\eta_i^{-1/2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Square-root</td>
<td align="left"><span class="math inline">\((0, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\sqrt{\mu_i}\)</span></td>
<td align="left"><span class="math inline">\(\eta_{i}^2\)</span></td>
</tr>
<tr class="even">
<td align="left">Logit</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\log(\mu / (1 - \mu_i)\)</span></td>
<td align="left"><span class="math inline">\(1 / (1 + \exp(-\eta_i))\)</span></td>
</tr>
<tr class="odd">
<td align="left">Probit</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\Phi^{-1}(\mu_i)\)</span></td>
<td align="left"><span class="math inline">\(\Phi(\eta_i)\)</span></td>
</tr>
<tr class="even">
<td align="left">Cauchit</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\tan(\pi (\mu_i - 1 / 2))\)</span></td>
<td align="left"><span class="math inline">\(\frac{1}{\pi} \arctan(\eta_i) + \frac{1}{2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Log-log</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(-\log(-log(\mu_i))\)</span></td>
<td align="left"><span class="math inline">\(\exp(-\exp(-\eta_i))\)</span></td>
</tr>
<tr class="even">
<td align="left">Complementary Log-log</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\log(-log(1 - \mu_i))\)</span></td>
<td align="left"><span class="math inline">\(1 - \exp(-\exp(\eta_i))\)</span></td>
</tr>
</tbody>
</table>
<table>
<caption>Common distributions and link functions. Table derived from <span class="citation">Fox (2016, 421)</span>, <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">Wikipedia</a>, and <a href="https://www.rdocumentation.org/packages/stats/topics/glm">stats</a>.</caption>
<thead>
<tr class="header">
<th align="left">Distribution</th>
<th align="left">Canonical Link</th>
<th align="left">Range of <span class="math inline">\(Y_i\)</span></th>
<th align="left">Other link functions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Normal</td>
<td align="left">Identity</td>
<td align="left">real: <span class="math inline">\((-\infty, +\infty)\)</span></td>
<td align="left">log, inverse</td>
</tr>
<tr class="even">
<td align="left">Exponential</td>
<td align="left">Inverse</td>
<td align="left">real: <span class="math inline">\((0, +\infty)\)</span></td>
<td align="left">identity, log</td>
</tr>
<tr class="odd">
<td align="left">Gamma</td>
<td align="left">Inverse</td>
<td align="left">real: <span class="math inline">\((0, +\infty)\)</span></td>
<td align="left">identity, log</td>
</tr>
<tr class="even">
<td align="left">Inverse-Gaussian</td>
<td align="left">Inverse-squared</td>
<td align="left">real: <span class="math inline">\((0, +\infty)\)</span></td>
<td align="left">inverse, identity, log</td>
</tr>
<tr class="odd">
<td align="left">Bernoulli</td>
<td align="left">Logit</td>
<td align="left">integer: <span class="math inline">\(\{0, 1\}\)</span></td>
<td align="left">probit, cauchit, log, cloglog</td>
</tr>
<tr class="even">
<td align="left">Binomial</td>
<td align="left">Logit</td>
<td align="left">integer: <span class="math inline">\(0, 1, \dots, n_i\)</span></td>
<td align="left">probit, cauchit, log, cloglog</td>
</tr>
<tr class="odd">
<td align="left">Poisson</td>
<td align="left">Log</td>
<td align="left">integer: <span class="math inline">\(0, 1, 2, \dots\)</span></td>
<td align="left">identity, sqrt</td>
</tr>
<tr class="even">
<td align="left">Categorical</td>
<td align="left">Logit</td>
<td align="left"><span class="math inline">\(0, 1, \dots, K\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Multinomial</td>
<td align="left">Logit</td>
<td align="left">K-vector of integers, <span class="math inline">\(\{x_1, \dots, x_K\}\)</span> s.t. <span class="math inline">\(\sum_k x_k = N\)</span>.</td>
<td align="left"></td>
</tr>
</tbody>
</table>
</div>
<div id="binomial" class="section level2">
<h2><span class="header-section-number">8.2</span> Binomial</h2>
<ul>
<li>The outcomes <span class="math inline">\(Y\)</span> are non-negative integers: <span class="math inline">\(0, 1, 2, \dots, n_i\)</span>.</li>
<li>The total number, <span class="math inline">\(n_i\)</span>, can vary by observation.</li>
<li>Special case: <span class="math inline">\(n_i = 1\)</span> for all <span class="math inline">\(i \in (1, 0)\)</span>: logit, probit models.</li>
</ul>
<p>The outcome is distributed Binomial, <span class="math display">\[
\begin{aligned}[t]
y_i \sim \dbinom\left(n_i, \pi \right)
\end{aligned}
\]</span></p>
<p>The parameter <span class="math inline">\(\pi \in [0, 1]\)</span> is modeled with a link function and a linear predictor.</p>
<p>There are several common link functions, but they all have to map <span class="math inline">\(R \to (0, 1)\)</span>.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p><strong>Logit:</strong> The logistic function, <span class="math display">\[
    \pi_i = \logistic(x_i\T \beta) = \frac{1}{1 + \exp(- x_i\T\beta)} .
    \]</span> Stan function <code>softmax</code>. - <strong>Probit:</strong> The CDF of the normal distribution. <span class="math display">\[
    \pi_i = \Phi(x_i\T \beta)
    \]</span> Stan function <code>normal_cdf</code>.</p>
<ul>
<li><strong>cauchit</strong>: The CDF of the Cauchy distribution. Stan function <code>cauchy_cdf</code>.</li>
<li><strong>cloglog</strong>: The inverse of the conditional log-log function (cloglog) is <span class="math display">\[
\pi_i = 1 - \exp(-\exp(x_i\T \beta)) .
\]</span> Stan function <code>inv_cloglog</code>.</li>
</ul>
<p>These link-functions are plotted below. Of these link functions, the probit has the narrowest tails (sensitivity to outliers), followed by the logit, and cauchit. The <a href="https://en.wikipedia.org/wiki/Generalized_linear_model#Complementary_log-log_.28cloglog.29">cloglog</a> function is different in that it is asymmetric; at zero its value is above 0.5, whereas the cauchit, logit, and probit links all equal 0.5 at 0,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">make.link</span>(<span class="st">&quot;cloglog&quot;</span>)<span class="op">$</span><span class="kw">linkinv</span>(<span class="dv">0</span>)
<span class="co">#&gt; [1] 0.632</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">map</span>(<span class="kw">c</span>(<span class="st">&quot;logit&quot;</span>, <span class="st">&quot;probit&quot;</span>, <span class="st">&quot;cauchit&quot;</span>, <span class="st">&quot;cloglog&quot;</span>),  make.link) <span class="op">%&gt;%</span>
<span class="kw">map_df</span>(
  <span class="cf">function</span>(link) {
    <span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length.out =</span> <span class="dv">101</span>),
           <span class="dt">y =</span> link<span class="op">$</span><span class="kw">linkinv</span>(x),
           <span class="dt">link_name =</span> link<span class="op">$</span>name)
  }
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">colour =</span> link_name)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>()</code></pre></div>
<p><img src="generalized-linear-models_files/figure-html/unnamed-chunk-3-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>In Stan, the Binomial distribution has two implementations:</p>
<ul>
<li><code>binomial_lpdf</code></li>
<li><code>binomial_logit_lpdf</code>: Poisson with a log link. This implementation is for numeric stability.</li>
</ul>
<div id="example-vote-turnout" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Example: Vote Turnout</h3>
<p>A general Stan model for estimating logit models is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod1</code></pre></div>
<pre>
  <code class="stan">// Logit Model
//
// y ~ Bernoulli(p)
// p = a + X B
// b0 \sim cauchy(0, 10)
// b \sim cauchy(0, 2.5)
data {
  // number of observations
  int N;
  // response
  // vectors are only real numbers
  // need to use an array
  int<lower = 0, upper = 1> y[N];
  // number of columns in the design matrix X
  int K;
  // design matrix X
  matrix [N, K] X;
}
parameters {
  // regression coefficient vector
  real b0;
  vector[K] b;
}
transformed parameters {
  vector<lower = 0.0, upper = 1.0>[N] p;
  p = inv_logit(b0 + X * b);
}
model {
  // priors
  b0 ~ cauchy(0.0, 10.0);
  b ~ cauchy(0.0, 2.5);
  // likelihood
  y ~ binomial(1, p);
}
generated quantities {
  // simulate data from the posterior
  vector[N] y_rep;
  // log-likelihood posterior
  vector[N] log_lik;
  for (i in 1:N) {
    y_rep[i] = binomial_rng(1, p[i]);
    log_lik[i] = binomial_lpmf(y[i] | 1, p[i]);
  }
}</code>
</pre>
<p>This uses the default semi-informative priors in Gelman 2008 â¦</p>
<p>Estimate a model of vote turnout in the 1992 from the American National Election Survey (ANES). The data is from <a href="https://www.rdocumentation.org/packages/Zelig/topics/turnout">Zelig</a>.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;turnout&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;Zelig&quot;</span>)</code></pre></div>
<p>Vote choice (<code>vote</code>) is modeled as a function of age, income, and race.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_formula &lt;-<span class="st"> </span>vote <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>educate <span class="op">+</span><span class="st"> </span>race <span class="op">-</span><span class="st"> </span><span class="dv">1</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod1_data &lt;-<span class="st"> </span><span class="kw">lm_preprocess</span>(mod_formula, <span class="dt">data =</span> turnout)</code></pre></div>
</div>
<div id="extensions" class="section level3">
<h3><span class="header-section-number">8.2.2</span> Extensions</h3>
<ul>
<li>Separation:</li>
<li>Rare events:</li>
</ul>
</div>
<div id="perfect-separation" class="section level3">
<h3><span class="header-section-number">8.2.3</span> Perfect Separation</h3>
<ul>
<li><span class="citation">Firth (1993)</span> proposes a penalized likelihood approach using the Jeffreys invariant prior</li>
<li><span class="citation">King and Zeng (2001a)</span> and <span class="citation">King and Zeng (2001b)</span> apply an approach similar to the penalized likelihood approach for the similar problem of rare events</li>
<li><span class="citation">Zorn (2005)</span> also suggests using the Firth logistic regression to avoid perfect separation</li>
<li><span class="citation">Rainey (2016a)</span> shows that Cauchy(0, 2.5) priors can be used</li>
<li><span class="citation">Greenland and Mansournia (2015)</span> provide another default prior to for binomial models: log F(1,1) and log F(2, 2) priors. These have the nice property that they are interpretable as additional observations.</li>
</ul>
</div>
<div id="references-3" class="section level3">
<h3><span class="header-section-number">8.2.4</span> References</h3>
<ul>
<li><span class="citation">Stan Development Team (2016 Sec. 8.5)</span></li>
<li><span class="citation">McElreath (2016 Ch 10)</span></li>
<li><span class="citation">Gelman and Hill (2007)</span> [Ch. 5; Sec 6.4-6.5]</li>
<li><span class="citation">Fox (2016 Ch. 14)</span></li>
<li><span class="citation">Gelman et al. (2013 Ch. 16)</span></li>
</ul>
</div>
</div>
<div id="count-models" class="section level2">
<h2><span class="header-section-number">8.3</span> Count Models</h2>
<div id="poisson" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Poisson</h3>
<p>The Poisson model is used for unbounded count data, <span class="math display">\[
Y = 0, 1, \dots, \infty
\]</span> The outcome is modeled as a Poisson distribution <span class="math display">\[
y_i \sim \dpois(\lambda_i)
\]</span> with positive mean parameter <span class="math inline">\(\lambda_i \in (0, \infty)\)</span>. Since <span class="math inline">\(\lambda_i\)</span> has to be positive, the most common link function is the log, <span class="math display">\[
\log(\lambda_i) = \exp(\vec{x}_i&#39; \vec{\beta})
\]</span> which has the inverse, <span class="math display">\[
\lambda_i = \log(\vec{x}_i \vec{\beta})
\]</span></p>
<p>In Stan, the Poisson distribution has two implementations:</p>
<ul>
<li><code>poisson_lpdf</code></li>
<li><code>poisson_log_lpdf</code>: Poisson with a log link. This is for numeric stability.</li>
</ul>
<p>Also, <code>rstanarm</code> supports the <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html">Poisson</a>.</p>
</div>
<div id="references-4" class="section level3">
<h3><span class="header-section-number">8.3.2</span> References</h3>
<ul>
<li><span class="citation">Gelman and Hill (2007, 109â16)</span></li>
<li><span class="citation">McElreath (2016 Ch 10)</span></li>
<li><span class="citation">Fox (2016 Ch. 14)</span></li>
<li><span class="citation">Gelman et al. (2013 Ch. 16)</span></li>
</ul>
</div>
</div>
<div id="negative-binomial" class="section level2">
<h2><span class="header-section-number">8.4</span> Negative Binomial</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">Negative Binomial</a> model is also used for unbounded count data, <span class="math display">\[
Y = 0, 1, \dots, \infty
\]</span> The Poisson distribution has the restriction that the mean is equal to the variance, <span class="math inline">\(\E(X) = \Var(X) = \lambda\)</span>. The Negative Binomial distribution has an additional parameter that allows the variance to vary (though it is always larger than the mean).</p>
<p>The outcome is modeled as a negative binomial distribution, <span class="math display">\[
y_i \sim \dnbinom(\alpha_i, \beta)
\]</span> with shape <span class="math inline">\(\alpha \in \R^{+}\)</span> and inverse scale <span class="math inline">\(\beta \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \alpha_i / \beta\)</span> and <span class="math inline">\(\Var(Y) = \frac{\alpha_i}{\beta^2}(\beta + 1)\)</span>. Then the mean can be modeled and transformed to the <span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\alpha_i &amp;= \mu_i / \beta
\end{aligned}
\]</span></p>
<p><strong>Important</strong> The negative binomial distribution has many different parameterizations. An alternative parameterization of the negative binomial uses the mean and a over-dispersion parameter. <span class="math display">\[
y_i \sim \dnbinomalt(\mu_i, \phi)
\]</span> with location parameter <span class="math inline">\(\mu \in \R^{+}\)</span> and over-dispersion parameter <span class="math inline">\(\phi \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \mu_i\)</span> and <span class="math inline">\(\Var(Y) = \mu_i + \frac{\mu_i^2}{\phi}\)</span>. Then the mean can be modeled and transformed to the <span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\end{aligned}
\]</span></p>
<p>In Stan, there are multiple parameterizations of the</p>
<ul>
<li><code>neg_binomial_lpdf(y | alpha, beta)</code>with shape parameter <code>alpha</code> and inverse scale parameter <code>beta</code>.</li>
<li><code>neg_binomial_2_lpdf(y | mu, phi)</code> with mean <code>mu</code> and over-dispersion parameter <code>phi</code>.</li>
<li><code>neg_binomial_2_log_lpdf(y | eta, phi)</code> with log-mean <code>eta</code> and over-dispersion parameter <code>phi</code></li>
</ul>
<p>Also, <code>rstanarm</code> supports Poisson and <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html">negative binomial models</a>.</p>
<ul>
<li><span class="citation">Gelman et al. (2013 Ch 16)</span></li>
</ul>
<div id="multinomial-categorical-models" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Multinomial / Categorical Models</h3>
</div>
</div>
<div id="gamma-regression" class="section level2">
<h2><span class="header-section-number">8.5</span> Gamma Regression</h2>
<p>The response variable is continuous and positive. In gamma regression, the coefficient of variation is constant rather than the variance. <span class="math display">\[
y_i \sim \dgamma(\alpha_i, \beta)
\]</span> and <span class="math display">\[
\begin{aligned}[t]
\alpha_i &amp;= \mu_i / \beta \\
\mu_i &amp;= \vec{x}_i \vec{\gamma}
\end{aligned}
\]</span></p>
<p>In Stan,</p>
<ul>
<li><code>gamma(y | alpha, beta)</code> with shape parameter <span class="math inline">\(\alpha &gt; 0\)</span> and inverse scale parameter <span class="math inline">\(\beta &gt; 0\)</span>. Then <span class="math inline">\(\E(Y) = \alpha / \beta\)</span> and <span class="math inline">\(\Var(Y) = \alpha / \beta^2\)</span>.</li>
</ul>
</div>
<div id="beta-regression" class="section level2">
<h2><span class="header-section-number">8.6</span> Beta Regression</h2>
<p>This is for a response variable that is a proportion, <span class="math inline">\(y_i \in (0, 1)\)</span>, <span class="math display">\[
y_i \sim \dbeta(\alpha_i, \beta_i)
\]</span> and <span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= g^{-1}(\vec{x}_i&#39; \vec{\gamma}) \\
\alpha_i &amp;= \mu_i \phi \\
\beta_i &amp;= (1 - \mu_i) \phi 
\end{aligned}
\]</span> Additionally, the <span class="math inline">\(\phi\)</span> parameter could also be modeled.</p>
<p>In Stan:</p>
<ul>
<li><code>beta(y | alpha, beta)</code> with positive prior successes plus one, <span class="math inline">\(\alpha &gt; 0\)</span>, and negative prior failures plus one, <span class="math inline">\(\beta &gt; 0\)</span>. Then <span class="math inline">\(\E(Y) = \alpha / (\alpha + \beta)\)</span> and <span class="math inline">\(\Var(Y) = \alpha\beta / ((\alpha + \beta)^2 (\alpha + \beta + 1))\)</span>.</li>
</ul>
<p><strong>rstanarm</strong> function <a href="https://www.rdocumentation.org/packages/rstasnarm/topics/stan_betareg">rstasnarm</a></p>
<p>See:</p>
<ul>
<li><span class="citation">Ferrari and Cribari-Neto (2004)</span>, <span class="citation">Cribari-Neto and Zeileis (2010)</span>, and <span class="citation">GrÃ¼n, Kosmidis, and Zeileis (2012)</span> on beta regression.</li>
<li><strong>rstanarm</strong> documentation <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/betareg.html">Modeling Rates/Proportions using Beta Regression with rstanarm</a></li>
</ul>
</div>
<div id="ordered-logistic" class="section level2">
<h2><span class="header-section-number">8.7</span> Ordered Logistic</h2>
<p><strong>rstanarm</strong> function <a href="https://www.rdocumentation.org/packages/rstasnarm/topics/stan_polr">rstasnarm</a></p>
<ul>
<li><span class="citation">Gelman and Hill (2007 Ch 6.5)</span></li>
<li>*rstanarm** vignette <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/polr.html">Estimating Ordinal Regression Models with rstanarm</a></li>
</ul>
</div>
<div id="references-5" class="section level2">
<h2><span class="header-section-number">8.8</span> References</h2>
<p>Texts:</p>
<ul>
<li><span class="citation">Gelman et al. (2013 Ch 16)</span></li>
<li><span class="citation">Gelman and Hill (2007 Ch. 5-6)</span></li>
<li><span class="citation">McElreath (2016 Ch. 9)</span></li>
<li><span class="citation">King (1998)</span> discusses MLE estimation of many common GLM models</li>
<li>Many econometrics/statistics textbooks, e.g. <span class="citation">Fox (2016)</span>, discuss GLMs. Though they are not derived from a Bayesian context, they can easily transferred.</li>
</ul>

</div>
</div>



</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>Since a CDF maps reals to <span class="math inline">\((0, 1)\)</span>, any CDF can be used as a link function.<a href="generalized-linear-models.html#fnref4">â©</a></p></li>
<li id="fn5"><p>Example from <a href="http://docs.zeligproject.org/en/latest/zelig-logit.html">Zelig-logit</a>.<a href="generalized-linear-models.html#fnref5">â©</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="heteroskedasticity-and-robust-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="notes.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/bayesian_notes/edit/master/generalized-linear-models.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
